id,author,created_at,last_modified,downloads,likes,tags,description,url,languages,tasks,size_categories
google/svq,google,2025-05-12 19:53:36+00:00,2025-07-07 19:09:55+00:00,542,18,"['task_categories:question-answering', 'task_categories:automatic-speech-recognition', 'language:ar', 'language:bn', 'language:en', 'language:fi', 'language:gu', 'language:hi', 'language:id', 'language:ja', 'language:kn', 'language:ko', 'language:ml', 'language:mr', 'language:ru', 'language:sw', 'language:ta', 'language:te', 'language:ur', 'license:cc-by-4.0', 'size_categories:100K<n<1M', 'region:us']","
	
		
		Simple Voice Questions
	

Simple Voice Questions (SVQ) is a set of short audio questions recorded in 26 locales across 17 languages under multiple audio conditions.

	
		
		Data Collection
	

Speakers were presented with recording instructions specifying the recording environment and text query to be recorded.
They recorded using their own phones or tablets under four conditions:

clean: Record in quiet environment
background speech noise: Record while audio from sources like podcasts… See the full description on the dataset page: https://huggingface.co/datasets/google/svq.",https://huggingface.co/datasets/google/svq,"['ar', 'bn', 'en', 'fi', 'gu', 'hi', 'id', 'ja', 'kn', 'ko', 'ml', 'mr', 'ru', 'sw', 'ta', 'te', 'ur']","['question-answering', 'automatic-speech-recognition']",['100K<n<1M']
amphion/Emilia-Dataset,amphion,2024-08-23 08:25:08+00:00,2025-02-28 05:41:37+00:00,68505,385,"['task_categories:text-to-speech', 'task_categories:automatic-speech-recognition', 'language:zh', 'language:en', 'language:ja', 'language:fr', 'language:de', 'language:ko', 'license:cc-by-4.0', 'size_categories:10M<n<100M', 'format:webdataset', 'modality:audio', 'modality:text', 'library:datasets', 'library:webdataset', 'library:mlcroissant', 'arxiv:2407.05361', 'arxiv:2501.15907', 'region:us']","
	
		
		Emilia: An Extensive, Multilingual, and Diverse Speech Dataset for Large-Scale Speech Generation
	


This is the official repository 👑 for the Emilia dataset and the source code for the Emilia-Pipe speech data preprocessing pipeline. 



	
		
		News 🔥
	


2025/02/26: The Emilia-Large dataset, featuring over 200,000 hours of data, is now available!!! Emilia-Large combines the original 101k-hour Emilia dataset (licensed under CC BY-NC 4.0) with the brand-new 114k-hour Emilia-YODAS… See the full description on the dataset page: https://huggingface.co/datasets/amphion/Emilia-Dataset.",https://huggingface.co/datasets/amphion/Emilia-Dataset,"['zh', 'en', 'ja', 'fr', 'de', 'ko']","['text-to-speech', 'automatic-speech-recognition']",['10M<n<100M']
ronantakizawa/japanese-text-difficulty,ronantakizawa,2025-10-02 03:03:18+00:00,2025-10-05 05:08:18+00:00,79,4,"['task_categories:text-classification', 'language:ja', 'license:mit', 'size_categories:1K<n<10K', 'format:parquet', 'modality:tabular', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us', 'japanese', 'text-difficulty', 'language-learning', 'linguistics', 'aozora-bunko', 'educational', 'curriculum-design']","
	
		
		Aozora Text Difficulty Dataset
	

This dataset contains Japanese literary texts from the Aozora Bunko digital library, enhanced with jReadability-based difficulty analysis for Japanese language learning and curriculum development.

	
		
		Dataset Overview
	


Source: Aozora Bunko (青空文庫) - Japan's premier digital library of public domain literature
Enhancement: jReadability-based difficulty scoring using research-backed Japanese readability models
Primary Methodology: jReadability - A… See the full description on the dataset page: https://huggingface.co/datasets/ronantakizawa/japanese-text-difficulty.",https://huggingface.co/datasets/ronantakizawa/japanese-text-difficulty,['ja'],['text-classification'],['1K<n<10K']
Aratako/LiquidAI-Hackathon-Tokyo-CPT-Data,Aratako,2025-10-12 01:30:20+00:00,2025-10-12 04:14:09+00:00,10,3,"['task_categories:automatic-speech-recognition', 'task_categories:text-to-speech', 'task_categories:audio-to-audio', 'language:ja', 'language:en', 'license:cc-by-nc-4.0', 'size_categories:1M<n<10M', 'format:parquet', 'library:datasets', 'library:dask', 'library:mlcroissant', 'library:polars', 'region:us']","
	
		
		LiquidAI-Hackathon-Tokyo-CPT-Data
	

Liquid AI Hackathon Tokyoで作成したモデルのCPTに利用したデータセットです。
",https://huggingface.co/datasets/Aratako/LiquidAI-Hackathon-Tokyo-CPT-Data,"['ja', 'en']","['automatic-speech-recognition', 'text-to-speech', 'audio-to-audio']",['1M<n<10M']
speechbrain/common_language,speechbrain,2022-03-02 23:29:22+00:00,2023-06-12 13:29:01+00:00,1139,38,"['task_categories:audio-classification', 'task_ids:speaker-identification', 'annotations_creators:crowdsourced', 'language_creators:crowdsourced', 'multilinguality:multilingual', 'source_datasets:extended|common_voice', 'language:ar', 'language:br', 'language:ca', 'language:cnh', 'language:cs', 'language:cv', 'language:cy', 'language:de', 'language:dv', 'language:el', 'language:en', 'language:eo', 'language:es', 'language:et', 'language:eu', 'language:fa', 'language:fr', 'language:fy', 'language:ia', 'language:id', 'language:it', 'language:ja', 'language:ka', 'language:kab', 'language:ky', 'language:lv', 'language:mn', 'language:mt', 'language:nl', 'language:pl', 'language:pt', 'language:rm', 'language:ro', 'language:ru', 'language:rw', 'language:sah', 'language:sl', 'language:sv', 'language:ta', 'language:tr', 'language:tt', 'language:uk', 'language:zh', 'license:cc-by-4.0', 'size_categories:100K<n<1M', 'region:us']","This dataset is composed of speech recordings from languages that were carefully selected from the CommonVoice database.
The total duration of audio recordings is 45.1 hours (i.e., 1 hour of material for each language).
The dataset has been extracted from CommonVoice to train language-id systems.",https://huggingface.co/datasets/speechbrain/common_language,"['ar', 'br', 'ca', 'cnh', 'cs', 'cv', 'cy', 'de', 'dv', 'el', 'en', 'eo', 'es', 'et', 'eu', 'fa', 'fr', 'fy', 'ia', 'id', 'it', 'ja', 'ka', 'kab', 'ky', 'lv', 'mn', 'mt', 'nl', 'pl', 'pt', 'rm', 'ro', 'ru', 'rw', 'sah', 'sl', 'sv', 'ta', 'tr', 'tt', 'uk', 'zh']",['audio-classification'],['100K<n<1M']
NilanE/ParallelFiction-Ja_En-100k,NilanE,2024-03-25 23:41:17+00:00,2024-06-02 18:03:38+00:00,109,73,"['task_categories:translation', 'language:ja', 'language:en', 'license:apache-2.0', 'size_categories:100K<n<1M', 'format:json', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","
	
		
		Dataset details:
	

Each entry in this dataset is a sentence-aligned Japanese web novel chapter and English fan translation.
The intended use-case is for document translation tasks.

	
		
		Dataset format:
	

{
    'src': 'JAPANESE WEB NOVEL CHAPTER',
    'trg': 'CORRESPONDING ENGLISH TRANSLATION',
    'meta': {
        'general': {
            'series_title_eng': 'ENGLISH SERIES TITLE',
            'series_title_jap': 'JAPANESE SERIES TITLE',
            'sentence_alignment_score':… See the full description on the dataset page: https://huggingface.co/datasets/NilanE/ParallelFiction-Ja_En-100k.",https://huggingface.co/datasets/NilanE/ParallelFiction-Ja_En-100k,"['ja', 'en']",['translation'],['100K<n<1M']
llm-jp/ja-vg-vqa-conversation,llm-jp,2024-10-22 06:14:02+00:00,2024-11-19 10:55:53+00:00,36,3,"['task_categories:visual-question-answering', 'language:ja', 'size_categories:10K<n<100K', 'format:json', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","
	
		
		Dataset Card for ja-vg-vqa-conversation
	


	
		
		Dataset details
	

This dataset consists of multiple QA pairs from Japanese Visual Genome VQA dataset that have been converted into multi-turn conversations.
The prompt 語句または短い文で答えてください。 has been appended to the questions in the first turn.
We excluded the samples from the JA-VG-VQA-500 dataset, resulting in a total of 98,708 samples.

	
		
	
	
		License
	

Creative Commons Attribution 4.0 License
",https://huggingface.co/datasets/llm-jp/ja-vg-vqa-conversation,['ja'],['visual-question-answering'],['10K<n<100K']
DataPilot/Zero_SFT_Ja_v3.5,DataPilot,2025-05-24 07:34:41+00:00,2025-06-02 14:07:45+00:00,20,3,"['task_categories:question-answering', 'language:ja', 'license:odc-by', 'size_categories:100K<n<1M', 'format:json', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'arxiv:2502.01697', 'region:us']","
	
		
		📦 Zero_SFT_Ja_v3.5
	


	
		
		🧭 イントロダクション
	

Zero_SFT_Ja_v3.5 は、Base-Refine（BARE）手法により構築された、108,000 件の日本語指示応答データセットです。以下の複数モデルを段階的に組み合わせることで、高い多様性と品質を両立しています：

🧠 質問生成: Sarashina2-70B
🎛 多様性フィルタリング: intfloat/multilingual-e5-large
🔐 内容フィルタリング: Microsoft Phi-4
📝 回答生成: Qwen3-235B-A22B



	
		
		🔍 データセットの特徴
	


	
		
🧩 特性
🔢 値


		
件数
108,000


言語
日本語


生成方式
BARE（二段階合成 + 多段階フィルタリング）


Q&A 生成モデル
Sarashina2-70B（質問）、Qwen3-235B-A22B（回答）


フィルタリング
Multilingual-E5-Large（類似度）、Phi-4（内容安全）… See the full description on the dataset page: https://huggingface.co/datasets/DataPilot/Zero_SFT_Ja_v3.5.",https://huggingface.co/datasets/DataPilot/Zero_SFT_Ja_v3.5,['ja'],['question-answering'],['100K<n<1M']
kokuren/inmQA_ja_9.315k,kokuren,2025-10-12 04:53:55+00:00,2025-10-12 04:59:37+00:00,4,2,"['task_categories:question-answering', 'language:ja', 'license:apache-2.0', 'size_categories:1K<n<10K', 'format:json', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","くさい子
",https://huggingface.co/datasets/kokuren/inmQA_ja_9.315k,['ja'],['question-answering'],['1K<n<10K']
IWSLT/iwslt2017,IWSLT,2022-03-02 23:29:22+00:00,2023-04-05 10:07:51+00:00,5540,37,"['task_categories:translation', 'annotations_creators:crowdsourced', 'language_creators:expert-generated', 'multilinguality:translation', 'source_datasets:original', 'language:ar', 'language:de', 'language:en', 'language:fr', 'language:it', 'language:ja', 'language:ko', 'language:nl', 'language:ro', 'language:zh', 'license:cc-by-nc-nd-4.0', 'size_categories:1M<n<10M', 'region:us']","The IWSLT 2017 Multilingual Task addresses text translation, including zero-shot translation, with a single MT system across all directions including English, German, Dutch, Italian and Romanian. As unofficial task, conventional bilingual text translation is offered between English and Arabic, French, Japanese, Chinese, German and Korean.",https://huggingface.co/datasets/IWSLT/iwslt2017,"['ar', 'de', 'en', 'fr', 'it', 'ja', 'ko', 'nl', 'ro', 'zh']",['translation'],['1M<n<10M']
papluca/language-identification,papluca,2022-03-02 23:29:22+00:00,2022-07-15 10:11:23+00:00,1441,57,"['task_categories:text-classification', 'task_ids:multi-class-classification', 'multilinguality:multilingual', 'source_datasets:extended|amazon_reviews_multi', 'source_datasets:extended|xnli', 'source_datasets:extended|stsb_multi_mt', 'language:ar', 'language:bg', 'language:de', 'language:el', 'language:en', 'language:es', 'language:fr', 'language:hi', 'language:it', 'language:ja', 'language:nl', 'language:pl', 'language:pt', 'language:ru', 'language:sw', 'language:th', 'language:tr', 'language:ur', 'language:vi', 'language:zh', 'size_categories:10K<n<100K', 'format:csv', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","
	
		
		Dataset Card for Language Identification dataset
	


	
		
		Dataset Summary
	

The Language Identification dataset is a collection of 90k samples consisting of text passages and corresponding language label. 
This dataset was created by collecting data from 3 sources: Multilingual Amazon Reviews Corpus, XNLI, and STSb Multi MT.

	
		
	
	
		Supported Tasks and Leaderboards
	

The dataset can be used to train a model for language identification, which is a multi-class text classification… See the full description on the dataset page: https://huggingface.co/datasets/papluca/language-identification.",https://huggingface.co/datasets/papluca/language-identification,"['ar', 'bg', 'de', 'el', 'en', 'es', 'fr', 'hi', 'it', 'ja', 'nl', 'pl', 'pt', 'ru', 'sw', 'th', 'tr', 'ur', 'vi', 'zh']",['text-classification'],['10K<n<100K']
OpenAssistant/oasst1,OpenAssistant,2023-04-13 15:48:16+00:00,2023-05-02 13:21:21+00:00,7652,1437,"['language:en', 'language:es', 'language:ru', 'language:de', 'language:pl', 'language:th', 'language:vi', 'language:sv', 'language:bn', 'language:da', 'language:he', 'language:it', 'language:fa', 'language:sk', 'language:id', 'language:nb', 'language:el', 'language:nl', 'language:hu', 'language:eu', 'language:zh', 'language:eo', 'language:ja', 'language:ca', 'language:cs', 'language:bg', 'language:fi', 'language:pt', 'language:tr', 'language:ro', 'language:ar', 'language:uk', 'language:gl', 'language:fr', 'language:ko', 'license:apache-2.0', 'size_categories:10K<n<100K', 'format:parquet', 'modality:tabular', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'arxiv:2304.07327', 'region:us', 'human-feedback']","
	
		
		OpenAssistant Conversations Dataset (OASST1)
	


	
		
		Dataset Summary
	

In an effort to democratize research on large-scale alignment, we release OpenAssistant 
Conversations (OASST1), a human-generated, human-annotated assistant-style conversation 
corpus consisting of 161,443 messages in 35 different languages, annotated with 461,292 
quality ratings, resulting in over 10,000 fully annotated conversation trees. The corpus 
is a product of a worldwide crowd-sourcing effort… See the full description on the dataset page: https://huggingface.co/datasets/OpenAssistant/oasst1.",https://huggingface.co/datasets/OpenAssistant/oasst1,"['en', 'es', 'ru', 'de', 'pl', 'th', 'vi', 'sv', 'bn', 'da', 'he', 'it', 'fa', 'sk', 'id', 'nb', 'el', 'nl', 'hu', 'eu', 'zh', 'eo', 'ja', 'ca', 'cs', 'bg', 'fi', 'pt', 'tr', 'ro', 'ar', 'uk', 'gl', 'fr', 'ko']",[],['10K<n<100K']
FredZhang7/toxi-text-3M,FredZhang7,2023-06-28 23:28:34+00:00,2025-04-27 19:07:53+00:00,991,28,"['task_categories:text-classification', 'task_categories:zero-shot-classification', 'language:ar', 'language:es', 'language:pa', 'language:th', 'language:et', 'language:fr', 'language:fi', 'language:hu', 'language:lt', 'language:ur', 'language:so', 'language:pl', 'language:el', 'language:mr', 'language:sk', 'language:gu', 'language:he', 'language:af', 'language:te', 'language:ro', 'language:lv', 'language:sv', 'language:ne', 'language:kn', 'language:it', 'language:mk', 'language:cs', 'language:en', 'language:de', 'language:da', 'language:ta', 'language:bn', 'language:pt', 'language:sq', 'language:tl', 'language:uk', 'language:bg', 'language:ca', 'language:sw', 'language:hi', 'language:zh', 'language:ja', 'language:hr', 'language:ru', 'language:vi', 'language:id', 'language:sl', 'language:cy', 'language:ko', 'language:nl', 'language:ml', 'language:tr', 'language:fa', 'language:no', 'language:multilingual', 'license:apache-2.0', 'size_categories:1M<n<10M', 'format:csv', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us', 'nlp', 'moderation']","This is a large multilingual toxicity dataset with 3M rows of text data from 55 natural languages, all of which are written/sent by humans, not machine translation models.
The preprocessed training data alone consists of 2,880,667 rows of comments, tweets, and messages. Among these rows, 416,529 are classified as toxic, while the remaining 2,463,773 are considered neutral. Below is a table to illustrate the data composition:

	
		

Toxic
Neutral
Total


		
multilingual-train-deduplicated.csv… See the full description on the dataset page: https://huggingface.co/datasets/FredZhang7/toxi-text-3M.",https://huggingface.co/datasets/FredZhang7/toxi-text-3M,"['ar', 'es', 'pa', 'th', 'et', 'fr', 'fi', 'hu', 'lt', 'ur', 'so', 'pl', 'el', 'mr', 'sk', 'gu', 'he', 'af', 'te', 'ro', 'lv', 'sv', 'ne', 'kn', 'it', 'mk', 'cs', 'en', 'de', 'da', 'ta', 'bn', 'pt', 'sq', 'tl', 'uk', 'bg', 'ca', 'sw', 'hi', 'zh', 'ja', 'hr', 'ru', 'vi', 'id', 'sl', 'cy', 'ko', 'nl', 'ml', 'tr', 'fa', 'no', 'multilingual']","['text-classification', 'zero-shot-classification']",['1M<n<10M']
izumi-lab/mc4-ja-filter-ja-normal,izumi-lab,2023-07-16 13:46:25+00:00,2023-07-29 03:11:41+00:00,654,5,"['language:ja', 'license:odc-by', 'size_categories:10M<n<100M', 'format:parquet', 'modality:text', 'library:datasets', 'library:dask', 'library:mlcroissant', 'library:polars', 'region:us']","
	
		
		Dataset Card for ""mc4-ja-filter-ja-normal""
	

More Information needed
",https://huggingface.co/datasets/izumi-lab/mc4-ja-filter-ja-normal,['ja'],[],['10M<n<100M']
facebook/belebele,facebook,2023-09-01 18:27:13+00:00,2024-08-12 22:18:08+00:00,17712,116,"['task_categories:question-answering', 'task_categories:zero-shot-classification', 'task_categories:text-classification', 'task_categories:multiple-choice', 'language:af', 'language:am', 'language:ar', 'language:az', 'language:as', 'language:bm', 'language:bn', 'language:bo', 'language:bg', 'language:ca', 'language:cs', 'language:ku', 'language:da', 'language:de', 'language:el', 'language:en', 'language:es', 'language:et', 'language:eu', 'language:fi', 'language:fr', 'language:ff', 'language:om', 'language:gu', 'language:gn', 'language:ht', 'language:ha', 'language:he', 'language:hi', 'language:hr', 'language:hu', 'language:hy', 'language:ig', 'language:id', 'language:it', 'language:is', 'language:jv', 'language:ja', 'language:ka', 'language:kn', 'language:kk', 'language:mn', 'language:km', 'language:rw', 'language:ky', 'language:ko', 'language:lo', 'language:ln', 'language:lt', 'language:lg', 'language:lv', 'language:ml', 'language:mr', 'language:mk', 'language:mt', 'language:mi', 'language:my', 'language:nl', 'language:no', 'language:ne', 'language:ny', 'language:or', 'language:pa', 'language:ps', 'language:fa', 'language:mg', 'language:pl', 'language:pt', 'language:ro', 'language:ru', 'language:sn', 'language:si', 'language:sl', 'language:sv', 'language:sk', 'language:sd', 'language:sw', 'language:ta', 'language:te', 'language:tg', 'language:tl', 'language:th', 'language:ti', 'language:tn', 'language:ts', 'language:tr', 'language:uk', 'language:ur', 'language:uz', 'language:vi', 'language:wo', 'language:xh', 'language:yo', 'language:zh', 'language:ms', 'language:zu', 'license:cc-by-sa-4.0', 'size_categories:100K<n<1M', 'format:json', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","
	
		
		The Belebele Benchmark for Massively Multilingual NLU Evaluation
	

Belebele is a multiple-choice machine reading comprehension (MRC) dataset spanning 122 language variants. This dataset enables the evaluation of mono- and multi-lingual models in high-, medium-, and low-resource languages. Each question has four multiple-choice answers and is linked to a short passage from the FLORES-200 dataset. The human annotation procedure was carefully curated to create questions that discriminate… See the full description on the dataset page: https://huggingface.co/datasets/facebook/belebele.",https://huggingface.co/datasets/facebook/belebele,"['af', 'am', 'ar', 'az', 'as', 'bm', 'bn', 'bo', 'bg', 'ca', 'cs', 'ku', 'da', 'de', 'el', 'en', 'es', 'et', 'eu', 'fi', 'fr', 'ff', 'om', 'gu', 'gn', 'ht', 'ha', 'he', 'hi', 'hr', 'hu', 'hy', 'ig', 'id', 'it', 'is', 'jv', 'ja', 'ka', 'kn', 'kk', 'mn', 'km', 'rw', 'ky', 'ko', 'lo', 'ln', 'lt', 'lg', 'lv', 'ml', 'mr', 'mk', 'mt', 'mi', 'my', 'nl', 'no', 'ne', 'ny', 'or', 'pa', 'ps', 'fa', 'mg', 'pl', 'pt', 'ro', 'ru', 'sn', 'si', 'sl', 'sv', 'sk', 'sd', 'sw', 'ta', 'te', 'tg', 'tl', 'th', 'ti', 'tn', 'ts', 'tr', 'uk', 'ur', 'uz', 'vi', 'wo', 'xh', 'yo', 'zh', 'ms', 'zu']","['question-answering', 'zero-shot-classification', 'text-classification', 'multiple-choice']",['100K<n<1M']
toshi456/LLaVA-CC3M-Pretrain-595K-JA,toshi456,2023-12-03 07:26:55+00:00,2024-04-12 03:21:46+00:00,29,11,"['task_categories:visual-question-answering', 'language:ja', 'license:other', 'size_categories:100K<n<1M', 'format:parquet', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","
	
		
		Dataset Card for ""LLaVA-CC3M-Pretrain-595K-JA""
	


	
		
		Dataset Details
	

Dataset Type:
Japanese LLaVA CC3M Pretrain 595K is a localized version of the original LLaVA Visual Instruct CC3M 595K dataset. This version is translated into Japanese using cyberagent/calm2-7b-chat and is aimed at serving similar purposes in the context of Japanese language.
Resources for More Information:
For information on the original dataset: liuhaotian/LLaVA-CC3M-Pretrain-595K
License:
Must comply with… See the full description on the dataset page: https://huggingface.co/datasets/toshi456/LLaVA-CC3M-Pretrain-595K-JA.",https://huggingface.co/datasets/toshi456/LLaVA-CC3M-Pretrain-595K-JA,['ja'],['visual-question-answering'],['100K<n<1M']
rayliuca/WikidataLabels,rayliuca,2024-01-01 00:23:08+00:00,2024-01-11 04:17:57+00:00,2995,3,"['task_categories:translation', 'language:en', 'language:fr', 'language:de', 'language:ja', 'language:zh', 'language:hi', 'language:ar', 'language:bn', 'language:ru', 'language:es', 'license:cc0-1.0', 'size_categories:100M<n<1B', 'format:parquet', 'modality:text', 'library:datasets', 'library:dask', 'library:mlcroissant', 'library:polars', 'region:us']","
	
		
		Wikidata Labels
	

Large parallel corpus for machine translation

Entity label data extracted from Wikidata (2022-01-03), filtered for item entities only  
Only download the languages you need with datasets>=2.14.0
Similar dataset: https://huggingface.co/datasets/wmt/wikititles (18 Wikipedia titles pairs instead of all Wikidata entities)


	
		
	
	
		Dataset Details
	


	
		
	
	
		Dataset Sources
	


Wikidata JSON dump (wikidata-20220103-all.json.gz)… See the full description on the dataset page: https://huggingface.co/datasets/rayliuca/WikidataLabels.",https://huggingface.co/datasets/rayliuca/WikidataLabels,"['en', 'fr', 'de', 'ja', 'zh', 'hi', 'ar', 'bn', 'ru', 'es']",['translation'],['100M<n<1B']
jpft/danbooru2023,jpft,2024-01-11 10:28:25+00:00,2024-01-11 10:28:25+00:00,490,4,"['task_categories:image-classification', 'task_categories:image-to-image', 'task_categories:text-to-image', 'language:en', 'language:ja', 'license:mit', 'size_categories:1M<n<10M', 'region:us']","


	
		
		Danbooru2023: A Large-Scale Crowdsourced and Tagged Anime Illustration Dataset
	



Danbooru2023 is a large-scale anime image dataset with over 5 million images contributed and annotated in detail by an enthusiast community. Image tags cover aspects like characters, scenes, copyrights, artists, etc with an average of 30 tags per image.
Danbooru is a veteran anime image board with high-quality images and extensive tag metadata. The dataset can be used to train image classification… See the full description on the dataset page: https://huggingface.co/datasets/jpft/danbooru2023.",https://huggingface.co/datasets/jpft/danbooru2023,"['en', 'ja']","['image-classification', 'image-to-image', 'text-to-image']",['1M<n<10M']
Shitao/MLDR,Shitao,2024-02-02 06:32:59+00:00,2024-02-06 08:44:31+00:00,1898,70,"['task_categories:text-retrieval', 'multilinguality:multilingual', 'language:ar', 'language:de', 'language:en', 'language:es', 'language:fr', 'language:hi', 'language:it', 'language:ja', 'language:ko', 'language:pt', 'language:ru', 'language:th', 'language:zh', 'license:mit', 'arxiv:2402.03216', 'region:us']","
	
		
		Dataset Summary
	

MLDR is a Multilingual Long-Document Retrieval dataset built on Wikipeida, Wudao and mC4, covering 13 typologically diverse languages. Specifically, we sample lengthy articles from Wikipedia, Wudao and mC4 datasets and randomly choose paragraphs from them. Then we use GPT-3.5 to generate questions based on these paragraphs. The generated question and the sampled article constitute a new text pair to the dataset. The prompt for GPT3.5 is “You are a curious AI… See the full description on the dataset page: https://huggingface.co/datasets/Shitao/MLDR.",https://huggingface.co/datasets/Shitao/MLDR,"['ar', 'de', 'en', 'es', 'fr', 'hi', 'it', 'ja', 'ko', 'pt', 'ru', 'th', 'zh']",['text-retrieval'],[]
SakanaAI/JA-VG-VQA-500,SakanaAI,2024-02-29 23:31:26+00:00,2024-05-14 04:11:31+00:00,325,16,"['task_categories:visual-question-answering', 'language:ja', 'license:cc-by-4.0', 'size_categories:1K<n<10K', 'format:parquet', 'modality:image', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'arxiv:2403.13187', 'region:us']","
	
		
		JA-VG-VQA-500
	


	
		
		Dataset Description
	

JA-VG-VQA-500 is a 500-sample subset of Japanese Visual Genome VQA dataset.
This dataset was used in the evaluation of EvoVLM-JP-v1-7B. 
Please refer to our report and blog for more details. 
We are grateful to the developers for making the dataset available under Creative Commons Attribution 4.0 License. 

Visual Genome
Japanese Visual Genome VQA dataset
	
		
		Usage
	

Use the code below to get started with the dataset.
from datasets… See the full description on the dataset page: https://huggingface.co/datasets/SakanaAI/JA-VG-VQA-500.",https://huggingface.co/datasets/SakanaAI/JA-VG-VQA-500,['ja'],['visual-question-answering'],['1K<n<10K']
U23-lab/wiki40b_qa_ja,U23-lab,2024-03-28 11:17:16+00:00,2024-03-28 11:45:07+00:00,21,2,"['task_categories:question-answering', 'language:ja', 'license:cc-by-sa-4.0', 'size_categories:1M<n<10M', 'format:parquet', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","wiki40b-ja から生成した質問応答データセット
",https://huggingface.co/datasets/U23-lab/wiki40b_qa_ja,['ja'],['question-answering'],['1M<n<10M']
Mitsua/wikidata-parallel-descriptions-en-ja,Mitsua,2024-05-13 12:02:42+00:00,2024-05-17 00:25:10+00:00,23,8,"['task_categories:translation', 'language:en', 'language:ja', 'license:cc0-1.0', 'size_categories:1M<n<10M', 'format:json', 'modality:text', 'library:datasets', 'library:dask', 'library:mlcroissant', 'library:polars', 'region:us']","
	
		
		Wikidata parallel descriptions en-ja
	


Parallel corpus for machine translation generated from wikidata dump (2024-05-06).
Currently we processed only English/Japanese pair.
The jsonl file is ready-to-train by Hugging Face transformers trainer for translation tasks.


	
		
		Dataset Details
	


https://www.wikidata.org/wiki/Wikidata:Database_download


	
		
		Dataset Creation
	


As Wikidata description field does not represent exact direct translation, filtering is required for… See the full description on the dataset page: https://huggingface.co/datasets/Mitsua/wikidata-parallel-descriptions-en-ja.",https://huggingface.co/datasets/Mitsua/wikidata-parallel-descriptions-en-ja,"['en', 'ja']",['translation'],['1M<n<10M']
shunk031/JDocQA,shunk031,2024-05-17 13:53:34+00:00,2024-05-21 16:00:57+00:00,143,9,"['task_categories:question-answering', 'task_ids:extractive-qa', 'task_ids:open-domain-qa', 'task_ids:closed-domain-qa', 'annotations_creators:crowdsourced', 'language_creators:found', 'multilinguality:monolingual', 'source_datasets:original', 'language:ja', 'license:cc-by-sa-4.0', 'size_categories:1K<n<10K', 'arxiv:2403.19454', 'region:us']","Japanese Document Question Answering (JDocQA), a large-scale document-based QA dataset, essentially requiring both visual and textual information to answer questions, which comprises 5,504 documents in PDF format and annotated 11,600 question-and-answer instances in Japanese.",https://huggingface.co/datasets/shunk031/JDocQA,['ja'],['question-answering'],['1K<n<10K']
deepghs/fgo_voices_jp,deepghs,2024-08-28 08:56:04+00:00,2024-08-28 09:14:22+00:00,76,12,"['task_categories:automatic-speech-recognition', 'task_categories:audio-classification', 'language:ja', 'license:other', 'size_categories:10K<n<100K', 'format:parquet', 'modality:tabular', 'modality:text', 'modality:audio', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us', 'audio', 'text', 'voice', 'anime', 'fgo']","
	
		
		JP Voice-Text Dataset for FGO Waifus
	

This is the JP voice-text dataset for FGO playable characters. Very useful for fine-tuning or evaluating ASR/ASV models.
Only the voices with strictly one voice actor is maintained here to reduce the noise of this dataset.
30800 records, 66.4 hours in total. Average duration is approximately 7.76s.

	
		
id
char_id
voice_actor_name
voice_title
voice_text
time
sample_rate
file_size
filename
mimetype
file_url


		
char_1_SV1_0_对话12
1
高桥李依
对话 12… See the full description on the dataset page: https://huggingface.co/datasets/deepghs/fgo_voices_jp.",https://huggingface.co/datasets/deepghs/fgo_voices_jp,['ja'],"['automatic-speech-recognition', 'audio-classification']",['10K<n<100K']
deepghs/azurlane_voices_jp,deepghs,2024-08-28 09:15:32+00:00,2024-08-28 09:38:53+00:00,31,8,"['task_categories:automatic-speech-recognition', 'task_categories:audio-classification', 'language:ja', 'license:other', 'size_categories:10K<n<100K', 'format:parquet', 'modality:tabular', 'modality:text', 'modality:audio', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us', 'audio', 'text', 'voice', 'anime', 'azurlane']","
	
		
		JP Voice-Text Dataset for Azur Lane Waifus
	

This is the JP voice-text dataset for azur lane playable characters. Very useful for fine-tuning or evaluating ASR/ASV models.
Only the voices with strictly one voice actor is maintained here to reduce the noise of this dataset.
30160 records, 75.8 hours in total. Average duration is approximately 9.05s.

	
		
id
char_id
voice_actor_name
voice_title
voice_text
time
sample_rate
file_size
filename
mimetype
file_url… See the full description on the dataset page: https://huggingface.co/datasets/deepghs/azurlane_voices_jp.",https://huggingface.co/datasets/deepghs/azurlane_voices_jp,['ja'],"['automatic-speech-recognition', 'audio-classification']",['10K<n<100K']
deepghs/girlsfrontline_voices_jp,deepghs,2024-08-28 11:32:04+00:00,2024-08-28 11:43:19+00:00,34,8,"['task_categories:automatic-speech-recognition', 'task_categories:audio-classification', 'language:ja', 'license:other', 'size_categories:10K<n<100K', 'format:parquet', 'modality:tabular', 'modality:text', 'modality:audio', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us', 'audio', 'text', 'voice', 'anime', 'girlsfrontline']","
	
		
		JP Voice-Text Dataset for Girls Front Line Waifus
	

This is the JP voice-text dataset for girls front line playable characters. Very useful for fine-tuning or evaluating ASR/ASV models.
Only the voices with strictly one voice actor is maintained here to reduce the noise of this dataset.
12508 records, 20.9 hours in total. Average duration is approximately 6.01s.

	
		
id
char_id
voice_actor_name
voice_title
voice_text
time
sample_rate
file_size
filename
mimetype
file_url… See the full description on the dataset page: https://huggingface.co/datasets/deepghs/girlsfrontline_voices_jp.",https://huggingface.co/datasets/deepghs/girlsfrontline_voices_jp,['ja'],"['automatic-speech-recognition', 'audio-classification']",['10K<n<100K']
openai/MMMLU,openai,2024-09-13 16:37:19+00:00,2024-10-16 18:39:00+00:00,10951,501,"['task_categories:question-answering', 'language:ar', 'language:bn', 'language:de', 'language:es', 'language:fr', 'language:hi', 'language:id', 'language:it', 'language:ja', 'language:ko', 'language:pt', 'language:sw', 'language:yo', 'language:zh', 'license:mit', 'size_categories:100K<n<1M', 'format:csv', 'modality:text', 'library:datasets', 'library:dask', 'library:mlcroissant', 'library:polars', 'arxiv:2009.03300', 'region:us']","
	
		
		Multilingual Massive Multitask Language Understanding (MMMLU)
	

The MMLU is a widely recognized benchmark of general knowledge attained by AI models. It covers a broad range of topics from 57 different categories, covering elementary-level knowledge up to advanced professional subjects like law, physics, history, and computer science.
We translated the MMLU’s test set into 14 languages using professional human translators. Relying on human translators for this evaluation increases… See the full description on the dataset page: https://huggingface.co/datasets/openai/MMMLU.",https://huggingface.co/datasets/openai/MMMLU,"['ar', 'bn', 'de', 'es', 'fr', 'hi', 'id', 'it', 'ja', 'ko', 'pt', 'sw', 'yo', 'zh']",['question-answering'],['100K<n<1M']
JMMMU/JMMMU,JMMMU,2024-09-29 22:21:14+00:00,2025-05-30 13:10:48+00:00,311,17,"['task_categories:question-answering', 'task_categories:visual-question-answering', 'task_categories:multiple-choice', 'language:ja', 'license:mit', 'size_categories:1K<n<10K', 'format:parquet', 'modality:image', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'arxiv:2410.17250', 'region:us']","
	
		
		JMMMU: A Japanese Massive Multi-discipline Multimodal Understanding Benchmark
	

🌐 Homepage | 🤗 Dataset | 🏆 HF Leaderboard | 📖 arXiv | 💻 Code

	
		
	
	
		Introduction
	

We introduce JMMMU (Japanese MMMU), a multimodal benchmark that can truly evaluate LMM performance in Japanese. To create JMMMU, we first carefully analyzed the existing MMMU benchmark and examined its cultural dependencies. Then, for questions in culture-agnostic subjects, we employed native Japanese speakers who… See the full description on the dataset page: https://huggingface.co/datasets/JMMMU/JMMMU.",https://huggingface.co/datasets/JMMMU/JMMMU,['ja'],"['question-answering', 'visual-question-answering', 'multiple-choice']",['1K<n<10K']
haoranxu/X-ALMA-Parallel-Data,haoranxu,2024-10-03 02:07:08+00:00,2024-10-07 06:11:17+00:00,539,7,"['language:en', 'language:da', 'language:nl', 'language:de', 'language:is', 'language:no', 'language:sc', 'language:af', 'language:ca', 'language:ro', 'language:gl', 'language:it', 'language:pt', 'language:es', 'language:bg', 'language:mk', 'language:sr', 'language:uk', 'language:ru', 'language:id', 'language:ms', 'language:th', 'language:vi', 'language:mg', 'language:fr', 'language:hu', 'language:el', 'language:cs', 'language:pl', 'language:lt', 'language:lv', 'language:ka', 'language:zh', 'language:ja', 'language:ko', 'language:fi', 'language:et', 'language:gu', 'language:hi', 'language:mr', 'language:ne', 'language:ur', 'language:az', 'language:kk', 'language:ky', 'language:tr', 'language:uz', 'language:ar', 'language:he', 'language:fa', 'size_categories:100K<n<1M', 'format:parquet', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'arxiv:2410.03115', 'region:us']","
This is the translation parallel dataset used by X-ALMA.
@misc{xu2024xalmaplugplay,
      title={X-ALMA: Plug & Play Modules and Adaptive Rejection for Quality Translation at Scale}, 
      author={Haoran Xu and Kenton Murray and Philipp Koehn and Hieu Hoang and Akiko Eriguchi and Huda Khayrallah},
      year={2024},
      eprint={2410.03115},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2410.03115}, 
}

",https://huggingface.co/datasets/haoranxu/X-ALMA-Parallel-Data,"['en', 'da', 'nl', 'de', 'is', 'no', 'sc', 'af', 'ca', 'ro', 'gl', 'it', 'pt', 'es', 'bg', 'mk', 'sr', 'uk', 'ru', 'id', 'ms', 'th', 'vi', 'mg', 'fr', 'hu', 'el', 'cs', 'pl', 'lt', 'lv', 'ka', 'zh', 'ja', 'ko', 'fi', 'et', 'gu', 'hi', 'mr', 'ne', 'ur', 'az', 'kk', 'ky', 'tr', 'uz', 'ar', 'he', 'fa']",[],['100K<n<1M']
rombodawg/Everything_Instruct_Multilingual,rombodawg,2024-10-08 21:13:18+00:00,2024-10-08 22:35:10+00:00,98,25,"['language:en', 'language:ru', 'language:zh', 'language:ko', 'language:ur', 'language:la', 'language:ar', 'language:de', 'language:es', 'language:fr', 'language:hi', 'language:it', 'language:ja', 'language:nl', 'language:pt', 'license:apache-2.0', 'size_categories:1M<n<10M', 'format:json', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us', 'Num_Rows = 7,799,967', 'Max_length = 8180']","
	
		
		Everything Instruct (Multilingual Edition)
	

Everything you need... all in one place 💘

Everything instruct (Multilingual Edition) is a massive alpaca instruct formatted dataset consisting of a wide variety of topics meant to bring LLM's to the next level in open source AI.
Note: This dataset is fully uncensored (No model will refuse any request trained on this dataset unless otherwise aligned)
Note2: This version of the dataset supports the following languages:

English
Russian… See the full description on the dataset page: https://huggingface.co/datasets/rombodawg/Everything_Instruct_Multilingual.",https://huggingface.co/datasets/rombodawg/Everything_Instruct_Multilingual,"['en', 'ru', 'zh', 'ko', 'ur', 'la', 'ar', 'de', 'es', 'fr', 'hi', 'it', 'ja', 'nl', 'pt']",[],['1M<n<10M']
Qwen/P-MMEval,Qwen,2024-11-13 06:12:25+00:00,2024-11-28 06:19:41+00:00,900,13,"['language:ar', 'language:es', 'language:fr', 'language:ja', 'language:ko', 'language:pt', 'language:th', 'language:vi', 'language:en', 'language:zh', 'license:apache-2.0', 'size_categories:10K<n<100K', 'format:json', 'modality:tabular', 'modality:text', 'library:datasets', 'library:dask', 'library:mlcroissant', 'arxiv:2411.09116', 'region:us']","
	
		
		P-MMEval: A Parallel Multilingual Multitask Benchmark for Consistent Evaluation of LLMs
	


	
		
		Introduction
	

We introduce a multilingual benchmark, P-MMEval, covering effective fundamental and capability-specialized datasets. We extend the existing benchmarks, ensuring consistent language coverage across all datasets and providing parallel samples among multiple languages, supporting up to 10 languages from 8 language families (i.e., en, zh, ar, es, ja, ko, th, fr, pt, vi). As a… See the full description on the dataset page: https://huggingface.co/datasets/Qwen/P-MMEval.",https://huggingface.co/datasets/Qwen/P-MMEval,"['ar', 'es', 'fr', 'ja', 'ko', 'pt', 'th', 'vi', 'en', 'zh']",[],['10K<n<100K']
hpprc/kaken-trans-ja-en,hpprc,2024-11-29 13:02:31+00:00,2025-01-09 04:09:18+00:00,78,9,"['task_categories:translation', 'language:ja', 'language:en', 'license:cc-by-4.0', 'size_categories:1M<n<10M', 'format:parquet', 'modality:text', 'library:datasets', 'library:dask', 'library:mlcroissant', 'library:polars', 'region:us', 'machine-translation', 'synthetic']","llm-jp-corpus-v3のkakenサブセット中の日本語テキストを、Qwen/Qwen2.5-32B-Instructを用いて日本語から英語に翻訳したデータセットです。
オープンな日英パラレルコーパスを意図して作成・公開しました。
id列は翻訳の際に使用したカラムであり、元データセットに存在するidカラムとは異なっています。
kakenサブセット自体のHF版データセットも合わせてご覧ください: hpprc/llmjp-kaken。
本データセットのライセンスは元データセットのライセンスを継承し、CC-BY 4.0とします。
",https://huggingface.co/datasets/hpprc/kaken-trans-ja-en,"['ja', 'en']",['translation'],['1M<n<10M']
Mitsua/art-museums-pd-440k,Mitsua,2024-12-15 13:55:05+00:00,2025-02-13 07:55:37+00:00,319,11,"['task_categories:image-to-text', 'task_categories:text-to-image', 'language:en', 'language:ja', 'license:cc-by-4.0', 'size_categories:100K<n<1M', 'format:webdataset', 'modality:image', 'modality:text', 'library:datasets', 'library:webdataset', 'library:mlcroissant', 'region:us', 'legal']","
	
		
		Art Museums PD 440K
	



	
		
		Summary
	

This is a dataset to train text-to-image or any text and image multimodal models with minimized copyright/licensing concerns.
All images and texts in this dataset are orignally shared under CC0 or public domain, and no pretrained models or any AI models are used to build this dataset except for our ElanMT model to translate English captions to Japanese.
ElanMT model is trained solely on licensed corpus.

	
		
	
	
		Data sources
	

Images and… See the full description on the dataset page: https://huggingface.co/datasets/Mitsua/art-museums-pd-440k.",https://huggingface.co/datasets/Mitsua/art-museums-pd-440k,"['en', 'ja']","['image-to-text', 'text-to-image']",['100K<n<1M']
Mitsua/safe-commons-pd-3m,Mitsua,2024-12-16 08:37:14+00:00,2025-02-13 07:56:14+00:00,119,5,"['task_categories:text-to-image', 'task_categories:image-to-text', 'language:en', 'language:ja', 'license:cc-by-sa-4.0', 'size_categories:1M<n<10M', 'format:parquet', 'modality:image', 'modality:text', 'library:datasets', 'library:dask', 'library:mlcroissant', 'library:polars', 'arxiv:2103.00020', 'arxiv:2309.16671', 'region:us', 'legal']","
	
		
		Safe Commons PD 3M
	


This is a balanced and safe-to-use public domain / CC0 images dataset.
All images and texts come from Wikimedia Commons and Wikidata with strict filtering.
Images license is either Public Domain or CC0 (varies by image).
Texts license is either CC0 or CC BY-SA (varies by caption source).
No synthetic data (AI generated images or captions) is in the dataset.

To build this dataset, we tried to avoid any knowledge leaks from existing pre-trained models at the… See the full description on the dataset page: https://huggingface.co/datasets/Mitsua/safe-commons-pd-3m.",https://huggingface.co/datasets/Mitsua/safe-commons-pd-3m,"['en', 'ja']","['text-to-image', 'image-to-text']",['1M<n<10M']
trojblue/danbooru2025-metadata,trojblue,2025-01-02 19:25:56+00:00,2025-04-16 12:53:18+00:00,604,13,"['task_categories:text-to-image', 'task_categories:image-classification', 'language:en', 'language:ja', 'license:mit', 'size_categories:1M<n<10M', 'format:parquet', 'modality:image', 'modality:tabular', 'modality:text', 'library:datasets', 'library:dask', 'library:mlcroissant', 'library:polars', 'region:us']"," 
   
 

🎨 Danbooru 2025 Metadata 


  Latest Post ID: 9,158,800
  (as of Apr 16, 2025)



📁 About the DatasetThis dataset provides structured metadata for user-submitted images on Danbooru, a large-scale imageboard focused on anime-style artwork.
Scraping began on January 2, 2025, and the data are stored in Parquet format for efficient programmatic access.Compared to earlier versions, this snapshot includes:

More consistent tag history tracking  
Better coverage of older or previously… See the full description on the dataset page: https://huggingface.co/datasets/trojblue/danbooru2025-metadata.",https://huggingface.co/datasets/trojblue/danbooru2025-metadata,"['en', 'ja']","['text-to-image', 'image-classification']",['1M<n<10M']
naist-nlp/MultiExpArt,naist-nlp,2025-01-30 01:46:38+00:00,2025-10-10 05:49:04+00:00,81,1,"['task_categories:text-generation', 'language:en', 'language:ja', 'language:zh', 'language:fr', 'language:it', 'language:nl', 'language:sv', 'language:de', 'language:ru', 'language:es', 'license:cc-by-nc-sa-4.0', 'size_categories:1M<n<10M', 'modality:image', 'arxiv:2409.01584', 'region:us', 'art']","
	
		
		Dataset Card for Multilingual Explain Artworks: MultiExpArt
	



This dataset card aims to be a base template for new datasets. It has been generated using this raw template.

	
		
		Dataset Description
	


	
		
		Dataset Summary
	


As the performance of Large-scale Vision Language Models (LVLMs) improves, they are increasingly capable of responding in multiple languages, and there is an expectation that the demand for explanations generated by LVLMs will grow. However, pre-training… See the full description on the dataset page: https://huggingface.co/datasets/naist-nlp/MultiExpArt.",https://huggingface.co/datasets/naist-nlp/MultiExpArt,"['en', 'ja', 'zh', 'fr', 'it', 'nl', 'sv', 'de', 'ru', 'es']",['text-generation'],['1M<n<10M']
agentlans/multilingual-sentences,agentlans,2025-01-30 07:32:37+00:00,2025-03-11 00:18:59+00:00,441,5,"['task_categories:text-generation', 'task_categories:text-classification', 'task_categories:text-retrieval', 'language:multilingual', 'language:ar', 'language:az', 'language:bg', 'language:bn', 'language:ca', 'language:cs', 'language:da', 'language:de', 'language:el', 'language:en', 'language:es', 'language:et', 'language:fa', 'language:fi', 'language:fr', 'language:he', 'language:hi', 'language:hu', 'language:hy', 'language:id', 'language:is', 'language:it', 'language:ja', 'language:ka', 'language:kk', 'language:ko', 'language:lt', 'language:lv', 'language:mk', 'language:ml', 'language:mr', 'language:ne', 'language:nl', 'language:no', 'language:pl', 'language:pt', 'language:ro', 'language:ru', 'language:sk', 'language:sl', 'language:sq', 'language:sr', 'language:sv', 'language:ta', 'language:th', 'language:tr', 'language:uk', 'language:ur', 'language:vi', 'language:zh', 'size_categories:10M<n<100M', 'format:text', 'modality:text', 'library:datasets', 'library:mlcroissant', 'region:us']","
	
		
		Multilingual Sentences
	

Dataset contains sentences from 50 languages, grouped by their two-letter ISO 639-1 codes. The ""all"" configuration includes sentences from all languages.

	
		
		Dataset Overview
	

Multilingual Sentence Dataset is a comprehensive collection of high-quality, linguistically diverse sentences. Dataset is designed to support a wide range of natural language processing tasks, including but not limited to language modeling, machine translation, and cross-lingual… See the full description on the dataset page: https://huggingface.co/datasets/agentlans/multilingual-sentences.",https://huggingface.co/datasets/agentlans/multilingual-sentences,"['multilingual', 'ar', 'az', 'bg', 'bn', 'ca', 'cs', 'da', 'de', 'el', 'en', 'es', 'et', 'fa', 'fi', 'fr', 'he', 'hi', 'hu', 'hy', 'id', 'is', 'it', 'ja', 'ka', 'kk', 'ko', 'lt', 'lv', 'mk', 'ml', 'mr', 'ne', 'nl', 'no', 'pl', 'pt', 'ro', 'ru', 'sk', 'sl', 'sq', 'sr', 'sv', 'ta', 'th', 'tr', 'uk', 'ur', 'vi', 'zh']","['text-generation', 'text-classification', 'text-retrieval']",['10M<n<100M']
AmirHossein2002/CAPTex,AmirHossein2002,2025-02-20 06:40:59+00:00,2025-09-28 06:47:49+00:00,31,2,"['language:en', 'language:fa', 'language:zh', 'language:ja', 'language:hi', 'language:id', 'language:ha', 'language:ur', 'license:cc-by-nc-4.0', 'size_categories:1K<n<10K', 'format:csv', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","
    CAPTex: A Benchmark for Culturally-Aware Procedural Text Understanding

 Amir Hossein Yari, Fajri Koto 

    Sharif University of Technology, MBZUAI




	
		
		Introduction
	

CAPTex (Culturally-Aware Procedural Texts) is a dataset designed to evaluate the ability of multilingual large language models (mLLMs) to comprehend and reason about procedural texts embedded in diverse cultural contexts. The dataset includes procedural knowledge from seven culturally distinct regions: China, India… See the full description on the dataset page: https://huggingface.co/datasets/AmirHossein2002/CAPTex.",https://huggingface.co/datasets/AmirHossein2002/CAPTex,"['en', 'fa', 'zh', 'ja', 'hi', 'id', 'ha', 'ur']",[],['1K<n<10K']
Pinkstack/Thinking-multilingual-big-10k-sft,Pinkstack,2025-03-01 01:22:38+00:00,2025-03-01 01:43:31+00:00,45,3,"['task_categories:text-generation', 'language:ar', 'language:zh', 'language:cs', 'language:da', 'language:nl', 'language:en', 'language:fi', 'language:fr', 'language:de', 'language:he', 'language:hu', 'language:it', 'language:ja', 'language:ko', 'language:no', 'language:pl', 'language:pt', 'language:ru', 'language:es', 'language:sv', 'language:th', 'language:tr', 'language:uk', 'license:apache-2.0', 'size_categories:10K<n<100K', 'format:json', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us', 'reasoning', 'superthoughts', 'cot']","
A dataset based off of openo1 math, 500 examples translated to 23 different languages. filtered out un-translated examples.
enjoy 👍
",https://huggingface.co/datasets/Pinkstack/Thinking-multilingual-big-10k-sft,"['ar', 'zh', 'cs', 'da', 'nl', 'en', 'fi', 'fr', 'de', 'he', 'hu', 'it', 'ja', 'ko', 'no', 'pl', 'pt', 'ru', 'es', 'sv', 'th', 'tr', 'uk']",['text-generation'],['10K<n<100K']
elyza/JaMARD,elyza,2025-03-09 14:57:33+00:00,2025-03-10 04:57:32+00:00,153,7,"['language:ja', 'license:mit', 'size_categories:100K<n<1M', 'arxiv:2305.20050', 'arxiv:2110.14168', 'region:us']","
	
		
		JaMARD: Japanese Mathematical Dataset with Assured Reasoning Description
	

English / Japanese

	
		
		Overview
	

JaMARD (Japanese Mathematical Dataset with Assured Reasoning Description) is a high-quality synthetic dataset for Japanese mathematical problems with chain-of-thought reasoning, where the correctness of synthetic instances is assured.
At first, we utilized the English educational resources PRM800K and GSM8K as seed dataset and translated their questions into Japanese using… See the full description on the dataset page: https://huggingface.co/datasets/elyza/JaMARD.",https://huggingface.co/datasets/elyza/JaMARD,['ja'],[],['100K<n<1M']
llm-jp/llm-jp-chatbot-arena-conversations,llm-jp,2025-04-10 09:56:47+00:00,2025-07-14 09:12:41+00:00,44,7,"['task_categories:question-answering', 'task_categories:text-generation', 'language:ja', 'license:cc', 'size_categories:n<1K', 'region:us']","
	
		
		LLM-jp Chatbot Arena Conversations Dataset
	

This dataset contains approximately 1,000 conversations with pairwise human preferences, most of which are in Japanese.
The data was collected during the trial phase of the LLM-jp Chatbot Arena (January–February 2025), where users compared responses from two different models in a head-to-head format.
Each sample includes a question ID, the names of the two models, their conversation transcripts, the user's vote, an anonymized user ID, a… See the full description on the dataset page: https://huggingface.co/datasets/llm-jp/llm-jp-chatbot-arena-conversations.",https://huggingface.co/datasets/llm-jp/llm-jp-chatbot-arena-conversations,['ja'],"['question-answering', 'text-generation']",['n<1K']
kigland/odp,kigland,2025-04-30 16:37:02+00:00,2025-05-21 17:14:01+00:00,6,1,"['task_categories:image-segmentation', 'language:zh', 'language:en', 'language:ja', 'size_categories:10K<n<100K', 'modality:text', 'region:us']","
	
		
		Optimised Danbooru Parsing
	

An optimised version of DP (Danbooru Parsing). We merged serveral features to keep it simple,
also, we convert it to numpy file so that can use np.load() load directly.
ODP is an anime face segmentation dataset (either the original DP). It has 11 labels:

	
		
ODP Label Id
Description
DP Label Id


		
0
Background
0


1
Face
1, 6


2
Eyebrows
2, 3


3
Eyes
4, 5


4
Ears
7, 8, 9


5
Nose
10


6
Mouth
11, 12, 13


7
Neck
14


8
Clothes
15, 16


9
Hair17


10… See the full description on the dataset page: https://huggingface.co/datasets/kigland/odp.",https://huggingface.co/datasets/kigland/odp,"['zh', 'en', 'ja']",['image-segmentation'],['10K<n<100K']
tokyotech-llm/swallow-code,tokyotech-llm,2025-05-01 07:27:11+00:00,2025-07-04 02:46:59+00:00,1011,55,"['task_categories:text-generation', 'language:en', 'language:ja', 'license:llama3.3', 'size_categories:100M<n<1B', 'format:json', 'modality:tabular', 'modality:text', 'library:datasets', 'library:dask', 'library:mlcroissant', 'arxiv:2505.02881', 'region:us', 'code']","
	
		
		SwallowCode
	




	
		
		Notice
	


May 21, 2025: We have deleted ablation/exp1-the-stack-v2-train-smol-ids-python because it was flagged as potentially containing unsafe data collected from the Python subset of https://huggingface.co/datasets/bigcode/the-stack-v2-train-smol-ids. However, since this dataset can be reconstructed from the-stack-v2-train-smol-ids, there is no issue in terms of reproducibility.
May 21, 2025: ClamAV has flagged “Win.Trojan.MSShellcode-88” in… See the full description on the dataset page: https://huggingface.co/datasets/tokyotech-llm/swallow-code.",https://huggingface.co/datasets/tokyotech-llm/swallow-code,"['en', 'ja']",['text-generation'],['100M<n<1B']
liboaccn/nmt-parallel-corpus,liboaccn,2025-05-26 17:45:16+00:00,2025-06-01 14:50:19+00:00,1073,8,"['task_categories:translation', 'language:am', 'language:ar', 'language:az', 'language:be', 'language:bg', 'language:bn', 'language:bo', 'language:bs', 'language:cs', 'language:de', 'language:el', 'language:en', 'language:es', 'language:et', 'language:fa', 'language:fr', 'language:ha', 'language:hi', 'language:hr', 'language:hu', 'language:hy', 'language:id', 'language:it', 'language:ja', 'language:ka', 'language:kk', 'language:km', 'language:ko', 'language:ky', 'language:lo', 'language:lt', 'language:lv', 'language:mg', 'language:mi', 'language:mk', 'language:mn', 'language:ms', 'language:my', 'language:ne', 'language:pl', 'language:prs', 'language:ps', 'language:pt', 'language:ro', 'language:ru', 'language:rw', 'language:si', 'language:sk', 'language:sl', 'language:so', 'language:sq', 'language:sr', 'language:sw', 'language:ta', 'language:th', 'language:ti', 'language:tk', 'language:tr', 'language:ug', 'language:uk', 'language:ur', 'language:vi', 'language:zh', 'license:cc-by-nc-4.0', 'size_categories:10B<n<100B', 'format:parquet', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'arxiv:2505.14256', 'region:us']","
	
		
		Neural Machine Translation parallel corpora
	


	
		
		Introduction
	

We use OpusTools to extract resources from the OPUS project, a renowned platform for parallel corpora, and create a multilingual dataset. Specifically, we collect the parallel corpora from prominent projects within OPUS, including NLLB, CCMatrix, and OpenSubtitles.
This comprehensive data collection process results in a corpus of more than 3T, covering 60 languages and over 1900 language pairs.… See the full description on the dataset page: https://huggingface.co/datasets/liboaccn/nmt-parallel-corpus.",https://huggingface.co/datasets/liboaccn/nmt-parallel-corpus,"['am', 'ar', 'az', 'be', 'bg', 'bn', 'bo', 'bs', 'cs', 'de', 'el', 'en', 'es', 'et', 'fa', 'fr', 'ha', 'hi', 'hr', 'hu', 'hy', 'id', 'it', 'ja', 'ka', 'kk', 'km', 'ko', 'ky', 'lo', 'lt', 'lv', 'mg', 'mi', 'mk', 'mn', 'ms', 'my', 'ne', 'pl', 'prs', 'ps', 'pt', 'ro', 'ru', 'rw', 'si', 'sk', 'sl', 'so', 'sq', 'sr', 'sw', 'ta', 'th', 'ti', 'tk', 'tr', 'ug', 'uk', 'ur', 'vi', 'zh']",['translation'],['10B<n<100B']
joujiboi/Galgame-VisualNovel-Reupload,joujiboi,2025-06-19 15:47:05+00:00,2025-06-21 13:28:35+00:00,1255,13,"['task_categories:automatic-speech-recognition', 'task_categories:text-to-speech', 'language:ja', 'license:unknown', 'size_categories:1M<n<10M', 'format:parquet', 'modality:audio', 'modality:text', 'library:datasets', 'library:dask', 'library:mlcroissant', 'library:polars', 'region:us', 'speech', 'anime', 'japanese']","
	
		
		Galgame VisualNovel Reupload
	

This repository is a reupload of the visual novel dataset OOPPEENN/56697375616C4E6F76656C5F44617461736574.
The goal of this reupload is to restructure the data for easier and more efficient use with the datasets library, instead of having to manually extract each archive file and parse json files of the original dataset.

	
		
	
	
		Loading the entire dataset
	

To load and stream all voice lines from all games combined, simply load the train split. The… See the full description on the dataset page: https://huggingface.co/datasets/joujiboi/Galgame-VisualNovel-Reupload.",https://huggingface.co/datasets/joujiboi/Galgame-VisualNovel-Reupload,['ja'],"['automatic-speech-recognition', 'text-to-speech']",['1M<n<10M']
SamsungResearch/TRUEBench,SamsungResearch,2025-07-30 03:13:59+00:00,2025-09-23 11:41:43+00:00,1109,28,"['task_categories:text-generation', 'language:ko', 'language:en', 'language:ja', 'language:zh', 'language:pl', 'language:de', 'language:pt', 'language:es', 'language:fr', 'language:it', 'language:ru', 'language:vi', 'license:apache-2.0', 'size_categories:n<1K', 'format:parquet', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","
	
		
		TRUEBench: A Benchmark for Assessing LLMs as Human Job Productivity Assistants
	

TRUEBench is a benchmark introduced by Samsung Research to evaluate the performance of large language models (LLMs) as human job assistants which consists of over 2,400 realistic and challenging samples. 
To assess performance in real-world applications, TRUEBench includes diverse dialog scenarios and language conditions.

	
		
		Main Features
	


Multilinguality: The user instructions are written in a… See the full description on the dataset page: https://huggingface.co/datasets/SamsungResearch/TRUEBench.",https://huggingface.co/datasets/SamsungResearch/TRUEBench,"['ko', 'en', 'ja', 'zh', 'pl', 'de', 'pt', 'es', 'fr', 'it', 'ru', 'vi']",['text-generation'],['n<1K']
mpasila/ParallelFiction-Ja_En-1k-16k-Gemma-3-ShareGPT-Filtered,mpasila,2025-08-10 11:55:49+00:00,2025-08-15 09:55:03+00:00,12,1,"['task_categories:translation', 'language:ja', 'language:en', 'license:apache-2.0', 'size_categories:1K<n<10K', 'format:json', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","Filtered version of NilanE/ParallelFiction-Ja_En-100k in ShareGPT formatting and only uses a thousand examples.
I used Mistral Small 3.2 via OpenRouter to go through thousand examples to fix the translations. I haven't checked all 1000 examples but overlooked a bit and it seems fine but it's possible there are horrible issues with the dataset so I'd recommend still checking it manually if you want to be sure it's not trash.
Conversations do not exceed 16384 tokens which was based on Gemma 3… See the full description on the dataset page: https://huggingface.co/datasets/mpasila/ParallelFiction-Ja_En-1k-16k-Gemma-3-ShareGPT-Filtered.",https://huggingface.co/datasets/mpasila/ParallelFiction-Ja_En-1k-16k-Gemma-3-ShareGPT-Filtered,"['ja', 'en']",['translation'],['1K<n<10K']
cl-okayama/jp-univ-essay,cl-okayama,2025-08-24 08:14:31+00:00,2025-08-25 02:06:08+00:00,34,1,"['task_categories:text-classification', 'task_categories:image-to-text', 'language:ja', 'license:cc-by-4.0', 'size_categories:1K<n<10K', 'format:imagefolder', 'modality:image', 'modality:text', 'library:datasets', 'library:mlcroissant', 'region:us', 'text', 'japanese', 'handwritten']","
	
		
		Okayama University Japanese Essay Data
	

This repository contains Japanese essays collected from Okayama University. The dataset is intended for research and analysis purposes, such as natural language processing, text mining, or educational studies.

	
		
		Contents
	


Essay texts in Japanese
Scores of four traints
Data files in jsonl and png image files for essays


	
		
		Usage
	

This dataset is provided in JSON Lines (.jsonl) format.Each line corresponds to one student's essay… See the full description on the dataset page: https://huggingface.co/datasets/cl-okayama/jp-univ-essay.",https://huggingface.co/datasets/cl-okayama/jp-univ-essay,['ja'],"['text-classification', 'image-to-text']",['1K<n<10K']
neoai-inc/Japanese-RAG-Generator-Benchmark,neoai-inc,2025-08-28 03:15:56+00:00,2025-10-06 04:17:29+00:00,129,3,"['task_categories:question-answering', 'multilinguality:monolingual', 'language:ja', 'license:cc-by-sa-4.0', 'size_categories:n<1K', 'format:json', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","
	
		
		Japanese RAG Generator Benchmark: 日本語 RAG における Generator 評価ベンチマーク
	


	
		
		データセット構造
	

{
  ""question"": ""質問文 (str)"",
  ""answer"": ""正答 (str)"",
  ""positive"": ""正解となるコンテキスト (list[str])"",
  ""negative"": ""不正解のコンテキスト (list[str])"",
}


	
	
	
		使用方法
	

from datasets importload_dataset

dataset = load_dataset(""neoai-inc/Japanese-RAG-Generator-Benchmark"")


	
		
		関連情報
	


スライド
テックブログ


	
		
		Developers
	


Koki Itai
Shunichi Hasegawa
Yuta Yamamoto
Gouki Minegishi
Masaki Otsuki


	
		
		License… See the full description on the dataset page: https://huggingface.co/datasets/neoai-inc/Japanese-RAG-Generator-Benchmark.",https://huggingface.co/datasets/neoai-inc/Japanese-RAG-Generator-Benchmark,['ja'],['question-answering'],['n<1K']
NandemoGHS/Japanese-Eroge-Voice,NandemoGHS,2025-08-31 11:55:19+00:00,2025-08-31 15:17:43+00:00,1116,21,"['task_categories:text-to-speech', 'task_categories:automatic-speech-recognition', 'language:ja', 'license:mit', 'size_categories:100K<n<1M', 'format:webdataset', 'modality:audio', 'modality:text', 'library:datasets', 'library:webdataset', 'library:mlcroissant', 'region:us', 'speech', 'audio', 'japanese', 'asmr', 'anime', 'voice']","
	
		
		Japanese-Eroge-Voice
	


	
		
		Description
	

This dataset contains pairs of audio data and corresponding transcriptions extracted from Japanese eroge (adult games) that I have personally purchased. The transcriptions are generated using the litagin/anime-whisper model.


	
		
		Preprocessing Steps
	

The raw audio data has undergone the following preprocessing steps:

Loudness Normalization:
Audio loudness is normalized using ffmpeg's 2-pass loudnorm filter to target parameters of… See the full description on the dataset page: https://huggingface.co/datasets/NandemoGHS/Japanese-Eroge-Voice.",https://huggingface.co/datasets/NandemoGHS/Japanese-Eroge-Voice,['ja'],"['text-to-speech', 'automatic-speech-recognition']",['100K<n<1M']
nvidia/Nemotron-Personas-Japan,nvidia,2025-09-20 02:14:15+00:00,2025-09-24 00:02:54+00:00,13241,76,"['task_categories:text-generation', 'language:ja', 'license:cc-by-4.0', 'size_categories:1M<n<10M', 'format:parquet', 'modality:image', 'modality:text', 'library:datasets', 'library:dask', 'library:mlcroissant', 'library:polars', 'region:us', 'synthetic', 'personas', 'NVIDIA']","
	
		
		Nemotron-Personas-Japan
	


  
  現実世界の分布に基づいたペルソナ生成のための複合AIアプローチ



	
		
		データセット概要 (Dataset Overview)
	

Nemotron-Personas-Japan は、日本における人口の多様性と豊かさを捉えることを目的とし、実世界の人口統計、地理的分布、性格特性の分布に基づいて合成的に生成されたペルソナのオープンソースデータセットです。名前、性別、年齢、背景、婚姻状況、学歴、職業、居住地などの統計に基づいて生成した初のデータセットされた Nemotron-Personas の日本語版です。本バージョンでは、日本語における多様なモデリングユースケースに適した高品質のペルソナを提供します
Nemotron-Personas-Japan は、日本のモデル開発者が重要な地域固有の人口統計や文化的背景を取り入れたソブリンAIシステムを開発することを支援します。本データセットは、日本の地理的・人口統計的な実分布を反映することで、合成データの多様性を高め、バイアスを軽減し、model… See the full description on the dataset page: https://huggingface.co/datasets/nvidia/Nemotron-Personas-Japan.",https://huggingface.co/datasets/nvidia/Nemotron-Personas-Japan,['ja'],['text-generation'],['1M<n<10M']
TangRain/SingMOS-Pro,TangRain,2025-10-02 07:17:57+00:00,2025-10-09 06:47:20+00:00,129,2,"['language:zh', 'language:ja', 'license:cc-by-4.0', 'size_categories:1K<n<10K', 'format:audiofolder', 'modality:audio', 'library:datasets', 'library:mlcroissant', 'arxiv:2510.01812', 'region:us', 'singing', 'MOS']","
	
		
		🎵 SingMOS-Pro
	


[Important Notice]We have officially released the SingMOS-Pro dataset — the official benchmark for singing voice quality assessment.



	
		
		📚 Related Resources
	


🧾 Paper: SingMOS-Pro: A Comprehensive Benchmark for Singing Quality Assessment→ Describes dataset design, annotation methodology, and experiments.

🎶 VoiceMOS 2024 Singing Track: SingMOS_v1→ For reproducing or comparing with the official VoiceMOS 2024 track.

🤖 Pretrained Model: Singing MOS… See the full description on the dataset page: https://huggingface.co/datasets/TangRain/SingMOS-Pro.",https://huggingface.co/datasets/TangRain/SingMOS-Pro,"['zh', 'ja']",[],['1K<n<10K']
monkt/doclang,monkt,2025-10-07 05:40:59+00:00,2025-10-07 06:46:59+00:00,367,1,"['task_categories:image-classification', 'language:ar', 'language:bg', 'language:de', 'language:en', 'language:es', 'language:fr', 'language:hi', 'language:it', 'language:ja', 'language:ru', 'language:zh', 'size_categories:10K<n<100K', 'format:imagefolder', 'modality:image', 'library:datasets', 'library:mlcroissant', 'region:us', 'document-classification', 'computer-vision', 'multilingual']","
	
		
		DocLang: Multilingual Document Type Classification
	

A multilingual document type classification dataset for identifying various document and visual content types. The dataset contains 13,200 images across 11 languages, with 1,200 images per language.

	
		
		Dataset Structure
	

The dataset is organized by language code:

ar/ - Arabic (1,200 images)
bg/ - Bulgarian (1,200 images)
de/ - German (1,200 images)
en/ - English (1,200 images)
es/ - Spanish (1,200 images)
fr/ - French (1,200… See the full description on the dataset page: https://huggingface.co/datasets/monkt/doclang.",https://huggingface.co/datasets/monkt/doclang,"['ar', 'bg', 'de', 'en', 'es', 'fr', 'hi', 'it', 'ja', 'ru', 'zh']",['image-classification'],['10K<n<100K']
Aratako/LiquidAI-Hackathon-Tokyo-SFT-Data,Aratako,2025-10-11 13:56:20+00:00,2025-10-12 04:13:18+00:00,5,1,"['task_categories:automatic-speech-recognition', 'task_categories:text-to-speech', 'task_categories:audio-to-audio', 'language:ja', 'language:en', 'license:cc-by-nc-4.0', 'size_categories:1M<n<10M', 'format:parquet', 'library:datasets', 'library:dask', 'library:mlcroissant', 'library:polars', 'region:us']","
	
		
		LiquidAI-Hackathon-Tokyo-SFT-Data
	

Liquid AI Hackathon Tokyoで作成したモデルのSFTに利用したデータセットです。
",https://huggingface.co/datasets/Aratako/LiquidAI-Hackathon-Tokyo-SFT-Data,"['ja', 'en']","['automatic-speech-recognition', 'text-to-speech', 'audio-to-audio']",['1M<n<10M']
OsakanaTeishoku/magpie-sft-v1.0-10k-gpt-oss-120b,OsakanaTeishoku,2025-10-11 15:39:21+00:00,2025-10-11 15:40:54+00:00,16,1,"['language:ja', 'language:en', 'license:apache-2.0', 'size_categories:10K<n<100K', 'format:parquet', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","llm-jp/magpie-sft-v1.0のうち10,000件の回答をopenai/gpt-oss-120bで再生成したものです
",https://huggingface.co/datasets/OsakanaTeishoku/magpie-sft-v1.0-10k-gpt-oss-120b,"['ja', 'en']",[],['10K<n<100K']
deepghs/danbooru_wikis_full,deepghs,2024-06-02 12:55:02+00:00,2024-06-16 02:31:41+00:00,36,12,"['task_categories:text-classification', 'task_categories:text-generation', 'task_categories:feature-extraction', 'annotations_creators:no-annotation', 'source_datasets:danbooru', 'language:en', 'language:ja', 'language:zh', 'language:ko', 'license:mit', 'size_categories:100K<n<1M', 'region:us', 'art', 'anime', 'not-for-all-audiences']","
	
		
		Danbooru Full Wiki Dataset
	

This is the full wiki dataset of danbooru.donmai.us, containing the wiki pages/tags/tag aliases/tag implications. You can train something like LLMs on this dataset

	
		
		Information
	


	
		
		Wiki Pages
	

There are 189161 wiki items in total. Last updated at 2024-06-16 02:31:27 UTC.
These are the information of recent 50 wiki items:

	
		
id
title
other_names
text_length
is_locked
is_deleted
created_at
updated_at


		
196503
li_yuting_(female)
[""离雨婷""… See the full description on the dataset page: https://huggingface.co/datasets/deepghs/danbooru_wikis_full.",https://huggingface.co/datasets/deepghs/danbooru_wikis_full,"['en', 'ja', 'zh', 'ko']","['text-classification', 'text-generation', 'feature-extraction']",['100K<n<1M']
litagin/moe-speech,litagin,2024-01-19 12:20:19+00:00,2025-05-26 02:52:02+00:00,168,261,"['task_categories:text-to-speech', 'task_categories:audio-to-audio', 'task_categories:audio-classification', 'task_ids:speaker-identification', 'multilinguality:monolingual', 'language:ja', 'license:other', 'size_categories:100K<n<1M', 'modality:audio', 'region:us', 'speech', 'audio', 'japanese', 'anime', 'voice', 'not-for-all-audiences']","
	
		
		Recomendation of OOPPEENN's VisualNovel_Dataset
	

I recommend OOPPEENN/VisualNovel_Dataset for Japanese voice corpus, which is:

Similar speech domain to this one (Japanese anime-style speech from Japanese Visual Novel), but
Huge amounts of audio compared to this dataset (600 hours for this, 10,000 hours for Galgame_Dataset!)
This dataset contains about 50 games, and Galgame_Dataset contains more than 500 games!


Contains true transcripts of each audio (this dataset doesn't contain… See the full description on the dataset page: https://huggingface.co/datasets/litagin/moe-speech.",https://huggingface.co/datasets/litagin/moe-speech,['ja'],"['text-to-speech', 'audio-to-audio', 'audio-classification']",['100K<n<1M']
Amber-River/Pixiv-2.6M,Amber-River,2024-06-25 18:06:59+00:00,2024-09-29 08:02:41+00:00,655,35,"['task_categories:image-classification', 'task_categories:image-to-text', 'task_categories:image-to-image', 'task_categories:text-to-image', 'task_categories:image-feature-extraction', 'language:en', 'language:ja', 'license:mit', 'size_categories:1M<n<10M', 'region:us', 'not-for-all-audiences']","
	
		
		Pixiv 2.6M specific
	

This dataset contain 2.6M images from Pixiv.

	
		
		Introduction
	

This dataset aims to add some concepts which is lacked or banned in danbooru.

	
		
		Images Content
	

The images is collected with search cralwer made with selenium and python
I use some tags which may lack in danbooru for example ""scenery"" or some tags for ""explicit contents"" to do the search and collect the url of result than download all the image.
Since there are lot of posts with multiple… See the full description on the dataset page: https://huggingface.co/datasets/Amber-River/Pixiv-2.6M.",https://huggingface.co/datasets/Amber-River/Pixiv-2.6M,"['en', 'ja']","['image-classification', 'image-to-text', 'image-to-image', 'text-to-image', 'image-feature-extraction']",['1M<n<10M']
deepghs/sankaku_full,deepghs,2024-10-23 06:42:37+00:00,2025-01-03 18:15:21+00:00,3406,92,"['task_categories:image-classification', 'task_categories:zero-shot-image-classification', 'task_categories:text-to-image', 'annotations_creators:no-annotation', 'source_datasets:sankaku', 'language:en', 'language:ja', 'license:other', 'size_categories:10M<n<100M', 'region:us', 'art', 'anime', 'not-for-all-audiences']","
	
		
		Sankaku Full Dataset
	

This is the full dataset of chan.sankakucomplex.com. And all the original images are maintained here.

	
		
		How to Painlessly Use This
	

Use cheesechaser to quickly get images from this repository.
Before using this code, you have to grant the access from this gated repository. And then set your personal HuggingFace token into HF_TOKEN environment variable to give the code authorization for this repository.
from cheesechaser.datapool import SankakuDataPool… See the full description on the dataset page: https://huggingface.co/datasets/deepghs/sankaku_full.",https://huggingface.co/datasets/deepghs/sankaku_full,"['en', 'ja']","['image-classification', 'zero-shot-image-classification', 'text-to-image']",['10M<n<100M']
Aratako/Synthetic-Japanese-Roleplay-NSFW-Claude-4.5s-3.5k,Aratako,2025-10-07 16:20:02+00:00,2025-10-07 16:26:41+00:00,51,1,"['task_categories:text-generation', 'language:ja', 'license:cc-by-nc-sa-4.0', 'size_categories:1K<n<10K', 'format:parquet', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us', 'roleplay', 'not-for-all-audiences']","
	
		
		Synthetic-Japanese-Roleplay-NSFW-Claude-4.5s-3.5k
	


	
		
		概要
	

Claude 4.5 Sonnetを用いて作成した、3500件の日本語ロールプレイの対話を収録した合成データセットです。各データは10ターンから20ターン程度あります。
このデータセットはNSFW表現を含みます。

	
		
		データの詳細
	

各データは以下のキーを含んでいます。

major_genre: ジャンル（大分類）
minor_genre: ジャンル（小分類）
tag: 年齢制限用タグ（R-18）
world_setting: 舞台・世界観の設定
scene_setting: 対話シーンの設定
user_setting: ユーザー側のキャラクターの設定
assistant_setting: アシスタント側のキャラクターの設定
dialogue_tone: 対話のトーン
system_message: ロールプレイ指示用のシステムメッセージ
conversations:… See the full description on the dataset page: https://huggingface.co/datasets/Aratako/Synthetic-Japanese-Roleplay-NSFW-Claude-4.5s-3.5k.",https://huggingface.co/datasets/Aratako/Synthetic-Japanese-Roleplay-NSFW-Claude-4.5s-3.5k,['ja'],['text-generation'],['1K<n<10K']
mutiyama/alt,mutiyama,2022-03-02 23:29:22+00:00,2024-01-09 12:07:24+00:00,813,19,"['task_categories:translation', 'task_categories:token-classification', 'task_ids:parsing', 'annotations_creators:expert-generated', 'language_creators:crowdsourced', 'multilinguality:multilingual', 'multilinguality:translation', 'source_datasets:original', 'language:bn', 'language:en', 'language:fil', 'language:hi', 'language:id', 'language:ja', 'language:km', 'language:lo', 'language:ms', 'language:my', 'language:th', 'language:vi', 'language:zh', 'license:cc-by-4.0', 'size_categories:100K<n<1M', 'format:parquet', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","
	
		
		Dataset Card for Asian Language Treebank (ALT)
	


	
		
		Dataset Summary
	

The ALT project aims to advance the state-of-the-art Asian natural language processing (NLP) techniques through the open collaboration for developing and using ALT. It was first conducted by NICT and UCSY as described in Ye Kyaw Thu, Win Pa Pa, Masao Utiyama, Andrew Finch and Eiichiro Sumita (2016). Then, it was developed under ASEAN IVO as described in this Web page. 
The process of building ALT began with… See the full description on the dataset page: https://huggingface.co/datasets/mutiyama/alt.",https://huggingface.co/datasets/mutiyama/alt,"['bn', 'en', 'fil', 'hi', 'id', 'ja', 'km', 'lo', 'ms', 'my', 'th', 'vi', 'zh']","['translation', 'token-classification']",['100K<n<1M']
defunct-datasets/amazon_reviews_multi,defunct-datasets,2022-03-02 23:29:22+00:00,2023-11-02 14:52:21+00:00,5160,99,"['task_categories:summarization', 'task_categories:text-generation', 'task_categories:fill-mask', 'task_categories:text-classification', 'task_ids:text-scoring', 'task_ids:language-modeling', 'task_ids:masked-language-modeling', 'task_ids:sentiment-classification', 'task_ids:sentiment-scoring', 'task_ids:topic-classification', 'annotations_creators:found', 'language_creators:found', 'multilinguality:monolingual', 'multilinguality:multilingual', 'source_datasets:original', 'language:de', 'language:en', 'language:es', 'language:fr', 'language:ja', 'language:zh', 'license:other', 'size_categories:100K<n<1M', 'arxiv:2010.02573', 'region:us']","We provide an Amazon product reviews dataset for multilingual text classification. The dataset contains reviews in English, Japanese, German, French, Chinese and Spanish, collected between November 1, 2015 and November 1, 2019. Each record in the dataset contains the review text, the review title, the star rating, an anonymized reviewer ID, an anonymized product ID and the coarse-grained product category (e.g. ‘books’, ‘appliances’, etc.) The corpus is balanced across stars, so each star rating constitutes 20% of the reviews in each language.

For each language, there are 200,000, 5,000 and 5,000 reviews in the training, development and test sets respectively. The maximum number of reviews per reviewer is 20 and the maximum number of reviews per product is 20. All reviews are truncated after 2,000 characters, and all reviews are at least 20 characters long.

Note that the language of a review does not necessarily match the language of its marketplace (e.g. reviews from amazon.de are primarily written in German, but could also be written in English, etc.). For this reason, we applied a language detection algorithm based on the work in Bojanowski et al. (2017) to determine the language of the review text and we removed reviews that were not written in the expected language.",https://huggingface.co/datasets/defunct-datasets/amazon_reviews_multi,"['de', 'en', 'es', 'fr', 'ja', 'zh']","['summarization', 'text-generation', 'fill-mask', 'text-classification']",['100K<n<1M']
ryo0634/bsd_ja_en,ryo0634,2022-03-02 23:29:22+00:00,2024-01-11 07:36:44+00:00,140,12,"['task_categories:translation', 'annotations_creators:expert-generated', 'language_creators:expert-generated', 'multilinguality:translation', 'source_datasets:original', 'language:en', 'language:ja', 'license:cc-by-nc-sa-4.0', 'size_categories:10K<n<100K', 'format:parquet', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us', 'business-conversations-translation']","
	
		
		Dataset Card for Business Scene Dialogue
	


	
		
		Dataset Summary
	

This is the Business Scene Dialogue (BSD) dataset, 
a Japanese-English parallel corpus containing written conversations
in various business scenarios. 
The dataset was constructed in 3 steps: 

selecting business scenes, 
writing monolingual conversation scenarios according to the selected scenes, and 
translating the scenarios into the other language.

Half of the monolingual scenarios were written in Japanese 
and… See the full description on the dataset page: https://huggingface.co/datasets/ryo0634/bsd_ja_en.",https://huggingface.co/datasets/ryo0634/bsd_ja_en,"['en', 'ja']",['translation'],['10K<n<100K']
legacy-datasets/common_voice,legacy-datasets,2022-03-02 23:29:22+00:00,2024-08-22 08:27:23+00:00,14346,140,"['task_categories:automatic-speech-recognition', 'annotations_creators:crowdsourced', 'language_creators:crowdsourced', 'multilinguality:multilingual', 'source_datasets:extended|common_voice', 'language:ab', 'language:ar', 'language:as', 'language:br', 'language:ca', 'language:cnh', 'language:cs', 'language:cv', 'language:cy', 'language:de', 'language:dv', 'language:el', 'language:en', 'language:eo', 'language:es', 'language:et', 'language:eu', 'language:fa', 'language:fi', 'language:fr', 'language:fy', 'language:ga', 'language:hi', 'language:hsb', 'language:hu', 'language:ia', 'language:id', 'language:it', 'language:ja', 'language:ka', 'language:kab', 'language:ky', 'language:lg', 'language:lt', 'language:lv', 'language:mn', 'language:mt', 'language:nl', 'language:or', 'language:pa', 'language:pl', 'language:pt', 'language:rm', 'language:ro', 'language:ru', 'language:rw', 'language:sah', 'language:sl', 'language:sv', 'language:ta', 'language:th', 'language:tr', 'language:tt', 'language:uk', 'language:vi', 'language:vot', 'language:zh', 'license:cc0-1.0', 'size_categories:100K<n<1M', 'region:us']","Common Voice is Mozilla's initiative to help teach machines how real people speak.
The dataset currently consists of 7,335 validated hours of speech in 60 languages, but we’re always adding more voices and languages.",https://huggingface.co/datasets/legacy-datasets/common_voice,"['ab', 'ar', 'as', 'br', 'ca', 'cnh', 'cs', 'cv', 'cy', 'de', 'dv', 'el', 'en', 'eo', 'es', 'et', 'eu', 'fa', 'fi', 'fr', 'fy', 'ga', 'hi', 'hsb', 'hu', 'ia', 'id', 'it', 'ja', 'ka', 'kab', 'ky', 'lg', 'lt', 'lv', 'mn', 'mt', 'nl', 'or', 'pa', 'pl', 'pt', 'rm', 'ro', 'ru', 'rw', 'sah', 'sl', 'sv', 'ta', 'th', 'tr', 'tt', 'uk', 'vi', 'vot', 'zh']",['automatic-speech-recognition'],['100K<n<1M']
conceptnet5/conceptnet5,conceptnet5,2022-03-02 23:29:22+00:00,2024-02-08 12:07:58+00:00,347,23,"['task_categories:text-classification', 'task_ids:multi-class-classification', 'annotations_creators:crowdsourced', 'language_creators:crowdsourced', 'language_creators:found', 'multilinguality:monolingual', 'source_datasets:original', 'language:de', 'language:en', 'language:es', 'language:fr', 'language:it', 'language:ja', 'language:nl', 'language:pt', 'language:ru', 'language:zh', 'license:cc-by-4.0', 'size_categories:10M<n<100M', 'format:parquet', 'modality:text', 'library:datasets', 'library:dask', 'library:mlcroissant', 'library:polars', 'arxiv:1612.03975', 'region:us']","
	
		
		Dataset Card for Conceptnet5
	


	
		
		Dataset Summary
	

ConceptNet is a multilingual knowledge base, representing words and
phrases that people use and the common-sense relationships between
them. The knowledge in ConceptNet is collected from a variety of
resources, including crowd-sourced resources (such as Wiktionary and
Open Mind Common Sense), games with a purpose (such as Verbosity and
nadya.jp), and expert-created resources (such as WordNet and JMDict).
You can browse what… See the full description on the dataset page: https://huggingface.co/datasets/conceptnet5/conceptnet5.",https://huggingface.co/datasets/conceptnet5/conceptnet5,"['de', 'en', 'es', 'fr', 'it', 'ja', 'nl', 'pt', 'ru', 'zh']",['text-classification'],['10M<n<100M']
community-datasets/covid_tweets_japanese,community-datasets,2022-03-02 23:29:22+00:00,2024-06-24 11:21:23+00:00,110,2,"['task_categories:text-classification', 'task_ids:fact-checking', 'annotations_creators:crowdsourced', 'language_creators:found', 'multilinguality:monolingual', 'source_datasets:original', 'language:ja', 'license:cc-by-nd-4.0', 'size_categories:10K<n<100K', 'format:parquet', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","
	
		
		Dataset Card for COVID-19 日本語Twitterデータセット (COVID-19 Japanese Twitter Dataset)
	


	
		
		Dataset Summary
	

53,640 Japanese tweets with annotation if a tweet is related to COVID-19 or not. The annotation is by majority decision by 5 - 10 crowd workers. Target tweets include ""COVID"" or ""コロナ"". The period of the tweets is from around January 2020 to around June 2020. The original tweets are not contained. Please use Twitter API to get them, for example.

	
		
		Supported Tasks and… See the full description on the dataset page: https://huggingface.co/datasets/community-datasets/covid_tweets_japanese.",https://huggingface.co/datasets/community-datasets/covid_tweets_japanese,['ja'],['text-classification'],['10K<n<100K']
facebook/covost2,facebook,2022-03-02 23:29:22+00:00,2024-01-18 11:02:25+00:00,453,38,"['task_categories:automatic-speech-recognition', 'annotations_creators:expert-generated', 'language_creators:crowdsourced', 'language_creators:expert-generated', 'multilinguality:multilingual', 'source_datasets:extended|other-common-voice', 'language:ar', 'language:ca', 'language:cy', 'language:de', 'language:es', 'language:et', 'language:fa', 'language:fr', 'language:id', 'language:it', 'language:ja', 'language:lv', 'language:mn', 'language:nl', 'language:pt', 'language:ru', 'language:sl', 'language:sv', 'language:ta', 'language:tr', 'language:zh', 'license:cc-by-nc-4.0', 'size_categories:100K<n<1M', 'arxiv:2007.10310', 'region:us']","CoVoST 2, a large-scale multilingual speech translation corpus covering translations from 21 languages into English and from English into 15 languages. The dataset is created using Mozilla’s open source Common Voice database of crowdsourced voice recordings.

Note that in order to limit the required storage for preparing this dataset, the audio
is stored in the .mp3 format and is not converted to a float32 array. To convert, the audio
file to a float32 array, please make use of the `.map()` function as follows:


```python
import torchaudio

def map_to_array(batch):
    speech_array, _ = torchaudio.load(batch[""file""])
    batch[""speech""] = speech_array.numpy()
    return batch

dataset = dataset.map(map_to_array, remove_columns=[""file""])
```",https://huggingface.co/datasets/facebook/covost2,"['ar', 'ca', 'cy', 'de', 'es', 'et', 'fa', 'fr', 'id', 'it', 'ja', 'lv', 'mn', 'nl', 'pt', 'ru', 'sl', 'sv', 'ta', 'tr', 'zh']",['automatic-speech-recognition'],['100K<n<1M']
Helsinki-NLP/kde4,Helsinki-NLP,2022-03-02 23:29:22+00:00,2024-01-18 11:07:20+00:00,2571,24,"['task_categories:translation', 'annotations_creators:found', 'language_creators:found', 'multilinguality:multilingual', 'source_datasets:original', 'language:af', 'language:ar', 'language:as', 'language:ast', 'language:be', 'language:bg', 'language:bn', 'language:br', 'language:ca', 'language:crh', 'language:cs', 'language:csb', 'language:cy', 'language:da', 'language:de', 'language:el', 'language:en', 'language:eo', 'language:es', 'language:et', 'language:eu', 'language:fa', 'language:fi', 'language:fr', 'language:fy', 'language:ga', 'language:gl', 'language:gu', 'language:ha', 'language:he', 'language:hi', 'language:hne', 'language:hr', 'language:hsb', 'language:hu', 'language:hy', 'language:id', 'language:is', 'language:it', 'language:ja', 'language:ka', 'language:kk', 'language:km', 'language:kn', 'language:ko', 'language:ku', 'language:lb', 'language:lt', 'language:lv', 'language:mai', 'language:mk', 'language:ml', 'language:mr', 'language:ms', 'language:mt', 'language:nb', 'language:nds', 'language:ne', 'language:nl', 'language:nn', 'language:nso', 'language:oc', 'language:or', 'language:pa', 'language:pl', 'language:ps', 'language:pt', 'language:ro', 'language:ru', 'language:rw', 'language:se', 'language:si', 'language:sk', 'language:sl', 'language:sr', 'language:sv', 'language:ta', 'language:te', 'language:tg', 'language:th', 'language:tr', 'language:uk', 'language:uz', 'language:vi', 'language:wa', 'language:xh', 'language:zh', 'license:unknown', 'size_categories:100K<n<1M', 'region:us']","A parallel corpus of KDE4 localization files (v.2).

92 languages, 4,099 bitexts
total number of files: 75,535
total number of tokens: 60.75M
total number of sentence fragments: 8.89M",https://huggingface.co/datasets/Helsinki-NLP/kde4,"['af', 'ar', 'as', 'ast', 'be', 'bg', 'bn', 'br', 'ca', 'crh', 'cs', 'csb', 'cy', 'da', 'de', 'el', 'en', 'eo', 'es', 'et', 'eu', 'fa', 'fi', 'fr', 'fy', 'ga', 'gl', 'gu', 'ha', 'he', 'hi', 'hne', 'hr', 'hsb', 'hu', 'hy', 'id', 'is', 'it', 'ja', 'ka', 'kk', 'km', 'kn', 'ko', 'ku', 'lb', 'lt', 'lv', 'mai', 'mk', 'ml', 'mr', 'ms', 'mt', 'nb', 'nds', 'ne', 'nl', 'nn', 'nso', 'oc', 'or', 'pa', 'pl', 'ps', 'pt', 'ro', 'ru', 'rw', 'se', 'si', 'sk', 'sl', 'sr', 'sv', 'ta', 'te', 'tg', 'th', 'tr', 'uk', 'uz', 'vi', 'wa', 'xh', 'zh']",['translation'],['100K<n<1M']
cis-lmu/m_lama,cis-lmu,2022-03-02 23:29:22+00:00,2025-05-14 08:05:50+00:00,123,6,"['task_categories:question-answering', 'task_categories:text-classification', 'task_ids:open-domain-qa', 'task_ids:text-scoring', 'annotations_creators:crowdsourced', 'annotations_creators:expert-generated', 'annotations_creators:machine-generated', 'language_creators:crowdsourced', 'language_creators:expert-generated', 'language_creators:machine-generated', 'multilinguality:translation', 'source_datasets:extended|lama', 'language:af', 'language:ar', 'language:az', 'language:be', 'language:bg', 'language:bn', 'language:ca', 'language:ceb', 'language:cs', 'language:cy', 'language:da', 'language:de', 'language:el', 'language:en', 'language:es', 'language:et', 'language:eu', 'language:fa', 'language:fi', 'language:fr', 'language:ga', 'language:gl', 'language:he', 'language:hi', 'language:hr', 'language:hu', 'language:hy', 'language:id', 'language:it', 'language:ja', 'language:ka', 'language:ko', 'language:la', 'language:lt', 'language:lv', 'language:ms', 'language:nl', 'language:pl', 'language:pt', 'language:ro', 'language:ru', 'language:sk', 'language:sl', 'language:sq', 'language:sr', 'language:sv', 'language:ta', 'language:th', 'language:tr', 'language:uk', 'language:ur', 'language:vi', 'language:zh', 'license:cc-by-nc-sa-4.0', 'size_categories:100K<n<1M', 'arxiv:2102.00894', 'region:us', 'probing']",mLAMA: a multilingual version of the LAMA benchmark (T-REx and GoogleRE) covering 53 languages.,https://huggingface.co/datasets/cis-lmu/m_lama,"['af', 'ar', 'az', 'be', 'bg', 'bn', 'ca', 'ceb', 'cs', 'cy', 'da', 'de', 'el', 'en', 'es', 'et', 'eu', 'fa', 'fi', 'fr', 'ga', 'gl', 'he', 'hi', 'hr', 'hu', 'hy', 'id', 'it', 'ja', 'ka', 'ko', 'la', 'lt', 'lv', 'ms', 'nl', 'pl', 'pt', 'ro', 'ru', 'sk', 'sl', 'sq', 'sr', 'sv', 'ta', 'th', 'tr', 'uk', 'ur', 'vi', 'zh']","['question-answering', 'text-classification']",['100K<n<1M']
apple/mkqa,apple,2022-03-02 23:29:22+00:00,2024-01-18 11:09:04+00:00,547,40,"['task_categories:question-answering', 'task_ids:open-domain-qa', 'annotations_creators:crowdsourced', 'language_creators:found', 'multilinguality:multilingual', 'multilinguality:translation', 'source_datasets:extended|natural_questions', 'source_datasets:original', 'language:ar', 'language:da', 'language:de', 'language:en', 'language:es', 'language:fi', 'language:fr', 'language:he', 'language:hu', 'language:it', 'language:ja', 'language:km', 'language:ko', 'language:ms', 'language:nl', 'language:no', 'language:pl', 'language:pt', 'language:ru', 'language:sv', 'language:th', 'language:tr', 'language:vi', 'language:zh', 'license:cc-by-3.0', 'size_categories:10K<n<100K', 'arxiv:2007.15207', 'region:us']","We introduce MKQA, an open-domain question answering evaluation set comprising 10k question-answer pairs sampled from the Google Natural Questions dataset, aligned across 26 typologically diverse languages (260k question-answer pairs in total). For each query we collected new passage-independent answers. These queries and answers were then human translated into 25 Non-English languages.",https://huggingface.co/datasets/apple/mkqa,"['ar', 'da', 'de', 'en', 'es', 'fi', 'fr', 'he', 'hu', 'it', 'ja', 'km', 'ko', 'ms', 'nl', 'no', 'pl', 'pt', 'ru', 'sv', 'th', 'tr', 'vi', 'zh']",['question-answering'],['10K<n<100K']
Helsinki-NLP/news_commentary,Helsinki-NLP,2022-03-02 23:29:22+00:00,2024-02-29 15:28:06+00:00,1883,37,"['task_categories:translation', 'annotations_creators:found', 'language_creators:found', 'multilinguality:multilingual', 'source_datasets:original', 'language:ar', 'language:cs', 'language:de', 'language:en', 'language:es', 'language:fr', 'language:it', 'language:ja', 'language:nl', 'language:pt', 'language:ru', 'language:zh', 'license:unknown', 'size_categories:1M<n<10M', 'format:parquet', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","
	
		
		Dataset Card for OPUS News-Commentary
	


	
		
		Dataset Summary
	

[More Information Needed]

	
		
		Supported Tasks and Leaderboards
	

[More Information Needed]

	
		
		Languages
	

[More Information Needed]

	
		
		Dataset Structure
	


	
		
		Data Instances
	

[More Information Needed]

	
		
		Data Fields
	

[More Information Needed]

	
		
		Data Splits
	

[More Information Needed]

	
		
		Dataset Creation
	


	
		
		Curation Rationale
	

[More Information Needed]

	
		
		Source… See the full description on the dataset page: https://huggingface.co/datasets/Helsinki-NLP/news_commentary.",https://huggingface.co/datasets/Helsinki-NLP/news_commentary,"['ar', 'cs', 'de', 'en', 'es', 'fr', 'it', 'ja', 'nl', 'pt', 'ru', 'zh']",['translation'],['1M<n<10M']
Helsinki-NLP/open_subtitles,Helsinki-NLP,2022-03-02 23:29:22+00:00,2024-01-18 11:11:17+00:00,853,71,"['task_categories:translation', 'annotations_creators:found', 'language_creators:found', 'multilinguality:multilingual', 'source_datasets:original', 'language:af', 'language:ar', 'language:bg', 'language:bn', 'language:br', 'language:bs', 'language:ca', 'language:cs', 'language:da', 'language:de', 'language:el', 'language:en', 'language:eo', 'language:es', 'language:et', 'language:eu', 'language:fa', 'language:fi', 'language:fr', 'language:gl', 'language:he', 'language:hi', 'language:hr', 'language:hu', 'language:hy', 'language:id', 'language:is', 'language:it', 'language:ja', 'language:ka', 'language:kk', 'language:ko', 'language:lt', 'language:lv', 'language:mk', 'language:ml', 'language:ms', 'language:nl', 'language:no', 'language:pl', 'language:pt', 'language:ro', 'language:ru', 'language:si', 'language:sk', 'language:sl', 'language:sq', 'language:sr', 'language:sv', 'language:ta', 'language:te', 'language:th', 'language:tl', 'language:tr', 'language:uk', 'language:ur', 'language:vi', 'language:zh', 'license:unknown', 'size_categories:10K<n<100K', 'region:us']","This is a new collection of translated movie subtitles from http://www.opensubtitles.org/.

IMPORTANT: If you use the OpenSubtitle corpus: Please, add a link to http://www.opensubtitles.org/ to your website and to your reports and publications produced with the data!

This is a slightly cleaner version of the subtitle collection using improved sentence alignment and better language checking.

62 languages, 1,782 bitexts
total number of files: 3,735,070
total number of tokens: 22.10G
total number of sentence fragments: 3.35G",https://huggingface.co/datasets/Helsinki-NLP/open_subtitles,"['af', 'ar', 'bg', 'bn', 'br', 'bs', 'ca', 'cs', 'da', 'de', 'el', 'en', 'eo', 'es', 'et', 'eu', 'fa', 'fi', 'fr', 'gl', 'he', 'hi', 'hr', 'hu', 'hy', 'id', 'is', 'it', 'ja', 'ka', 'kk', 'ko', 'lt', 'lv', 'mk', 'ml', 'ms', 'nl', 'no', 'pl', 'pt', 'ro', 'ru', 'si', 'sk', 'sl', 'sq', 'sr', 'sv', 'ta', 'te', 'th', 'tl', 'tr', 'uk', 'ur', 'vi', 'zh']",['translation'],['10K<n<100K']
Helsinki-NLP/opus-100,Helsinki-NLP,2022-03-02 23:29:22+00:00,2024-02-28 09:17:34+00:00,22054,208,"['task_categories:translation', 'annotations_creators:no-annotation', 'language_creators:found', 'multilinguality:translation', 'source_datasets:extended', 'language:af', 'language:am', 'language:an', 'language:ar', 'language:as', 'language:az', 'language:be', 'language:bg', 'language:bn', 'language:br', 'language:bs', 'language:ca', 'language:cs', 'language:cy', 'language:da', 'language:de', 'language:dz', 'language:el', 'language:en', 'language:eo', 'language:es', 'language:et', 'language:eu', 'language:fa', 'language:fi', 'language:fr', 'language:fy', 'language:ga', 'language:gd', 'language:gl', 'language:gu', 'language:ha', 'language:he', 'language:hi', 'language:hr', 'language:hu', 'language:hy', 'language:id', 'language:ig', 'language:is', 'language:it', 'language:ja', 'language:ka', 'language:kk', 'language:km', 'language:kn', 'language:ko', 'language:ku', 'language:ky', 'language:li', 'language:lt', 'language:lv', 'language:mg', 'language:mk', 'language:ml', 'language:mn', 'language:mr', 'language:ms', 'language:mt', 'language:my', 'language:nb', 'language:ne', 'language:nl', 'language:nn', 'language:no', 'language:oc', 'language:or', 'language:pa', 'language:pl', 'language:ps', 'language:pt', 'language:ro', 'language:ru', 'language:rw', 'language:se', 'language:sh', 'language:si', 'language:sk', 'language:sl', 'language:sq', 'language:sr', 'language:sv', 'language:ta', 'language:te', 'language:tg', 'language:th', 'language:tk', 'language:tr', 'language:tt', 'language:ug', 'language:uk', 'language:ur', 'language:uz', 'language:vi', 'language:wa', 'language:xh', 'language:yi', 'language:yo', 'language:zh', 'language:zu', 'license:unknown', 'size_categories:10M<n<100M', 'format:parquet', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'arxiv:2004.11867', 'region:us']","
	
		
		Dataset Card for OPUS-100
	


	
		
		Dataset Summary
	

OPUS-100 is an English-centric multilingual corpus covering 100 languages.
OPUS-100 is English-centric, meaning that all training pairs include English on either the source or target side. The corpus covers 100 languages (including English).
The languages were selected based on the volume of parallel data available in OPUS.

	
		
		Supported Tasks and Leaderboards
	

Translation.

	
		
		Languages
	

OPUS-100 contains… See the full description on the dataset page: https://huggingface.co/datasets/Helsinki-NLP/opus-100.",https://huggingface.co/datasets/Helsinki-NLP/opus-100,"['af', 'am', 'an', 'ar', 'as', 'az', 'be', 'bg', 'bn', 'br', 'bs', 'ca', 'cs', 'cy', 'da', 'de', 'dz', 'el', 'en', 'eo', 'es', 'et', 'eu', 'fa', 'fi', 'fr', 'fy', 'ga', 'gd', 'gl', 'gu', 'ha', 'he', 'hi', 'hr', 'hu', 'hy', 'id', 'ig', 'is', 'it', 'ja', 'ka', 'kk', 'km', 'kn', 'ko', 'ku', 'ky', 'li', 'lt', 'lv', 'mg', 'mk', 'ml', 'mn', 'mr', 'ms', 'mt', 'my', 'nb', 'ne', 'nl', 'nn', 'no', 'oc', 'or', 'pa', 'pl', 'ps', 'pt', 'ro', 'ru', 'rw', 'se', 'sh', 'si', 'sk', 'sl', 'sq', 'sr', 'sv', 'ta', 'te', 'tg', 'th', 'tk', 'tr', 'tt', 'ug', 'uk', 'ur', 'uz', 'vi', 'wa', 'xh', 'yi', 'yo', 'zh', 'zu']",['translation'],['10M<n<100M']
Helsinki-NLP/opus_openoffice,Helsinki-NLP,2022-03-02 23:29:22+00:00,2024-02-22 15:14:50+00:00,411,7,"['task_categories:translation', 'annotations_creators:found', 'language_creators:found', 'multilinguality:multilingual', 'source_datasets:original', 'language:de', 'language:en', 'language:es', 'language:fr', 'language:ja', 'language:ru', 'language:sv', 'language:zh', 'license:unknown', 'size_categories:1M<n<10M', 'format:parquet', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","
	
		
		Dataset Card for [Dataset Name]
	


	
		
		Dataset Summary
	

A collection of documents from http://www.openoffice.org/.
8 languages, 28 bitexts

	
		
		Supported Tasks and Leaderboards
	

The underlying task is machine translation.

	
		
		Languages
	

[More Information Needed]

	
		
		Dataset Structure
	


	
		
		Data Instances
	

[More Information Needed]

	
		
		Data Fields
	

[More Information Needed]

	
		
		Data Splits
	

[More Information Needed]

	
		
		Dataset Creation… See the full description on the dataset page: https://huggingface.co/datasets/Helsinki-NLP/opus_openoffice.",https://huggingface.co/datasets/Helsinki-NLP/opus_openoffice,"['de', 'en', 'es', 'fr', 'ja', 'ru', 'sv', 'zh']",['translation'],['1M<n<10M']
ParaPat/para_pat,ParaPat,2022-03-02 23:29:22+00:00,2024-01-18 11:12:32+00:00,127,16,"['task_categories:text-generation', 'task_categories:fill-mask', 'task_categories:translation', 'task_ids:language-modeling', 'task_ids:masked-language-modeling', 'annotations_creators:machine-generated', 'language_creators:expert-generated', 'multilinguality:translation', 'source_datasets:original', 'language:cs', 'language:de', 'language:el', 'language:en', 'language:es', 'language:fr', 'language:hu', 'language:ja', 'language:ko', 'language:pt', 'language:ro', 'language:ru', 'language:sk', 'language:uk', 'language:zh', 'license:cc-by-4.0', 'size_categories:10K<n<100K', 'region:us']","ParaPat: The Multi-Million Sentences Parallel Corpus of Patents Abstracts

This dataset contains the developed parallel corpus from the open access Google
Patents dataset in 74 language pairs, comprising more than 68 million sentences
and 800 million tokens. Sentences were automatically aligned using the Hunalign algorithm
for the largest 22 language pairs, while the others were abstract (i.e. paragraph) aligned.",https://huggingface.co/datasets/ParaPat/para_pat,"['cs', 'de', 'el', 'en', 'es', 'fr', 'hu', 'ja', 'ko', 'pt', 'ro', 'ru', 'sk', 'uk', 'zh']","['text-generation', 'fill-mask', 'translation']",['10K<n<100K']
google-research-datasets/paws-x,google-research-datasets,2022-03-02 23:29:22+00:00,2024-01-04 16:17:17+00:00,5691,47,"['task_categories:text-classification', 'task_ids:semantic-similarity-classification', 'task_ids:semantic-similarity-scoring', 'task_ids:text-scoring', 'task_ids:multi-input-text-classification', 'annotations_creators:expert-generated', 'annotations_creators:machine-generated', 'language_creators:expert-generated', 'language_creators:machine-generated', 'multilinguality:multilingual', 'source_datasets:extended|other-paws', 'language:de', 'language:en', 'language:es', 'language:fr', 'language:ja', 'language:ko', 'language:zh', 'license:other', 'size_categories:100K<n<1M', 'format:parquet', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'arxiv:1908.11828', 'region:us', 'paraphrase-identification']","
	
		
		Dataset Card for PAWS-X: A Cross-lingual Adversarial Dataset for Paraphrase Identification
	


	
		
		Dataset Summary
	

This dataset contains 23,659 human translated PAWS evaluation pairs and
296,406 machine translated training pairs in six typologically distinct
languages: French, Spanish, German, Chinese, Japanese, and Korean. All
translated pairs are sourced from examples in
PAWS-Wiki.
For further details, see the accompanying paper:
PAWS-X: A Cross-lingual Adversarial Dataset for… See the full description on the dataset page: https://huggingface.co/datasets/google-research-datasets/paws-x.",https://huggingface.co/datasets/google-research-datasets/paws-x,"['de', 'en', 'es', 'fr', 'ja', 'ko', 'zh']",['text-classification'],['100K<n<1M']
Helsinki-NLP/php,Helsinki-NLP,2022-03-02 23:29:22+00:00,2024-01-18 11:12:57+00:00,109,4,"['task_categories:translation', 'annotations_creators:found', 'language_creators:found', 'multilinguality:multilingual', 'source_datasets:original', 'language:cs', 'language:de', 'language:en', 'language:es', 'language:fi', 'language:fr', 'language:he', 'language:hu', 'language:it', 'language:ja', 'language:ko', 'language:nl', 'language:pl', 'language:pt', 'language:ro', 'language:ru', 'language:sk', 'language:sl', 'language:sv', 'language:tr', 'language:tw', 'language:zh', 'license:unknown', 'size_categories:10K<n<100K', 'region:us']","A parallel corpus originally extracted from http://se.php.net/download-docs.php. The original documents are written in English and have been partly translated into 21 languages. The original manuals contain about 500,000 words. The amount of actually translated texts varies for different languages between 50,000 and 380,000 words. The corpus is rather noisy and may include parts from the English original in some of the translations. The corpus is tokenized and each language pair has been sentence aligned.

23 languages, 252 bitexts
total number of files: 71,414
total number of tokens: 3.28M
total number of sentence fragments: 1.38M",https://huggingface.co/datasets/Helsinki-NLP/php,"['cs', 'de', 'en', 'es', 'fi', 'fr', 'he', 'hu', 'it', 'ja', 'ko', 'nl', 'pl', 'pt', 'ro', 'ru', 'sk', 'sl', 'sv', 'tr', 'tw', 'zh']",['translation'],['10K<n<100K']
rmyeid/polyglot_ner,rmyeid,2022-03-02 23:29:22+00:00,2024-01-18 11:13:26+00:00,1668,39,"['task_categories:token-classification', 'task_ids:named-entity-recognition', 'annotations_creators:machine-generated', 'language_creators:found', 'multilinguality:multilingual', 'source_datasets:original', 'language:ar', 'language:bg', 'language:ca', 'language:cs', 'language:da', 'language:de', 'language:el', 'language:en', 'language:es', 'language:et', 'language:fa', 'language:fi', 'language:fr', 'language:he', 'language:hi', 'language:hr', 'language:hu', 'language:id', 'language:it', 'language:ja', 'language:ko', 'language:lt', 'language:lv', 'language:ms', 'language:nl', 'language:no', 'language:pl', 'language:pt', 'language:ro', 'language:ru', 'language:sk', 'language:sl', 'language:sr', 'language:sv', 'language:th', 'language:tl', 'language:tr', 'language:uk', 'language:vi', 'language:zh', 'license:unknown', 'arxiv:1410.3791', 'region:us']","Polyglot-NER
A training dataset automatically generated from Wikipedia and Freebase the task
of named entity recognition. The dataset contains the basic Wikipedia based
training data for 40 languages we have (with coreference resolution) for the task of
named entity recognition. The details of the procedure of generating them is outlined in
Section 3 of the paper (https://arxiv.org/abs/1410.3791). Each config contains the data
corresponding to a different language. For example, ""es"" includes only spanish examples.",https://huggingface.co/datasets/rmyeid/polyglot_ner,"['ar', 'bg', 'ca', 'cs', 'da', 'de', 'el', 'en', 'es', 'et', 'fa', 'fi', 'fr', 'he', 'hi', 'hr', 'hu', 'id', 'it', 'ja', 'ko', 'lt', 'lv', 'ms', 'nl', 'no', 'pl', 'pt', 'ro', 'ru', 'sk', 'sl', 'sr', 'sv', 'th', 'tl', 'tr', 'uk', 'vi', 'zh']",['token-classification'],[]
senti-lex/senti_lex,senti-lex,2022-03-02 23:29:22+00:00,2023-06-08 12:24:00+00:00,1719,8,"['task_categories:text-classification', 'task_ids:sentiment-classification', 'annotations_creators:expert-generated', 'language_creators:expert-generated', 'multilinguality:multilingual', 'source_datasets:original', 'language:af', 'language:an', 'language:ar', 'language:az', 'language:be', 'language:bg', 'language:bn', 'language:br', 'language:bs', 'language:ca', 'language:cs', 'language:cy', 'language:da', 'language:de', 'language:el', 'language:eo', 'language:es', 'language:et', 'language:eu', 'language:fa', 'language:fi', 'language:fo', 'language:fr', 'language:fy', 'language:ga', 'language:gd', 'language:gl', 'language:gu', 'language:he', 'language:hi', 'language:hr', 'language:ht', 'language:hu', 'language:hy', 'language:ia', 'language:id', 'language:io', 'language:is', 'language:it', 'language:ja', 'language:ka', 'language:km', 'language:kn', 'language:ko', 'language:ku', 'language:ky', 'language:la', 'language:lb', 'language:lt', 'language:lv', 'language:mk', 'language:mr', 'language:ms', 'language:mt', 'language:nl', 'language:nn', 'language:no', 'language:pl', 'language:pt', 'language:rm', 'language:ro', 'language:ru', 'language:sk', 'language:sl', 'language:sq', 'language:sr', 'language:sv', 'language:sw', 'language:ta', 'language:te', 'language:th', 'language:tk', 'language:tl', 'language:tr', 'language:uk', 'language:ur', 'language:uz', 'language:vi', 'language:vo', 'language:wa', 'language:yi', 'language:zh', 'language:zhw', 'license:gpl-3.0', 'size_categories:1K<n<10K', 'region:us']",This dataset add sentiment lexicons for 81 languages generated via graph propagation based on a knowledge graph--a graphical representation of real-world entities and the links between them.,https://huggingface.co/datasets/senti-lex/senti_lex,"['af', 'an', 'ar', 'az', 'be', 'bg', 'bn', 'br', 'bs', 'ca', 'cs', 'cy', 'da', 'de', 'el', 'eo', 'es', 'et', 'eu', 'fa', 'fi', 'fo', 'fr', 'fy', 'ga', 'gd', 'gl', 'gu', 'he', 'hi', 'hr', 'ht', 'hu', 'hy', 'ia', 'id', 'io', 'is', 'it', 'ja', 'ka', 'km', 'kn', 'ko', 'ku', 'ky', 'la', 'lb', 'lt', 'lv', 'mk', 'mr', 'ms', 'mt', 'nl', 'nn', 'no', 'pl', 'pt', 'rm', 'ro', 'ru', 'sk', 'sl', 'sq', 'sr', 'sv', 'sw', 'ta', 'te', 'th', 'tk', 'tl', 'tr', 'uk', 'ur', 'uz', 'vi', 'vo', 'wa', 'yi', 'zh', 'zhw']",['text-classification'],['1K<n<10K']
SNOW-NLP/snow_simplified_japanese_corpus,SNOW-NLP,2022-03-02 23:29:22+00:00,2024-01-18 11:16:01+00:00,117,21,"['task_categories:translation', 'annotations_creators:crowdsourced', 'annotations_creators:other', 'language_creators:found', 'multilinguality:translation', 'source_datasets:original', 'language:en', 'language:ja', 'license:cc-by-4.0', 'size_categories:10K<n<100K', 'region:us']","About SNOW T15: The simplified corpus for the Japanese language. The corpus has 50,000 manually simplified and aligned sentences. This corpus contains the original sentences, simplified sentences and English translation of the original sentences. It can be used for automatic text simplification as well as translating simple Japanese into English and vice-versa. The core vocabulary is restricted to 2,000 words where it is selected by accounting for several factors such as meaning preservation, variation, simplicity and the UniDic word segmentation criterion.
For details, refer to the explanation page of Japanese simplification (http://www.jnlp.org/research/Japanese_simplification). The original texts are from ""small_parallel_enja: 50k En/Ja Parallel Corpus for Testing SMT Methods"", which is a bilingual corpus for machine translation. About SNOW T23: An expansion corpus of 35,000 sentences rewritten in easy Japanese (simple Japanese vocabulary) based on SNOW T15. The original texts are from ""Tanaka Corpus"" (http://www.edrdg.org/wiki/index.php/Tanaka_Corpus).",https://huggingface.co/datasets/SNOW-NLP/snow_simplified_japanese_corpus,"['en', 'ja']",['translation'],['10K<n<100K']
Helsinki-NLP/tanzil,Helsinki-NLP,2022-03-02 23:29:22+00:00,2024-01-18 11:16:42+00:00,189,4,"['task_categories:translation', 'annotations_creators:found', 'language_creators:found', 'multilinguality:multilingual', 'source_datasets:original', 'language:am', 'language:ar', 'language:az', 'language:bg', 'language:bn', 'language:bs', 'language:cs', 'language:de', 'language:dv', 'language:en', 'language:es', 'language:fa', 'language:fr', 'language:ha', 'language:hi', 'language:id', 'language:it', 'language:ja', 'language:ko', 'language:ku', 'language:ml', 'language:ms', 'language:nl', 'language:no', 'language:pl', 'language:pt', 'language:ro', 'language:ru', 'language:sd', 'language:so', 'language:sq', 'language:sv', 'language:sw', 'language:ta', 'language:tg', 'language:th', 'language:tr', 'language:tt', 'language:ug', 'language:ur', 'language:uz', 'language:zh', 'license:unknown', 'size_categories:100K<n<1M', 'region:us']","This is a collection of Quran translations compiled by the Tanzil project
The translations provided at this page are for non-commercial purposes only. If used otherwise, you need to obtain necessary permission from the translator or the publisher.

If you are using more than three of the following translations in a website or application, we require you to put a link back to this page to make sure that subsequent users have access to the latest updates.

42 languages, 878 bitexts
total number of files: 105
total number of tokens: 22.33M
total number of sentence fragments: 1.01M",https://huggingface.co/datasets/Helsinki-NLP/tanzil,"['am', 'ar', 'az', 'bg', 'bn', 'bs', 'cs', 'de', 'dv', 'en', 'es', 'fa', 'fr', 'ha', 'hi', 'id', 'it', 'ja', 'ko', 'ku', 'ml', 'ms', 'nl', 'no', 'pl', 'pt', 'ro', 'ru', 'sd', 'so', 'sq', 'sv', 'sw', 'ta', 'tg', 'th', 'tr', 'tt', 'ug', 'ur', 'uz', 'zh']",['translation'],['100K<n<1M']
community-datasets/tapaco,community-datasets,2022-03-02 23:29:22+00:00,2024-06-26 07:42:27+00:00,1788,47,"['task_categories:translation', 'task_categories:text-classification', 'task_ids:semantic-similarity-classification', 'annotations_creators:machine-generated', 'language_creators:crowdsourced', 'multilinguality:multilingual', 'source_datasets:extended|other-tatoeba', 'language:af', 'language:ar', 'language:az', 'language:be', 'language:ber', 'language:bg', 'language:bn', 'language:br', 'language:ca', 'language:cbk', 'language:cmn', 'language:cs', 'language:da', 'language:de', 'language:el', 'language:en', 'language:eo', 'language:es', 'language:et', 'language:eu', 'language:fi', 'language:fr', 'language:gl', 'language:gos', 'language:he', 'language:hi', 'language:hr', 'language:hu', 'language:hy', 'language:ia', 'language:id', 'language:ie', 'language:io', 'language:is', 'language:it', 'language:ja', 'language:jbo', 'language:kab', 'language:ko', 'language:kw', 'language:la', 'language:lfn', 'language:lt', 'language:mk', 'language:mr', 'language:nb', 'language:nds', 'language:nl', 'language:orv', 'language:ota', 'language:pes', 'language:pl', 'language:pt', 'language:rn', 'language:ro', 'language:ru', 'language:sl', 'language:sr', 'language:sv', 'language:tk', 'language:tl', 'language:tlh', 'language:tok', 'language:tr', 'language:tt', 'language:ug', 'language:uk', 'language:ur', 'language:vi', 'language:vo', 'language:war', 'language:wuu', 'language:yue', 'license:cc-by-2.0', 'size_categories:1M<n<10M', 'format:parquet', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us', 'paraphrase-generation']","
	
		
		Dataset Card for TaPaCo Corpus
	


	
		
		Dataset Summary
	

A freely available paraphrase corpus for 73 languages extracted from the Tatoeba database. 
Tatoeba is a crowdsourcing project mainly geared towards language learners. Its aim is to provide example sentences 
and translations for particular linguistic constructions and words. The paraphrase corpus is created by populating a 
graph with Tatoeba sentences and equivalence links between sentences “meaning the same thing”. This… See the full description on the dataset page: https://huggingface.co/datasets/community-datasets/tapaco.",https://huggingface.co/datasets/community-datasets/tapaco,"['af', 'ar', 'az', 'be', 'ber', 'bg', 'bn', 'br', 'ca', 'cbk', 'cmn', 'cs', 'da', 'de', 'el', 'en', 'eo', 'es', 'et', 'eu', 'fi', 'fr', 'gl', 'gos', 'he', 'hi', 'hr', 'hu', 'hy', 'ia', 'id', 'ie', 'io', 'is', 'it', 'ja', 'jbo', 'kab', 'ko', 'kw', 'la', 'lfn', 'lt', 'mk', 'mr', 'nb', 'nds', 'nl', 'orv', 'ota', 'pes', 'pl', 'pt', 'rn', 'ro', 'ru', 'sl', 'sr', 'sv', 'tk', 'tl', 'tlh', 'tok', 'tr', 'tt', 'ug', 'uk', 'ur', 'vi', 'vo', 'war', 'wuu', 'yue']","['translation', 'text-classification']",['1M<n<10M']
google-research-datasets/tydiqa,google-research-datasets,2022-03-02 23:29:22+00:00,2024-08-08 05:57:11+00:00,1656,34,"['task_categories:question-answering', 'task_ids:extractive-qa', 'annotations_creators:crowdsourced', 'language_creators:crowdsourced', 'multilinguality:multilingual', 'source_datasets:extended|wikipedia', 'language:ar', 'language:bn', 'language:en', 'language:fi', 'language:id', 'language:ja', 'language:ko', 'language:ru', 'language:sw', 'language:te', 'language:th', 'license:apache-2.0', 'size_categories:100K<n<1M', 'format:parquet', 'modality:text', 'library:datasets', 'library:dask', 'library:mlcroissant', 'library:polars', 'region:us']","
	
		
		Dataset Card for ""tydiqa""
	


	
		
		Dataset Summary
	

TyDi QA is a question answering dataset covering 11 typologically diverse languages with 204K question-answer pairs.
The languages of TyDi QA are diverse with regard to their typology -- the set of linguistic features that each language
expresses -- such that we expect models performing well on this set to generalize across a large number of the languages
in the world. It contains language phenomena that would not be found in… See the full description on the dataset page: https://huggingface.co/datasets/google-research-datasets/tydiqa.",https://huggingface.co/datasets/google-research-datasets/tydiqa,"['ar', 'bn', 'en', 'fi', 'id', 'ja', 'ko', 'ru', 'sw', 'te', 'th']",['question-answering'],['100K<n<1M']
google-research-datasets/wiki_atomic_edits,google-research-datasets,2022-03-02 23:29:22+00:00,2024-01-18 11:18:00+00:00,332,15,"['task_categories:summarization', 'annotations_creators:found', 'language_creators:found', 'multilinguality:multilingual', 'source_datasets:original', 'language:de', 'language:en', 'language:es', 'language:fr', 'language:it', 'language:ja', 'language:ru', 'language:zh', 'license:cc-by-sa-4.0', 'size_categories:100K<n<1M', 'region:us']","A dataset of atomic wikipedia edits containing insertions and deletions of a contiguous chunk of text in a sentence. This dataset contains ~43 million edits across 8 languages.

An atomic edit is defined as an edit e applied to a natural language expression S as the insertion, deletion, or substitution of a sub-expression P such that both the original expression S and the resulting expression e(S) are well-formed semantic constituents (MacCartney, 2009). In this corpus, we release such atomic insertions and deletions made to sentences in wikipedia.",https://huggingface.co/datasets/google-research-datasets/wiki_atomic_edits,"['de', 'en', 'es', 'fr', 'it', 'ja', 'ru', 'zh']",['summarization'],['100K<n<1M']
esdurmus/wiki_lingua,esdurmus,2022-03-02 23:29:22+00:00,2024-01-05 08:06:54+00:00,930,50,"['task_categories:summarization', 'annotations_creators:crowdsourced', 'language_creators:crowdsourced', 'multilinguality:multilingual', 'source_datasets:original', 'language:ar', 'language:cs', 'language:de', 'language:en', 'language:es', 'language:fr', 'language:hi', 'language:id', 'language:it', 'language:ja', 'language:ko', 'language:nl', 'language:pt', 'language:ru', 'language:th', 'language:tr', 'language:vi', 'language:zh', 'license:cc-by-3.0', 'size_categories:100K<n<1M', 'format:parquet', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'arxiv:2010.03093', 'region:us']","
	
		
		Dataset Card for ""wiki_lingua""
	


	
		
		Dataset Summary
	

We introduce WikiLingua, a large-scale, multilingual dataset for the evaluation of cross-lingual abstractive summarization systems. We extract article and summary pairs in 18 languages from WikiHow, a high quality, collaborative resource of how-to guides on a diverse set of topics written by human authors. We create gold-standard article-summary alignments across languages by aligning the images that are used to describe each… See the full description on the dataset page: https://huggingface.co/datasets/esdurmus/wiki_lingua.",https://huggingface.co/datasets/esdurmus/wiki_lingua,"['ar', 'cs', 'de', 'en', 'es', 'fr', 'hi', 'id', 'it', 'ja', 'ko', 'nl', 'pt', 'ru', 'th', 'tr', 'vi', 'zh']",['summarization'],['100K<n<1M']
INK-USC/xcsr,INK-USC,2022-03-02 23:29:22+00:00,2024-01-04 17:03:17+00:00,3725,7,"['task_categories:question-answering', 'task_ids:multiple-choice-qa', 'annotations_creators:crowdsourced', 'language_creators:crowdsourced', 'language_creators:machine-generated', 'multilinguality:multilingual', 'source_datasets:extended|codah', 'source_datasets:extended|commonsense_qa', 'language:ar', 'language:de', 'language:en', 'language:es', 'language:fr', 'language:hi', 'language:it', 'language:ja', 'language:nl', 'language:pl', 'language:pt', 'language:ru', 'language:sw', 'language:ur', 'language:vi', 'language:zh', 'license:mit', 'size_categories:10K<n<100K', 'format:parquet', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'arxiv:2106.06937', 'region:us']","
	
		
		Dataset Card for X-CSR
	


	
		
		Dataset Summary
	

To evaluate multi-lingual language models (ML-LMs) for commonsense reasoning in a cross-lingual zero-shot transfer setting (X-CSR), i.e., training in English and test in other languages, we create two benchmark datasets, namely X-CSQA and X-CODAH. Specifically, we automatically translate the original CSQA and CODAH datasets, which only have English versions, to 15 other languages, forming development and test sets for studying X-CSR.… See the full description on the dataset page: https://huggingface.co/datasets/INK-USC/xcsr.",https://huggingface.co/datasets/INK-USC/xcsr,"['ar', 'de', 'en', 'es', 'fr', 'hi', 'it', 'ja', 'nl', 'pl', 'pt', 'ru', 'sw', 'ur', 'vi', 'zh']",['question-answering'],['10K<n<100K']
akariasai/xor_tydi_qa,akariasai,2022-03-02 23:29:22+00:00,2024-01-18 11:18:45+00:00,155,2,"['task_categories:question-answering', 'task_ids:open-domain-qa', 'annotations_creators:crowdsourced', 'language_creators:expert-generated', 'language_creators:found', 'multilinguality:multilingual', 'source_datasets:original', 'source_datasets:extended|tydiqa', 'language:ar', 'language:bn', 'language:fi', 'language:ja', 'language:ko', 'language:ru', 'language:te', 'license:mit', 'size_categories:10K<n<100K', 'arxiv:2010.11856', 'region:us']","    XOR-TyDi QA brings together for the first time information-seeking questions,
    open-retrieval QA, and multilingual QA to create a multilingual open-retrieval
    QA dataset that enables cross-lingual answer retrieval. It consists of questions
    written by information-seeking native speakers in 7 typologically diverse languages
    and answer annotations that are retrieved from multilingual document collections.
    There are three sub-tasks: XOR-Retrieve, XOR-EnglishSpan, and XOR-Full.",https://huggingface.co/datasets/akariasai/xor_tydi_qa,"['ar', 'bn', 'fi', 'ja', 'ko', 'ru', 'te']",['question-answering'],['10K<n<100K']
google/xtreme,google,2022-03-02 23:29:22+00:00,2024-02-22 17:12:06+00:00,17838,108,"['task_categories:multiple-choice', 'task_categories:question-answering', 'task_categories:token-classification', 'task_categories:text-classification', 'task_categories:text-retrieval', 'task_ids:multiple-choice-qa', 'task_ids:extractive-qa', 'task_ids:open-domain-qa', 'task_ids:natural-language-inference', 'task_ids:named-entity-recognition', 'task_ids:part-of-speech', 'annotations_creators:found', 'language_creators:found', 'multilinguality:multilingual', 'multilinguality:translation', 'source_datasets:extended|xnli', 'source_datasets:extended|paws-x', 'source_datasets:extended|wikiann', 'source_datasets:extended|xquad', 'source_datasets:extended|mlqa', 'source_datasets:extended|tydiqa', 'source_datasets:extended|tatoeba', 'source_datasets:extended|squad', 'language:af', 'language:ar', 'language:bg', 'language:bn', 'language:de', 'language:el', 'language:en', 'language:es', 'language:et', 'language:eu', 'language:fa', 'language:fi', 'language:fr', 'language:he', 'language:hi', 'language:hu', 'language:id', 'language:it', 'language:ja', 'language:jv', 'language:ka', 'language:kk', 'language:ko', 'language:ml', 'language:mr', 'language:ms', 'language:my', 'language:nl', 'language:pt', 'language:ru', 'language:sw', 'language:ta', 'language:te', 'language:th', 'language:tl', 'language:tr', 'language:ur', 'language:vi', 'language:yo', 'language:zh', 'license:apache-2.0', 'license:cc-by-4.0', 'license:cc-by-2.0', 'license:cc-by-sa-4.0', 'license:other', 'license:cc-by-nc-4.0', 'size_categories:1M<n<10M', 'format:parquet', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'arxiv:2003.11080', 'region:us', 'parallel-sentence-retrieval', 'paraphrase-identification']","
	
		
		Dataset Card for ""xtreme""
	


	
		
		Dataset Summary
	

The Cross-lingual Natural Language Inference (XNLI) corpus is a crowd-sourced collection of 5,000 test and
2,500 dev pairs for the MultiNLI corpus. The pairs are annotated with textual entailment and translated into
14 languages: French, Spanish, German, Greek, Bulgarian, Russian, Turkish, Arabic, Vietnamese, Thai, Chinese,
Hindi, Swahili and Urdu. This results in 112.5k annotated pairs. Each premise can be associated with the… See the full description on the dataset page: https://huggingface.co/datasets/google/xtreme.",https://huggingface.co/datasets/google/xtreme,"['af', 'ar', 'bg', 'bn', 'de', 'el', 'en', 'es', 'et', 'eu', 'fa', 'fi', 'fr', 'he', 'hi', 'hu', 'id', 'it', 'ja', 'jv', 'ka', 'kk', 'ko', 'ml', 'mr', 'ms', 'my', 'nl', 'pt', 'ru', 'sw', 'ta', 'te', 'th', 'tl', 'tr', 'ur', 'vi', 'yo', 'zh']","['multiple-choice', 'question-answering', 'token-classification', 'text-classification', 'text-retrieval']",['1M<n<10M']
Atsushi/fungi_diagnostic_chars_comparison_japanese,Atsushi,2022-03-02 23:29:22+00:00,2025-09-26 00:07:56+00:00,208,0,"['task_categories:text-classification', 'task_ids:multi-class-classification', 'annotations_creators:other', 'multilinguality:monolingual', 'source_datasets:original', 'language:ja', 'license:cc-by-4.0', 'size_categories:100K<n<1M', 'format:csv', 'modality:tabular', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","
	
		
		fungi_diagnostic_chars_comparison_japanese大菌輪「識別形質まとめ」データセット最終更新日 / Last updated: 2025/5/2（up to R3-12744）
	


	
		
		Languages
	

Japanese  
This dataset is available in Japanese only.  

	
		
		概要 / Overview
	

Atsushi Nakajima（中島淳志）が個人で運営しているWebサイト大菌輪では、数千件以上の菌類分類学論文を「論文3行まとめ」という形で要約および索引付け（インデキシング）した情報を提供しています。その一環として、ある菌と別の菌の「共通する」あるいは「異なる」識別形質 (diagnostic characters) に関する記述を人手で抽出しています。
Daikinrin, a website personally operated by Atsushi Nakajima, provides summaries and indexing… See the full description on the dataset page: https://huggingface.co/datasets/Atsushi/fungi_diagnostic_chars_comparison_japanese.",https://huggingface.co/datasets/Atsushi/fungi_diagnostic_chars_comparison_japanese,['ja'],['text-classification'],['100K<n<1M']
Atsushi/fungi_indexed_mycological_papers_japanese,Atsushi,2022-03-02 23:29:22+00:00,2025-09-26 00:08:01+00:00,177,0,"['annotations_creators:other', 'multilinguality:monolingual', 'source_datasets:original', 'language:ja', 'license:cc-by-4.0', 'size_categories:10K<n<100K', 'format:csv', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","
	
		
		fungi_indexed_mycological_papers_japanese
大菌輪「論文3行まとめ」データセット最終更新日：2025/5/2（R3-12744まで）  
	


	
		
		Languages
	

Japanese  
This dataset is available in Japanese only.  

	
		
		概要 / Overview
	

大菌輪は、Atsushi Nakajima（中島淳志）が個人で運営しているWebサイトです。ここでは、数千件以上の菌類分類学論文を「論文3行まとめ」という形で要約および索引付け（インデキシング）した情報を提供しています。
Daikinrin is a website personally operated by Atsushi Nakajima. It provides summaries and indexing information for thousands of mycological taxonomy papers in the form of ""Three-line… See the full description on the dataset page: https://huggingface.co/datasets/Atsushi/fungi_indexed_mycological_papers_japanese.",https://huggingface.co/datasets/Atsushi/fungi_indexed_mycological_papers_japanese,['ja'],[],['10K<n<100K']
Atsushi/fungi_trait_circus_database,Atsushi,2022-03-02 23:29:22+00:00,2025-09-28 11:20:44+00:00,126,0,"['task_categories:other', 'annotations_creators:other', 'multilinguality:multilingual', 'source_datasets:original', 'language:en', 'language:ja', 'license:cc-by-4.0', 'size_categories:1M<n<10M', 'format:parquet', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us', 'fungi', 'mycology', 'taxonomy', 'traits', 'biodiversity', 'natural-language-processing', 'controlled-vocabulary', 'morphology']","
	
		
		fungi_trait_circus_database
	


	
		
		大菌輪「Trait Circus」データセット（統制形質）
最終更新日：2025/09/28
重要：データ形式を大幅に更新しました（v2.0）
	


	
		
		Languages
	

Japanese and English
Please do not use this dataset for academic purposes for the time being. (casual use only)
非専門家が作成したデータセットです。学術目的での使用はご遠慮ください。

	
		
		更新履歴
	


2025/09/28 (v2.0) - データ構造を全面改訂、Parquet形式に移行、データ量を約2倍に拡充（約400万件）
2025/08/12 (v1.0) - 初回公開版（約180万件）


	
		
		概要
	

Atsushi Nakajima（中島淳志）が個人で運営しているWebサイト大菌輪… See the full description on the dataset page: https://huggingface.co/datasets/Atsushi/fungi_trait_circus_database.",https://huggingface.co/datasets/Atsushi/fungi_trait_circus_database,"['en', 'ja']",['other'],['1M<n<10M']
GEM/surface_realisation_st_2020,GEM,2022-03-02 23:29:22+00:00,2022-10-24 15:30:30+00:00,763,1,"['task_categories:table-to-text', 'annotations_creators:none', 'language_creators:unknown', 'multilinguality:unknown', 'source_datasets:original', 'language:ar', 'language:zh', 'language:en', 'language:fr', 'language:hi', 'language:id', 'language:ja', 'language:ko', 'language:pt', 'language:ru', 'language:es', 'license:cc-by-2.5', 'size_categories:100K<n<1M', 'format:json', 'modality:text', 'library:datasets', 'library:dask', 'library:mlcroissant', 'region:us', 'data-to-text']","
	
		
		Dataset Card for GEM/surface_realisation_st_2020
	


	
		
		Link to Main Data Card
	

You can find the main data card on the GEM Website.

	
		
		Dataset Summary
	

This dataset was used as part of the multilingual surface realization shared task in which a model gets full or partial universal dependency structures and has to reconstruct the natural language. This dataset support 11 languages. 
You can load the dataset via:
import datasets
data =… See the full description on the dataset page: https://huggingface.co/datasets/GEM/surface_realisation_st_2020.",https://huggingface.co/datasets/GEM/surface_realisation_st_2020,"['ar', 'zh', 'en', 'fr', 'hi', 'id', 'ja', 'ko', 'pt', 'ru', 'es']",['table-to-text'],['100K<n<1M']
GEM/wiki_lingua,GEM,2022-03-02 23:29:22+00:00,2023-02-16 09:23:29+00:00,31383,50,"['task_categories:summarization', 'annotations_creators:none', 'language_creators:unknown', 'multilinguality:multilingual', 'source_datasets:original', 'language:ar', 'language:cs', 'language:de', 'language:en', 'language:es', 'language:fr', 'language:hi', 'language:id', 'language:it', 'language:ja', 'language:ko', 'language:nl', 'language:pt', 'language:ru', 'language:th', 'language:tr', 'language:vi', 'language:zh', 'license:cc-by-nc-sa-3.0', 'region:us']","WikiLingua is a large-scale multilingual dataset for the evaluation of
crosslingual abstractive summarization systems. The dataset includes ~770k
article and summary pairs in 18 languages from WikiHow. The gold-standard
article-summary alignments across languages was done by aligning the images
that are used to describe each how-to step in an article.",https://huggingface.co/datasets/GEM/wiki_lingua,"['ar', 'cs', 'de', 'en', 'es', 'fr', 'hi', 'id', 'it', 'ja', 'ko', 'nl', 'pt', 'ru', 'th', 'tr', 'vi', 'zh']",['summarization'],[]
GEM/xlsum,GEM,2022-03-02 23:29:22+00:00,2024-10-03 19:09:00+00:00,4385,5,"['task_categories:summarization', 'annotations_creators:none', 'language_creators:unknown', 'multilinguality:unknown', 'source_datasets:original', 'language:am', 'language:ar', 'language:az', 'language:bn', 'language:my', 'language:zh', 'language:en', 'language:fr', 'language:gu', 'language:ha', 'language:hi', 'language:ig', 'language:id', 'language:ja', 'language:rn', 'language:ko', 'language:ky', 'language:mr', 'language:ne', 'language:om', 'language:ps', 'language:fa', 'language:gpe', 'language:pt', 'language:pa', 'language:ru', 'language:gd', 'language:sr', 'language:rsb', 'language:si', 'language:so', 'language:es', 'language:sw', 'language:ta', 'language:te', 'language:th', 'language:ti', 'language:tr', 'language:uk', 'language:ur', 'language:uz', 'language:vi', 'language:cy', 'language:yo', 'license:cc-by-nc-sa-4.0', 'arxiv:1607.01759', 'region:us']","We present XLSum, a comprehensive and diverse dataset comprising 1.35 million professionally
annotated article-summary pairs from BBC, extracted using a set of carefully designed heuristics.
The dataset covers 45 languages ranging from low to high-resource, for many of which no
public dataset is currently available. XL-Sum is highly abstractive, concise,
and of high quality, as indicated by human and intrinsic evaluation.",https://huggingface.co/datasets/GEM/xlsum,"['am', 'ar', 'az', 'bn', 'my', 'zh', 'en', 'fr', 'gu', 'ha', 'hi', 'ig', 'id', 'ja', 'rn', 'ko', 'ky', 'mr', 'ne', 'om', 'ps', 'fa', 'gpe', 'pt', 'pa', 'ru', 'gd', 'sr', 'rsb', 'si', 'so', 'es', 'sw', 'ta', 'te', 'th', 'ti', 'tr', 'uk', 'ur', 'uz', 'vi', 'cy', 'yo']",['summarization'],[]
Helsinki-NLP/tatoeba_mt,Helsinki-NLP,2022-03-02 23:29:22+00:00,2024-10-08 18:12:10+00:00,2023,61,"['task_categories:text-generation', 'task_categories:translation', 'annotations_creators:no-annotation', 'language_creators:crowdsourced', 'multilinguality:translation', 'source_datasets:original', 'language:af', 'language:ar', 'language:az', 'language:be', 'language:bg', 'language:bn', 'language:br', 'language:bs', 'language:ca', 'language:ch', 'language:cs', 'language:cv', 'language:cy', 'language:da', 'language:de', 'language:el', 'language:en', 'language:eo', 'language:es', 'language:et', 'language:eu', 'language:fa', 'language:fi', 'language:fo', 'language:fr', 'language:fy', 'language:ga', 'language:gd', 'language:gl', 'language:gn', 'language:he', 'language:hi', 'language:hr', 'language:hu', 'language:hy', 'language:ia', 'language:id', 'language:ie', 'language:io', 'language:is', 'language:it', 'language:ja', 'language:jv', 'language:ka', 'language:kk', 'language:km', 'language:ko', 'language:ku', 'language:kw', 'language:la', 'language:lb', 'language:lt', 'language:lv', 'language:mi', 'language:mk', 'language:ml', 'language:mn', 'language:mr', 'language:ms', 'language:mt', 'language:my', 'language:nb', 'language:nl', 'language:nn', 'language:no', 'language:oc', 'language:pl', 'language:pt', 'language:qu', 'language:rn', 'language:ro', 'language:ru', 'language:sh', 'language:sl', 'language:sq', 'language:sr', 'language:sv', 'language:sw', 'language:ta', 'language:te', 'language:th', 'language:tk', 'language:tl', 'language:tr', 'language:tt', 'language:ug', 'language:uk', 'language:ur', 'language:uz', 'language:vi', 'language:vo', 'language:yi', 'language:zh', 'license:cc-by-2.0', 'region:us']","The Tatoeba Translation Challenge is a multilingual data set of
machine translation benchmarks derived from user-contributed
translations collected by [Tatoeba.org](https://tatoeba.org/) and
provided as parallel corpus from [OPUS](https://opus.nlpl.eu/). This
dataset includes test and development data sorted by language pair. It
includes test sets for hundreds of language pairs and is continuously
updated. Please, check the version number tag to refer to the release
that your are using.",https://huggingface.co/datasets/Helsinki-NLP/tatoeba_mt,"['af', 'ar', 'az', 'be', 'bg', 'bn', 'br', 'bs', 'ca', 'ch', 'cs', 'cv', 'cy', 'da', 'de', 'el', 'en', 'eo', 'es', 'et', 'eu', 'fa', 'fi', 'fo', 'fr', 'fy', 'ga', 'gd', 'gl', 'gn', 'he', 'hi', 'hr', 'hu', 'hy', 'ia', 'id', 'ie', 'io', 'is', 'it', 'ja', 'jv', 'ka', 'kk', 'km', 'ko', 'ku', 'kw', 'la', 'lb', 'lt', 'lv', 'mi', 'mk', 'ml', 'mn', 'mr', 'ms', 'mt', 'my', 'nb', 'nl', 'nn', 'no', 'oc', 'pl', 'pt', 'qu', 'rn', 'ro', 'ru', 'sh', 'sl', 'sq', 'sr', 'sv', 'sw', 'ta', 'te', 'th', 'tk', 'tl', 'tr', 'tt', 'ug', 'uk', 'ur', 'uz', 'vi', 'vo', 'yi', 'zh']","['text-generation', 'translation']",[]
SkelterLabsInc/JaQuAD,SkelterLabsInc,2022-03-02 23:29:22+00:00,2022-10-25 09:06:40+00:00,304,11,"['task_categories:question-answering', 'task_ids:extractive-qa', 'annotations_creators:crowdsourced', 'language_creators:crowdsourced', 'language_creators:found', 'multilinguality:monolingual', 'source_datasets:original', 'language:ja', 'license:cc-by-sa-3.0', 'size_categories:10K<n<100K', 'modality:text', 'library:datasets', 'library:mlcroissant', 'arxiv:2202.01764', 'region:us']","
	
		
		Dataset Card for JaQuAD
	


	
		
		Dataset Summary
	

Japanese Question Answering Dataset (JaQuAD), released in 2022, is a
human-annotated dataset created for Japanese Machine Reading Comprehension.
JaQuAD is developed to provide a SQuAD-like QA dataset in Japanese.
JaQuAD contains 39,696 question-answer pairs.
Questions and answers are manually curated by human annotators.
Contexts are collected from Japanese Wikipedia articles.
Fine-tuning BERT-Japanese
on JaQuAD achieves 78.92% for… See the full description on the dataset page: https://huggingface.co/datasets/SkelterLabsInc/JaQuAD.",https://huggingface.co/datasets/SkelterLabsInc/JaQuAD,['ja'],['question-answering'],['10K<n<100K']
anton-l/common_language,anton-l,2022-03-02 23:29:22+00:00,2022-10-21 16:20:41+00:00,155,0,"['annotations_creators:crowdsourced', 'language_creators:crowdsourced', 'multilinguality:multilingual', 'source_datasets:extended|common_voice', 'language:ar', 'language:br', 'language:ca', 'language:cnh', 'language:cs', 'language:cv', 'language:cy', 'language:de', 'language:dv', 'language:el', 'language:en', 'language:eo', 'language:es', 'language:et', 'language:eu', 'language:fa', 'language:fr', 'language:fy', 'language:ia', 'language:id', 'language:it', 'language:ja', 'language:ka', 'language:kab', 'language:ky', 'language:lv', 'language:mn', 'language:mt', 'language:nl', 'language:pl', 'language:pt', 'language:rm', 'language:ro', 'language:ru', 'language:rw', 'language:sah', 'language:sl', 'language:sv', 'language:ta', 'language:tr', 'language:tt', 'language:uk', 'language:zh', 'license:cc-by-nc-4.0', 'size_categories:100K<n<1M', 'region:us']","This dataset is composed of speech recordings from languages that were carefully selected from the CommonVoice database.
The total duration of audio recordings is 45.1 hours (i.e., 1 hour of material for each language).
The dataset has been extracted from CommonVoice to train language-id systems.",https://huggingface.co/datasets/anton-l/common_language,"['ar', 'br', 'ca', 'cnh', 'cs', 'cv', 'cy', 'de', 'dv', 'el', 'en', 'eo', 'es', 'et', 'eu', 'fa', 'fr', 'fy', 'ia', 'id', 'it', 'ja', 'ka', 'kab', 'ky', 'lv', 'mn', 'mt', 'nl', 'pl', 'pt', 'rm', 'ro', 'ru', 'rw', 'sah', 'sl', 'sv', 'ta', 'tr', 'tt', 'uk', 'zh']",[],['100K<n<1M']
lmqg/qg_jaquad,lmqg,2022-03-02 23:29:22+00:00,2022-12-02 18:51:27+00:00,427,5,"['task_categories:text-generation', 'task_ids:language-modeling', 'multilinguality:monolingual', 'source_datasets:SkelterLabsInc/JaQuAD', 'language:ja', 'license:cc-by-sa-3.0', 'size_categories:10K<n<100K', 'modality:text', 'library:datasets', 'library:mlcroissant', 'arxiv:2210.03992', 'region:us', 'question-generation']","[JaQuAD](https://github.com/SkelterLabsInc/JaQuAD) dataset for question generation (QG) task. The test set of the original 
data is not publicly released, so we randomly sampled test questions from the training set.",https://huggingface.co/datasets/lmqg/qg_jaquad,['ja'],['text-generation'],['10K<n<100K']
castorini/mr-tydi-corpus,castorini,2022-03-02 23:29:22+00:00,2022-10-12 20:25:51+00:00,466,8,"['task_categories:text-retrieval', 'multilinguality:multilingual', 'language:ar', 'language:bn', 'language:en', 'language:fi', 'language:id', 'language:ja', 'language:ko', 'language:ru', 'language:sw', 'language:te', 'language:th', 'license:apache-2.0', 'size_categories:10M<n<100M', 'modality:text', 'library:datasets', 'library:mlcroissant', 'arxiv:2108.08787', 'region:us']","
	
		
		Dataset Summary
	

Mr. TyDi is a multi-lingual benchmark dataset built on TyDi, covering eleven typologically diverse languages. It is designed for monolingual retrieval, specifically to evaluate ranking with learned dense representations.
This dataset stores documents of Mr. TyDi. To access the queries and judgments, please refer to castorini/mr-tydi.

	
		
	
	
		Dataset Structure
	

The only configuration here is the language. As all three folds (train, dev and test) share the same… See the full description on the dataset page: https://huggingface.co/datasets/castorini/mr-tydi-corpus.",https://huggingface.co/datasets/castorini/mr-tydi-corpus,"['ar', 'bn', 'en', 'fi', 'id', 'ja', 'ko', 'ru', 'sw', 'te', 'th']",['text-retrieval'],['10M<n<100M']
castorini/mr-tydi,castorini,2022-03-02 23:29:22+00:00,2022-10-12 20:25:19+00:00,2285,21,"['task_categories:text-retrieval', 'multilinguality:multilingual', 'language:ar', 'language:bn', 'language:en', 'language:fi', 'language:id', 'language:ja', 'language:ko', 'language:ru', 'language:sw', 'language:te', 'language:th', 'license:apache-2.0', 'size_categories:100K<n<1M', 'modality:text', 'library:datasets', 'library:mlcroissant', 'arxiv:2108.08787', 'region:us']","
	
		
		Dataset Summary
	

Mr. TyDi is a multi-lingual benchmark dataset built on TyDi, covering eleven typologically diverse languages. It is designed for monolingual retrieval, specifically to evaluate ranking with learned dense representations.
This dataset stores the queries, judgements, and example training data of Mr. TyDi. To access the corpus, please refer to castorini/mr-tydi-corpus.

	
		
	
	
		Dataset Structure
	

The only configuration here is the language, 
For each language… See the full description on the dataset page: https://huggingface.co/datasets/castorini/mr-tydi.",https://huggingface.co/datasets/castorini/mr-tydi,"['ar', 'bn', 'en', 'fi', 'id', 'ja', 'ko', 'ru', 'sw', 'te', 'th']",['text-retrieval'],['100K<n<1M']
clips/mqa,clips,2022-03-02 23:29:22+00:00,2022-09-27 12:38:50+00:00,2942,54,"['task_categories:question-answering', 'task_ids:multiple-choice-qa', 'annotations_creators:no-annotation', 'language_creators:other', 'multilinguality:multilingual', 'source_datasets:original', 'language:ca', 'language:en', 'language:de', 'language:es', 'language:fr', 'language:ru', 'language:ja', 'language:it', 'language:zh', 'language:pt', 'language:nl', 'language:tr', 'language:pl', 'language:vi', 'language:ar', 'language:id', 'language:uk', 'language:ro', 'language:no', 'language:th', 'language:sv', 'language:el', 'language:fi', 'language:he', 'language:da', 'language:cs', 'language:ko', 'language:fa', 'language:hi', 'language:hu', 'language:sk', 'language:lt', 'language:et', 'language:hr', 'language:is', 'language:lv', 'language:ms', 'language:bg', 'language:sr', 'license:cc0-1.0', 'size_categories:100M<n<1B', 'modality:text', 'library:datasets', 'library:mlcroissant', 'region:us']",MQA is a multilingual corpus of questions and answers parsed from the Common Crawl. Questions are divided between Frequently Asked Questions (FAQ) pages and Community Question Answering (CQA) pages.,https://huggingface.co/datasets/clips/mqa,"['ca', 'en', 'de', 'es', 'fr', 'ru', 'ja', 'it', 'zh', 'pt', 'nl', 'tr', 'pl', 'vi', 'ar', 'id', 'uk', 'ro', 'no', 'th', 'sv', 'el', 'fi', 'he', 'da', 'cs', 'ko', 'fa', 'hi', 'hu', 'sk', 'lt', 'et', 'hr', 'is', 'lv', 'ms', 'bg', 'sr']",['question-answering'],['100M<n<1B']
csebuetnlp/xlsum,csebuetnlp,2022-03-02 23:29:22+00:00,2023-04-18 01:46:20+00:00,37454,144,"['task_categories:summarization', 'task_categories:text-generation', 'annotations_creators:found', 'language_creators:found', 'multilinguality:multilingual', 'source_datasets:original', 'language:am', 'language:ar', 'language:az', 'language:bn', 'language:my', 'language:zh', 'language:en', 'language:fr', 'language:gu', 'language:ha', 'language:hi', 'language:ig', 'language:id', 'language:ja', 'language:rn', 'language:ko', 'language:ky', 'language:mr', 'language:ne', 'language:om', 'language:ps', 'language:fa', 'language:pcm', 'language:pt', 'language:pa', 'language:ru', 'language:gd', 'language:sr', 'language:si', 'language:so', 'language:es', 'language:sw', 'language:ta', 'language:te', 'language:th', 'language:ti', 'language:tr', 'language:uk', 'language:ur', 'language:uz', 'language:vi', 'language:cy', 'language:yo', 'license:cc-by-nc-sa-4.0', 'size_categories:1M<n<10M', 'modality:text', 'library:datasets', 'library:mlcroissant', 'arxiv:1607.01759', 'region:us', 'conditional-text-generation']","We present XLSum, a comprehensive and diverse dataset comprising 1.35 million professionally 
annotated article-summary pairs from BBC, extracted using a set of carefully designed heuristics.
The dataset covers 45 languages ranging from low to high-resource, for many of which no
public dataset is currently available. XL-Sum is highly abstractive, concise, 
and of high quality, as indicated by human and intrinsic evaluation.",https://huggingface.co/datasets/csebuetnlp/xlsum,"['am', 'ar', 'az', 'bn', 'my', 'zh', 'en', 'fr', 'gu', 'ha', 'hi', 'ig', 'id', 'ja', 'rn', 'ko', 'ky', 'mr', 'ne', 'om', 'ps', 'fa', 'pcm', 'pt', 'pa', 'ru', 'gd', 'sr', 'si', 'so', 'es', 'sw', 'ta', 'te', 'th', 'ti', 'tr', 'uk', 'ur', 'uz', 'vi', 'cy', 'yo']","['summarization', 'text-generation']",['1M<n<10M']
gsarti/wmt_vat,gsarti,2022-03-02 23:29:22+00:00,2022-10-27 08:37:41+00:00,1409,7,"['task_categories:text-generation', 'task_categories:translation', 'annotations_creators:found', 'language_creators:expert-generated', 'multilinguality:multilingual', 'multilinguality:translation', 'source_datasets:extended|wmt16', 'source_datasets:extended|wmt17', 'source_datasets:extended|wmt18', 'source_datasets:extended|wmt19', 'source_datasets:extended|wmt20', 'language:cs', 'language:de', 'language:en', 'language:et', 'language:fi', 'language:fr', 'language:gu', 'language:iu', 'language:ja', 'language:kk', 'language:km', 'language:lt', 'language:lv', 'language:pl', 'language:ps', 'language:ro', 'language:ru', 'language:ta', 'language:tr', 'language:zh', 'license:unknown', 'region:us', 'conditional-text-generation']","The Variance-Aware Machine Translation corpus contains 70 small and discriminative test sets for machine translation (MT) 
evaluation called variance-aware test sets (VAT), covering 35 translation directions from WMT16 to WMT20 competitions. 
VAT is automatically created by a novel variance-aware filtering method that filters the indiscriminative test instances 
of the current MT benchmark without any human labor. Experimental results show that VAT outperforms the original WMT benchmark 
in terms of the correlation with human judgment across mainstream language pairs and test sets. Further analysis on the properties 
of VAT reveals the challenging linguistic features (e.g., translation of low-frequency words and proper nouns) for the competitive 
MT systems, providing guidance for constructing future MT test sets.",https://huggingface.co/datasets/gsarti/wmt_vat,"['cs', 'de', 'en', 'et', 'fi', 'fr', 'gu', 'iu', 'ja', 'kk', 'km', 'lt', 'lv', 'pl', 'ps', 'ro', 'ru', 'ta', 'tr', 'zh']","['text-generation', 'translation']",[]
pasinit/xlwic,pasinit,2022-03-02 23:29:22+00:00,2022-10-25 09:54:22+00:00,169,6,"['task_categories:text-classification', 'task_ids:semantic-similarity-classification', 'annotations_creators:expert-generated', 'language_creators:found', 'multilinguality:multilingual', 'source_datasets:original', 'language:en', 'language:bg', 'language:zh', 'language:hr', 'language:da', 'language:nl', 'language:et', 'language:fa', 'language:ja', 'language:ko', 'language:it', 'language:fr', 'language:de', 'license:cc-by-nc-4.0', 'size_categories:100K<n<1M', 'modality:text', 'library:datasets', 'library:mlcroissant', 'region:us']","A system's task on any of the XL-WiC datasets is to identify the intended meaning of a word in a context of a given language. XL-WiC is framed as a binary classification task. Each instance in XL-WiC has a target word w, either a verb or a noun, for which two contexts are provided. Each of these contexts triggers a specific meaning of w. The task is to identify if the occurrences of w in the two contexts correspond to the same meaning or not.

XL-WiC provides dev and test sets in the following 12 languages:

Bulgarian (BG)
Danish (DA)
German (DE)
Estonian (ET)
Farsi (FA)
French (FR)
Croatian (HR)
Italian (IT)
Japanese (JA)
Korean (KO)
Dutch (NL)
Chinese (ZH)
and training sets in the following 3 languages:

German (DE)
French (FR)
Italian (IT)",https://huggingface.co/datasets/pasinit/xlwic,"['en', 'bg', 'zh', 'hr', 'da', 'nl', 'et', 'fa', 'ja', 'ko', 'it', 'fr', 'de']",['text-classification'],['100K<n<1M']
vumichien/common_voice_large_jsut_jsss_css10,vumichien,2022-03-02 23:29:22+00:00,2022-10-25 00:35:20+00:00,100,0,"['task_categories:automatic-speech-recognition', 'language_creators:expert-generated', 'multilinguality:monolingual', 'language:ja', 'license:cc-by-nc-nd-4.0', 'region:us']","
	
		
		Dataset Card for vumichien/common_voice_large_jsut_jsss_css10
	

",https://huggingface.co/datasets/vumichien/common_voice_large_jsut_jsss_css10,['ja'],['automatic-speech-recognition'],[]
wikimedia/wikisource,wikimedia,2022-03-02 23:29:22+00:00,2023-12-08 13:36:41+00:00,1346,81,"['task_categories:text-generation', 'task_categories:fill-mask', 'task_ids:language-modeling', 'task_ids:masked-language-modeling', 'language:ar', 'language:as', 'language:az', 'language:ban', 'language:be', 'language:bg', 'language:bn', 'language:br', 'language:bs', 'language:ca', 'language:cs', 'language:cy', 'language:da', 'language:de', 'language:el', 'language:en', 'language:eo', 'language:es', 'language:et', 'language:eu', 'language:fa', 'language:fi', 'language:fo', 'language:fr', 'language:gl', 'language:gu', 'language:he', 'language:hi', 'language:hr', 'language:hu', 'language:hy', 'language:id', 'language:is', 'language:it', 'language:ja', 'language:jv', 'language:kn', 'language:ko', 'language:la', 'language:li', 'language:lij', 'language:lt', 'language:mk', 'language:ml', 'language:mr', 'language:nan', 'language:nap', 'language:nl', 'language:no', 'language:or', 'language:pa', 'language:pl', 'language:pms', 'language:pt', 'language:ro', 'language:ru', 'language:sa', 'language:sah', 'language:sk', 'language:sl', 'language:sr', 'language:su', 'language:sv', 'language:ta', 'language:te', 'language:th', 'language:tr', 'language:uk', 'language:vec', 'language:vi', 'language:wa', 'language:yi', 'language:zh', 'license:cc-by-sa-3.0', 'license:gfdl', 'size_categories:1M<n<10M', 'format:parquet', 'modality:text', 'library:datasets', 'library:dask', 'library:mlcroissant', 'library:polars', 'region:us']","
	
		
		Dataset Card for Wikimedia Wikisource
	


	
		
		Dataset Summary
	

Wikisource dataset containing cleaned articles of all languages.
The dataset is built from the Wikisource dumps (https://dumps.wikimedia.org/)
with one subset per language, each containing a single train split.
Each example contains the content of one full Wikisource text with cleaning to strip
markdown and unwanted sections (references, etc.).
All language subsets have already been processed for recent dump, and you… See the full description on the dataset page: https://huggingface.co/datasets/wikimedia/wikisource.",https://huggingface.co/datasets/wikimedia/wikisource,"['ar', 'as', 'az', 'ban', 'be', 'bg', 'bn', 'br', 'bs', 'ca', 'cs', 'cy', 'da', 'de', 'el', 'en', 'eo', 'es', 'et', 'eu', 'fa', 'fi', 'fo', 'fr', 'gl', 'gu', 'he', 'hi', 'hr', 'hu', 'hy', 'id', 'is', 'it', 'ja', 'jv', 'kn', 'ko', 'la', 'li', 'lij', 'lt', 'mk', 'ml', 'mr', 'nan', 'nap', 'nl', 'no', 'or', 'pa', 'pl', 'pms', 'pt', 'ro', 'ru', 'sa', 'sah', 'sk', 'sl', 'sr', 'su', 'sv', 'ta', 'te', 'th', 'tr', 'uk', 'vec', 'vi', 'wa', 'yi', 'zh']","['text-generation', 'fill-mask']",['1M<n<10M']
yhavinga/ccmatrix,yhavinga,2022-03-19 08:54:43+00:00,2024-03-14 08:43:02+00:00,53232,24,"['task_categories:translation', 'annotations_creators:found', 'language_creators:found', 'multilinguality:multilingual', 'source_datasets:original', 'language:af', 'language:am', 'language:ar', 'language:ast', 'language:az', 'language:be', 'language:bg', 'language:bn', 'language:br', 'language:ca', 'language:ceb', 'language:cs', 'language:cy', 'language:da', 'language:de', 'language:el', 'language:en', 'language:eo', 'language:es', 'language:et', 'language:eu', 'language:fa', 'language:fi', 'language:fr', 'language:fy', 'language:ga', 'language:gd', 'language:gl', 'language:ha', 'language:he', 'language:hi', 'language:hr', 'language:hu', 'language:hy', 'language:id', 'language:ig', 'language:ilo', 'language:is', 'language:it', 'language:ja', 'language:jv', 'language:ka', 'language:kk', 'language:km', 'language:ko', 'language:la', 'language:lb', 'language:lg', 'language:lt', 'language:lv', 'language:mg', 'language:mk', 'language:ml', 'language:mr', 'language:ms', 'language:my', 'language:ne', 'language:nl', 'language:no', 'language:oc', 'language:om', 'language:or', 'language:pl', 'language:pt', 'language:ro', 'language:ru', 'language:sd', 'language:si', 'language:sk', 'language:sl', 'language:so', 'language:sq', 'language:sr', 'language:su', 'language:sv', 'language:sw', 'language:ta', 'language:tl', 'language:tr', 'language:tt', 'language:uk', 'language:ur', 'language:uz', 'language:vi', 'language:wo', 'language:xh', 'language:yi', 'language:yo', 'language:zh', 'language:zu', 'language:se', 'license:unknown', 'arxiv:1911.04944', 'arxiv:1911.00359', 'arxiv:2010.11125', 'region:us', 'conditional-text-generation']","CCMatrix: Mining Billions of High-Quality Parallel Sentences on the WEB

We show that margin-based bitext mining in LASER's multilingual sentence space can be applied to
monolingual corpora of billions of sentences to produce high quality aligned translation data.
We use thirty-two snapshots of a curated common crawl corpus [1] totaling 69 billion unique sentences.
Using one unified approach for 80 languages, we were able to mine 10.8 billion parallel sentences,
out of which only 2.9 billion are aligned with English.

IMPORTANT: Please cite reference [2][3] if you use this data.

[1] Guillaume Wenzek, Marie-Anne Lachaux, Alexis Conneau, Vishrav Chaudhary, Francisco Guzmán, Armand Jouli
    and Edouard Grave, CCNet: Extracting High Quality Monolingual Datasets from Web Crawl Data

[2] Holger Schwenk, Guillaume Wenzek, Sergey Edunov, Edouard Grave and Armand Joulin,
    CCMatrix: Mining Billions of High-Quality Parallel Sentences on the WEB

[3] Angela Fan, Shruti Bhosale, Holger Schwenk, Zhiyi Ma, Ahmed El-Kishky, Siddharth Goyal, Mandeep Baines,
    Onur Celebi, Guillaume Wenzek, Vishrav Chaudhary, Naman Goyal, Tom Birch, Vitaliy Liptchinsky,
    Sergey Edunov, Edouard Grave, Michael Auli, and Armand Joulin.
    Beyond English-Centric Multilingual Machine Translation
    
90 languages, 1,197 bitexts
total number of files: 90
total number of tokens: 112.14G
total number of sentence fragments: 7.37G",https://huggingface.co/datasets/yhavinga/ccmatrix,"['af', 'am', 'ar', 'ast', 'az', 'be', 'bg', 'bn', 'br', 'ca', 'ceb', 'cs', 'cy', 'da', 'de', 'el', 'en', 'eo', 'es', 'et', 'eu', 'fa', 'fi', 'fr', 'fy', 'ga', 'gd', 'gl', 'ha', 'he', 'hi', 'hr', 'hu', 'hy', 'id', 'ig', 'ilo', 'is', 'it', 'ja', 'jv', 'ka', 'kk', 'km', 'ko', 'la', 'lb', 'lg', 'lt', 'lv', 'mg', 'mk', 'ml', 'mr', 'ms', 'my', 'ne', 'nl', 'no', 'oc', 'om', 'or', 'pl', 'pt', 'ro', 'ru', 'sd', 'si', 'sk', 'sl', 'so', 'sq', 'sr', 'su', 'sv', 'sw', 'ta', 'tl', 'tr', 'tt', 'uk', 'ur', 'uz', 'vi', 'wo', 'xh', 'yi', 'yo', 'zh', 'zu', 'se']",['translation'],[]
csebuetnlp/CrossSum,csebuetnlp,2022-04-20 08:27:10+00:00,2024-06-19 17:09:58+00:00,446,15,"['task_categories:summarization', 'task_ids:news-articles-summarization', 'annotations_creators:found', 'language_creators:found', 'multilinguality:multilingual', 'source_datasets:original', 'language:am', 'language:ar', 'language:az', 'language:bn', 'language:my', 'language:zh', 'language:en', 'language:fr', 'language:gu', 'language:ha', 'language:hi', 'language:ig', 'language:id', 'language:ja', 'language:rn', 'language:ko', 'language:ky', 'language:mr', 'language:ne', 'language:om', 'language:ps', 'language:fa', 'language:pcm', 'language:pt', 'language:pa', 'language:ru', 'language:gd', 'language:sr', 'language:si', 'language:so', 'language:es', 'language:sw', 'language:ta', 'language:te', 'language:th', 'language:ti', 'language:tr', 'language:uk', 'language:ur', 'language:uz', 'language:vi', 'language:cy', 'language:yo', 'license:cc-by-nc-sa-4.0', 'size_categories:1M<n<10M', 'arxiv:2112.08804', 'region:us']","We present CrossSum, a large-scale dataset
comprising 1.70 million cross-lingual article summary samples in 1500+ language-pairs
constituting 45 languages. We use the multilingual XL-Sum dataset and align identical 
articles written in different languages via crosslingual retrieval using a language-agnostic 
representation model.",https://huggingface.co/datasets/csebuetnlp/CrossSum,"['am', 'ar', 'az', 'bn', 'my', 'zh', 'en', 'fr', 'gu', 'ha', 'hi', 'ig', 'id', 'ja', 'rn', 'ko', 'ky', 'mr', 'ne', 'om', 'ps', 'fa', 'pcm', 'pt', 'pa', 'ru', 'gd', 'sr', 'si', 'so', 'es', 'sw', 'ta', 'te', 'th', 'ti', 'tr', 'uk', 'ur', 'uz', 'vi', 'cy', 'yo']",['summarization'],['1M<n<10M']
adithya7/xlel_wd_dictionary,adithya7,2022-04-22 02:36:27+00:00,2022-07-01 17:30:21+00:00,469,3,"['annotations_creators:found', 'language_creators:found', 'multilinguality:multilingual', 'source_datasets:original', 'language:af', 'language:ar', 'language:be', 'language:bg', 'language:bn', 'language:ca', 'language:cs', 'language:da', 'language:de', 'language:el', 'language:en', 'language:es', 'language:fa', 'language:fi', 'language:fr', 'language:he', 'language:hi', 'language:hu', 'language:id', 'language:it', 'language:ja', 'language:ko', 'language:ml', 'language:mr', 'language:ms', 'language:nl', 'language:no', 'language:pl', 'language:pt', 'language:ro', 'language:ru', 'language:si', 'language:sk', 'language:sl', 'language:sr', 'language:sv', 'language:sw', 'language:ta', 'language:te', 'language:th', 'language:tr', 'language:uk', 'language:vi', 'language:zh', 'license:cc-by-4.0', 'size_categories:100K<n<1M', 'modality:text', 'library:datasets', 'library:mlcroissant', 'arxiv:2204.06535', 'region:us']",XLEL-WD is a multilingual event linking dataset. This sub-dataset contains a dictionary of events from Wikidata. The multilingual descriptions for Wikidata event items are taken from the corresponding Wikipedia articles.,https://huggingface.co/datasets/adithya7/xlel_wd_dictionary,"['af', 'ar', 'be', 'bg', 'bn', 'ca', 'cs', 'da', 'de', 'el', 'en', 'es', 'fa', 'fi', 'fr', 'he', 'hi', 'hu', 'id', 'it', 'ja', 'ko', 'ml', 'mr', 'ms', 'nl', 'no', 'pl', 'pt', 'ro', 'ru', 'si', 'sk', 'sl', 'sr', 'sv', 'sw', 'ta', 'te', 'th', 'tr', 'uk', 'vi', 'zh']",[],['100K<n<1M']
adithya7/xlel_wd,adithya7,2022-04-22 02:50:11+00:00,2022-07-13 07:46:57+00:00,970,2,"['annotations_creators:found', 'language_creators:found', 'multilinguality:multilingual', 'source_datasets:original', 'language:af', 'language:ar', 'language:be', 'language:bg', 'language:bn', 'language:ca', 'language:cs', 'language:da', 'language:de', 'language:el', 'language:en', 'language:es', 'language:fa', 'language:fi', 'language:fr', 'language:he', 'language:hi', 'language:hu', 'language:id', 'language:it', 'language:ja', 'language:ko', 'language:ml', 'language:mr', 'language:ms', 'language:nl', 'language:no', 'language:pl', 'language:pt', 'language:ro', 'language:ru', 'language:si', 'language:sk', 'language:sl', 'language:sr', 'language:sv', 'language:sw', 'language:ta', 'language:te', 'language:th', 'language:tr', 'language:uk', 'language:vi', 'language:zh', 'license:cc-by-4.0', 'size_categories:1M<n<10M', 'modality:text', 'library:datasets', 'library:mlcroissant', 'arxiv:2204.06535', 'region:us']",XLEL-WD is a multilingual event linking dataset. This dataset contains mention references from multilingual Wikipedia/Wikinews articles to event items in Wikidata. The text descriptions for Wikidata events are compiled from Wikipedia articles.,https://huggingface.co/datasets/adithya7/xlel_wd,"['af', 'ar', 'be', 'bg', 'bn', 'ca', 'cs', 'da', 'de', 'el', 'en', 'es', 'fa', 'fi', 'fr', 'he', 'hi', 'hu', 'id', 'it', 'ja', 'ko', 'ml', 'mr', 'ms', 'nl', 'no', 'pl', 'pt', 'ro', 'ru', 'si', 'sk', 'sl', 'sr', 'sv', 'sw', 'ta', 'te', 'th', 'tr', 'uk', 'vi', 'zh']",[],['1M<n<10M']
qanastek/MASSIVE,qanastek,2022-04-23 16:23:09+00:00,2022-12-23 21:28:08+00:00,229,26,"['task_categories:text-classification', 'task_ids:intent-classification', 'task_ids:multi-class-classification', 'task_ids:named-entity-recognition', 'annotations_creators:machine-generated', 'annotations_creators:expert-generated', 'language_creators:found', 'multilinguality:multilingual', 'source_datasets:original', 'language:af', 'language:am', 'language:ar', 'language:az', 'language:bn', 'language:cy', 'language:da', 'language:de', 'language:el', 'language:en', 'language:es', 'language:fa', 'language:fi', 'language:fr', 'language:he', 'language:hi', 'language:hu', 'language:hy', 'language:id', 'language:is', 'language:it', 'language:ja', 'language:jv', 'language:ka', 'language:km', 'language:kn', 'language:ko', 'language:lv', 'language:ml', 'language:mn', 'language:ms', 'language:my', 'language:nb', 'language:nl', 'language:pl', 'language:pt', 'language:ro', 'language:ru', 'language:sl', 'language:sq', 'language:sv', 'language:sw', 'language:ta', 'language:te', 'language:th', 'language:tl', 'language:tr', 'language:ur', 'language:vi', 'language:zh', 'size_categories:100K<n<1M', 'arxiv:2204.08582', 'region:us']","MASSIVE is a parallel dataset of > 1M utterances across 51 languages with annotations
for the Natural Language Understanding tasks of intent prediction and slot annotation.
Utterances span 60 intents and include 55 slot types. MASSIVE was created by localizing
the SLURP dataset, composed of general Intelligent Voice Assistant single-shot interactions.",https://huggingface.co/datasets/qanastek/MASSIVE,"['af', 'am', 'ar', 'az', 'bn', 'cy', 'da', 'de', 'el', 'en', 'es', 'fa', 'fi', 'fr', 'he', 'hi', 'hu', 'hy', 'id', 'is', 'it', 'ja', 'jv', 'ka', 'km', 'kn', 'ko', 'lv', 'ml', 'mn', 'ms', 'my', 'nb', 'nl', 'pl', 'pt', 'ro', 'ru', 'sl', 'sq', 'sv', 'sw', 'ta', 'te', 'th', 'tl', 'tr', 'ur', 'vi', 'zh']",['text-classification'],['100K<n<1M']
google/wit,google,2022-05-02 11:22:32+00:00,2022-07-04 10:47:07+00:00,227,59,"['task_categories:text-retrieval', 'task_categories:image-to-text', 'task_ids:image-captioning', 'annotations_creators:machine-generated', 'language_creators:found', 'multilinguality:multilingual', 'source_datasets:original', 'source_datasets:extended|wikipedia', 'language:af', 'language:ar', 'language:ast', 'language:azb', 'language:be', 'language:bg', 'language:bn', 'language:br', 'language:ca', 'language:cs', 'language:cy', 'language:da', 'language:de', 'language:el', 'language:en', 'language:eo', 'language:es', 'language:et', 'language:eu', 'language:fa', 'language:fi', 'language:fr', 'language:fy', 'language:ga', 'language:gl', 'language:hr', 'language:hu', 'language:hy', 'language:id', 'language:it', 'language:iw', 'language:ja', 'language:ka', 'language:ko', 'language:la', 'language:lt', 'language:lv', 'language:mk', 'language:ml', 'language:ms', 'language:nl', 'language:nn', 'language:no', 'language:pl', 'language:pt', 'language:ro', 'language:ru', 'language:sk', 'language:sl', 'language:sr', 'language:sv', 'language:th', 'language:tr', 'language:uk', 'language:ur', 'language:vi', 'language:vo', 'language:zh', 'license:cc-by-sa-3.0', 'size_categories:1M<n<10M', 'modality:image', 'modality:tabular', 'modality:text', 'library:datasets', 'library:mlcroissant', 'arxiv:2103.01913', 'region:us']","Wikipedia-based Image Text (WIT) Dataset is a large multimodal multilingual dataset.
WIT is composed of a curated set of 37.6 million entity rich image-text examples with 11.5 million unique images across 108 Wikipedia languages.
Its size enables WIT to be used as a pretraining dataset for multimodal machine learning models.",https://huggingface.co/datasets/google/wit,"['af', 'ar', 'ast', 'azb', 'be', 'bg', 'bn', 'br', 'ca', 'cs', 'cy', 'da', 'de', 'el', 'en', 'eo', 'es', 'et', 'eu', 'fa', 'fi', 'fr', 'fy', 'ga', 'gl', 'hr', 'hu', 'hy', 'id', 'it', 'iw', 'ja', 'ka', 'ko', 'la', 'lt', 'lv', 'mk', 'ml', 'ms', 'nl', 'nn', 'no', 'pl', 'pt', 'ro', 'ru', 'sk', 'sl', 'sr', 'sv', 'th', 'tr', 'uk', 'ur', 'vi', 'vo', 'zh']","['text-retrieval', 'image-to-text']",['1M<n<10M']
LHF/escorpius-mr,LHF,2022-05-03 18:49:47+00:00,2023-05-11 22:29:21+00:00,12435,5,"['task_categories:text-generation', 'task_categories:fill-mask', 'task_ids:language-modeling', 'task_ids:masked-language-modeling', 'multilinguality:multilingual', 'source_datasets:original', 'language:af', 'language:ar', 'language:bn', 'language:ca', 'language:cs', 'language:da', 'language:de', 'language:el', 'language:eu', 'language:fa', 'language:fi', 'language:fr', 'language:gl', 'language:hi', 'language:hr', 'language:it', 'language:ja', 'language:ko', 'language:mt', 'language:nl', 'language:no', 'language:oc', 'language:pa', 'language:pl', 'language:pt', 'language:ro', 'language:sl', 'language:sr', 'language:sv', 'language:tr', 'language:uk', 'language:ur', 'license:cc-by-nc-nd-4.0', 'size_categories:1B<n<10B', 'format:json', 'modality:text', 'library:datasets', 'library:dask', 'library:mlcroissant', 'arxiv:2206.15147', 'region:us']","
	
		
		esCorpius Multilingual Raw
	

In the recent years, Transformer-based models have lead to significant advances in language modelling for natural language processing. However, they require a vast amount of data to be (pre-)trained and there is a lack of corpora in languages other than English. Recently, several initiatives have presented multilingual datasets obtained from automatic web crawling. However, they present important shortcomings for languages different from English, as they… See the full description on the dataset page: https://huggingface.co/datasets/LHF/escorpius-mr.",https://huggingface.co/datasets/LHF/escorpius-mr,"['af', 'ar', 'bn', 'ca', 'cs', 'da', 'de', 'el', 'eu', 'fa', 'fi', 'fr', 'gl', 'hi', 'hr', 'it', 'ja', 'ko', 'mt', 'nl', 'no', 'oc', 'pa', 'pl', 'pt', 'ro', 'sl', 'sr', 'sv', 'tr', 'uk', 'ur']","['text-generation', 'fill-mask']",['1B<n<10B']
khalidalt/tydiqa-goldp,khalidalt,2022-05-18 14:20:23+00:00,2024-09-10 18:28:52+00:00,734,11,"['task_categories:question-answering', 'task_ids:extractive-qa', 'annotations_creators:crowdsourced', 'language_creators:crowdsourced', 'multilinguality:multilingual', 'source_datasets:extended|wikipedia', 'language:en', 'language:ar', 'language:bn', 'language:fi', 'language:id', 'language:ja', 'language:sw', 'language:ko', 'language:ru', 'language:te', 'language:th', 'license:apache-2.0', 'region:us']","TyDi QA is a question answering dataset covering 11 typologically diverse languages with 204K question-answer pairs.
The languages of TyDi QA are diverse with regard to their typology -- the set of linguistic features that each language
expresses -- such that we expect models performing well on this set to generalize across a large number of the languages
in the world. It contains language phenomena that would not be found in English-only corpora. To provide a realistic
information-seeking task and avoid priming effects, questions are written by people who want to know the answer, but
don’t know the answer yet, (unlike SQuAD and its descendents) and the data is collected directly in each language without
the use of translation (unlike MLQA and XQuAD).",https://huggingface.co/datasets/khalidalt/tydiqa-goldp,"['en', 'ar', 'bn', 'fi', 'id', 'ja', 'sw', 'ko', 'ru', 'te', 'th']",['question-answering'],[]
mteb/amazon_reviews_multi,mteb,2022-05-25 19:22:51+00:00,2022-09-27 19:10:01+00:00,3383,25,"['language:de', 'language:en', 'language:es', 'language:fr', 'language:ja', 'language:zh', 'size_categories:1M<n<10M', 'modality:text', 'library:datasets', 'library:mlcroissant', 'region:us']","We provide an Amazon product reviews dataset for multilingual text classification. The dataset contains reviews in English, Japanese, German, French, Chinese and Spanish, collected between November 1, 2015 and November 1, 2019. Each record in the dataset contains the review text, the review title, the star rating, an anonymized reviewer ID, an anonymized product ID and the coarse-grained product category (e.g. ‘books’, ‘appliances’, etc.) The corpus is balanced across stars, so each star rating constitutes 20% of the reviews in each language.
For each language, there are 200,000, 5,000 and 5,000 reviews in the training, development and test sets respectively. The maximum number of reviews per reviewer is 20 and the maximum number of reviews per product is 20. All reviews are truncated after 2,000 characters, and all reviews are at least 20 characters long.
Note that the language of a review does not necessarily match the language of its marketplace (e.g. reviews from amazon.de are primarily written in German, but could also be written in English, etc.). For this reason, we applied a language detection algorithm based on the work in Bojanowski et al. (2017) to determine the language of the review text and we removed reviews that were not written in the expected language.",https://huggingface.co/datasets/mteb/amazon_reviews_multi,"['de', 'en', 'es', 'fr', 'ja', 'zh']",[],['1M<n<10M']
juletxara/tydiqa_xtreme,juletxara,2022-06-08 10:42:42+00:00,2024-09-10 18:48:21+00:00,1285,1,"['task_categories:question-answering', 'task_ids:extractive-qa', 'annotations_creators:crowdsourced', 'language_creators:crowdsourced', 'multilinguality:multilingual', 'source_datasets:extended|wikipedia', 'language:en', 'language:ar', 'language:bn', 'language:fi', 'language:id', 'language:ja', 'language:sw', 'language:ko', 'language:ru', 'language:te', 'language:th', 'license:apache-2.0', 'arxiv:2003.11080', 'region:us']","TyDi QA is a question answering dataset covering 11 typologically diverse languages with 204K question-answer pairs.
The languages of TyDi QA are diverse with regard to their typology -- the set of linguistic features that each language
expresses -- such that we expect models performing well on this set to generalize across a large number of the languages
in the world. It contains language phenomena that would not be found in English-only corpora. To provide a realistic
information-seeking task and avoid priming effects, questions are written by people who want to know the answer, but
don’t know the answer yet, (unlike SQuAD and its descendents) and the data is collected directly in each language without
the use of translation (unlike MLQA and XQuAD).

We also include ""translate-train"" and ""translate-test"" splits for each non-English languages from XTREME (Hu et al., 2020). These splits are the automatic translations from English to each target language used in the XTREME paper [https://arxiv.org/abs/2003.11080]. The ""translate-train"" split purposefully ignores the non-English TyDiQA-GoldP training data to simulate the transfer learning scenario where original-language data is not available and system builders must rely on labeled English data plus existing machine translation systems.",https://huggingface.co/datasets/juletxara/tydiqa_xtreme,"['en', 'ar', 'bn', 'fi', 'id', 'ja', 'sw', 'ko', 'ru', 'te', 'th']",['question-answering'],[]
AhmedSSabir/Japanese-wiki-dump-sentence-dataset,AhmedSSabir,2022-06-08 11:34:04+00:00,2023-07-11 12:22:09+00:00,114,7,"['task_categories:sentence-similarity', 'task_categories:text-classification', 'task_categories:text-generation', 'language:ja', 'size_categories:1M<n<10M', 'format:text', 'modality:text', 'library:datasets', 'library:mlcroissant', 'region:us']","
	
		
		Dataset
	

5M (5121625) clean Japanese full sentence with the context. This dataset can be used to learn unsupervised semantic similarity, etc.
",https://huggingface.co/datasets/AhmedSSabir/Japanese-wiki-dump-sentence-dataset,['ja'],"['sentence-similarity', 'text-classification', 'text-generation']",['1M<n<10M']
khalidalt/tydiqa-primary,khalidalt,2022-06-16 17:20:46+00:00,2022-07-28 21:56:04+00:00,123,0,"['task_categories:question-answering', 'task_ids:extractive-qa', 'annotations_creators:crowdsourced', 'language_creators:crowdsourced', 'multilinguality:multilingual', 'source_datasets:extended|wikipedia', 'language:en', 'language:ar', 'language:bn', 'language:fi', 'language:id', 'language:ja', 'language:sw', 'language:ko', 'language:ru', 'language:te', 'language:th', 'license:apache-2.0', 'region:us']","TyDi QA is a question answering dataset covering 11 typologically diverse languages with 204K question-answer pairs.
The languages of TyDi QA are diverse with regard to their typology -- the set of linguistic features that each language
expresses -- such that we expect models performing well on this set to generalize across a large number of the languages
in the world. It contains language phenomena that would not be found in English-only corpora. To provide a realistic
information-seeking task and avoid priming effects, questions are written by people who want to know the answer, but
don’t know the answer yet, (unlike SQuAD and its descendents) and the data is collected directly in each language without
the use of translation (unlike MLQA and XQuAD).",https://huggingface.co/datasets/khalidalt/tydiqa-primary,"['en', 'ar', 'bn', 'fi', 'id', 'ja', 'sw', 'ko', 'ru', 'te', 'th']",['question-answering'],[]
LHF/escorpius-m,LHF,2022-07-16 18:37:38+00:00,2023-05-11 22:28:28+00:00,32,3,"['task_categories:text-generation', 'task_categories:fill-mask', 'task_ids:language-modeling', 'task_ids:masked-language-modeling', 'multilinguality:multilingual', 'source_datasets:original', 'language:af', 'language:ar', 'language:bn', 'language:ca', 'language:cs', 'language:da', 'language:de', 'language:el', 'language:eu', 'language:fa', 'language:fi', 'language:fr', 'language:gl', 'language:hi', 'language:hr', 'language:it', 'language:ja', 'language:ko', 'language:mt', 'language:nl', 'language:no', 'language:oc', 'language:pa', 'language:pl', 'language:pt', 'language:ro', 'language:sl', 'language:sr', 'language:sv', 'language:tr', 'language:uk', 'language:ur', 'license:cc-by-nc-nd-4.0', 'size_categories:100B<n<1T', 'arxiv:2206.15147', 'region:us']","
	
		
		esCorpius Multilingual
	

In the recent years, Transformer-based models have lead to significant advances in language modelling for natural language processing. However, they require a vast amount of data to be (pre-)trained and there is a lack of corpora in languages other than English. Recently, several initiatives have presented multilingual datasets obtained from automatic web crawling. However, they present important shortcomings for languages different from English, as they are… See the full description on the dataset page: https://huggingface.co/datasets/LHF/escorpius-m.",https://huggingface.co/datasets/LHF/escorpius-m,"['af', 'ar', 'bn', 'ca', 'cs', 'da', 'de', 'el', 'eu', 'fa', 'fi', 'fr', 'gl', 'hi', 'hr', 'it', 'ja', 'ko', 'mt', 'nl', 'no', 'oc', 'pa', 'pl', 'pt', 'ro', 'sl', 'sr', 'sv', 'tr', 'uk', 'ur']","['text-generation', 'fill-mask']",['100B<n<1T']
Muennighoff/xwinograd,Muennighoff,2022-07-17 15:20:09+00:00,2025-04-28 10:20:36+00:00,13935,17,"['language:en', 'language:fr', 'language:ja', 'language:pt', 'language:ru', 'language:zh', 'license:cc-by-4.0', 'size_categories:1K<n<10K', 'format:parquet', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'arxiv:2211.01786', 'arxiv:2106.12066', 'region:us']","
	
		
		XWinograd
	

Multilingual winograd schema challenge as used in Crosslingual Generalization through Multitask Finetuning.

	
		
		Languages & Samples
	


""en"": 2325
""fr"": 83
""jp"": 959
""pt"": 263 
""ru"": 315
""zh"": 504


	
		
		Dataset creation
	

The Winograd schema challenges in this dataset combine winograd schemas from the XWinograd dataset introduced in Tikhonov et al and as it only contains 16 Chinese schemas, we add 488 Chinese schemas from clue/cluewsc2020.
If you only want the… See the full description on the dataset page: https://huggingface.co/datasets/Muennighoff/xwinograd.",https://huggingface.co/datasets/Muennighoff/xwinograd,"['en', 'fr', 'ja', 'pt', 'ru', 'zh']",[],['1K<n<10K']
google/cvss,google,2022-08-11 00:54:54+00:00,2024-02-10 04:34:53+00:00,109,15,"['language:en', 'language:ar', 'language:ca', 'language:cy', 'language:de', 'language:es', 'language:et', 'language:fa', 'language:fr', 'language:id', 'language:it', 'language:ja', 'language:lv', 'language:mn', 'language:nl', 'language:pt', 'language:ru', 'language:sl', 'language:sv', 'language:ta', 'language:tr', 'language:zh', 'license:cc-by-4.0', 'arxiv:2201.03713', 'region:us']","CVSS is a massively multilingual-to-English speech-to-speech translation corpus,
covering sentence-level parallel speech-to-speech translation pairs from 21
languages into English.",https://huggingface.co/datasets/google/cvss,"['en', 'ar', 'ca', 'cy', 'de', 'es', 'et', 'fa', 'fr', 'id', 'it', 'ja', 'lv', 'mn', 'nl', 'pt', 'ru', 'sl', 'sv', 'ta', 'tr', 'zh']",[],[]
copenlu/answerable_tydiqa,copenlu,2022-08-16 11:31:34+00:00,2024-07-12 11:53:23+00:00,514,8,"['task_categories:question-answering', 'task_ids:extractive-qa', 'annotations_creators:crowdsourced', 'language_creators:crowdsourced', 'multilinguality:multilingual', 'source_datasets:extended|wikipedia', 'language:en', 'language:ar', 'language:bn', 'language:fi', 'language:id', 'language:ja', 'language:sw', 'language:ko', 'language:ru', 'language:te', 'language:th', 'license:apache-2.0', 'size_categories:100K<n<1M', 'format:parquet', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","
	
		
		Dataset Card for ""answerable-tydiqa""
	


	
		
		Dataset Summary
	

TyDi QA is a question answering dataset covering 11 typologically diverse languages. 
Answerable TyDi QA is an extension of the GoldP subtask of the original TyDi QA dataset to also include unanswertable questions.

	
		
		Dataset Structure
	

The dataset contains a train and a validation set, with 116067 and 13325 examples, respectively. Access them with
from datasets import load_dataset
dataset =… See the full description on the dataset page: https://huggingface.co/datasets/copenlu/answerable_tydiqa.",https://huggingface.co/datasets/copenlu/answerable_tydiqa,"['en', 'ar', 'bn', 'fi', 'id', 'ja', 'sw', 'ko', 'ru', 'te', 'th']",['question-answering'],['100K<n<1M']
copenlu/tydiqa_copenlu,copenlu,2022-08-16 12:04:50+00:00,2022-08-16 12:10:21+00:00,44,0,"['task_categories:question-answering', 'task_ids:extractive-qa', 'annotations_creators:crowdsourced', 'language_creators:crowdsourced', 'multilinguality:multilingual', 'source_datasets:extended|wikipedia', 'language:ar', 'language:bn', 'language:en', 'language:fi', 'language:id', 'language:ja', 'language:ko', 'language:ru', 'language:sw', 'language:te', 'language:th', 'license:apache-2.0', 'size_categories:100K<n<1M', 'format:csv', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","
	
		
		Dataset Card for ""tydiqa""
	


	
		
		Dataset Summary
	

TyDi QA is a question answering dataset covering 11 typologically diverse languages with 204K question-answer pairs.
The languages of TyDi QA are diverse with regard to their typology -- the set of linguistic features that each language
expresses -- such that we expect models performing well on this set to generalize across a large number of the languages
in the world. It contains language phenomena that would not be found in… See the full description on the dataset page: https://huggingface.co/datasets/copenlu/tydiqa_copenlu.",https://huggingface.co/datasets/copenlu/tydiqa_copenlu,"['ar', 'bn', 'en', 'fi', 'id', 'ja', 'ko', 'ru', 'sw', 'te', 'th']",['question-answering'],['100K<n<1M']
MoritzLaurer/multilingual-NLI-26lang-2mil7,MoritzLaurer,2022-08-17 15:28:16+00:00,2022-08-22 21:40:14+00:00,2009,47,"['task_categories:text-classification', 'task_ids:natural-language-inference', 'task_ids:multi-input-text-classification', 'annotations_creators:crowdsourced', 'language_creators:machinetranslation', 'source_datasets:multi_nli', 'source_datasets:anli', 'source_datasets:fever', 'source_datasets:lingnli', 'source_datasets:alisawuffles/WANLI', 'language:multilingual', 'language:zh', 'language:ja', 'language:ar', 'language:ko', 'language:de', 'language:fr', 'language:es', 'language:pt', 'language:hi', 'language:id', 'language:it', 'language:tr', 'language:ru', 'language:bn', 'language:ur', 'language:mr', 'language:ta', 'language:vi', 'language:fa', 'language:pl', 'language:uk', 'language:nl', 'language:sv', 'language:he', 'language:sw', 'language:ps', 'size_categories:1M<n<10M', 'format:parquet', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'arxiv:2104.07179', 'region:us']","
	
		
		Datasheet for the dataset: multilingual-NLI-26lang-2mil7
	


	
		
		Dataset Summary
	

This dataset contains 2 730 000 NLI text pairs in 26 languages spoken by more than 4 billion people. The dataset can be used to train models for multilingual NLI (Natural Language Inference) or zero-shot classification. The dataset is based on the English datasets MultiNLI, Fever-NLI, ANLI, LingNLI and WANLI and was created using the latest open-source machine translation models. 
The dataset is… See the full description on the dataset page: https://huggingface.co/datasets/MoritzLaurer/multilingual-NLI-26lang-2mil7.",https://huggingface.co/datasets/MoritzLaurer/multilingual-NLI-26lang-2mil7,"['multilingual', 'zh', 'ja', 'ar', 'ko', 'de', 'fr', 'es', 'pt', 'hi', 'id', 'it', 'tr', 'ru', 'bn', 'ur', 'mr', 'ta', 'vi', 'fa', 'pl', 'uk', 'nl', 'sv', 'he', 'sw', 'ps']",['text-classification'],['1M<n<10M']
tyqiangz/multilingual-sentiments,tyqiangz,2022-08-21 11:04:38+00:00,2023-05-23 15:01:51+00:00,2231,50,"['task_categories:text-classification', 'task_ids:sentiment-analysis', 'task_ids:sentiment-classification', 'multilinguality:monolingual', 'multilinguality:multilingual', 'language:de', 'language:en', 'language:es', 'language:fr', 'language:ja', 'language:zh', 'language:id', 'language:ar', 'language:hi', 'language:it', 'language:ms', 'language:pt', 'license:apache-2.0', 'size_categories:100K<n<1M', 'modality:text', 'library:datasets', 'library:mlcroissant', 'region:us']","
	
		
		Multilingual Sentiments Dataset
	

A collection of multilingual sentiments datasets grouped into 3 classes -- positive, neutral, negative.
Most multilingual sentiment datasets are either 2-class positive or negative, 5-class ratings of products reviews (e.g. Amazon multilingual dataset) or multiple classes of emotions. However, to an average person, sometimes positive, negative and neutral classes suffice and are more straightforward to perceive and annotate. Also, a positive/negative… See the full description on the dataset page: https://huggingface.co/datasets/tyqiangz/multilingual-sentiments.",https://huggingface.co/datasets/tyqiangz/multilingual-sentiments,"['de', 'en', 'es', 'fr', 'ja', 'zh', 'id', 'ar', 'hi', 'it', 'ms', 'pt']",['text-classification'],['100K<n<1M']
Fhrozen/CABankSakura,Fhrozen,2022-09-14 05:47:24+00:00,2022-12-03 03:26:50+00:00,71,0,"['task_categories:audio-classification', 'task_categories:automatic-speech-recognition', 'task_ids:speaker-identification', 'annotations_creators:expert-generated', 'language_creators:crowdsourced', 'language_creators:expert-generated', 'multilinguality:monolingual', 'source_datasets:found', 'language:ja', 'license:cc', 'size_categories:n<1K', 'modality:video', 'library:datasets', 'library:mlcroissant', 'region:us', 'speech-recognition']","
	
		
		CABank Japanese Sakura Corpus
	


Susanne Miyata
Department of Medical Sciences
Aichi Shukotoku University
smiyata@asu.aasa.ac.jp
website: https://ca.talkbank.org/access/Sakura.html


	
		
		Important
	

This data set is a copy from the original one located at https://ca.talkbank.org/access/Sakura.html.

	
		
		Details
	


Participants:   31
Type of Study:  xxx
Location:   Japan
Media type: audio
DOI:    doi:10.21415/T5M90R


	
		
		Citation information
	

Some citation here.
In… See the full description on the dataset page: https://huggingface.co/datasets/Fhrozen/CABankSakura.",https://huggingface.co/datasets/Fhrozen/CABankSakura,['ja'],"['audio-classification', 'automatic-speech-recognition']",['n<1K']
Fhrozen/CABankSakuraCHJP,Fhrozen,2022-09-14 05:48:24+00:00,2022-12-03 03:26:43+00:00,90,2,"['task_categories:audio-classification', 'task_categories:automatic-speech-recognition', 'task_ids:speaker-identification', 'annotations_creators:expert-generated', 'language_creators:crowdsourced', 'language_creators:expert-generated', 'multilinguality:monolingual', 'source_datasets:found', 'language:ja', 'license:cc', 'size_categories:100K<n<1M', 'modality:audio', 'region:us', 'speech-recognition']","
	
		
		CABank Japanese CallHome Corpus
	


Participants:   120

Type of Study:  phone call

Location:   United States

Media type: audio

DOI:    doi:10.21415/T5H59V

Web: https://ca.talkbank.org/access/CallHome/jpn.html



	
		
		Citation information
	

Some citation here.
In accordance with TalkBank rules, any use of data from this corpus must be accompanied by at least one of the above references.

	
		
		Project Description
	

This is the Japanese portion of CallHome.
Speakers were… See the full description on the dataset page: https://huggingface.co/datasets/Fhrozen/CABankSakuraCHJP.",https://huggingface.co/datasets/Fhrozen/CABankSakuraCHJP,['ja'],"['audio-classification', 'automatic-speech-recognition']",['100K<n<1M']
Nexdata/Japanese_Conversational_Speech_by_Mobile_Phone,Nexdata,2022-09-16 10:14:35+00:00,2025-04-24 06:08:50+00:00,18,1,"['language:ja', 'size_categories:n<1K', 'format:audiofolder', 'modality:audio', 'modality:text', 'library:datasets', 'library:mlcroissant', 'region:us']","
	
		
		Dataset Card for Nexdata/Japanese_Conversational_Speech_by_Mobile_Phone
	


	
		
		Dataset Summary
	

This dataset is just a sample of Japanese Conversational Speech by Mobile Phone(paid dataset).About 1000 speakers participated in the recording, and conducted face-to-face communication in a natural way. They had free discussion on a number of given topics, with a wide range of fields; the voice was natural and fluent, in line with the actual dialogue scene. Text is transferred… See the full description on the dataset page: https://huggingface.co/datasets/Nexdata/Japanese_Conversational_Speech_by_Mobile_Phone.",https://huggingface.co/datasets/Nexdata/Japanese_Conversational_Speech_by_Mobile_Phone,['ja'],[],['n<1K']
miracl/miracl-corpus,miracl,2022-09-29 14:49:58+00:00,2023-01-05 17:28:26+00:00,3262,46,"['task_categories:text-retrieval', 'task_ids:document-retrieval', 'annotations_creators:expert-generated', 'multilinguality:multilingual', 'language:ar', 'language:bn', 'language:en', 'language:es', 'language:fa', 'language:fi', 'language:fr', 'language:hi', 'language:id', 'language:ja', 'language:ko', 'language:ru', 'language:sw', 'language:te', 'language:th', 'language:zh', 'license:apache-2.0', 'size_categories:10M<n<100M', 'modality:text', 'library:datasets', 'library:mlcroissant', 'arxiv:2210.09984', 'region:us']","
	
		
		Dataset Card for MIRACL Corpus
	

MIRACL 🌍🙌🌏 (Multilingual Information Retrieval Across a Continuum of Languages) is a multilingual retrieval dataset that focuses on search across 18 different languages, which collectively encompass over three billion native speakers around the world.
This dataset contains the collection data of the 16 ""known languages"". The remaining 2 ""surprise languages"" will not be released until later.
The corpus for each language is prepared from a Wikipedia… See the full description on the dataset page: https://huggingface.co/datasets/miracl/miracl-corpus.",https://huggingface.co/datasets/miracl/miracl-corpus,"['ar', 'bn', 'en', 'es', 'fa', 'fi', 'fr', 'hi', 'id', 'ja', 'ko', 'ru', 'sw', 'te', 'th', 'zh']",['text-retrieval'],['10M<n<100M']
DFKI-SLT/multitacred,DFKI-SLT,2022-09-30 11:31:31+00:00,2025-07-17 13:09:40+00:00,61,7,"['task_categories:text-classification', 'task_ids:multi-class-classification', 'annotations_creators:crowdsourced', 'annotations_creators:expert-generated', 'language_creators:found', 'source_datasets:DFKI-NLP/tacred', 'language:ar', 'language:de', 'language:es', 'language:fi', 'language:fr', 'language:hi', 'language:hu', 'language:ja', 'language:pl', 'language:ru', 'language:tr', 'language:zh', 'license:other', 'size_categories:100K<n<1M', 'arxiv:2305.04582', 'region:us', 'relation extraction']","MultiTACRED is a multilingual version of the large-scale TAC Relation Extraction Dataset 
(https://nlp.stanford.edu/projects/tacred). It covers 12 typologically diverse languages from 9 language families, 
and was created by the Speech & Language Technology group of DFKI (https://www.dfki.de/slt) by machine-translating the
instances of the original TACRED dataset and automatically projecting their entity annotations. For details of the 
original TACRED's data collection and annotation process, see the Stanford paper (https://aclanthology.org/D17-1004/). 
Translations are syntactically validated by checking the correctness of the XML tag markup. Any translations with an 
invalid tag structure, e.g. missing or invalid head or tail tag pairs, are discarded (on average, 2.3% of the 
instances).

Languages covered are: Arabic, Chinese, Finnish, French, German, Hindi, Hungarian, Japanese, Polish,
 Russian, Spanish, Turkish. Intended use is supervised relation classification. Audience - researchers.

 Please see our ACL paper (https://arxiv.org/abs/2305.04582) for full details.

NOTE: This Datasetreader supports a reduced version of the original TACRED JSON format with the following changes:
- Removed fields: stanford_pos, stanford_ner, stanford_head, stanford_deprel, docid
The motivation for this is that we want to support additional languages, for which these fields were not required
or available. The reader expects the specification of a language-specific configuration specifying the variant
(original, revisited or retacred) and the language (as a two-letter iso code).

The DatasetReader changes the offsets of the following fields, to conform with standard Python usage (see
_generate_examples()):
- subj_end to subj_end + 1 (make end offset exclusive)
- obj_end to obj_end + 1 (make end offset exclusive)

NOTE 2: The MultiTACRED dataset offers an additional 'split', namely the backtranslated test data (translated to a
target language and then back to English). To access this split, use dataset['backtranslated_test'].

You can find the TACRED dataset reader for the English version of the dataset at 
https://huggingface.co/datasets/DFKI-SLT/tacred.",https://huggingface.co/datasets/DFKI-SLT/multitacred,"['ar', 'de', 'es', 'fi', 'fr', 'hi', 'hu', 'ja', 'pl', 'ru', 'tr', 'zh']",['text-classification'],['100K<n<1M']
rogerdehe/xfund,rogerdehe,2022-10-09 08:22:00+00:00,2022-10-12 12:42:35+00:00,20,2,"['task_categories:text-classification', 'annotations_creators:found', 'language_creators:found', 'multilinguality:multilingual', 'language:de', 'language:es', 'language:fr', 'language:it', 'language:ja', 'license:other', 'region:us', 'layoutlmv3', 'xfund', 'funsd']",https://github.com/doc-analysis/XFUND,https://huggingface.co/datasets/rogerdehe/xfund,"['de', 'es', 'fr', 'it', 'ja']",['text-classification'],[]
miracl/miracl,miracl,2022-10-11 22:20:12+00:00,2024-12-29 05:45:14+00:00,1481,61,"['task_categories:text-retrieval', 'task_ids:document-retrieval', 'annotations_creators:expert-generated', 'multilinguality:multilingual', 'language:ar', 'language:bn', 'language:en', 'language:es', 'language:fa', 'language:fi', 'language:fr', 'language:hi', 'language:id', 'language:ja', 'language:ko', 'language:ru', 'language:sw', 'language:te', 'language:th', 'language:zh', 'language:de', 'language:yo', 'license:apache-2.0', 'arxiv:2210.09984', 'region:us']","
	
		
		Dataset Card for MIRACL (Topics and Qrels)
	


	
		
		Dataset Description
	

Homepage | 
Repository: | 
Paper | 
ArXiv
MIRACL 🌍🙌🌏 (Multilingual Information Retrieval Across a Continuum of Languages) is a multilingual retrieval dataset that focuses on search across 18 different languages, which collectively encompass over three billion native speakers around the world.
This dataset contains the collection data of the 16 ""known languages"". The remaining 2 ""surprise languages"" will not… See the full description on the dataset page: https://huggingface.co/datasets/miracl/miracl.",https://huggingface.co/datasets/miracl/miracl,"['ar', 'bn', 'en', 'es', 'fa', 'fi', 'fr', 'hi', 'id', 'ja', 'ko', 'ru', 'sw', 'te', 'th', 'zh', 'de', 'yo']",['text-retrieval'],[]
svjack/pokemon-blip-captions-en-ja,svjack,2022-10-29 07:26:57+00:00,2022-10-31 06:22:04+00:00,28,4,"['task_categories:text-to-image', 'annotations_creators:machine-generated', 'language_creators:other', 'multilinguality:multilingual', 'source_datasets:huggan/few-shot-pokemon', 'language:en', 'language:ja', 'license:cc-by-nc-sa-4.0', 'size_categories:n<1K', 'format:parquet', 'modality:image', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","
	
		
		Dataset Card for Pokémon BLIP captions with English and Japanese.
	

Dataset used to train Pokémon text to image model, add a Japanese Column of Pokémon BLIP captions
BLIP generated captions for Pokémon images from Few Shot Pokémon dataset introduced by Towards Faster and Stabilized GAN Training for High-fidelity Few-shot Image Synthesis (FastGAN). Original images were obtained from FastGAN-pytorch and captioned with the pre-trained BLIP model.
For each row the dataset contains image… See the full description on the dataset page: https://huggingface.co/datasets/svjack/pokemon-blip-captions-en-ja.",https://huggingface.co/datasets/svjack/pokemon-blip-captions-en-ja,"['en', 'ja']",['text-to-image'],['n<1K']
Twitter/HashtagPrediction,Twitter,2022-11-06 02:52:17+00:00,2022-11-21 21:22:07+00:00,42,2,"['language:sl', 'language:ur', 'language:sd', 'language:pl', 'language:vi', 'language:sv', 'language:am', 'language:da', 'language:mr', 'language:no', 'language:gu', 'language:in', 'language:ja', 'language:el', 'language:lv', 'language:it', 'language:ca', 'language:is', 'language:cs', 'language:te', 'language:tl', 'language:ro', 'language:ckb', 'language:pt', 'language:ps', 'language:zh', 'language:sr', 'language:pa', 'language:si', 'language:ml', 'language:ht', 'language:kn', 'language:ar', 'language:hu', 'language:nl', 'language:bg', 'language:bn', 'language:ne', 'language:hi', 'language:de', 'language:ko', 'language:fi', 'language:fr', 'language:es', 'language:et', 'language:en', 'language:fa', 'language:lt', 'language:or', 'language:cy', 'language:eu', 'language:iw', 'language:ta', 'language:th', 'language:tr', 'license:cc-by-4.0', 'size_categories:1M<n<10M', 'format:csv', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'arxiv:2209.07562', 'region:us', 'Twitter', 'Multilingual', 'Classification', 'Benchmark']","
	
		
		Hashtag Prediction Dataset from paper TwHIN-BERT: A Socially-Enriched Pre-trained Language Model for Multilingual Tweet Representations
	

  
This repo contains the Hashtag prediction dataset from our paper TwHIN-BERT: A Socially-Enriched Pre-trained Language Model for Multilingual Tweet Representations. 
[arXiv][HuggingFace Models]
[Github repo]
This work is licensed under a Creative Commons Attribution 4.0 International License.

	
		
	
	
		Download
	

Use the… See the full description on the dataset page: https://huggingface.co/datasets/Twitter/HashtagPrediction.",https://huggingface.co/datasets/Twitter/HashtagPrediction,"['sl', 'ur', 'sd', 'pl', 'vi', 'sv', 'am', 'da', 'mr', 'no', 'gu', 'in', 'ja', 'el', 'lv', 'it', 'ca', 'is', 'cs', 'te', 'tl', 'ro', 'ckb', 'pt', 'ps', 'zh', 'sr', 'pa', 'si', 'ml', 'ht', 'kn', 'ar', 'hu', 'nl', 'bg', 'bn', 'ne', 'hi', 'de', 'ko', 'fi', 'fr', 'es', 'et', 'en', 'fa', 'lt', 'or', 'cy', 'eu', 'iw', 'ta', 'th', 'tr']",[],['1M<n<10M']
bigbio/ntcir_13_medweb,bigbio,2022-11-13 22:11:06+00:00,2022-12-22 15:46:09+00:00,34,0,"['multilinguality:multilingual', 'language:en', 'language:zh', 'language:ja', 'license:cc-by-4.0', 'region:us']","NTCIR-13 MedWeb (Medical Natural Language Processing for Web Document) task requires
to perform a multi-label classification that labels for eight diseases/symptoms must
be assigned to each tweet. Given pseudo-tweets, the output are Positive:p or Negative:n
labels for eight diseases/symptoms. The achievements of this task can almost be
directly applied to a fundamental engine for actual applications.

This task provides pseudo-Twitter messages in a cross-language and multi-label corpus,
covering three languages (Japanese, English, and Chinese), and annotated with eight
labels such as influenza, diarrhea/stomachache, hay fever, cough/sore throat, headache,
fever, runny nose, and cold.

For more information, see:
http://research.nii.ac.jp/ntcir/permission/ntcir-13/perm-en-MedWeb.html

As this dataset also provides a parallel corpus of pseudo-tweets for english,
japanese and chinese it can also be used to train translation models between
these three languages.",https://huggingface.co/datasets/bigbio/ntcir_13_medweb,"['en', 'zh', 'ja']",[],[]
SYH99999/autotrain-data-translator-3c03831c-5fcf2e86-839aa322-a7658498-cb30b55a-eefc0458,SYH99999,2022-11-28 06:00:17+00:00,2022-11-28 11:51:52+00:00,21,0,"['task_categories:translation', 'language:ja', 'language:en', 'region:us']","
	
		
		AutoTrain Dataset for project: translator
	


	
		
		Dataset Description
	

This dataset has been automatically processed by AutoTrain for project translator.

	
		
		Languages
	

The BCP-47 code for the dataset's language is ja2en.

	
		
		Dataset Structure
	


	
		
		Data Instances
	

A sample from this dataset looks as follows:
[
  {
    ""source"": ""He was also named the Pittsburgh Pirates' Minor League Pitcher of the Year. These segments end when the player reaches the entrance of… See the full description on the dataset page: https://huggingface.co/datasets/SYH99999/autotrain-data-translator-3c03831c-5fcf2e86-839aa322-a7658498-cb30b55a-eefc0458.",https://huggingface.co/datasets/SYH99999/autotrain-data-translator-3c03831c-5fcf2e86-839aa322-a7658498-cb30b55a-eefc0458,"['ja', 'en']",['translation'],[]
Elite35P-Server/EliteVoiceProject,Elite35P-Server,2022-11-30 16:10:15+00:00,2023-01-14 19:28:16+00:00,142,12,"['annotations_creators:crowdsourced', 'language_creators:さくらみこ', 'language_creators:hololive production', 'multilinguality:monolingual', 'language:ja', 'license:other', 'size_categories:1K<n<10K', 'modality:audio', 'modality:text', 'library:datasets', 'library:mlcroissant', 'region:us']","
	
		
		Elite Voice Project
	

これはホロライブ所属Vtuberさくらみこ氏の声をデータセット化し音声認識などで活用できるようにする事を目的とした非公式プロジェクトです。


	
		
		LICENSEについて
	


	
		
		データセット内の音声データ
	

すべてのデータは、hololive productionの二次創作ガイドラインに準拠する形で利用されています。
これらのデータの著作権はカバー株式会社等が保有しており、リポジトリオーナー、コントリビューターは一切の権利を有しておりません。


	
		
		当プロジェクトへのご協力
	

当プロジェクトは皆様のご協力を心より歓迎いたします。 以下の方法をご一読いただき、そのうえでプルリクエストをお願い致します。

	
		
		始める前に
	

hololive productionの二次創作ガイドラインを必ずお読みください。


	
		
		音声データの追加… See the full description on the dataset page: https://huggingface.co/datasets/Elite35P-Server/EliteVoiceProject.",https://huggingface.co/datasets/Elite35P-Server/EliteVoiceProject,['ja'],[],['1K<n<10K']
shunk031/jsnli,shunk031,2022-11-30 16:34:02+00:00,2022-12-12 07:36:58+00:00,119,5,"['task_categories:text-classification', 'task_ids:natural-language-inference', 'task_ids:multi-input-text-classification', 'multilinguality:monolingual', 'language:ja', 'license:cc-by-sa-4.0', 'size_categories:1M<n<10M', 'modality:text', 'library:datasets', 'library:mlcroissant', 'region:us', 'natural-language-inference', 'nli', 'jsnli']","== 日本語SNLI(JSNLI)データセット ==

SNLI コーパスを日本語に翻訳した自然言語推論データセット
学習データは元データを翻訳し、計算機によるフィルタリングによって作成
評価データは日本語として意味が通るか、翻訳後のラベルが元のラベルと一致しているかどうかの2段階のクラウドソーシングによりデータをフィルタリング",https://huggingface.co/datasets/shunk031/jsnli,['ja'],['text-classification'],['1M<n<10M']
lmqg/qag_jaquad,lmqg,2022-12-18 07:05:33+00:00,2022-12-18 07:54:08+00:00,17,0,"['task_categories:text-generation', 'task_ids:language-modeling', 'multilinguality:monolingual', 'source_datasets:lmqg/qg_jaquad', 'language:ja', 'license:cc-by-sa-4.0', 'size_categories:10K<n<100K', 'modality:text', 'library:datasets', 'library:mlcroissant', 'arxiv:2210.03992', 'region:us', 'question-generation']",Question & answer generation dataset based on SQuAD.,https://huggingface.co/datasets/lmqg/qag_jaquad,['ja'],['text-generation'],['10K<n<100K']
jhu-clsp/bernice-pretrain-data,jhu-clsp,2023-01-03 01:48:26+00:00,2023-01-03 21:28:00+00:00,72,5,"['task_categories:other', 'annotations_creators:no-annotation', 'language_creators:found', 'multilinguality:multilingual', 'source_datasets:original', 'language:en', 'language:es', 'language:pt', 'language:ja', 'language:ar', 'language:in', 'language:ko', 'language:tr', 'language:fr', 'language:tl', 'language:ru', 'language:it', 'language:th', 'language:de', 'language:hi', 'language:pl', 'language:nl', 'language:fa', 'language:et', 'language:ht', 'language:ur', 'language:sv', 'language:ca', 'language:el', 'language:fi', 'language:cs', 'language:iw', 'language:da', 'language:vi', 'language:zh', 'language:ta', 'language:ro', 'language:no', 'language:uk', 'language:cy', 'language:ne', 'language:hu', 'language:eu', 'language:sl', 'language:lv', 'language:lt', 'language:bn', 'language:sr', 'language:bg', 'language:mr', 'language:ml', 'language:is', 'language:te', 'language:gu', 'language:kn', 'language:ps', 'language:ckb', 'language:si', 'language:hy', 'language:or', 'language:pa', 'language:am', 'language:sd', 'language:my', 'language:ka', 'language:km', 'language:dv', 'language:lo', 'language:ug', 'language:bo', 'license:mit', 'size_categories:1B<n<10B', 'region:us', 'twitter', 'slang', 'code switch', 'social', 'social media']","Tweet IDs for the 2.5 billion multilingual tweets used to train Bernice, a Twitter encoder.
The tweets are from the public 1% Twitter API stream from January 2016 to December 2021. 
Twitter-provided language metadata is provided with the tweet ID. The data contains 66 unique languages, 
as identified by ISO 639 language codes, including `und` for undefined languages.
Tweets need to be re-gathered via the Twitter API.",https://huggingface.co/datasets/jhu-clsp/bernice-pretrain-data,"['en', 'es', 'pt', 'ja', 'ar', 'in', 'ko', 'tr', 'fr', 'tl', 'ru', 'it', 'th', 'de', 'hi', 'pl', 'nl', 'fa', 'et', 'ht', 'ur', 'sv', 'ca', 'el', 'fi', 'cs', 'iw', 'da', 'vi', 'zh', 'ta', 'ro', 'no', 'uk', 'cy', 'ne', 'hu', 'eu', 'sl', 'lv', 'lt', 'bn', 'sr', 'bg', 'mr', 'ml', 'is', 'te', 'gu', 'kn', 'ps', 'ckb', 'si', 'hy', 'or', 'pa', 'am', 'sd', 'my', 'ka', 'km', 'dv', 'lo', 'ug', 'bo']",['other'],['1B<n<10B']
neulab/odex,neulab,2023-01-06 14:30:00+00:00,2023-02-10 18:01:34+00:00,100,11,"['task_categories:text-generation', 'language:en', 'language:es', 'language:ja', 'language:ru', 'license:cc-by-sa-4.0', 'size_categories:n<1K', 'modality:text', 'library:datasets', 'library:mlcroissant', 'arxiv:2212.10481', 'region:us']","ODEX is an Open-Domain EXecution-based NL-to-Code generation data benchmark. 
It contains 945 samples with a total of 1,707 human-written test cases, 
covering intents in four different natural languages -- 439 in English, 90 in Spanish, 164 in Japanese, and 252 in Russian.",https://huggingface.co/datasets/neulab/odex,"['en', 'es', 'ja', 'ru']",['text-generation'],['n<1K']
Plachta/Umamusume-voice-text-pairs,Plachta,2023-01-07 14:49:21+00:00,2024-10-10 19:01:04+00:00,59,29,"['task_categories:text-to-speech', 'task_categories:automatic-speech-recognition', 'language:ja', 'license:mit', 'size_categories:10K<n<100K', 'modality:audio', 'region:us']",,https://huggingface.co/datasets/Plachta/Umamusume-voice-text-pairs,['ja'],"['text-to-speech', 'automatic-speech-recognition']",['10K<n<100K']
shunk031/wrime,shunk031,2023-01-12 03:04:20+00:00,2023-01-15 03:39:01+00:00,476,27,"['task_categories:text-classification', 'task_ids:sentiment-classification', 'annotations_creators:crowdsourced', 'language_creators:crowdsourced', 'multilinguality:monolingual', 'language:ja', 'license:unknown', 'region:us', 'sentiment-analysis', 'wrime']",WRIME dataset is a new dataset for emotional intensity estimation with subjective and objective annotations.,https://huggingface.co/datasets/shunk031/wrime,['ja'],['text-classification'],[]
dbarbedillo/SMS_Spam_Multilingual_Collection_Dataset,dbarbedillo,2023-01-13 02:13:03+00:00,2023-01-13 03:07:17+00:00,108,13,"['task_categories:text-classification', 'language:en', 'language:zh', 'language:es', 'language:hi', 'language:fr', 'language:de', 'language:ar', 'language:bn', 'language:ru', 'language:pt', 'language:id', 'language:ur', 'language:ja', 'language:pa', 'language:jv', 'language:tr', 'language:ko', 'language:mr', 'language:uk', 'language:sv', 'language:no', 'license:gpl', 'size_categories:1K<n<10K', 'format:csv', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","SMS Spam Multilingual Collection Dataset
Collection of Multilingual SMS messages tagged as spam or legitimate
About Dataset
Context
The SMS Spam Collection is a set of SMS-tagged messages that have been collected for SMS Spam research. It originally contained one set of SMS messages in English of 5,574 messages, tagged according to being ham (legitimate) or spam and later Machine Translated into Hindi, German and French.
The text has been further translated into Spanish, Chinese, Arabic… See the full description on the dataset page: https://huggingface.co/datasets/dbarbedillo/SMS_Spam_Multilingual_Collection_Dataset.",https://huggingface.co/datasets/dbarbedillo/SMS_Spam_Multilingual_Collection_Dataset,"['en', 'zh', 'es', 'hi', 'fr', 'de', 'ar', 'bn', 'ru', 'pt', 'id', 'ur', 'ja', 'pa', 'jv', 'tr', 'ko', 'mr', 'uk', 'sv', 'no']",['text-classification'],['1K<n<10K']
Cohere/wikipedia-22-12-ja-embeddings,Cohere,2023-01-14 03:52:53+00:00,2023-03-22 16:55:06+00:00,180,1,"['task_categories:text-retrieval', 'task_ids:document-retrieval', 'multilinguality:multilingual', 'language:ja', 'license:apache-2.0', 'size_categories:1M<n<10M', 'format:parquet', 'modality:tabular', 'modality:text', 'library:datasets', 'library:dask', 'library:mlcroissant', 'library:polars', 'region:us']","
	
		
		Wikipedia (ja) embedded with cohere.ai multilingual-22-12 encoder
	

We encoded Wikipedia (ja) using the cohere.ai multilingual-22-12 embedding model.
To get an overview how this dataset was created and pre-processed, have a look at Cohere/wikipedia-22-12.

	
		
	
	
		Embeddings
	

We compute for title+"" ""+text the embeddings using our multilingual-22-12 embedding model, a state-of-the-art model that works for semantic search in 100 languages.  If you want to learn more about this… See the full description on the dataset page: https://huggingface.co/datasets/Cohere/wikipedia-22-12-ja-embeddings.",https://huggingface.co/datasets/Cohere/wikipedia-22-12-ja-embeddings,['ja'],['text-retrieval'],['1M<n<10M']
reazon-research/reazonspeech,reazon-research,2023-01-17 23:03:48+00:00,2024-11-10 04:55:07+00:00,913,98,"['task_categories:automatic-speech-recognition', 'language:ja', 'license:other', 'size_categories:10M<n<100M', 'region:us']","
	
		
		Dataset Card for ReazonSpeech
	


	
		
		Dataset Summary
	

This dataset contains a diverse set of natural Japanese speech, collected
from terrestrial television streams. It contains more than 35000 hours of
audio.
Paper: ReazonSpeech: A Free and Massive Corpus for Japanese ASR

	
		
		Disclaimer
	

TO USE THIS DATASET, YOU MUST AGREE THAT YOU WILL USE THE DATASET
SOLELY FOR THE PURPOSE OF JAPANESE COPYRIGHT ACT ARTICLE 30-4.

	
		
		Dataset Format
	

Audio files are available in FLAC… See the full description on the dataset page: https://huggingface.co/datasets/reazon-research/reazonspeech.",https://huggingface.co/datasets/reazon-research/reazonspeech,['ja'],['automatic-speech-recognition'],['10M<n<100M']
shunk031/livedoor-news-corpus,shunk031,2023-01-18 08:30:24+00:00,2023-10-28 05:40:17+00:00,307,6,"['task_categories:text-classification', 'task_ids:multi-class-classification', 'language_creators:found', 'multilinguality:monolingual', 'language:ja', 'license:cc-by-nd-4.0', 'region:us']",本コーパスは、NHN Japan株式会社が運営する「livedoor ニュース」のうち、下記のクリエイティブ・コモンズライセンスが適用されるニュース記事を収集し、可能な限りHTMLタグを取り除いて作成したものです。,https://huggingface.co/datasets/shunk031/livedoor-news-corpus,['ja'],['text-classification'],[]
kubota/defamation-japanese-twitter,kubota,2023-01-20 06:50:46+00:00,2023-02-06 18:26:10+00:00,90,2,"['task_categories:text-classification', 'annotations_creators:crowdsourced', 'language_creators:crowdsourced', 'multilinguality:monolingual', 'source_datasets:original', 'language:ja', 'license:cc-by-4.0', 'size_categories:1K<n<10K', 'modality:text', 'library:datasets', 'library:mlcroissant', 'region:us']","
	
		
		defamation_japanese_twitter
	


	
		
		Twitter日本語誹謗中傷検出データセット
	




	
		
		Dataset Summary
	

SNSにおける誹謗中傷検出のためのデータセットです．
5,000件の日本語のツイートに，それぞれ以下で定義している誹謗中傷の対象者と内容をアノテーションしています．アノテーションは，3人のクラウドワーカーにより行われています．2022年2月15日から2022年6月30日までのツイートです．
元のツイートは含まれていないため，Twitter APIを用いてデータセットを収集してください．
中傷対象(target)と中傷内容(label)の2項目がアノテーションされています．

target ：テキストが話題にしている対象者の分類
label ： targetで選択された対象者に対する誹謗中傷の種類の分類

文として成立しておらず意味の取れないものはラベルC(0)としています．

	
		
target
対象
例


		
A1(1)
(人種・性別・職業・思想などを共通とする)グループ… See the full description on the dataset page: https://huggingface.co/datasets/kubota/defamation-japanese-twitter.",https://huggingface.co/datasets/kubota/defamation-japanese-twitter,['ja'],['text-classification'],['1K<n<10K']
p1atdev/pvc,p1atdev,2023-01-21 16:12:04+00:00,2023-11-29 12:01:52+00:00,283,7,"['language:en', 'language:ja', 'license:cc0-1.0', 'size_categories:1K<n<10K', 'format:parquet', 'modality:image', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","
	
		
		PVC figure products dataset
	

This dataset contains product information of figure images scraped from multiple Web sites.

	
		
		Dataset information
	


	
		
Subset
Source
Size


		
goodsmile-figma
https://www.goodsmile.info/ja/products/category/figma/announced/2023
947


goodsmile-nendoroid
https://www.goodsmile.info/ja/products/category/nendoroid_series/announced/2023
3378


goodsmile-scale
https://www.goodsmile.info/ja/products/category/scale/announced/2023
2203


kotobukiya… See the full description on the dataset page: https://huggingface.co/datasets/p1atdev/pvc.",https://huggingface.co/datasets/p1atdev/pvc,"['en', 'ja']",[],['1K<n<10K']
pierreguillou/DocLayNet-large,pierreguillou,2023-01-25 15:14:52+00:00,2023-05-17 08:56:48+00:00,182,12,"['task_categories:object-detection', 'task_categories:image-segmentation', 'task_categories:token-classification', 'task_ids:instance-segmentation', 'annotations_creators:crowdsourced', 'language:en', 'language:de', 'language:fr', 'language:ja', 'license:other', 'size_categories:10K<n<100K', 'arxiv:2206.01062', 'region:us', 'DocLayNet', 'COCO', 'PDF', 'IBM', 'Financial-Reports', 'Finance', 'Manuals', 'Scientific-Articles', 'Science', 'Laws', 'Law', 'Regulations', 'Patents', 'Government-Tenders', 'object-detection', 'image-segmentation', 'token-classification']","Accurate document layout analysis is a key requirement for high-quality PDF document conversion. With the recent availability of public, large ground-truth datasets such as PubLayNet and DocBank, deep-learning models have proven to be very effective at layout detection and segmentation. While these datasets are of adequate size to train such models, they severely lack in layout variability since they are sourced from scientific article repositories such as PubMed and arXiv only. Consequently, the accuracy of the layout segmentation drops significantly when these models are applied on more challenging and diverse layouts. In this paper, we present \textit{DocLayNet}, a new, publicly available, document-layout annotation dataset in COCO format. It contains 80863 manually annotated pages from diverse data sources to represent a wide variability in layouts. For each PDF page, the layout annotations provide labelled bounding-boxes with a choice of 11 distinct classes. DocLayNet also provides a subset of double- and triple-annotated pages to determine the inter-annotator agreement. In multiple experiments, we provide largeline accuracy scores (in mAP) for a set of popular object detection models. We also demonstrate that these models fall approximately 10\% behind the inter-annotator agreement. Furthermore, we provide evidence that DocLayNet is of sufficient size. Lastly, we compare models trained on PubLayNet, DocBank and DocLayNet, showing that layout predictions of the DocLayNet-trained models are more robust and thus the preferred choice for general-purpose document-layout analysis.",https://huggingface.co/datasets/pierreguillou/DocLayNet-large,"['en', 'de', 'fr', 'ja']","['object-detection', 'image-segmentation', 'token-classification']",['10K<n<100K']
pierreguillou/DocLayNet-small,pierreguillou,2023-01-25 17:47:43+00:00,2023-05-17 08:56:10+00:00,314,12,"['task_categories:object-detection', 'task_categories:image-segmentation', 'task_categories:token-classification', 'task_ids:instance-segmentation', 'annotations_creators:crowdsourced', 'language:en', 'language:de', 'language:fr', 'language:ja', 'license:other', 'size_categories:n<1K', 'modality:image', 'modality:text', 'library:datasets', 'library:mlcroissant', 'arxiv:2206.01062', 'region:us', 'DocLayNet', 'COCO', 'PDF', 'IBM', 'Financial-Reports', 'Finance', 'Manuals', 'Scientific-Articles', 'Science', 'Laws', 'Law', 'Regulations', 'Patents', 'Government-Tenders', 'object-detection', 'image-segmentation', 'token-classification']","Accurate document layout analysis is a key requirement for high-quality PDF document conversion. With the recent availability of public, large ground-truth datasets such as PubLayNet and DocBank, deep-learning models have proven to be very effective at layout detection and segmentation. While these datasets are of adequate size to train such models, they severely lack in layout variability since they are sourced from scientific article repositories such as PubMed and arXiv only. Consequently, the accuracy of the layout segmentation drops significantly when these models are applied on more challenging and diverse layouts. In this paper, we present \textit{DocLayNet}, a new, publicly available, document-layout annotation dataset in COCO format. It contains 80863 manually annotated pages from diverse data sources to represent a wide variability in layouts. For each PDF page, the layout annotations provide labelled bounding-boxes with a choice of 11 distinct classes. DocLayNet also provides a subset of double- and triple-annotated pages to determine the inter-annotator agreement. In multiple experiments, we provide smallline accuracy scores (in mAP) for a set of popular object detection models. We also demonstrate that these models fall approximately 10\% behind the inter-annotator agreement. Furthermore, we provide evidence that DocLayNet is of sufficient size. Lastly, we compare models trained on PubLayNet, DocBank and DocLayNet, showing that layout predictions of the DocLayNet-trained models are more robust and thus the preferred choice for general-purpose document-layout analysis.",https://huggingface.co/datasets/pierreguillou/DocLayNet-small,"['en', 'de', 'fr', 'ja']","['object-detection', 'image-segmentation', 'token-classification']",['n<1K']
pierreguillou/DocLayNet-base,pierreguillou,2023-01-25 17:53:26+00:00,2023-05-17 08:56:30+00:00,307,15,"['task_categories:object-detection', 'task_categories:image-segmentation', 'task_categories:token-classification', 'task_ids:instance-segmentation', 'annotations_creators:crowdsourced', 'language:en', 'language:de', 'language:fr', 'language:ja', 'license:other', 'size_categories:1K<n<10K', 'modality:image', 'modality:text', 'library:datasets', 'library:mlcroissant', 'arxiv:2206.01062', 'region:us', 'DocLayNet', 'COCO', 'PDF', 'IBM', 'Financial-Reports', 'Finance', 'Manuals', 'Scientific-Articles', 'Science', 'Laws', 'Law', 'Regulations', 'Patents', 'Government-Tenders', 'object-detection', 'image-segmentation', 'token-classification']","Accurate document layout analysis is a key requirement for high-quality PDF document conversion. With the recent availability of public, large ground-truth datasets such as PubLayNet and DocBank, deep-learning models have proven to be very effective at layout detection and segmentation. While these datasets are of adequate size to train such models, they severely lack in layout variability since they are sourced from scientific article repositories such as PubMed and arXiv only. Consequently, the accuracy of the layout segmentation drops significantly when these models are applied on more challenging and diverse layouts. In this paper, we present \textit{DocLayNet}, a new, publicly available, document-layout annotation dataset in COCO format. It contains 80863 manually annotated pages from diverse data sources to represent a wide variability in layouts. For each PDF page, the layout annotations provide labelled bounding-boxes with a choice of 11 distinct classes. DocLayNet also provides a subset of double- and triple-annotated pages to determine the inter-annotator agreement. In multiple experiments, we provide smallline accuracy scores (in mAP) for a set of popular object detection models. We also demonstrate that these models fall approximately 10\% behind the inter-annotator agreement. Furthermore, we provide evidence that DocLayNet is of sufficient size. Lastly, we compare models trained on PubLayNet, DocBank and DocLayNet, showing that layout predictions of the DocLayNet-trained models are more robust and thus the preferred choice for general-purpose document-layout analysis.",https://huggingface.co/datasets/pierreguillou/DocLayNet-base,"['en', 'de', 'fr', 'ja']","['object-detection', 'image-segmentation', 'token-classification']",['1K<n<10K']
Cohere/miracl-ja-corpus-22-12,Cohere,2023-01-31 08:42:35+00:00,2023-02-06 11:57:11+00:00,15,1,"['task_categories:text-retrieval', 'task_ids:document-retrieval', 'annotations_creators:expert-generated', 'multilinguality:multilingual', 'language:ja', 'license:apache-2.0', 'size_categories:1M<n<10M', 'format:parquet', 'modality:text', 'library:datasets', 'library:dask', 'library:mlcroissant', 'library:polars', 'region:us']","
	
		
		MIRACL (ja) embedded with cohere.ai multilingual-22-12 encoder
	

We encoded the MIRACL dataset using the cohere.ai multilingual-22-12 embedding model.
The query embeddings can be found in Cohere/miracl-ja-queries-22-12 and the corpus embeddings can be found in Cohere/miracl-ja-corpus-22-12.
For the orginal datasets, see miracl/miracl and miracl/miracl-corpus.
Dataset info:

MIRACL 🌍🙌🌏 (Multilingual Information Retrieval Across a Continuum of Languages) is a multilingual retrieval… See the full description on the dataset page: https://huggingface.co/datasets/Cohere/miracl-ja-corpus-22-12.",https://huggingface.co/datasets/Cohere/miracl-ja-corpus-22-12,['ja'],['text-retrieval'],['1M<n<10M']
Cohere/miracl-ja-queries-22-12,Cohere,2023-01-31 09:20:40+00:00,2023-02-06 11:57:00+00:00,34,3,"['task_categories:text-retrieval', 'task_ids:document-retrieval', 'annotations_creators:expert-generated', 'multilinguality:multilingual', 'language:ja', 'license:apache-2.0', 'size_categories:1K<n<10K', 'format:parquet', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","
	
		
		MIRACL (ja) embedded with cohere.ai multilingual-22-12 encoder
	

We encoded the MIRACL dataset using the cohere.ai multilingual-22-12 embedding model.
The query embeddings can be found in Cohere/miracl-ja-queries-22-12 and the corpus embeddings can be found in Cohere/miracl-ja-corpus-22-12.
For the orginal datasets, see miracl/miracl and miracl/miracl-corpus.
Dataset info:

MIRACL 🌍🙌🌏 (Multilingual Information Retrieval Across a Continuum of Languages) is a multilingual retrieval… See the full description on the dataset page: https://huggingface.co/datasets/Cohere/miracl-ja-queries-22-12.",https://huggingface.co/datasets/Cohere/miracl-ja-queries-22-12,['ja'],['text-retrieval'],['1K<n<10K']
range3/wikipedia-ja-20230101,range3,2023-02-04 04:29:29+00:00,2023-02-04 05:44:41+00:00,100,4,"['task_categories:text-generation', 'task_categories:fill-mask', 'language:ja', 'license:cc-by-sa-3.0', 'license:gfdl', 'size_categories:1M<n<10M', 'format:parquet', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","
	
		
		range3/wikipedia-ja-20230101
	

This dataset consists of a parquet file from the wikipedia dataset with only Japanese data extracted. It is generated by the following python code.
このデータセットは、wikipediaデータセットの日本語データのみを抽出したparquetファイルで構成されます。以下のpythonコードによって生成しています。
import datasets
dss = datasets.load_dataset(
    ""wikipedia"",
    language=""ja"",
    date=""20230101"",
    beam_runner=""DirectRunner"",
)

for split,ds in dss.items():
    ds.to_parquet(f""wikipedia-ja-20230101/{split}.parquet"")

",https://huggingface.co/datasets/range3/wikipedia-ja-20230101,['ja'],"['text-generation', 'fill-mask']",['1M<n<10M']
range3/wiki40b-ja,range3,2023-02-04 04:54:17+00:00,2023-02-04 05:44:21+00:00,104,9,"['task_categories:text-generation', 'task_categories:fill-mask', 'language:ja', 'size_categories:100K<n<1M', 'format:parquet', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","
	
		
		range3/wiki40b-ja
	

This dataset consists of three parquet files from the wiki40b dataset with only Japanese data extracted. It is generated by the following python code.
このデータセットは、wiki40bデータセットの日本語データのみを抽出した3つのparquetファイルで構成されます。以下のpythonコードによって生成しています。
import datasets

dss = datasets.load_dataset(
    ""wiki40b"",
    ""ja"",
    beam_runner=""DirectRunner"",
)

for split,ds in dss.items():
    ds.to_parquet(f""wikipedia-ja-20230101/{split}.parquet"")

",https://huggingface.co/datasets/range3/wiki40b-ja,['ja'],"['text-generation', 'fill-mask']",['100K<n<1M']
range3/cc100-ja,range3,2023-02-04 05:10:34+00:00,2023-02-04 05:43:32+00:00,316,21,"['task_categories:text-generation', 'task_categories:fill-mask', 'language:ja', 'license:unknown', 'size_categories:100M<n<1B', 'format:parquet', 'modality:text', 'library:datasets', 'library:dask', 'library:mlcroissant', 'library:polars', 'region:us']","
	
		
		range3/cc100-ja
	

This dataset consists of parquet files from the cc100 dataset with only the Japanese language extracted and sharded.
このデータセットは、cc100データセットの日本語のみを抽出し、シャーディングしたparquetファイルで構成されます。
",https://huggingface.co/datasets/range3/cc100-ja,['ja'],"['text-generation', 'fill-mask']",['100M<n<1B']
alfredplpl/video-to-video-dataset,alfredplpl,2023-02-04 23:52:54+00:00,2023-02-05 05:33:49+00:00,70,3,"['language:ja', 'language:en', 'license:other', 'size_categories:n<1K', 'format:imagefolder', 'modality:image', 'modality:video', 'library:datasets', 'library:mlcroissant', 'region:us']","
	
		
		Video-to-Video Dataset
	

This is a dataset for video-to-video.
You have not to worry about this copyright if you read the outline of license.

	
		
		Outline of License
	

This is under Unity-Chan License. The outline is as follow:

You can use this for commercial purpose.
You must display ""Song/Motion: © Unity Technologies Japan/UCL."" in your work.

The official guideline is here.
Please read it.

	
		
		Copyrights
	


	
		
		3D Model
	

This model is CC-0.
More

	
		
		Song
	

Unity… See the full description on the dataset page: https://huggingface.co/datasets/alfredplpl/video-to-video-dataset.",https://huggingface.co/datasets/alfredplpl/video-to-video-dataset,"['ja', 'en']",[],['n<1K']
Phantom-Artist/phantom-diffusion-dataset,Phantom-Artist,2023-02-05 11:06:08+00:00,2023-02-05 11:13:34+00:00,15,1,"['language:en', 'language:ja', 'license:cc0-1.0', 'size_categories:n<1K', 'format:imagefolder', 'modality:image', 'library:datasets', 'library:mlcroissant', 'region:us']","Images trained for my phantom diffusion series.
Since they are all AI generated images that are public domain under the US law, I claim it is legal to redistribute them as public domain.
However, they might have copyright in your/their original country.
Still, many countries including Japan allow us to use them for training an AI under their copyrights law, and because all the artists here are from Japan, I assume it should be allowed to reuse it for training globally.
",https://huggingface.co/datasets/Phantom-Artist/phantom-diffusion-dataset,"['en', 'ja']",[],['n<1K']
Mitsua/vroid-image-dataset-lite,Mitsua,2023-02-09 12:27:18+00:00,2023-03-03 15:02:51+00:00,38,10,"['task_categories:text-to-image', 'language:en', 'language:ja', 'license:openrail++', 'size_categories:1K<n<10K', 'format:imagefolder', 'modality:image', 'library:datasets', 'library:mlcroissant', 'region:us']","
	
		
		VRoid Image Dataset Lite
	

This is a dataset to train text-to-image or other models without any copyright issue.
All materials used in this dataset are CC0 or properly licensed.
This dataset is also used to train Mitsua Diffusion One, which is a latent text-to-image diffusion model, whose VAE and U-Net are trained from scratch using only public domain/CC0 or copyright images with permission for use. 
Various parameters such as camera angle, pose, skin color and facial expression were… See the full description on the dataset page: https://huggingface.co/datasets/Mitsua/vroid-image-dataset-lite.",https://huggingface.co/datasets/Mitsua/vroid-image-dataset-lite,"['en', 'ja']",['text-to-image'],['1K<n<10K']
neulab/mconala,neulab,2023-02-10 18:08:54+00:00,2023-02-10 19:01:31+00:00,42,2,"['task_categories:text-generation', 'task_categories:translation', 'language:es', 'language:ja', 'language:ru', 'license:cc-by-sa-4.0', 'size_categories:n<1K', 'modality:text', 'library:datasets', 'library:mlcroissant', 'arxiv:2203.08388', 'region:us', 'code generation']","MCoNaLa is a Multilingual Code/Natural Language Challenge dataset with 
896 NL-Code pairs in three languages: Spanish, Japanese, and Russian.",https://huggingface.co/datasets/neulab/mconala,"['es', 'ja', 'ru']","['text-generation', 'translation']",['n<1K']
RicardoRei/wmt-da-human-evaluation,RicardoRei,2023-02-16 18:49:07+00:00,2023-02-17 10:41:18+00:00,271,7,"['language:bn', 'language:cs', 'language:de', 'language:en', 'language:et', 'language:fi', 'language:fr', 'language:gu', 'language:ha', 'language:hi', 'language:is', 'language:ja', 'language:kk', 'language:km', 'language:lt', 'language:lv', 'language:pl', 'language:ps', 'language:ru', 'language:ta', 'language:tr', 'language:uk', 'language:xh', 'language:zh', 'language:zu', 'license:apache-2.0', 'size_categories:1M<n<10M', 'format:csv', 'modality:tabular', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us', 'mt-evaluation', 'WMT', '41-lang-pairs']","
	
		
		Dataset Summary
	

This dataset contains all DA human annotations from previous WMT News Translation shared tasks.
The data is organised into 8 columns:

lp: language pair
src: input text
mt: translation
ref: reference translation
score: z score
raw: direct assessment
annotators: number of annotators
domain: domain of the input text (e.g. news)
year: collection year

You can also find the original data for each year in the results section https://www.statmt.org/wmt{YEAR}/results.html… See the full description on the dataset page: https://huggingface.co/datasets/RicardoRei/wmt-da-human-evaluation.",https://huggingface.co/datasets/RicardoRei/wmt-da-human-evaluation,"['bn', 'cs', 'de', 'en', 'et', 'fi', 'fr', 'gu', 'ha', 'hi', 'is', 'ja', 'kk', 'km', 'lt', 'lv', 'pl', 'ps', 'ru', 'ta', 'tr', 'uk', 'xh', 'zh', 'zu']",[],['1M<n<10M']
RicardoRei/wmt-sqm-human-evaluation,RicardoRei,2023-02-17 10:42:46+00:00,2023-02-17 11:10:39+00:00,25,1,"['language:cs', 'language:de', 'language:en', 'language:hr', 'language:ja', 'language:liv', 'language:ru', 'language:sah', 'language:uk', 'language:zh', 'license:apache-2.0', 'size_categories:100K<n<1M', 'format:csv', 'modality:tabular', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us', 'mt-evaluation', 'WMT', '12-lang-pairs']","
	
		
		Dataset Summary
	

In 2022, several changes were made to the annotation procedure used in the WMT Translation task. In contrast to the standard DA (sliding scale from 0-100) used in previous years, in 2022 annotators performed DA+SQM (Direct Assessment + Scalar Quality Metric). In DA+SQM, the annotators still provide a raw score between 0 and 100, but also are presented with seven labeled tick marks. DA+SQM helps to stabilize scores across annotators (as compared to DA).
The data is… See the full description on the dataset page: https://huggingface.co/datasets/RicardoRei/wmt-sqm-human-evaluation.",https://huggingface.co/datasets/RicardoRei/wmt-sqm-human-evaluation,"['cs', 'de', 'en', 'hr', 'ja', 'liv', 'ru', 'sah', 'uk', 'zh']",[],['100K<n<1M']
ThePioneer/Artificial-Super-Girlfriend-for-Dreambooth,ThePioneer,2023-02-19 11:29:22+00:00,2023-02-19 11:35:23+00:00,11,0,"['language:en', 'language:ja', 'license:cc0-1.0', 'size_categories:n<1K', 'format:imagefolder', 'modality:image', 'library:datasets', 'library:mlcroissant', 'region:us']","This is a dataset of ""atashi,"" the artificial girlfriend of mine, which I used for the training of my new model based on ChaosMix.
All the images has 87 or more beauty score before cropping it to square (it could slightly change, however, because of my cropping), and many of them score 90 or more (which afaik do not exist in real person).
Feel free to use them to reach a super beauty. Since the person is based on myself and is a fictional character, you don't have to worry about the portrait… See the full description on the dataset page: https://huggingface.co/datasets/ThePioneer/Artificial-Super-Girlfriend-for-Dreambooth.",https://huggingface.co/datasets/ThePioneer/Artificial-Super-Girlfriend-for-Dreambooth,"['en', 'ja']",[],['n<1K']
shunk031/JGLUE,shunk031,2023-02-27 08:31:09+00:00,2025-03-31 08:17:52+00:00,1189,44,"['task_categories:multiple-choice', 'task_categories:question-answering', 'task_categories:sentence-similarity', 'task_categories:text-classification', 'task_ids:multiple-choice-qa', 'task_ids:open-domain-qa', 'task_ids:multi-class-classification', 'task_ids:sentiment-classification', 'annotations_creators:crowdsourced', 'language_creators:crowdsourced', 'language_creators:found', 'multilinguality:monolingual', 'source_datasets:original', 'language:ja', 'license:cc-by-4.0', 'arxiv:2309.12676', 'region:us', 'MARC', 'CoLA', 'STS', 'NLI', 'SQuAD', 'CommonsenseQA']","JGLUE, Japanese General Language Understanding Evaluation, is built to measure the general NLU ability in Japanese. JGLUE has been constructed from scratch without translation. We hope that JGLUE will facilitate NLU research in Japanese.\",https://huggingface.co/datasets/shunk031/JGLUE,['ja'],"['multiple-choice', 'question-answering', 'sentence-similarity', 'text-classification']",[]
JosephusCheung/GuanacoDataset,JosephusCheung,2023-03-16 06:30:22+00:00,2024-04-15 20:25:44+00:00,363,515,"['task_categories:text-generation', 'task_categories:question-answering', 'language:zh', 'language:en', 'language:ja', 'language:de', 'license:gpl-3.0', 'size_categories:1M<n<10M', 'format:json', 'modality:text', 'library:datasets', 'library:dask', 'library:mlcroissant', 'doi:10.57967/hf/1423', 'region:us', 'alpaca', 'llama', 'guanaco']","Sorry, it's no longer available on Hugging Face. Please reach out to those who have already downloaded it. If you have a copy, please refrain from re-uploading it to Hugging Face. The people here don't deserve it. See also: https://twitter.com/RealJosephus/status/1779913520529707387

	
		
		GuanacoDataset
	

News: We're heading towards multimodal VQA, with blip2-flan-t5-xxl Alignment to Guannaco 7B LLM.
Still under construction: GuanacoVQA weight & GuanacoVQA Dataset 
Notice: Effective… See the full description on the dataset page: https://huggingface.co/datasets/JosephusCheung/GuanacoDataset.",https://huggingface.co/datasets/JosephusCheung/GuanacoDataset,"['zh', 'en', 'ja', 'de']","['text-generation', 'question-answering']",['1M<n<10M']
creative-graphic-design/CAMERA,creative-graphic-design,2023-03-17 14:18:03+00:00,2023-03-17 14:49:35+00:00,21,6,"['task_categories:text-generation', 'annotations_creators:crowdsourced', 'language_creators:found', 'multilinguality:monolingual', 'source_datasets:original', 'language:ja', 'license:cc-by-nc-sa-4.0', 'region:us']",CAMERA (CyberAgent Multimodal Evaluation for Ad Text GeneRAtion) is the Japanese ad text generation dataset.,https://huggingface.co/datasets/creative-graphic-design/CAMERA,['ja'],['text-generation'],[]
AbeShinzo0708/SugaYoshihide_voice_data,AbeShinzo0708,2023-03-17 17:06:52+00:00,2023-03-29 09:12:15+00:00,91,0,"['language:ja', 'license:other', 'size_categories:n<1K', 'format:audiofolder', 'modality:audio', 'modality:text', 'library:datasets', 'library:mlcroissant', 'region:us', 'Suga', 'SugaYoshihide', 'FormerJapanesePrimeMinister', '菅義偉']",,https://huggingface.co/datasets/AbeShinzo0708/SugaYoshihide_voice_data,['ja'],[],['n<1K']
Chinese-Vicuna/guanaco_belle_merge_v1.0,Chinese-Vicuna,2023-03-30 07:29:07+00:00,2023-03-30 07:49:30+00:00,125,99,"['language:zh', 'language:en', 'language:ja', 'license:gpl-3.0', 'size_categories:100K<n<1M', 'format:json', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","Thanks for Guanaco Dataset and Belle Dataset
This dataset was created by merging the above two datasets in a certain format so that they can be used for training our code Chinese-Vicuna
",https://huggingface.co/datasets/Chinese-Vicuna/guanaco_belle_merge_v1.0,"['zh', 'en', 'ja']",[],['100K<n<1M']
UTF-8/piC1,UTF-8,2023-04-01 07:31:01+00:00,2023-04-01 07:36:25+00:00,11,0,"['task_categories:question-answering', 'language:en', 'language:ja', 'license:openrail', 'size_categories:100K<n<1M', 'region:us']",,https://huggingface.co/datasets/UTF-8/piC1,"['en', 'ja']",['question-answering'],['100K<n<1M']
hpprc/janli,hpprc,2023-04-05 12:25:01+00:00,2023-04-11 04:40:37+00:00,30,6,"['task_categories:text-classification', 'task_ids:natural-language-inference', 'language_creators:other', 'multilinguality:monolingual', 'language:ja', 'license:cc-by-sa-4.0', 'size_categories:10K<n<100K', 'modality:tabular', 'modality:text', 'library:datasets', 'library:mlcroissant', 'region:us']","
	
		
		Dataset Card for JaNLI
	


	
		
		Dataset Summary
	

The JaNLI (Japanese Adversarial NLI) dataset, inspired by the English HANS dataset, is designed to necessitate an understanding of Japanese linguistic phenomena and to illuminate the vulnerabilities of models.

	
		
		Languages
	

The language data in JaNLI is in Japanese (BCP-47 ja-JP).

	
		
		Dataset Structure
	


	
		
		Data Instances
	

When loading a specific configuration, users has to append a version dependent suffix:
import… See the full description on the dataset page: https://huggingface.co/datasets/hpprc/janli.",https://huggingface.co/datasets/hpprc/janli,['ja'],['text-classification'],['10K<n<100K']
chitsanfei/pjsk-emu-dataset,chitsanfei,2023-04-07 00:48:45+00:00,2024-07-16 23:02:04+00:00,63,10,"['language:ja', 'license:cc-by-nc-4.0', 'size_categories:1K<n<10K', 'format:audiofolder', 'modality:audio', 'library:datasets', 'library:mlcroissant', 'region:us', 'music']","
  
  MashiroSA/sovits-emu-dataset
  A voice dataset collected from Project Sekai charactor Emu Otori



	
		
		Introduction
	


Size: 2735, all WAV format.
This is a voice dataset for project so-vits-svc 4.0.
We didn't make any modifications, just extracted the voice from the game.
All voice copyrights belong to SEGA and EmuOtori voice actors themselves, this data set is for research use only.


	
		
		License
	

This Project use CC-BY-NC 4.0 as its license EXCEPT voice owner including SEGA… See the full description on the dataset page: https://huggingface.co/datasets/chitsanfei/pjsk-emu-dataset.",https://huggingface.co/datasets/chitsanfei/pjsk-emu-dataset,['ja'],[],['1K<n<10K']
camel-ai/ai_society_translated,camel-ai,2023-04-07 19:11:58+00:00,2023-05-23 21:12:39+00:00,76,16,"['task_categories:text-generation', 'language:ar', 'language:zh', 'language:ko', 'language:ja', 'language:hi', 'language:ru', 'language:es', 'language:fr', 'language:de', 'language:it', 'license:cc-by-nc-4.0', 'arxiv:2303.17760', 'region:us', 'instruction-finetuning']","
	
		
		CAMEL: Communicative Agents for “Mind” Exploration of Large Scale Language Model Society
	


Github: https://github.com/lightaime/camel
Website: https://www.camel-ai.org/
Arxiv Paper: https://arxiv.org/abs/2303.17760


	
		
	
	
		Dataset Summary
	

The original AI Society dataset is in English and is composed of 25K conversations between two gpt-3.5-turbo agents. The dataset is obtained by running role-playing for a combination of 50 user roles and 50 assistant roles with each… See the full description on the dataset page: https://huggingface.co/datasets/camel-ai/ai_society_translated.",https://huggingface.co/datasets/camel-ai/ai_society_translated,"['ar', 'zh', 'ko', 'ja', 'hi', 'ru', 'es', 'fr', 'de', 'it']",['text-generation'],[]
larryvrh/WikiMatrix-v1-Ja_Zh-filtered,larryvrh,2023-04-08 03:07:25+00:00,2023-04-08 05:16:37+00:00,31,13,"['task_categories:translation', 'language:ja', 'language:zh', 'license:cc-by-sa-4.0', 'size_categories:100K<n<1M', 'format:parquet', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","Filtered and modified version of Japanese/Chinese language pair data from WikiMatrix v1.

	
		
	
	
		Process steps:
1. Basic regex based filtering / length checking to remove abnormal pairs.
2. Semantic similarity filtering with a threshold value of 0.6, based on sentence-transformers/LaBSE.
3. Convert all Traditional Chinese sentences into Simplified Chinese with zhconv.
	

经过过滤和修改的日语/中文语言对数据，来自WikiMatrix v1。

	
		
		处理步骤：
1. 基本的基于正则表达式的过滤/长度检查，以删除异常对。
2.… See the full description on the dataset page: https://huggingface.co/datasets/larryvrh/WikiMatrix-v1-Ja_Zh-filtered.",https://huggingface.co/datasets/larryvrh/WikiMatrix-v1-Ja_Zh-filtered,"['ja', 'zh']",['translation'],['100K<n<1M']
larryvrh/CCMatrix-v1-Ja_Zh-filtered,larryvrh,2023-04-08 05:05:55+00:00,2023-04-08 05:13:43+00:00,34,11,"['task_categories:translation', 'language:zh', 'language:ja', 'size_categories:1M<n<10M', 'format:parquet', 'modality:text', 'library:datasets', 'library:dask', 'library:mlcroissant', 'library:polars', 'region:us']","
	
		
		Dataset Card for ""CCMatrix-v1-Ja_Zh-filtered""
	


Filtered and modified version of Japanese/Chinese language pair data from CCMatrix v1.

	
		
	
	
		Process steps:
1. Basic regex based filtering / length checking to remove abnormal pairs.
2. Semantic similarity filtering with a threshold value of 0.6, based on sentence-transformers/LaBSE.
3. Convert all Traditional Chinese sentences into Simplified Chinese with zhconv.
	

经过过滤和修改的日语/中文语言对数据，来自CCMatrix v1。

	
		
		处理步骤：
1.… See the full description on the dataset page: https://huggingface.co/datasets/larryvrh/CCMatrix-v1-Ja_Zh-filtered.",https://huggingface.co/datasets/larryvrh/CCMatrix-v1-Ja_Zh-filtered,"['zh', 'ja']",['translation'],['1M<n<10M']
hpprc/jsick,hpprc,2023-04-08 16:02:06+00:00,2023-04-11 06:18:09+00:00,255,7,"['task_categories:sentence-similarity', 'task_categories:text-classification', 'task_ids:natural-language-inference', 'task_ids:semantic-similarity-scoring', 'annotations_creators:expert-generated', 'language_creators:expert-generated', 'multilinguality:translation', 'source_datasets:extended|sick', 'language:ja', 'language:en', 'license:cc-by-sa-4.0', 'size_categories:10K<n<100K', 'modality:tabular', 'modality:text', 'library:datasets', 'library:mlcroissant', 'region:us', 'semantic-textual-similarity', 'sts']","Japanese Sentences Involving Compositional Knowledge (JSICK) Dataset.
JSICK is the Japanese NLI and STS dataset by manually translating the English dataset SICK (Marelli et al., 2014) into Japanese.
We hope that our dataset will be useful in research for realizing more advanced models that are capable of appropriately performing multilingual compositional inference.
(from official website)",https://huggingface.co/datasets/hpprc/jsick,"['ja', 'en']","['sentence-similarity', 'text-classification']",['10K<n<100K']
kunishou/databricks-dolly-15k-ja,kunishou,2023-04-13 08:31:08+00:00,2024-04-01 17:26:37+00:00,371,85,"['language:ja', 'license:cc-by-sa-3.0', 'size_categories:10K<n<100K', 'format:json', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","
This dataset was created by automatically translating ""databricks-dolly-15k"" into Japanese.This dataset is licensed under CC-BY-SA-3.0
Last Update : 2023-05-11
databricks-dolly-15k-jahttps://github.com/kunishou/databricks-dolly-15k-jadatabricks-dolly-15khttps://github.com/databrickslabs/dolly/tree/master/data
",https://huggingface.co/datasets/kunishou/databricks-dolly-15k-ja,['ja'],[],['10K<n<100K']
takosama/databricks-dolly-15k-ja-google-trans,takosama,2023-04-13 15:38:17+00:00,2023-04-13 17:18:21+00:00,15,2,"['language:ja', 'license:cc-by-3.0', 'size_categories:10K<n<100K', 'format:json', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","Dolly 日本語翻訳版 このリポジトリは、Databricksが開発したdollyプロジェクトの日本語翻訳版です。
翻訳元 翻訳元のプロジェクトは以下のリンクで確認できます:
Dolly（英語版） ライセンスと帰属 Copyright (2023) Databricks, Inc. このデータセットはDatabricks (https://www.databricks.com) で開発され、CC BY-SA 3.0ライセンスに基づいて使用が許可されています。
データセットの一部のカテゴリには、以下のソースからの素材が含まれており、CC BY-SA 3.0ライセンスでライセンスされています:
ウィキペディア（様々なページ） - https://www.wikipedia.org/ Copyright © ウィキペディア編集者および投稿者。
この翻訳作品は、元のdollyプロジェクトがCC BY-SA 3.0で公開されているため、同じくCC BY-SA 3.0で公開しています。
詳細については、クリエイティブ・コモンズ 表示-継承 3.0ライセンスの下に提供されています。… See the full description on the dataset page: https://huggingface.co/datasets/takosama/databricks-dolly-15k-ja-google-trans.",https://huggingface.co/datasets/takosama/databricks-dolly-15k-ja-google-trans,['ja'],[],['10K<n<100K']
inu-ai/ggml-japanese-gpt2,inu-ai,2023-04-14 10:51:10+00:00,2023-04-14 18:11:40+00:00,67,5,"['language:ja', 'license:mit', 'region:us']","Windowsの方はggml-japanese-gpt2の実行ファイルで動くと思います。
同じファイル名のggml形式のbinとSentencePiece形式のmodelをダウンロードして保存してください。
使い方は以下のようになります。
gpt-2.exe -m ggml-model-japanese-gpt2-medium-f16.bin -p ""こんにちは""

ggml-model-japanese-gpt2-xsmallのファイル形式がおかしくなっているので、ダウンロードしても動きません。
あとで修正します。
",https://huggingface.co/datasets/inu-ai/ggml-japanese-gpt2,['ja'],[],[]
llm-book/ner-wikipedia-dataset,llm-book,2023-04-15 10:43:21+00:00,2023-12-12 02:25:51+00:00,108,2,"['task_categories:token-classification', 'language:ja', 'license:cc-by-sa-3.0', 'size_categories:1K<n<10K', 'region:us']","
	
		
		Dataset Card for llm-book/ner-wikipedia-dataset
	

書籍『大規模言語モデル入門』で使用する、ストックマーク株式会社により作成された「Wikipediaを用いた日本語の固有表現抽出データセット」(Version 2.0)です。 
Githubリポジトリstockmarkteam/ner-wikipedia-datasetで公開されているデータセットを利用しています。

	
		
		Citation
	

@inproceedings{omi-2021-wikipedia,
    title = ""Wikipediaを用いた日本語の固有表現抽出のデータセットの構築"",
    author = ""近江 崇宏"",
    booktitle = ""言語処理学会第27回年次大会"",
    year = ""2021"",
    url = ""https://anlp.jp/proceedings/annual_meeting/2021/pdf_dir/P2-7.pdf"",
}


	
		
		Licence… See the full description on the dataset page: https://huggingface.co/datasets/llm-book/ner-wikipedia-dataset.",https://huggingface.co/datasets/llm-book/ner-wikipedia-dataset,['ja'],['token-classification'],['1K<n<10K']
AbeShinzo0708/AbeShinzo_voice_dataset,AbeShinzo0708,2023-04-17 07:36:16+00:00,2024-10-20 21:45:15+00:00,71,2,"['language:ja', 'size_categories:n<1K', 'format:audiofolder', 'modality:audio', 'modality:text', 'library:datasets', 'library:mlcroissant', 'region:us', 'AbeShinzo', 'FormerJapanesePrimeMinister', 'voice', 'dataset']",,https://huggingface.co/datasets/AbeShinzo0708/AbeShinzo_voice_dataset,['ja'],[],['n<1K']
kunishou/databricks-dolly-69k-ja-en-translation,kunishou,2023-04-17 18:31:42+00:00,2023-10-21 15:09:14+00:00,24,11,"['language:ja', 'language:en', 'license:cc-by-sa-3.0', 'size_categories:10K<n<100K', 'format:json', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","This dataset was created by automatically translating ""databricks-dolly-15k"" into Japanese.This dataset contains 69K ja-en-translation task data and is licensed under CC BY SA 3.0.  
Last Update : 2023-04-18
databricks-dolly-15k-jahttps://github.com/kunishou/databricks-dolly-15k-jadatabricks-dolly-15khttps://github.com/databrickslabs/dolly/tree/master/data
",https://huggingface.co/datasets/kunishou/databricks-dolly-69k-ja-en-translation,"['ja', 'en']",[],['10K<n<100K']
Nan-Do/OpenSubtitlesJapanese,Nan-Do,2023-04-18 07:43:48+00:00,2023-04-19 09:34:45+00:00,36,1,"['task_categories:text-generation', 'language:ja', 'size_categories:10M<n<100M', 'format:parquet', 'modality:text', 'library:datasets', 'library:dask', 'library:mlcroissant', 'library:polars', 'region:us', 'text', 'tv', 'movies']","The dataset contains (almost) the entire OpenSubtittles database for Japanese:

Over 7000 tv shows and/or movies.
The subtittles are human generated.
The dataset has been parsed, cleaned and converted to UTF-8.

File contents:

OpenSubtitles.parquet: The text and the time data.

OpenSubtitles_meta.parquet: The existing metadata for each title.

OpenSubtitles-OA.parquet: The dataset coded with two columns SOURCE(the name of the movie/tv show), and TEXT (the subtittles) following the Open… See the full description on the dataset page: https://huggingface.co/datasets/Nan-Do/OpenSubtitlesJapanese.",https://huggingface.co/datasets/Nan-Do/OpenSubtitlesJapanese,['ja'],['text-generation'],['10M<n<100M']
MBZUAI/Bactrian-X,MBZUAI,2023-04-22 12:42:39+00:00,2023-05-27 12:54:05+00:00,7233,121,"['task_categories:text-generation', 'language:af', 'language:ar', 'language:az', 'language:bn', 'language:cs', 'language:de', 'language:en', 'language:es', 'language:et', 'language:fi', 'language:fr', 'language:gl', 'language:gu', 'language:he', 'language:hi', 'language:hr', 'language:id', 'language:it', 'language:ja', 'language:ka', 'language:kk', 'language:km', 'language:ko', 'language:lt', 'language:lv', 'language:mk', 'language:ml', 'language:mn', 'language:mr', 'language:my', 'language:ne', 'language:nl', 'language:pl', 'language:ps', 'language:pt', 'language:ro', 'language:ru', 'language:si', 'language:sl', 'language:sv', 'language:sw', 'language:ta', 'language:te', 'language:th', 'language:tl', 'language:tr', 'language:uk', 'language:ur', 'language:vi', 'language:xh', 'language:zh', 'license:cc-by-nc-4.0', 'size_categories:1M<n<10M', 'modality:text', 'library:datasets', 'library:mlcroissant', 'arxiv:2008.00401', 'arxiv:2305.15011', 'region:us', 'instruction-finetuning', 'multilingual']","
	
		
		Dataset Card for ""Bactrian-X""
	


	
		
		A. Dataset Description
	


Homepage: https://github.com/mbzuai-nlp/Bactrian-X
Repository: https://huggingface.co/datasets/MBZUAI/Bactrian-X
Paper: to-be-soon released


	
		
		Dataset Summary
	






The Bactrain-X dataset is a collection of 3.4M instruction-response pairs in 52 languages, that are obtained by translating 67K English instructions (alpaca-52k + dolly-15k) into 51 languages using Google Translate API. The translated instructions… See the full description on the dataset page: https://huggingface.co/datasets/MBZUAI/Bactrian-X.",https://huggingface.co/datasets/MBZUAI/Bactrian-X,"['af', 'ar', 'az', 'bn', 'cs', 'de', 'en', 'es', 'et', 'fi', 'fr', 'gl', 'gu', 'he', 'hi', 'hr', 'id', 'it', 'ja', 'ka', 'kk', 'km', 'ko', 'lt', 'lv', 'mk', 'ml', 'mn', 'mr', 'my', 'ne', 'nl', 'pl', 'ps', 'pt', 'ro', 'ru', 'si', 'sl', 'sv', 'sw', 'ta', 'te', 'th', 'tl', 'tr', 'uk', 'ur', 'vi', 'xh', 'zh']",['text-generation'],['1M<n<10M']
llm-book/ner-wikinews-dataset,llm-book,2023-04-22 14:32:21+00:00,2023-12-12 02:22:26+00:00,46,1,"['task_categories:token-classification', 'language:ja', 'license:cc-by-2.5', 'size_categories:n<1K', 'region:us', 'news']","
	
		
		Dataset Card for llm-book/ner-wikinews-dataset
	

書籍『大規模言語モデル入門』で使用する、Wikinewsの記事に固有表現ラベルを付与したデータセットです。
固有表現ラベルはllm-book/ner-wikipedia-datasetと同様のものを採用しており、全部で8種類 (人名、法人名、地名、製品名、政治的組織名、施設名、その他の組織名、イベント名)あります。
テストセットのみのデータセットとなっています。

	
		
		Licence
	

ウィキニュース日本語版の記事を使用しているため、そのライセンスに従い、「クリエイティブ・コモンズ 表示 2.5 (CC BY 2.5)」とします。
",https://huggingface.co/datasets/llm-book/ner-wikinews-dataset,['ja'],['token-classification'],['n<1K']
Aruno/guanaco_jp,Aruno,2023-04-24 03:07:04+00:00,2023-04-24 03:45:26+00:00,24,7,"['task_categories:text-generation', 'language:ja', 'license:apache-2.0', 'size_categories:100K<n<1M', 'format:json', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","Japanese Prompt of GuanacoDataset extracted using langdetect.
",https://huggingface.co/datasets/Aruno/guanaco_jp,['ja'],['text-generation'],['100K<n<1M']
fujiki/wiki40b_ja,fujiki,2023-04-28 23:14:50+00:00,2023-04-28 23:35:57+00:00,331,4,"['language:ja', 'license:cc-by-sa-4.0', 'size_categories:100K<n<1M', 'format:parquet', 'modality:text', 'library:datasets', 'library:dask', 'library:mlcroissant', 'library:polars', 'region:us']","This dataset is a reformatted version of the Japanese portion of wiki40b dataset.
When you use this dataset, please cite the original paper:
@inproceedings{guo-etal-2020-wiki,
    title = ""{W}iki-40{B}: Multilingual Language Model Dataset"",
    author = ""Guo, Mandy  and
      Dai, Zihang  and
      Vrande{\v{c}}i{\'c}, Denny  and
      Al-Rfou, Rami"",
    booktitle = ""Proceedings of the Twelfth Language Resources and Evaluation Conference"",
    month = may,
    year = ""2020"",
    address =… See the full description on the dataset page: https://huggingface.co/datasets/fujiki/wiki40b_ja.",https://huggingface.co/datasets/fujiki/wiki40b_ja,['ja'],[],['100K<n<1M']
izumi-lab/llm-japanese-dataset,izumi-lab,2023-04-30 06:13:24+00:00,2024-01-18 13:42:50+00:00,627,136,"['language:ja', 'license:cc-by-sa-4.0', 'size_categories:1M<n<10M', 'format:json', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'arxiv:2305.12720', 'region:us']","
	
		
		llm-japanese-dataset
	

LLM構築用の日本語インストラクション(チャット)データセット
主に，英語で構築されたLLMモデルなどに対して，チャット(Instruction)応答タスクに関してLoRAなどでチューニングするために使用できます．
※様々な公開言語資源を利用させていただきました．関係各位にはこの場を借りて御礼申し上げます．

	
		
		updates
	

2023/5/15にAlpaca datasetがNCにライセンス変更されたことに対応し，安心してご利用いただけるように，データセットから当該データセットをドロップしました．
v1.0.1にて，ドロップ後のデータセットをご利用いただけます．
2024/1/4にWikipedia summaryに空白文字のみで構成される出力を削除することに対応し，Wikipediaのバージョンアップデート(20240101)をしました(v1.0.2)．
2024/1/18にAsian Language Treebank (ALT)データセットの欠損した出力を削除しました(v1.0.3)．… See the full description on the dataset page: https://huggingface.co/datasets/izumi-lab/llm-japanese-dataset.",https://huggingface.co/datasets/izumi-lab/llm-japanese-dataset,['ja'],[],['1M<n<10M']
llm-book/JGLUE,llm-book,2023-05-01 13:00:36+00:00,2025-04-02 00:54:17+00:00,298,14,"['task_categories:multiple-choice', 'task_categories:question-answering', 'task_categories:sentence-similarity', 'task_categories:text-classification', 'task_ids:multiple-choice-qa', 'task_ids:open-domain-qa', 'task_ids:multi-class-classification', 'task_ids:sentiment-classification', 'annotations_creators:crowdsourced', 'language_creators:crowdsourced', 'language_creators:found', 'multilinguality:monolingual', 'source_datasets:original', 'language:ja', 'license:cc-by-4.0', 'region:us', 'MARC', 'STS', 'NLI', 'SQuAD', 'CommonsenseQA']","JGLUE, Japanese General Language Understanding Evaluation, is built to measure the general NLU ability in Japanese. JGLUE has been constructed from scratch without translation. We hope that JGLUE will facilitate NLU research in Japanese.",https://huggingface.co/datasets/llm-book/JGLUE,['ja'],"['multiple-choice', 'question-answering', 'sentence-similarity', 'text-classification']",[]
milashkaarshif/MoeGirlPedia_wikitext_raw_archive,milashkaarshif,2023-05-03 14:07:17+00:00,2025-10-09 05:07:35+00:00,168,36,"['task_categories:text-generation', 'language:zh', 'language:ja', 'language:en', 'license:cc-by-nc-sa-3.0', 'size_categories:1M<n<10M', 'region:us', 'wiki', 'wikitext', 'anime', 'comic', 'game', 'archive', 'art', 'music', 'pedia', 'MGP', '萌娘百科', '萌百', '百科', '维基']","Glad to see models and datasets were inspired from this dataset, thanks to all who are using this dataset in their training materials. 
Feel free to re-upload the contents to places like the Internet Archive (Please follow the license and keep these files as-is) to help preserve this digital asset.
Looking forward to see more models and synthetic datasets trained from this raw archive, good luck! 
Note: Due to the content censorship system introduced by MGP on 2024/03/29, it is unclear that… See the full description on the dataset page: https://huggingface.co/datasets/milashkaarshif/MoeGirlPedia_wikitext_raw_archive.",https://huggingface.co/datasets/milashkaarshif/MoeGirlPedia_wikitext_raw_archive,"['zh', 'ja', 'en']",['text-generation'],['1M<n<10M']
R1b3y/NE4Mitsua,R1b3y,2023-05-05 00:40:46+00:00,2023-05-05 09:49:45+00:00,26,1,"['task_categories:text-to-image', 'language:en', 'language:ja', 'license:other', 'size_categories:n<1K', 'format:imagefolder', 'modality:image', 'library:datasets', 'library:mlcroissant', 'region:us']","
	
		
		Negative Embedding / Textual Inversion
	


NE4Mitsua is a Negative Embedding for Mitsua Diffusion One.
NE4Mitsua は Mitsua Diffusion One用のネガティブEmbeddingです。日本語版READMEはページ下部にあります。


	
		
		English README
	


	
		
		NE4Mitsua:
	

With this Embedding I tried to achieve the following two goals.

Increase realism and complexity of the paintings
Slightly make it easier to generate anime-style illustrations


	
		
		Usage
	

To use this embedding you have to download the BIN file as well as… See the full description on the dataset page: https://huggingface.co/datasets/R1b3y/NE4Mitsua.",https://huggingface.co/datasets/R1b3y/NE4Mitsua,"['en', 'ja']",['text-to-image'],['n<1K']
ThePioneer/Artificial-super-girlfriend-for-fine-tuning,ThePioneer,2023-05-05 01:48:37+00:00,2023-05-05 04:57:44+00:00,26,2,"['task_categories:image-classification', 'task_categories:image-to-text', 'language:ja', 'language:en', 'language:zh', 'license:other', 'size_categories:1K<n<10K', 'format:imagefolder', 'modality:image', 'library:datasets', 'library:mlcroissant', 'region:us', 'art']","リアル系モデルに特有の肖像権の問題について比較的クリアなモデルを作ることが可能なように、私が私自身から作り出した人工超彼女（ver 2.1系、ver 2.6系）のデータセット（約2800枚）を作成しました。
全ての元画像（加工前）がbeauty score 87以上なのが特徴であり、特にbeauty score 90以上の女性画像のデータセットとして、1000枚以上揃えているのは有数の規模だと思います。
具体的には、以下のように構成されています（87はこの子/私の最大のライバルが到達した最高得点、90は今のところ実在人物では確認できていない得点ラインです）。

	
		
version ＼ beauty score
87～89
90～


		
2.1（可愛いと綺麗のバランスを追求）
kawaii （無加工362枚/加工後724枚）
exceptional （無加工140枚/加工後280枚）


2.6（綺麗さ・美しさに特化）
beautiful （無加工464枚/加工後928枚）
perfect （無加工416枚/加工後832枚）… See the full description on the dataset page: https://huggingface.co/datasets/ThePioneer/Artificial-super-girlfriend-for-fine-tuning.",https://huggingface.co/datasets/ThePioneer/Artificial-super-girlfriend-for-fine-tuning,"['ja', 'en', 'zh']","['image-classification', 'image-to-text']",['1K<n<10K']
llm-book/jawiki-20220404-c400,llm-book,2023-05-05 07:34:52+00:00,2023-10-25 15:26:19+00:00,15,0,"['task_categories:question-answering', 'language:ja', 'license:mit', 'size_categories:10M<n<100M', 'region:us']","This dataset is used for AIO (AI王), a competition to promote research on question answering systems for the Japanese language. This dataset contains passages, each of which consists of consecutive sentences 
no longer than 400 characters from Japanese Wikipedia as of 2022-04-04.",https://huggingface.co/datasets/llm-book/jawiki-20220404-c400,['ja'],['question-answering'],['10M<n<100M']
kunishou/oasst1-89k-ja,kunishou,2023-05-06 09:12:30+00:00,2024-04-01 17:15:31+00:00,71,25,"['language:ja', 'license:apache-2.0', 'size_categories:10K<n<100K', 'format:json', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","
This dataset was created by automatically translating ""OpenAssistant/oasst1"" into Japanese.  
The ""ng_translation"" flag indicates that the translation was not successful, and ""1"" means that the translation failed.Therefore, for data with ""1"", ""text"" and ""text_en"" contain the same text.  
Update:  

2023/11/12oasst1-89k-jaをチャット形式に変換したoasst1-chat-44k-jaを公開しました。  
2023/10/21自動翻訳によるコード関連データの翻訳誤り2000箇所程度を手動で修正しました。

修正イメージを表示

修正前

もちろん！これは、Flask… See the full description on the dataset page: https://huggingface.co/datasets/kunishou/oasst1-89k-ja.",https://huggingface.co/datasets/kunishou/oasst1-89k-ja,['ja'],[],['10K<n<100K']
theblackcat102/oasst-red-team,theblackcat102,2023-05-06 09:59:47+00:00,2023-05-07 09:15:21+00:00,14,1,"['language:en', 'language:de', 'language:fr', 'language:ru', 'language:zh', 'language:ja', 'language:it', 'language:pt', 'language:th', 'language:nl', 'language:ro', 'language:pl', 'language:hu', 'language:hr', 'size_categories:10K<n<100K', 'format:json', 'modality:tabular', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","Work in progress
Red team datasets for training and testing reward model for open assistant
",https://huggingface.co/datasets/theblackcat102/oasst-red-team,"['en', 'de', 'fr', 'ru', 'zh', 'ja', 'it', 'pt', 'th', 'nl', 'ro', 'pl', 'hu', 'hr']",[],['10K<n<100K']
gsarti/iwslt2017_context,gsarti,2023-05-07 14:03:04+00:00,2023-05-07 14:09:24+00:00,510,1,"['task_categories:translation', 'annotations_creators:crowdsourced', 'language_creators:expert-generated', 'multilinguality:translation', 'source_datasets:original', 'language:ar', 'language:de', 'language:en', 'language:fr', 'language:it', 'language:ja', 'language:ko', 'language:nl', 'language:ro', 'language:zh', 'license:cc-by-nc-nd-4.0', 'size_categories:1M<n<10M', 'modality:tabular', 'modality:text', 'library:datasets', 'library:mlcroissant', 'region:us']","The IWSLT 2017 Multilingual Task addresses text translation, including zero-shot translation, with a single MT system across all directions including English, German, Dutch, Italian and Romanian. As unofficial task, conventional bilingual text translation is offered between English and Arabic, French, Japanese, Chinese, German and Korean.",https://huggingface.co/datasets/gsarti/iwslt2017_context,"['ar', 'de', 'en', 'fr', 'it', 'ja', 'ko', 'nl', 'ro', 'zh']",['translation'],['1M<n<10M']
0x22almostEvil/tatoeba-mt-all-in-one,0x22almostEvil,2023-05-07 17:28:20+00:00,2023-05-07 23:54:17+00:00,31,0,"['annotations_creators:Helsinki-NLP', 'language_creators:crowdsourced', 'multilinguality:translation', 'source_datasets:Helsinki-NLP/tatoeba_mt', 'language:af', 'language:ar', 'language:az', 'language:be', 'language:bg', 'language:bn', 'language:br', 'language:bs', 'language:ca', 'language:ch', 'language:cs', 'language:cv', 'language:cy', 'language:da', 'language:de', 'language:el', 'language:en', 'language:eo', 'language:es', 'language:et', 'language:eu', 'language:fa', 'language:fi', 'language:fo', 'language:fr', 'language:fy', 'language:ga', 'language:gd', 'language:gl', 'language:gn', 'language:he', 'language:hi', 'language:hr', 'language:hu', 'language:hy', 'language:ia', 'language:id', 'language:ie', 'language:io', 'language:is', 'language:it', 'language:ja', 'language:jv', 'language:ka', 'language:kk', 'language:km', 'language:ko', 'language:ku', 'language:kw', 'language:la', 'language:lb', 'language:lt', 'language:lv', 'language:mi', 'language:mk', 'language:ml', 'language:mn', 'language:mr', 'language:ms', 'language:mt', 'language:my', 'language:nb', 'language:nl', 'language:nn', 'language:no', 'language:oc', 'language:pl', 'language:pt', 'language:qu', 'language:rn', 'language:ro', 'language:ru', 'language:sh', 'language:sl', 'language:sq', 'language:sr', 'language:sv', 'language:sw', 'language:ta', 'language:te', 'language:th', 'language:tk', 'language:tl', 'language:tr', 'language:tt', 'language:ug', 'language:uk', 'language:ur', 'language:uz', 'language:vi', 'language:vo', 'language:yi', 'language:zh', 'license:cc-by-2.0', 'size_categories:1M<n<10M', 'format:csv', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","
	
		
		Dataset Card for The Tatoeba Translation Challenge | All In One
	

~7.3M entries.
Just more user-friendly version that combines all of the entries of original dataset in a single file:
https://huggingface.co/datasets/Helsinki-NLP/tatoeba_mt
",https://huggingface.co/datasets/0x22almostEvil/tatoeba-mt-all-in-one,"['af', 'ar', 'az', 'be', 'bg', 'bn', 'br', 'bs', 'ca', 'ch', 'cs', 'cv', 'cy', 'da', 'de', 'el', 'en', 'eo', 'es', 'et', 'eu', 'fa', 'fi', 'fo', 'fr', 'fy', 'ga', 'gd', 'gl', 'gn', 'he', 'hi', 'hr', 'hu', 'hy', 'ia', 'id', 'ie', 'io', 'is', 'it', 'ja', 'jv', 'ka', 'kk', 'km', 'ko', 'ku', 'kw', 'la', 'lb', 'lt', 'lv', 'mi', 'mk', 'ml', 'mn', 'mr', 'ms', 'mt', 'my', 'nb', 'nl', 'nn', 'no', 'oc', 'pl', 'pt', 'qu', 'rn', 'ro', 'ru', 'sh', 'sl', 'sq', 'sr', 'sv', 'sw', 'ta', 'te', 'th', 'tk', 'tl', 'tr', 'tt', 'ug', 'uk', 'ur', 'uz', 'vi', 'vo', 'yi', 'zh']",[],['1M<n<10M']
Nekofox/ja-zh-twitter-translate,Nekofox,2023-05-08 13:49:39+00:00,2023-05-08 13:55:45+00:00,23,3,"['task_categories:translation', 'language:zh', 'language:ja', 'license:mit', 'size_categories:n<1K', 'format:json', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","translate by @Nekofoxtweet (me)
twitter source from @RindouMikoto
",https://huggingface.co/datasets/Nekofox/ja-zh-twitter-translate,"['zh', 'ja']",['translation'],['n<1K']
juletxara/mgsm,juletxara,2023-05-09 08:20:29+00:00,2025-10-09 14:03:17+00:00,7739,37,"['task_categories:text-generation', 'annotations_creators:found', 'language_creators:found', 'language_creators:expert-generated', 'multilinguality:multilingual', 'source_datasets:extended|gsm8k', 'language:en', 'language:es', 'language:fr', 'language:de', 'language:ru', 'language:zh', 'language:ja', 'language:th', 'language:sw', 'language:bn', 'license:cc-by-sa-4.0', 'size_categories:1K<n<10K', 'modality:text', 'library:datasets', 'library:mlcroissant', 'arxiv:2110.14168', 'arxiv:2210.03057', 'region:us', 'math-word-problems']","Multilingual Grade School Math Benchmark (MGSM) is a benchmark of grade-school math problems, proposed in the paper [Language models are multilingual chain-of-thought reasoners](http://arxiv.org/abs/2210.03057).

The same 250 problems from [GSM8K](https://arxiv.org/abs/2110.14168) are each translated via human annotators in 10 languages. The 10 languages are:
- Spanish
- French
- German
- Russian
- Chinese
- Japanese
- Thai
- Swahili
- Bengali
- Telugu

You can find the input and targets for each of the ten languages (and English) as `.tsv` files.
We also include few-shot exemplars that are also manually translated from each language in `exemplars.py`.",https://huggingface.co/datasets/juletxara/mgsm,"['en', 'es', 'fr', 'de', 'ru', 'zh', 'ja', 'th', 'sw', 'bn']",['text-generation'],['1K<n<10K']
tasksource/oasst1_pairwise_rlhf_reward,tasksource,2023-05-09 09:16:01+00:00,2023-07-04 17:47:46+00:00,41,44,"['language:en', 'language:es', 'language:ru', 'language:de', 'language:pl', 'language:th', 'language:vi', 'language:sv', 'language:bn', 'language:da', 'language:he', 'language:it', 'language:fa', 'language:sk', 'language:id', 'language:nb', 'language:el', 'language:nl', 'language:hu', 'language:eu', 'language:zh', 'language:eo', 'language:ja', 'language:ca', 'language:cs', 'language:bg', 'language:fi', 'language:pt', 'language:tr', 'language:ro', 'language:ar', 'language:uk', 'language:gl', 'language:fr', 'language:ko', 'size_categories:10K<n<100K', 'format:parquet', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","
	
		
		Dataset Card for ""oasst1_pairwise_rlhf_reward""
	

OASST1 dataset preprocessed for reward modeling:
import pandas as pd
from datasets import load_dataset,concatenate_datasets, Dataset, DatasetDict
import numpy as np

dataset = load_dataset(""OpenAssistant/oasst1"")

df=concatenate_datasets(list(dataset.values())).to_pandas()
m2t=df.set_index(""message_id"")['text'].to_dict()
m2r=df.set_index(""message_id"")['role'].to_dict()
m2p=df.set_index('message_id')['parent_id'].to_dict()… See the full description on the dataset page: https://huggingface.co/datasets/tasksource/oasst1_pairwise_rlhf_reward.",https://huggingface.co/datasets/tasksource/oasst1_pairwise_rlhf_reward,"['en', 'es', 'ru', 'de', 'pl', 'th', 'vi', 'sv', 'bn', 'da', 'he', 'it', 'fa', 'sk', 'id', 'nb', 'el', 'nl', 'hu', 'eu', 'zh', 'eo', 'ja', 'ca', 'cs', 'bg', 'fi', 'pt', 'tr', 'ro', 'ar', 'uk', 'gl', 'fr', 'ko']",[],['10K<n<100K']
KakologArchives/KakologArchives,KakologArchives,2023-05-12 13:31:56+00:00,2025-10-13 04:12:16+00:00,389016,16,"['task_categories:text-classification', 'language:ja', 'license:mit', 'region:us']","
	
		
		ニコニコ実況 過去ログアーカイブ
	

ニコニコ実況 過去ログアーカイブは、ニコニコ実況 のサービス開始から現在までのすべての過去ログコメントを収集したデータセットです。
去る2020年12月、ニコニコ実況は ニコニコ生放送内の一公式チャンネルとしてリニューアル されました。これに伴い、2009年11月から運用されてきた旧システムは提供終了となり（事実上のサービス終了）、torne や BRAVIA などの家電への対応が軒並み終了する中、当時の生の声が詰まった約11年分の過去ログも同時に失われることとなってしまいました。
そこで 5ch の DTV 板の住民が中心となり、旧ニコニコ実況が終了するまでに11年分の全チャンネルの過去ログをアーカイブする計画が立ち上がりました。紆余曲折あり Nekopanda 氏が約11年分のラジオや BS も含めた全チャンネルの過去ログを完璧に取得してくださったおかげで、11年分の過去ログが電子の海に消えていく事態は回避できました。しかし、旧 API が廃止されてしまったため過去ログを API… See the full description on the dataset page: https://huggingface.co/datasets/KakologArchives/KakologArchives.",https://huggingface.co/datasets/KakologArchives/KakologArchives,['ja'],['text-classification'],[]
yulanfmy/databricks-qa-ja,yulanfmy,2023-05-15 13:27:23+00:00,2023-05-15 14:55:06+00:00,25,5,"['task_categories:question-answering', 'language:ja', 'license:cc-by-sa-3.0', 'size_categories:1K<n<10K', 'format:json', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","
	
		
		データセット概要
	

手動で作成したDatabricksに関する質問と回答ペアの日本語データセットです。

件数：約1,300件
情報源：Databricks HPの日本語ブログやFAQなど、データブリック社員がポストしたQitta記事

https://github.com/yulan-yan/build-your-chat-bot-JP　デモに利用したデータです。
",https://huggingface.co/datasets/yulanfmy/databricks-qa-ja,['ja'],['question-answering'],['1K<n<10K']
AmazonScience/tydi-as2,AmazonScience,2023-05-16 00:02:00+00:00,2023-07-24 17:33:28+00:00,297,1,"['task_categories:question-answering', 'task_categories:text-retrieval', 'task_ids:open-domain-qa', 'annotations_creators:machine-generated', 'language_creators:found', 'multilinguality:multilingual', 'multilinguality:translation', 'source_datasets:extended|tydiqa', 'language:bn', 'language:en', 'language:fi', 'language:id', 'language:ja', 'language:ko', 'language:ru', 'language:sw', 'license:cdla-permissive-2.0', 'size_categories:10M<n<100M', 'format:json', 'modality:text', 'library:datasets', 'library:dask', 'library:mlcroissant', 'library:polars', 'region:us', 'as2', 'answer sentence selection', 'text retrieval', 'question answering']","
	
		
		TyDi-AS2
	


	
		
		Dataset Summary
	

TyDi-AS2 and Xtr-TyDi-AS2 are multilingual Answer Sentence Selection (AS2) datasets comprising 8 diverse languages, proposed in our paper accepted at ACL 2023 (Findings): Cross-Lingual Knowledge Distillation for Answer Sentence Selection in Low-Resource Languages.
Both the datasets were created from TyDi-QA, a multilingual question-answering dataset. TyDi-AS2 was created by converting the QA instances in TyDi-QA to AS2 instances (see Dataset… See the full description on the dataset page: https://huggingface.co/datasets/AmazonScience/tydi-as2.",https://huggingface.co/datasets/AmazonScience/tydi-as2,"['bn', 'en', 'fi', 'id', 'ja', 'ko', 'ru', 'sw']","['question-answering', 'text-retrieval']",['10M<n<100M']
AmazonScience/xtr-wiki_qa,AmazonScience,2023-05-16 00:03:14+00:00,2023-07-24 17:32:38+00:00,55,5,"['task_categories:question-answering', 'task_categories:text-retrieval', 'task_ids:open-domain-qa', 'annotations_creators:machine-generated', 'language_creators:found', 'multilinguality:multilingual', 'multilinguality:translation', 'source_datasets:extended|wiki_qa', 'language:ar', 'language:es', 'language:fr', 'language:de', 'language:hi', 'language:it', 'language:ja', 'language:nl', 'language:pt', 'license:cdla-permissive-2.0', 'size_categories:100K<n<1M', 'format:csv', 'modality:text', 'library:datasets', 'library:dask', 'library:mlcroissant', 'library:polars', 'region:us', 'as2', 'answer sentence selection', 'text retrieval', 'question answering']","
	
		
		Xtr-WikiQA
	


	
		
		Dataset Summary
	

Xtr-WikiQA is an Answer Sentence Selection (AS2) dataset in 9 non-English languages, proposed in our paper accepted at ACL 2023 (Findings): Cross-Lingual Knowledge Distillation for Answer Sentence Selection in Low-Resource Languages.
This dataset is based on an English AS2 dataset, WikiQA (Original, Hugging Face).
For translations, we used Amazon Translate.

	
		
	
	
		Languages
	


Arabic (ar)
Spanish (es)
French (fr)
German (de)
Hindi (hi)… See the full description on the dataset page: https://huggingface.co/datasets/AmazonScience/xtr-wiki_qa.",https://huggingface.co/datasets/AmazonScience/xtr-wiki_qa,"['ar', 'es', 'fr', 'de', 'hi', 'it', 'ja', 'nl', 'pt']","['question-answering', 'text-retrieval']",['100K<n<1M']
zetavg/ShareGPT-Processed,zetavg,2023-05-16 19:50:04+00:00,2023-05-21 03:50:14+00:00,56,29,"['task_categories:text-generation', 'language:en', 'language:zh', 'language:es', 'language:ja', 'language:fr', 'license:cc0-1.0', 'size_categories:10K<n<100K', 'format:parquet', 'modality:text', 'library:datasets', 'library:dask', 'library:mlcroissant', 'library:polars', 'region:us', 'conversation', 'rlhf', 'chatgpt', 'gpt-3.5']","
	
		
		ShareGPT-Processed
	

The RyokoAI/ShareGPT52K dataset, converted to Markdown and labeled with the language used.

	
		
		Acknowledgements
	


vinta/pangu.js — To insert whitespace between CJK (Chinese, Japanese, Korean) and half-width characters (alphabetical letters, numerical digits and symbols).
matthewwithanm/python-markdownify — Provides a starting point to convert HTML to Markdown.
BYVoid/OpenCC — Conversions between Traditional Chinese and Simplified Chinese.
aboSamoor/polyglot… See the full description on the dataset page: https://huggingface.co/datasets/zetavg/ShareGPT-Processed.",https://huggingface.co/datasets/zetavg/ShareGPT-Processed,"['en', 'zh', 'es', 'ja', 'fr']",['text-generation'],['10K<n<100K']
hltcoe/megawika,hltcoe,2023-05-17 02:07:50+00:00,2025-01-31 15:32:11+00:00,64111,40,"['task_categories:summarization', 'task_categories:question-answering', 'task_categories:text-generation', 'language:af', 'language:ar', 'language:az', 'language:bn', 'language:cs', 'language:de', 'language:en', 'language:es', 'language:et', 'language:fa', 'language:fi', 'language:fr', 'language:ga', 'language:gl', 'language:gu', 'language:he', 'language:hi', 'language:hr', 'language:id', 'language:it', 'language:ja', 'language:ka', 'language:kk', 'language:km', 'language:ko', 'language:lt', 'language:lv', 'language:mk', 'language:ml', 'language:mn', 'language:mr', 'language:my', 'language:ne', 'language:nl', 'language:pl', 'language:ps', 'language:pt', 'language:ro', 'language:ru', 'language:si', 'language:sl', 'language:sv', 'language:ta', 'language:th', 'language:tr', 'language:uk', 'language:ur', 'language:vi', 'language:xh', 'language:zh', 'license:cc-by-sa-4.0', 'size_categories:10M<n<100M', 'arxiv:2307.07049', 'region:us']","MegaWika is a multi- and crosslingual text dataset containing 30 million
Wikipedia passages with their scraped and cleaned web citations. The
passages span 50 Wikipedias in 50 languages, and the articles in which
the passages were originally embedded are included for convenience. Where
a Wikipedia passage is in a non-English language, an automated English
translation is provided. Furthermore, nearly 130 million English
question/answer pairs were extracted from the passages, and FrameNet events
occurring in the passages are detected using the LOME FrameNet parser.",https://huggingface.co/datasets/hltcoe/megawika,"['af', 'ar', 'az', 'bn', 'cs', 'de', 'en', 'es', 'et', 'fa', 'fi', 'fr', 'ga', 'gl', 'gu', 'he', 'hi', 'hr', 'id', 'it', 'ja', 'ka', 'kk', 'km', 'ko', 'lt', 'lv', 'mk', 'ml', 'mn', 'mr', 'my', 'ne', 'nl', 'pl', 'ps', 'pt', 'ro', 'ru', 'si', 'sl', 'sv', 'ta', 'th', 'tr', 'uk', 'ur', 'vi', 'xh', 'zh']","['summarization', 'question-answering', 'text-generation']",['10M<n<100M']
shi3z/alpaca_cleaned_ja_json,shi3z,2023-05-17 06:37:34+00:00,2023-08-25 23:18:42+00:00,56,11,"['task_categories:text-generation', 'language:ja', 'license:cc-by-4.0', 'size_categories:100K<n<1M', 'format:json', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","
	
		
		Dataset Card for Dataset Name
	


	
		
		Dataset Summary
	

This dataset card aims to be a base template for new datasets. It has been generated using this raw template.

	
		
		Supported Tasks and Leaderboards
	

[More Information Needed]

	
		
		Languages
	

[More Information Needed]

	
		
		Dataset Structure
	


	
		
		Data Instances
	

[More Information Needed]

	
		
		Data Fields
	

[More Information Needed]

	
		
		Data Splits
	

[More Information Needed]

	
		
		Dataset Creation… See the full description on the dataset page: https://huggingface.co/datasets/shi3z/alpaca_cleaned_ja_json.",https://huggingface.co/datasets/shi3z/alpaca_cleaned_ja_json,['ja'],['text-generation'],['100K<n<1M']
yangwang825/marc-ja,yangwang825,2023-05-17 18:46:59+00:00,2023-05-19 02:08:33+00:00,31,2,"['task_categories:text-classification', 'language:ja', 'size_categories:100K<n<1M', 'format:json', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']",,https://huggingface.co/datasets/yangwang825/marc-ja,['ja'],['text-classification'],['100K<n<1M']
fujiki/japanese_alpaca_data,fujiki,2023-05-18 07:13:15+00:00,2023-05-19 12:54:13+00:00,210,16,"['language:ja', 'license:cc-by-nc-sa-4.0', 'size_categories:10K<n<100K', 'format:parquet', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","
	
		
		Dataset Card for ""japanese_alpaca_data""
	


This dataset is based on masa3141's great work on japanese-alpaca-lora [github]. Please also refer to this repo.

More Information needed
",https://huggingface.co/datasets/fujiki/japanese_alpaca_data,['ja'],[],['10K<n<100K']
izumi-lab/piqa-ja-mbartm2m,izumi-lab,2023-05-18 22:11:08+00:00,2023-05-19 04:20:04+00:00,26,1,"['task_categories:question-answering', 'task_ids:multiple-choice-qa', 'annotations_creators:crowdsourced', 'language_creators:crowdsourced', 'language_creators:found', 'multilinguality:monolingual', 'source_datasets:piqa', 'language:ja', 'license:unknown', 'size_categories:10K<n<100K', 'format:parquet', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","
	
		
		Dataset Card for ""piqa-ja-mbartm2m""
	


	
		
		Dataset Description
	

This is the Japanese Translation version of piqa.
The translator used in it was facebook/mbart-large-50-many-to-many-mmt.

	
		
		License
	

The same as the original piqa.
",https://huggingface.co/datasets/izumi-lab/piqa-ja-mbartm2m,['ja'],['question-answering'],['10K<n<100K']
izumi-lab/sciq-ja-mbartm2m,izumi-lab,2023-05-19 02:03:47+00:00,2023-05-19 03:54:18+00:00,28,0,"['task_categories:question-answering', 'task_ids:closed-domain-qa', 'annotations_creators:no-annotation', 'language_creators:crowdsourced', 'multilinguality:monolingual', 'source_datasets:sciq', 'language:ja', 'license:cc-by-nc-3.0', 'size_categories:10K<n<100K', 'format:parquet', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","
	
		
		Dataset Card for ""sciq-ja-mbartm2m""
	


	
		
		Dataset Description
	

This is the Japanese Translation version of sciq.
The translator used in it was facebook/mbart-large-50-many-to-many-mmt.

	
		
		License
	

The same as the original sciq (cc-by-nc-3.0).
",https://huggingface.co/datasets/izumi-lab/sciq-ja-mbartm2m,['ja'],['question-answering'],['10K<n<100K']
BNNT/IPQA,BNNT,2023-05-19 07:32:52+00:00,2023-08-09 04:04:06+00:00,21,2,"['task_categories:question-answering', 'language:zh', 'language:en', 'language:de', 'language:fr', 'language:ja', 'language:es', 'language:ru', 'license:cc-by-nc-sa-4.0', 'size_categories:n<1K', 'format:json', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us', 'Intellectual property']","
	
		
		QA evaluation dataset in intellectual property
	

The IPQA contains questions in seven languages, and the 100 data items include 35 each in Chinese and English, and 6 each in Spanish, Japanese, German, French, and Russian.
",https://huggingface.co/datasets/BNNT/IPQA,"['zh', 'en', 'de', 'fr', 'ja', 'es', 'ru']",['question-answering'],['n<1K']
AntonioRenatoMontefusco/kddChallenge2023,AntonioRenatoMontefusco,2023-05-19 16:07:50+00:00,2023-05-22 18:58:07+00:00,15,0,"['task_categories:text-generation', 'language:it', 'language:en', 'language:ja', 'language:fr', 'language:de', 'language:es', 'license:cc-by-nc-2.0', 'size_categories:1M<n<10M', 'region:us', 'code']",,https://huggingface.co/datasets/AntonioRenatoMontefusco/kddChallenge2023,"['it', 'en', 'ja', 'fr', 'de', 'es']",['text-generation'],['1M<n<10M']
ZurichNLP/rsd-ists-2016,ZurichNLP,2023-05-20 16:24:04+00:00,2025-06-17 09:41:34+00:00,289,0,"['task_categories:token-classification', 'language_creators:machine-generated', 'language:en', 'language:de', 'language:es', 'language:fr', 'language:ja', 'language:ko', 'language:zh', 'language:it', 'license:cc-by-sa-4.0', 'size_categories:10K<n<100K', 'format:parquet', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'arxiv:2305.13303', 'region:us']","Training and test data for the task of Recognizing Semantic Differences (RSD).
See the paper for details on how the dataset was created, and see our code at https://github.com/ZurichNLP/recognizing-semantic-differences for an example of how to use the data for evaluation.
The data are derived from the SemEval-2016 Task 2 for Interpretable Semantic Textual Similarity organized by Agirre et al. (2016).
The original URLs of the data are:

Train:… See the full description on the dataset page: https://huggingface.co/datasets/ZurichNLP/rsd-ists-2016.",https://huggingface.co/datasets/ZurichNLP/rsd-ists-2016,"['en', 'de', 'es', 'fr', 'ja', 'ko', 'zh', 'it']",['token-classification'],['10K<n<100K']
ebisuke/liz-nojaloli-ja-ds,ebisuke,2023-05-23 06:24:13+00:00,2023-08-17 00:57:13+00:00,26,3,"['language:ja', 'license:mit', 'region:us']","
	
		
		ebisuke/liz-nojaloli-ja-ds
	


	
		
		License
	

MIT License  

	
		
		Description
	

ebisuke/liz-nojaloli-jaの学習元のデータセットです。私（ebisuke）の手打ちのデータセットになります。pythonのコードについてはqiitaを参照している場合があります。

	
		
		Plan
	


RLHF用のデータセットの準備をしてみる。

",https://huggingface.co/datasets/ebisuke/liz-nojaloli-ja-ds,['ja'],[],[]
izumi-lab/llm-japanese-dataset-vanilla,izumi-lab,2023-05-23 14:45:27+00:00,2024-02-17 16:17:18+00:00,148,32,"['language:ja', 'license:cc-by-sa-4.0', 'size_categories:1M<n<10M', 'format:json', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'arxiv:2305.12720', 'region:us']","
	
		
		llm-japanese-dataset-vanilla
	

LLM構築用の日本語チャットデータセット
izumi-lab/llm-japanese-dataset から，日英翻訳のデータセット等を抜いたものです．
主に，日本語LLMモデルなどに対して，チャット(Instruction)応答タスクに関してLoRAなどでチューニングするために使用できます．
※様々な公開言語資源を利用させていただきました．関係各位にはこの場を借りて御礼申し上げます．

	
		
		データの詳細
	

データの詳細は，izumi-lab/llm-japanese-dataset に関する，以下の論文を参照してください．

日本語: https://jxiv.jst.go.jp/index.php/jxiv/preprint/view/383
英語: https://arxiv.org/abs/2305.12720
GitHub: https://github.com/masanorihirano/llm-japanese-dataset
最新情報: llm.msuzuki.me.… See the full description on the dataset page: https://huggingface.co/datasets/izumi-lab/llm-japanese-dataset-vanilla.",https://huggingface.co/datasets/izumi-lab/llm-japanese-dataset-vanilla,['ja'],[],['1M<n<10M']
Brand24/mms,Brand24,2023-05-24 12:07:06+00:00,2023-08-23 21:49:55+00:00,29,12,"['task_categories:text-classification', 'task_ids:sentiment-classification', 'annotations_creators:mixed', 'multilinguality:multi-lingual', 'language:ar', 'language:bg', 'language:bs', 'language:cs', 'language:de', 'language:el', 'language:en', 'language:es', 'language:fa', 'language:fr', 'language:he', 'language:hi', 'language:hr', 'language:hu', 'language:it', 'language:ja', 'language:lv', 'language:pl', 'language:pt', 'language:ru', 'language:sk', 'language:sl', 'language:sq', 'language:sr', 'language:sv', 'language:th', 'language:ur', 'language:zh', 'license:other', 'size_categories:1M<n<10M', 'modality:tabular', 'modality:text', 'library:datasets', 'library:mlcroissant', 'arxiv:2306.07902', 'region:us']","    This work presents the most extensive open massively multi-lingual corpus of datasets for training sentiment models. 
    The corpus consists of 79 manually selected from over 350 datasets reported in the scientific literature based on strict quality criteria and covers 25 languages. 
    Datasets can be queried using several linguistic and functional features. 
    In addition, we present a multi-faceted sentiment classification benchmark summarizing hundreds of experiments conducted on different base models, training objectives, dataset collections, and fine-tuning strategies.",https://huggingface.co/datasets/Brand24/mms,"['ar', 'bg', 'bs', 'cs', 'de', 'el', 'en', 'es', 'fa', 'fr', 'he', 'hi', 'hr', 'hu', 'it', 'ja', 'lv', 'pl', 'pt', 'ru', 'sk', 'sl', 'sq', 'sr', 'sv', 'th', 'ur', 'zh']",['text-classification'],['1M<n<10M']
ShoukanLabs/OpenNiji-Dataset,ShoukanLabs,2023-05-26 07:28:21+00:00,2023-09-29 02:59:14+00:00,69,16,"['task_categories:text-to-image', 'language:en', 'language:ja', 'language:ko', 'license:cc-by-nc-4.0', 'size_categories:100K<n<1M', 'format:json', 'modality:image', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us', 'anime', 'dataset', 'Nijijourney', 'Midjourney', 'discord']","
	
		
		NOTE:
	

Recently Discord has added link expiry and tracking for their CDN content, however, this is for CDN attachments outside of Discord, now due to the nature of how this was scraped (being directly from the API) We're uncertain as to whether URL decay will start to become a problem. We have already created versions of the dataset in splits to combat this, we are well aware that this may not be an option for some and we apologise. 
",https://huggingface.co/datasets/ShoukanLabs/OpenNiji-Dataset,"['en', 'ja', 'ko']",['text-to-image'],['100K<n<1M']
nakayama/hh-rlhf-helpful-base-ja,nakayama,2023-05-26 15:48:51+00:00,2023-05-26 15:57:12+00:00,9,0,"['language:ja', 'license:mit', 'size_categories:10K<n<100K', 'format:json', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","https://github.com/anthropics/hh-rlhf　の内容のうち、helpful-base内のchosenに記載されている英文をfuguMTで翻訳、うまく翻訳できていないものを除外、修正したものです。  
",https://huggingface.co/datasets/nakayama/hh-rlhf-helpful-base-ja,['ja'],[],['10K<n<100K']
fujiki/japanese_hh-rlhf-49k,fujiki,2023-05-28 05:55:53+00:00,2023-05-28 06:08:04+00:00,20,12,"['language:ja', 'license:mit', 'size_categories:10K<n<100K', 'format:parquet', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","
This is a little bit different version of kunishou/hh-rlhf-49k-ja without ng_translation == 1 examples.
Please also refer to the original dataset kunishou/hh-rlhf-49k-ja.

",https://huggingface.co/datasets/fujiki/japanese_hh-rlhf-49k,['ja'],[],['10K<n<100K']
singletongue/wikipedia-utils,singletongue,2023-05-29 01:42:43+00:00,2024-04-09 23:32:12+00:00,1481,7,"['language:ja', 'license:cc-by-sa-3.0', 'license:gfdl', 'size_categories:100M<n<1B', 'format:parquet', 'modality:tabular', 'modality:text', 'library:datasets', 'library:dask', 'library:mlcroissant', 'library:polars', 'region:us']","
	
		
		Wikipedia-Utils: Preprocessed Wikipedia Texts for NLP
	

Preprocessed Wikipedia texts generated with the scripts in singletongue/wikipedia-utils repo.
For detailed information on how the texts are processed, please refer to the repo.
",https://huggingface.co/datasets/singletongue/wikipedia-utils,['ja'],[],['100M<n<1B']
polm-stability/jblimp,polm-stability,2023-05-29 09:31:31+00:00,2023-05-29 09:49:16+00:00,22,0,"['language:ja', 'size_categories:n<1K', 'format:json', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","
	
		
		JBLiMP
	

This is the data from ""JBLiMP: Japanese Benchmark of Linguistic Minimal Pairs"" (Someya and Oseki, 2023). Only the validated pairs used for benchmarks are included, and only in JSONL format, since it's redundant with the TSV. 
For details see the original git repo or the paper. 
",https://huggingface.co/datasets/polm-stability/jblimp,['ja'],[],['n<1K']
shi3z/rachel,shi3z,2023-06-01 00:02:31+00:00,2023-06-01 23:28:53+00:00,11,0,"['task_categories:question-answering', 'language:ja', 'license:mit', 'size_categories:n<1K', 'format:json', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","This is a handmade dataset for making a Japanese chatbot. Conversations will continue to grow.
",https://huggingface.co/datasets/shi3z/rachel,['ja'],['question-answering'],['n<1K']
llm-book/jawiki-sentences,llm-book,2023-06-03 03:02:08+00:00,2023-10-25 15:22:05+00:00,109,1,"['language:ja', 'license:cc-by-sa-3.0', 'license:gfdl', 'size_categories:10M<n<100M', 'region:us']","
	
		
		Dataset Card for llm-book/jawiki-sentences
	

書籍『大規模言語モデル入門』で使用する Wikipedia 文のデータセットです。
GitHub リポジトリ singletongue/wikipedia-utils で公開されているデータセットを利用しています。

	
		
		Licence
	

本データセットで使用している Wikipedia のコンテンツは、クリエイティブ・コモンズ表示・継承ライセンス 3.0 (CC BY-SA 3.0) および GNU 自由文書ライセンス (GFDL) の下に配布されているものです。
",https://huggingface.co/datasets/llm-book/jawiki-sentences,['ja'],[],['10M<n<100M']
llm-book/jawiki-paragraphs,llm-book,2023-06-03 03:04:05+00:00,2023-06-03 03:04:43+00:00,49,0,"['language:ja', 'license:cc-by-sa-3.0', 'license:gfdl', 'size_categories:1M<n<10M', 'modality:tabular', 'modality:text', 'library:datasets', 'library:mlcroissant', 'region:us']","
	
		
		Dataset Card for llm-book/jawiki-paragraphs
	

書籍『大規模言語モデル入門』で使用する Wikipedia 段落のデータセットです。
GitHub リポジトリ singletongue/wikipedia-utils で公開されているデータセットを利用しています。

	
		
		Licence
	

本データセットで使用している Wikipedia のコンテンツは、クリエイティブ・コモンズ表示・継承ライセンス 3.0 (CC BY-SA 3.0) および GNU 自由文書ライセンス (GFDL) の下に配布されているものです。
",https://huggingface.co/datasets/llm-book/jawiki-paragraphs,['ja'],[],['1M<n<10M']
llm-book/aio-passages,llm-book,2023-06-06 02:03:33+00:00,2023-06-24 05:55:37+00:00,22,1,"['language:ja', 'license:cc-by-sa-3.0', 'license:gfdl', 'size_categories:1M<n<10M', 'modality:tabular', 'modality:text', 'library:datasets', 'library:mlcroissant', 'region:us']","
	
		
		Dataset Card for llm-book/aio-passages
	

書籍『大規模言語モデル入門』で使用する、「AI王」コンペティションのパッセージデータセットです。
GitHub リポジトリ cl-tohoku/quiz-datasets で公開されているデータセットを利用しています。

	
		
		Licence
	

本データセットで利用している Wikipedia のコンテンツは、クリエイティブ・コモンズ表示・継承ライセンス 3.0 (CC BY-SA 3.0) および GNU 自由文書ライセンス (GFDL) の下に配布されているものです。
",https://huggingface.co/datasets/llm-book/aio-passages,['ja'],[],['1M<n<10M']
Coaso/yokote_test,Coaso,2023-06-06 05:45:27+00:00,2023-06-06 08:09:30+00:00,14,0,"['task_categories:table-question-answering', 'language:ja', 'license:apache-2.0', 'size_categories:n<1K', 'format:json', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","test
",https://huggingface.co/datasets/Coaso/yokote_test,['ja'],['table-question-answering'],['n<1K']
llm-book/aio-passages-bpr-bert-base-japanese-v3,llm-book,2023-06-06 08:24:36+00:00,2023-06-30 10:30:40+00:00,88,1,"['language:ja', 'license:cc-by-sa-3.0', 'license:gfdl', 'size_categories:1M<n<10M', 'format:parquet', 'modality:tabular', 'modality:text', 'library:datasets', 'library:dask', 'library:mlcroissant', 'library:polars', 'region:us']","
	
		
		Dataset Card for llm-book/aio-passages-bert-base-japanese-v3-bpr
	

書籍『大規模言語モデル入門』で使用する、「AI王」コンペティションのパッセージデータセットに BPR によるパッセージの埋め込みを適用したデータセットです。
llm-book/aio-passages のデータセットに対して、llm-book/bert-base-japanese-v3-bpr-passage-encoder によるパッセージのバイナリベクトルが embeddings フィールドに追加されています。

	
		
	
	
		Licence
	

本データセットで利用している Wikipedia のコンテンツは、クリエイティブ・コモンズ表示・継承ライセンス 3.0 (CC BY-SA 3.0) および GNU 自由文書ライセンス (GFDL) の下に配布されているものです。
",https://huggingface.co/datasets/llm-book/aio-passages-bpr-bert-base-japanese-v3,['ja'],[],['1M<n<10M']
dinhanhx/crossmodal-3600,dinhanhx,2023-06-06 14:07:54+00:00,2023-06-06 14:38:51+00:00,138,6,"['task_categories:image-to-text', 'task_ids:image-captioning', 'source_datasets:wikipedia', 'source_datasets:google', 'language:ar', 'language:bn', 'language:cs', 'language:da', 'language:de', 'language:el', 'language:en', 'language:es', 'language:fa', 'language:fi', 'language:fil', 'language:fr', 'language:hi', 'language:hr', 'language:hu', 'language:id', 'language:it', 'language:he', 'language:ja', 'language:ko', 'language:mi', 'language:nl', 'language:no', 'language:pl', 'language:pt', 'language:quz', 'language:ro', 'language:ru', 'language:sv', 'language:sw', 'language:te', 'language:th', 'language:tr', 'language:uk', 'language:vi', 'language:zh', 'license:other', 'size_categories:1K<n<10K', 'format:imagefolder', 'modality:image', 'library:datasets', 'library:mlcroissant', 'region:us', 'crossmodal-3600']","
	
		
		Crossmodal-3600: A Massively Multilingual Multimodal Evaluation Dataset
	


	
		
		Abstract
	

Research in massively multilingual image captioning has been severely hampered by a lack of high-quality evaluation datasets. In this paper we present the Crossmodal-3600 dataset (XM3600 in short), a geographically-diverse set of 3600 images annotated with human-generated reference captions in 36 languages. The images were selected from across the world, covering regions where the 36… See the full description on the dataset page: https://huggingface.co/datasets/dinhanhx/crossmodal-3600.",https://huggingface.co/datasets/dinhanhx/crossmodal-3600,"['ar', 'bn', 'cs', 'da', 'de', 'el', 'en', 'es', 'fa', 'fi', 'fil', 'fr', 'hi', 'hr', 'hu', 'id', 'it', 'he', 'ja', 'ko', 'mi', 'nl', 'no', 'pl', 'pt', 'quz', 'ro', 'ru', 'sv', 'sw', 'te', 'th', 'tr', 'uk', 'vi', 'zh']",['image-to-text'],['1K<n<10K']
Coaso/test-dolly-15ja-for-stftrainer,Coaso,2023-06-07 01:40:58+00:00,2023-06-07 02:29:14+00:00,13,0,"['task_categories:question-answering', 'language:ja', 'license:cc-by-sa-3.0', 'size_categories:10K<n<100K', 'format:json', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","
	
		
		Dataset Card for Dataset Name
	


	
		
		Dataset Summary
	

It is just a dataset of dolly-15k-jp(*1) converted to jsonl form so that it can be used in SFTTrainer(*2)'s dataset_text_field property. 
(*1)https://huggingface.co/datasets/kunishou/databricks-dolly-15k-ja(*2)https://huggingface.co/docs/trl/main/en/sft_trainer  

	
		
	
	
		Languages
	

ja

	
		
	
	
		Licensing Information
	

This dataset is licensed under CC BY SA 3.0
Special… See the full description on the dataset page: https://huggingface.co/datasets/Coaso/test-dolly-15ja-for-stftrainer.",https://huggingface.co/datasets/Coaso/test-dolly-15ja-for-stftrainer,['ja'],['question-answering'],['10K<n<100K']
dinhanhx/evjvqa,dinhanhx,2023-06-07 02:36:55+00:00,2023-06-24 01:55:42+00:00,22,0,"['task_categories:visual-question-answering', 'task_ids:visual-question-answering', 'language:en', 'language:vi', 'language:ja', 'license:unknown', 'size_categories:1K<n<10K', 'format:imagefolder', 'modality:image', 'library:datasets', 'library:mlcroissant', 'arxiv:2302.11752', 'region:us', 'evjvqa']","
	
		
		EVJVQA - Multilingual Visual Question Answering
	


	
		
		Abstract
	

Visual Question Answering (VQA) is a challenging task of natural language processing (NLP) and computer vision (CV), attracting significant attention from researchers. English is a resource-rich language that has witnessed various developments in datasets and models for visual question answering. Visual question answering in other languages also would be developed for resources and models. In addition, there is no… See the full description on the dataset page: https://huggingface.co/datasets/dinhanhx/evjvqa.",https://huggingface.co/datasets/dinhanhx/evjvqa,"['en', 'vi', 'ja']",['visual-question-answering'],['1K<n<10K']
saldra/sakura_japanese_dataset,saldra,2023-06-07 05:44:23+00:00,2023-06-08 11:31:06+00:00,79,18,"['task_categories:question-answering', 'language:ja', 'license:other', 'size_categories:n<1K', 'format:json', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","
	
		
		Sakura_dataset
	

商用利用可能な超小規模高品質日本語データセット。
categoryは以下

commonsense_qa: 常識問題
Calc-ape210k: 数学問題
japanese-commonsense-openqa: 日本の常識問題(自作)

下記データセットを使用しています。

commonsense_qa
MU-NLPC/Calc-ape210k


	
		
		LICENSE
	

This dataset is licensed under Database Contents License (DbCL) v1.0

	
		
		Update
	

Last Update : 2023-06-07

	
		
		Example Code
	

# モデルの読み込み
import os

from peft.utils.config import TaskType
os.environ[""CUDA_VISIBLE_DEVICES""]=""0""

import peft
import transformers
import… See the full description on the dataset page: https://huggingface.co/datasets/saldra/sakura_japanese_dataset.",https://huggingface.co/datasets/saldra/sakura_japanese_dataset,['ja'],['question-answering'],['n<1K']
AlekseyScorpi/docs_on_several_languages,AlekseyScorpi,2023-06-11 13:50:31+00:00,2025-04-06 12:41:04+00:00,22,1,"['task_categories:text-classification', 'task_categories:translation', 'task_categories:feature-extraction', 'language:az', 'language:be', 'language:en', 'language:et', 'language:fi', 'language:ka', 'language:ja', 'language:ko', 'language:kk', 'language:lv', 'language:lt', 'language:mn', 'language:no', 'language:pl', 'language:ru', 'language:uk', 'language:zh', 'license:mit', 'size_categories:1K<n<10K', 'format:parquet', 'modality:image', 'library:datasets', 'library:dask', 'library:mlcroissant', 'library:polars', 'region:us', 'code']","
	
		
		Dataset Card for ""docs_on_several_languages""
	

This dataset is a collection of different images in different languages.
The daset includes the following languages: Azerbaijani (az: 0), Belorussian (be: 1), Chinese (zh: 16), English (en: 2), Estonian (et: 3), Finnish (fn: 4), Georgian (gr: 5), Japanese (ja: 6), Korean (ko: 7), Kazakh (kk: 8), Latvian (lv: 10), Lithuanian (lt: 9), Mongolian (mn: 11), Norwegian (no: 12), Polish (pl: 13), Russian (ru: 14), Ukranian (uk: 15).
Each language… See the full description on the dataset page: https://huggingface.co/datasets/AlekseyScorpi/docs_on_several_languages.",https://huggingface.co/datasets/AlekseyScorpi/docs_on_several_languages,"['az', 'be', 'en', 'et', 'fi', 'ka', 'ja', 'ko', 'kk', 'lv', 'lt', 'mn', 'no', 'pl', 'ru', 'uk', 'zh']","['text-classification', 'translation', 'feature-extraction']",['1K<n<10K']
tzmtwtr/tw-posts-japanese,tzmtwtr,2023-06-13 14:31:25+00:00,2023-06-16 05:17:23+00:00,33,0,"['language:ja', 'license:other', 'size_categories:10K<n<100K', 'format:json', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","データ制作者（t_w）がデライトに投稿した5万件の投稿をEmbeddingの学習用にいい感じにしたやつ。

	
		
		License
	

Licenseは設定していないため、日本の法律に従って利用されたい。従って、学習に用いるのは問題ないが再配布は不可。
",https://huggingface.co/datasets/tzmtwtr/tw-posts-japanese,['ja'],[],['10K<n<100K']
Babelscape/SREDFM,Babelscape,2023-06-13 18:35:19+00:00,2023-06-20 07:33:28+00:00,2218,13,"['task_categories:token-classification', 'language:ar', 'language:ca', 'language:de', 'language:el', 'language:en', 'language:es', 'language:fr', 'language:hi', 'language:it', 'language:ja', 'language:ko', 'language:nl', 'language:pl', 'language:pt', 'language:ru', 'language:sv', 'language:vi', 'language:zh', 'license:cc-by-sa-4.0', 'size_categories:10M<n<100M', 'modality:text', 'library:datasets', 'library:mlcroissant', 'arxiv:2306.09802', 'region:us']","Relation Extraction (RE) is a task that identifies relationships between entities in a text, enabling the acquisition of relational facts and bridging the gap between natural language and structured knowledge. However, current RE models often rely on small datasets with low coverage of relation types, particularly when working with languages other than English. \In this paper, we address the above issue and provide two new resources that enable the training and evaluation of multilingual RE systems.
First, we present SRED\textsuperscript{FM}, an automatically annotated dataset covering 18 languages, 400 relation types, 13 entity types, totaling more than 40 million triplet instances. Second, we propose RED\textsuperscript{FM}, a smaller, human-revised dataset for seven languages that allows for the evaluation of multilingual RE systems. 
To demonstrate the utility of these novel datasets, we experiment with the first end-to-end multilingual RE model, mREBEL, 
that extracts triplets, including entity types, in multiple languages. We release our resources and model checkpoints at \href{https://www.github.com/babelscape/rebel}{https://www.github.com/babelscape/rebel}.",https://huggingface.co/datasets/Babelscape/SREDFM,"['ar', 'ca', 'de', 'el', 'en', 'es', 'fr', 'hi', 'it', 'ja', 'ko', 'nl', 'pl', 'pt', 'ru', 'sv', 'vi', 'zh']",['token-classification'],['10M<n<100M']
ynklab/XCodeSearchNet,ynklab,2023-06-15 17:33:42+00:00,2023-07-12 15:18:20+00:00,38,1,"['language:en', 'language:fr', 'language:ja', 'language:zh', 'license:mit', 'arxiv:2306.15604', 'region:us', 'codesearch']","Paper on arXiv

	
		
		pre-training data
	

You need to manually combine each dataset if you want to use a multilingual dataset.
from datasets import load_dataset
xcsn_pt_python_en = load_dataset(""ynklab/XCodeSearchNet"", data_dir='pretraining/python/en')
""""""
DatasetDict({
    train: Dataset({
        features: ['function_tokens', 'docstring'],
        num_rows: 453623
    })
    validation: Dataset({
        features: ['function_tokens', 'docstring'],
        num_rows: 4596
})
    test:… See the full description on the dataset page: https://huggingface.co/datasets/ynklab/XCodeSearchNet.",https://huggingface.co/datasets/ynklab/XCodeSearchNet,"['en', 'fr', 'ja', 'zh']",[],[]
mkshing/xlsum_ja,mkshing,2023-06-16 04:15:41+00:00,2023-06-20 23:28:48+00:00,279,6,"['task_categories:summarization', 'task_categories:text-classification', 'language:ja', 'license:cc-by-nc-sa-4.0', 'size_categories:1K<n<10K', 'format:csv', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'arxiv:2305.10403', 'region:us']","This is the filtered Japanese subset of XL-Sum followed by PaLM 2
filters

15-gram overlap

* code: https://gist.github.com/mkshing/d6371cbfdd50d4f352cee247fd4dd86a
number of examples

train: 4215 (before: 7113)
validation: 758 (before: 889)
test: 766 (before: 889)

",https://huggingface.co/datasets/mkshing/xlsum_ja,['ja'],"['summarization', 'text-classification']",['1K<n<10K']
llm-book/jsnli,llm-book,2023-06-19 12:31:46+00:00,2023-10-25 15:22:46+00:00,25,0,"['language:ja', 'license:cc-by-sa-4.0', 'size_categories:100K<n<1M', 'region:us']","
	
		
		Dataset Card for llm-book/jsnli
	

書籍『大規模言語モデル入門』で使用する JSNLI のデータセットです。
JSNLI Version 1.1 のデータセットのうち、フィルタリング後の訓練セット (train_w_filtering) と検証セット (dev) を使用しています。

	
		
		Licence
	

CC BY-SA 4.0
",https://huggingface.co/datasets/llm-book/jsnli,['ja'],[],['100K<n<1M']
llm-book/livedoor-news-corpus,llm-book,2023-06-21 07:16:52+00:00,2023-12-12 02:19:43+00:00,175,4,"['task_categories:summarization', 'language:ja', 'size_categories:1K<n<10K', 'region:us', 'news']","
	
		
		Dataset Card for llm-book/ner-wikinews-dataset
	

書籍『大規模言語モデル入門』で使用する、株式会社ロンウイットが提供する「livedoorニュースコーパス」によるデータセットです。 
オリジナルのサイトと同じものを使用しています。
本コーパスは、NHN Japan株式会社が運営する「livedoor ニュース」のうち、下記のクリエイティブ・コモンズライセンスが適用されるニュース記事を収集し、可能な限りHTMLタグを取り除いて作成したものです。

	
		
		Licence
	

Attribution-NoDerivs 2.1 Japan (CC BY-ND 2.1 JP) License
",https://huggingface.co/datasets/llm-book/livedoor-news-corpus,['ja'],['summarization'],['1K<n<10K']
kumapo/JAQKET,kumapo,2023-06-21 13:04:38+00:00,2023-10-09 06:44:28+00:00,287,5,"['task_categories:multiple-choice', 'task_categories:question-answering', 'language:ja', 'license:cc-by-sa-4.0', 'size_categories:10K<n<100K', 'modality:text', 'library:datasets', 'library:mlcroissant', 'region:us']",JAQKET: JApanese Questions on Knowledge of EnTitie,https://huggingface.co/datasets/kumapo/JAQKET,['ja'],"['multiple-choice', 'question-answering']",['10K<n<100K']
yuzuai/rakuda-questions,yuzuai,2023-06-23 01:08:52+00:00,2023-06-23 08:01:35+00:00,899,8,"['task_categories:question-answering', 'source_datasets:original', 'language:ja', 'license:mit', 'size_categories:n<1K', 'format:json', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","
	
		
		Rakuda - Questions for Japanese models
	

Repository: https://github.com/yuzu-ai/japanese-llm-ranking
This is a set of 40 questions in Japanese about Japanese-specific topics designed to evaluate the capabilities of AI Assistants in Japanese.
The questions are evenly distributed between four categories: history, society, government, and geography. 
Questions in the first three categories are open-ended, while the geography questions are more specific.
Answers to these questions can be… See the full description on the dataset page: https://huggingface.co/datasets/yuzuai/rakuda-questions.",https://huggingface.co/datasets/yuzuai/rakuda-questions,['ja'],['question-answering'],['n<1K']
tamdiep106/autotrain-data-tam_jp,tamdiep106,2023-06-23 09:01:33+00:00,2023-06-23 10:46:11+00:00,11,0,"['language:ja', 'region:us']","
	
		
		AutoTrain Dataset for project: tam_jp
	


	
		
		Dataset Description
	

This dataset has been automatically processed by AutoTrain for project tam_jp.

	
		
		Languages
	

The BCP-47 code for the dataset's language is ja.

	
		
		Dataset Structure
	


	
		
		Data Instances
	

A sample from this dataset looks as follows:
[
  {
    ""context"":… See the full description on the dataset page: https://huggingface.co/datasets/tamdiep106/autotrain-data-tam_jp.",https://huggingface.co/datasets/tamdiep106/autotrain-data-tam_jp,['ja'],[],[]
tzmtwtr/tw-posts-japanese-v2,tzmtwtr,2023-06-23 14:09:41+00:00,2023-06-23 19:53:02+00:00,12,0,"['language:ja', 'license:other', 'size_categories:10K<n<100K', 'format:json', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","データ制作者（t_w）がデライトに投稿した5万件の投稿をEmbeddingの学習用にいい感じにしたやつ。
tzmtwtr/tw-posts-japaneseに「本文が抜けている」という不備があったので修正。
ついでにデータ構造を変えた。

	
		
		License
	

Licenseは設定していないため、日本の法律に従って利用されたい。従って、学習に用いるのは問題ないが再配布は不可。
",https://huggingface.co/datasets/tzmtwtr/tw-posts-japanese-v2,['ja'],[],['10K<n<100K']
fujiki/guanaco_ja,fujiki,2023-06-24 08:27:30+00:00,2023-07-16 15:01:30+00:00,14,5,"['language:ja', 'license:gpl-3.0', 'size_categories:100K<n<1M', 'format:parquet', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","
This is a Japanese portion of the Guanaco dataset.
You can also refer to other similar datasets like inu-ai/alpaca-guanaco-japanese-gpt-1b.

",https://huggingface.co/datasets/fujiki/guanaco_ja,['ja'],[],['100K<n<1M']
globis-university/aozorabunko-clean,globis-university,2023-06-26 13:31:28+00:00,2023-10-27 13:22:32+00:00,330,34,"['task_categories:text-generation', 'task_categories:text-classification', 'language:ja', 'license:cc-by-4.0', 'size_categories:10K<n<100K', 'format:json', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","
	
		
		Overview
	

This dataset provides a convenient and user-friendly format of data from Aozora Bunko (青空文庫), a website that compiles public-domain books in Japan, ideal for Machine Learning applications.
[For Japanese] 日本語での概要説明を Qiita に記載しました: https://qiita.com/akeyhero/items/b53eae1c0bc4d54e321f

	
		
		Methodology
	

The code to reproduce this dataset is made available on GitHub: globis-org/aozorabunko-exctractor.

	
		
		1. Data collection
	

We firstly downloaded the CSV file that… See the full description on the dataset page: https://huggingface.co/datasets/globis-university/aozorabunko-clean.",https://huggingface.co/datasets/globis-university/aozorabunko-clean,['ja'],"['text-generation', 'text-classification']",['10K<n<100K']
sakusakumura/databricks-dolly-15k-ja-scored,sakusakumura,2023-06-27 09:14:41+00:00,2023-06-27 09:18:39+00:00,302,6,"['task_categories:question-answering', 'task_categories:summarization', 'language:ja', 'license:cc-by-sa-3.0', 'size_categories:10K<n<100K', 'format:json', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'arxiv:1904.09675', 'region:us']","For the English version, please click here.

	
		
		概要
	

databricks-dolly-15k-ja-scoredはkunishou/databricks-dolly-15k-jaの派生であり、BERTScoreによって提供される翻訳品質スコアが追加されています。
このデータセットは、学術的・商業的問わずクリエイティブ・コモンズ 表示 - 継承 3.0 非移植ライセンスの条件の下で何にでも使用することができます。

	
		
		翻訳の品質スコア
	

databricks-dolly-15k-jaは、databricks-dolly-15kを機械翻訳したものです。databricks-dolly-15k-jaに含まれるデータを調べてみると、以下のような品質の悪いデータが存在することが分かりました。  

inputとoutputが全く同じであるデータ
outputがinstructionにコピーされているデータ
表記ゆれによって表現の一貫性が保たれていないデータ
固有名詞などの翻訳に失敗しているデータ… See the full description on the dataset page: https://huggingface.co/datasets/sakusakumura/databricks-dolly-15k-ja-scored.",https://huggingface.co/datasets/sakusakumura/databricks-dolly-15k-ja-scored,['ja'],"['question-answering', 'summarization']",['10K<n<100K']
den2nova/den2niji,den2nova,2023-07-04 04:13:58+00:00,2023-07-07 01:55:08+00:00,17,0,"['language:ja', 'license:cc0-1.0', 'region:us']","LoRAデータセット開示用データ。私がnijijourney v5で生成したイラストです。
280枚、女性のイラストのみ収録。一部版権キャラクターが含まれます。
モデルマージの透明性確保のためのデータセット公開ですが、収録した画像データとタグが記載されているテキストファイルはご自由にご利用頂けます。
ただし犯罪行為への利用や他人へ迷惑をかける行為に利用するのはおやめください。
また版権のあるキャラクターに関しましては、権利元の不利益になるようなご使用はおやめください。
キャプションはwd14-taggerそのままで精査していません。

	
		
		LoRA本体もダウンロード可能です（SDHKv3.0で学習）
	

",https://huggingface.co/datasets/den2nova/den2niji,['ja'],[],[]
llm-book/aio-retriever,llm-book,2023-07-04 04:53:47+00:00,2023-10-25 15:31:08+00:00,63,0,"['language:ja', 'size_categories:10K<n<100K', 'region:us']","
	
		
		Dataset Card for llm-book/aio-retriever
	

書籍『大規模言語モデル入門』で使用する、「AI王」コンペティションのQAデータセット（文書検索モデル訓練用）です。
GitHub リポジトリ cl-tohoku/quiz-datasets で公開されているデータセットを利用しています。

	
		
		Licence
	

本データセットに含まれる一部のクイズ問題の著作権は abc/EQIDEN 実行委員会に帰属するものであり、これらのクイズ問題は本書における使用許諾を得ているものです。
本データセットに含まれる一部のクイズ問題は株式会社キュービックおよび株式会社カプリティオに依頼し作成したものであり、これらのクイズ問題はクリエイティブ・コモンズ表示・継承ライセンス 4.0 (CC BY-SA 4.0) ライセンスの下に提供されています。
本データセットにパッセージとして付与されている Wikipedia のコンテンツは、クリエイティブ・コモンズ表示・継承ライセンス 3.0 (CC BY-SA 3.0) および GNU… See the full description on the dataset page: https://huggingface.co/datasets/llm-book/aio-retriever.",https://huggingface.co/datasets/llm-book/aio-retriever,['ja'],[],['10K<n<100K']
sudy-super/CoTangent,sudy-super,2023-07-04 09:15:33+00:00,2024-12-28 17:26:22+00:00,18,21,"['language:ja', 'license:apache-2.0', 'size_categories:n<1K', 'format:json', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","CoTangentは人手で作成された高品質でクリーンな100セットの日本語CoT用データセットです。
CoTangent_ja.json: CoT部分とoutput部分が繋がっています。
CoTangent_separated_ja.json: CoT部分とoutput部分が分離されていますが、CoTangent_ja.jsonの方が繋ぎが自然です。
",https://huggingface.co/datasets/sudy-super/CoTangent,['ja'],[],['n<1K']
FredZhang7/all-scam-spam,FredZhang7,2023-07-04 22:07:15+00:00,2025-01-03 08:53:30+00:00,241,13,"['task_categories:text-classification', 'task_categories:zero-shot-classification', 'language:no', 'language:es', 'language:so', 'language:ca', 'language:af', 'language:it', 'language:nl', 'language:hi', 'language:cy', 'language:ar', 'language:sv', 'language:cs', 'language:pl', 'language:de', 'language:lt', 'language:sq', 'language:uk', 'language:tl', 'language:sl', 'language:hr', 'language:en', 'language:fi', 'language:vi', 'language:id', 'language:da', 'language:ko', 'language:bg', 'language:mr', 'language:ja', 'language:bn', 'language:ro', 'language:pt', 'language:fr', 'language:hu', 'language:tr', 'language:zh', 'language:mk', 'language:ur', 'language:sk', 'language:ne', 'language:et', 'language:sw', 'language:ru', 'language:multilingual', 'license:apache-2.0', 'size_categories:10K<n<100K', 'format:csv', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us', 'nlp', 'moderation']","This is a large corpus of 42,619 preprocessed text messages and emails sent by humans in 43 languages. is_spam=1 means spam and is_spam=0 means ham.
1040 rows of balanced data, consisting of casual conversations and scam emails in ≈10 languages, were manually collected and annotated by me, with some help from ChatGPT.



	
		
		Some preprcoessing algorithms
	


spam_assassin.js, followed by spam_assassin.py
enron_spam.py




	
		
		Data composition
	





	
		
		Description
	

To make the text… See the full description on the dataset page: https://huggingface.co/datasets/FredZhang7/all-scam-spam.",https://huggingface.co/datasets/FredZhang7/all-scam-spam,"['no', 'es', 'so', 'ca', 'af', 'it', 'nl', 'hi', 'cy', 'ar', 'sv', 'cs', 'pl', 'de', 'lt', 'sq', 'uk', 'tl', 'sl', 'hr', 'en', 'fi', 'vi', 'id', 'da', 'ko', 'bg', 'mr', 'ja', 'bn', 'ro', 'pt', 'fr', 'hu', 'tr', 'zh', 'mk', 'ur', 'sk', 'ne', 'et', 'sw', 'ru', 'multilingual']","['text-classification', 'zero-shot-classification']",['10K<n<100K']
izumi-lab/mc4-ja,izumi-lab,2023-07-06 00:43:16+00:00,2023-07-29 03:11:03+00:00,488,6,"['language:ja', 'license:odc-by', 'size_categories:10M<n<100M', 'format:parquet', 'modality:text', 'library:datasets', 'library:dask', 'library:mlcroissant', 'library:polars', 'region:us']","
	
		
		Dataset Card for ""mc4-ja""
	

More Information needed
",https://huggingface.co/datasets/izumi-lab/mc4-ja,['ja'],[],['10M<n<100M']
yjg30737/onepiece-characters,yjg30737,2023-07-08 05:28:59+00:00,2023-07-08 08:33:08+00:00,36,1,"['task_categories:table-question-answering', 'language:en', 'language:ja', 'language:ko', 'license:mit', 'size_categories:1K<n<10K', 'format:json', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","
	
		
		onepiece-character
	

This is a dataset created from crawling the One Piece Fandom on 2023-07-08.
",https://huggingface.co/datasets/yjg30737/onepiece-characters,"['en', 'ja', 'ko']",['table-question-answering'],['1K<n<10K']
WarriorMama777/databricks-dolly-15k-ja_cool,WarriorMama777,2023-07-08 06:16:29+00:00,2023-07-08 06:45:18+00:00,14,1,"['language:ja', 'license:cc-by-3.0', 'size_categories:10K<n<100K', 'format:json', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","
	
		
		Overview
	

This dataset is edited from kunishou/databricks-dolly-15k-en.It was edited so that it would be like Yuki Nagato, who appears in ""The Melancholy of Haruhi Suzumiya,"" with an emotionless and indifferent way of speaking.In more detail, I used VS CODE etc. to replace ""です、ます"" and ""だ、である"", etc.  
It's a dataset for my hobby, but feel free to use it.


	
		
		Links… See the full description on the dataset page: https://huggingface.co/datasets/WarriorMama777/databricks-dolly-15k-ja_cool.",https://huggingface.co/datasets/WarriorMama777/databricks-dolly-15k-ja_cool,['ja'],[],['10K<n<100K']
zan/lima-ja,zan,2023-07-08 07:35:34+00:00,2023-07-08 13:39:45+00:00,35,3,"['language:ja', 'license:cc-by-nc-sa-4.0', 'size_categories:1K<n<10K', 'modality:text', 'library:datasets', 'library:mlcroissant', 'arxiv:2305.11206', 'region:us']",A high-quality japanese dataset for efficient instruction tuning.,https://huggingface.co/datasets/zan/lima-ja,['ja'],[],['1K<n<10K']
Beluuuuuuga/Japanese-Instruction-Linux-Command-169,Beluuuuuuga,2023-07-08 18:20:48+00:00,2023-07-17 11:06:56+00:00,50,3,"['task_categories:question-answering', 'language:ja', 'license:cc-by-nc-4.0', 'size_categories:n<1K', 'format:json', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']",,https://huggingface.co/datasets/Beluuuuuuga/Japanese-Instruction-Linux-Command-169,['ja'],['question-answering'],['n<1K']
Atom007/mc4-japanese-data,Atom007,2023-07-09 14:56:56+00:00,2023-07-09 15:04:14+00:00,29,1,"['language:ja', 'license:apache-2.0', 'size_categories:10K<n<100K', 'format:json', 'modality:text', 'library:datasets', 'library:dask', 'library:mlcroissant', 'library:polars', 'region:us']","Reference https://huggingface.co/datasets/mc4
",https://huggingface.co/datasets/Atom007/mc4-japanese-data,['ja'],[],['10K<n<100K']
FredZhang7/malicious-website-features-2.4M,FredZhang7,2023-07-11 05:15:27+00:00,2023-08-14 05:21:51+00:00,444,6,"['task_categories:text-classification', 'task_categories:feature-extraction', 'task_categories:tabular-classification', 'language:no', 'language:af', 'language:en', 'language:et', 'language:sw', 'language:sv', 'language:sq', 'language:de', 'language:ca', 'language:hu', 'language:da', 'language:tl', 'language:so', 'language:fi', 'language:fr', 'language:cs', 'language:hr', 'language:cy', 'language:es', 'language:sl', 'language:tr', 'language:pl', 'language:pt', 'language:nl', 'language:id', 'language:sk', 'language:lt', 'language:lv', 'language:vi', 'language:it', 'language:ro', 'language:ru', 'language:mk', 'language:bg', 'language:th', 'language:ja', 'language:ko', 'language:multilingual', 'license:apache-2.0', 'size_categories:1M<n<10M', 'region:us']","Important Notice:

A subset of the URL dataset is from Kaggle, and the Kaggle datasets contained 10%-15% mislabelled data. See this dicussion I opened for some false positives. I have contacted Kaggle regarding their erroneous ""Usability"" score calculation for these unreliable datasets.
The feature extraction methods shown here are not robust at all in 2023, and there're even silly mistakes in 3 functions: not_indexed_by_google, domain_registration_length, and age_of_domain.



The features… See the full description on the dataset page: https://huggingface.co/datasets/FredZhang7/malicious-website-features-2.4M.",https://huggingface.co/datasets/FredZhang7/malicious-website-features-2.4M,"['no', 'af', 'en', 'et', 'sw', 'sv', 'sq', 'de', 'ca', 'hu', 'da', 'tl', 'so', 'fi', 'fr', 'cs', 'hr', 'cy', 'es', 'sl', 'tr', 'pl', 'pt', 'nl', 'id', 'sk', 'lt', 'lv', 'vi', 'it', 'ro', 'ru', 'mk', 'bg', 'th', 'ja', 'ko', 'multilingual']","['text-classification', 'feature-extraction', 'tabular-classification']",['1M<n<10M']
pufanyi/MIMICIT,pufanyi,2023-07-12 07:22:42+00:00,2024-03-28 03:35:16+00:00,118,44,"['language:en', 'language:zh', 'language:es', 'language:ja', 'language:fr', 'language:ko', 'language:ar', 'license:mit', 'size_categories:1M<n<10M', 'format:parquet', 'modality:image', 'modality:text', 'library:datasets', 'library:dask', 'library:mlcroissant', 'library:polars', 'arxiv:2306.05425', 'region:us']","






    Bo Li*,♠,1 
    Yuanhan Zhang*,♠,1 
    Liangyu Chen*,1 
    Jinghao Wang*,1 
    Fanyi Pu*,1 
    
    Jingkang Yang1 
    Chunyuan Li2 
    Ziwei Liu✉,1



    1S-Lab, Nanyang Technological University 
    2Microsoft Research, Redmond
    
    ♠Co-Project Lead 
    * Equal Contribution 
    ✉ Corresponding Author
    


Note 1: To reduce memory consumption during image loading and improve loading speed, we are converting the JSON format of images to the Parquet format. For… See the full description on the dataset page: https://huggingface.co/datasets/pufanyi/MIMICIT.",https://huggingface.co/datasets/pufanyi/MIMICIT,"['en', 'zh', 'es', 'ja', 'fr', 'ko', 'ar']",[],['1M<n<10M']
izumi-lab/oscar2301-ja-filter-ja-normal,izumi-lab,2023-07-12 16:38:36+00:00,2023-07-29 03:16:00+00:00,247,5,"['language:ja', 'license:cc0-1.0', 'size_categories:10M<n<100M', 'format:parquet', 'modality:text', 'library:datasets', 'library:dask', 'library:mlcroissant', 'library:polars', 'region:us']","
	
		
		Dataset Card for ""oscar2301-ja-filter-ja-normal""
	

More Information needed
",https://huggingface.co/datasets/izumi-lab/oscar2301-ja-filter-ja-normal,['ja'],[],['10M<n<100M']
sudy-super/dialogsum-ja,sudy-super,2023-07-15 10:16:20+00:00,2023-07-15 10:27:58+00:00,29,15,"['task_categories:summarization', 'language:ja', 'license:mit', 'size_categories:10K<n<100K', 'format:json', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","dialogsum-ja
このデータセットはdialogsum、CSDSなどを翻訳した日本語対話要約データセットです。
元のデータセット
knkarthick/dialogsum https://huggingface.co/datasets/knkarthick/dialogsum
xiaolinAndy/CSDS https://github.com/xiaolinAndy/CSDS
",https://huggingface.co/datasets/sudy-super/dialogsum-ja,['ja'],['summarization'],['10K<n<100K']
tet550/jawiki_sentences,tet550,2023-07-16 00:14:53+00:00,2023-07-16 08:17:58+00:00,66,1,"['language:ja', 'license:cc-by-3.0', 'size_categories:10M<n<100M', 'format:parquet', 'modality:text', 'library:datasets', 'library:dask', 'library:mlcroissant', 'library:polars', 'region:us']","
	
		
		Jawiki Sentences Dataset
	

このデータセットは、日本語版Wikipediaの記事を元に作成されました。原文からできる限り不要なタグや表など文章にならないものを取り除いています。各エントリーには、その文が含まれる記事タイトル、セクションタイトルを含めています。

	
		
		データの構造
	

各エントリーは以下の3つのフィールドからなります:

article_title: 記事のタイトルを表す文字列。
topic_title: 記事のセクションタイトルを表す文字列。
text: セクションのテキストを表す文字列。


	
		
		データの生成
	

このデータセットは、下記スクリプトで日本語Wikipediaダンプファイルから生成しています。
https://github.com/tet550/jawiki_sentences

	
		
		ライセンス
	

ウィキペディアのコンテンツは Creative Commons Attribution-ShareAlike 4.0 International License (CC… See the full description on the dataset page: https://huggingface.co/datasets/tet550/jawiki_sentences.",https://huggingface.co/datasets/tet550/jawiki_sentences,['ja'],[],['10M<n<100M']
MichaelR207/MultiSim,MichaelR207,2023-07-18 21:55:31+00:00,2023-11-14 00:32:32+00:00,321,8,"['task_categories:summarization', 'task_categories:text-generation', 'language:en', 'language:fr', 'language:ru', 'language:ja', 'language:it', 'language:da', 'language:es', 'language:de', 'language:pt', 'language:sl', 'language:ur', 'language:eu', 'license:mit', 'size_categories:1M<n<10M', 'arxiv:2305.15678', 'arxiv:1904.07733', 'region:us', 'medical', 'legal', 'wikipedia', 'encyclopedia', 'science', 'literature', 'news', 'websites']",MultiSim is a growing collection of Text Simplfication datasets in multiple languages.  Each dataset is a set of complex and simple sentence pairs.,https://huggingface.co/datasets/MichaelR207/MultiSim,"['en', 'fr', 'ru', 'ja', 'it', 'da', 'es', 'de', 'pt', 'sl', 'ur', 'eu']","['summarization', 'text-generation']",['1M<n<10M']
RyokoExtra/MissingKeys,RyokoExtra,2023-07-19 12:17:40+00:00,2024-04-10 09:14:30+00:00,23,2,"['task_categories:text-classification', 'task_categories:text-generation', 'task_categories:text-to-image', 'task_categories:text-to-video', 'language:ja', 'license:apache-2.0', 'region:us']","
	
		
		Dataset Card for MissingKeys
	

NOTE: This contains old data before 10/04/24. The uploader has moved to here!

	
		
		Dataset Summary
	

MissingKeys is a raw dataset archive of the misskey.io network.

	
		
		Supported Tasks and Leaderboards
	

This dataset is primarily intended for unsupervised training of text generation models; however, it may be useful for other purposes.

text-classification
text-generation


	
		
		Languages
	

Primarily japanese, however there are also english… See the full description on the dataset page: https://huggingface.co/datasets/RyokoExtra/MissingKeys.",https://huggingface.co/datasets/RyokoExtra/MissingKeys,['ja'],"['text-classification', 'text-generation', 'text-to-image', 'text-to-video']",[]
y2lan/japan-law,y2lan,2023-07-20 06:26:25+00:00,2023-07-20 06:45:14+00:00,31,19,"['task_categories:summarization', 'task_categories:text-generation', 'task_categories:question-answering', 'language:ja', 'license:mit', 'size_categories:1K<n<10K', 'format:json', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","
	
		
		Japanese Laws
	

This dataset comprises 8.75K law records retrieved from the official Japanese government website e-Gov. Each entry furnishes comprehensive details about a particular law, encapsulating its number, title, unique ID, the date it came into effect, and its complete text.
To ensure the dataset's uniqueness, deduplication was executed based on the most recent effective version as of August 1, 2023.
A typical entry in this dataset is structured as follows:
{
    ""num"": ""Law… See the full description on the dataset page: https://huggingface.co/datasets/y2lan/japan-law.",https://huggingface.co/datasets/y2lan/japan-law,['ja'],"['summarization', 'text-generation', 'question-answering']",['1K<n<10K']
Amani27/massive_translation_dataset,Amani27,2023-07-20 16:09:42+00:00,2023-07-25 14:54:44+00:00,74,10,"['task_categories:translation', 'language:en', 'language:de', 'language:es', 'language:hi', 'language:fr', 'language:it', 'language:ar', 'language:nl', 'language:ja', 'language:pt', 'license:cc-by-4.0', 'size_categories:10K<n<100K', 'format:csv', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","
	
		
		Dataset Card for Massive Dataset for Translation
	


	
		
		Dataset Summary
	

This dataset is derived from AmazonScience/MASSIVE dataset for translation task purpose.

	
		
		Supported Tasks and Leaderboards
	

Translation

	
		
		Languages
	


English (en_US)
German (de_DE)
Hindi (hi_IN)
Spanish (es_ES)
French (fr_FR)
Italian (it_IT)
Arabic (ar_SA)
Dutch (nl_NL)
Japanese (ja_JP)
Portugese (pt_PT)

",https://huggingface.co/datasets/Amani27/massive_translation_dataset,"['en', 'de', 'es', 'hi', 'fr', 'it', 'ar', 'nl', 'ja', 'pt']",['translation'],['10K<n<100K']
HachiML/humaneval-ja-v0.6,HachiML,2023-07-23 13:32:38+00:00,2023-07-24 08:25:21+00:00,45,3,"['source_datasets:openai_humaneval', 'language:ja', 'license:mit', 'size_categories:n<1K', 'format:parquet', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us', 'code', 'code-generation']","
	
		
		Dataset Card for ""humaneval-ja""
	

More Information needed
",https://huggingface.co/datasets/HachiML/humaneval-ja-v0.6,['ja'],[],['n<1K']
FreedomIntelligence/MMLU_Japanese,FreedomIntelligence,2023-07-24 05:43:09+00:00,2023-08-06 08:06:24+00:00,13,1,"['language:ja', 'license:mit', 'region:us']","Japanese version of MMLU dataset tranlasted by gpt-3.5-turbo.The dataset is used in the research related to MultilingualSIFT. 
",https://huggingface.co/datasets/FreedomIntelligence/MMLU_Japanese,['ja'],[],[]
tombailey/oasst1-ja,tombailey,2023-07-24 14:34:59+00:00,2023-07-26 11:32:45+00:00,8,1,"['language:ja', 'license:apache-2.0', 'size_categories:n<1K', 'format:text', 'modality:text', 'library:datasets', 'library:mlcroissant', 'region:us']","
	
		
		oasst1-ja
	


	
		
		Description
	

Based on OpenAssistant Conversations Dataset (OASST1) but only the messages labeled as Japanese.

	
		
		Structure
	

The format is changed to ### Human: ...### Assistant: ....
Each row of the text file contains a single human message and the assistant's reply. This means a single row may be missing context from messages earlier in the conversation.
",https://huggingface.co/datasets/tombailey/oasst1-ja,['ja'],[],['n<1K']
OzoneAsai/calculation,OzoneAsai,2023-07-26 04:41:58+00:00,2023-08-06 08:27:18+00:00,922,2,"['language:en', 'language:zh', 'language:de', 'language:ru', 'language:ko', 'language:fr', 'language:ja', 'license:wtfpl', 'region:us']","
	
		
		Dataset Card for Calculation
	


	
		
		size
	

  JSON file: output1.json≒1.3GB
  ~
    output60.json
     In total 70 ~ 80GB

	
		
		Dataset Summary
	

en: Calculation. Its range will be expanded later.
zh: 计算。其范围将在以后扩展。
de: Berechnung. Der Umfang wird später erweitert werden.
ru: Расчет. Его диапазон будет расширен позже.
ko: 계산. 범위는 나중에 확장될 것입니다.
fr: Calcul. Sa portée sera étendue ultérieurement.
ja: 計算。範囲は後で拡張されます。

	
		
	
	
		Supported Tasks and Leaderboards
	

en: conversation… See the full description on the dataset page: https://huggingface.co/datasets/OzoneAsai/calculation.",https://huggingface.co/datasets/OzoneAsai/calculation,"['en', 'zh', 'de', 'ru', 'ko', 'fr', 'ja']",[],[]
hac541309/basic_korean_dict,hac541309,2023-07-26 12:13:04+00:00,2023-07-26 12:28:43+00:00,47,6,"['task_categories:table-question-answering', 'task_categories:text-generation', 'task_categories:text-classification', 'task_categories:question-answering', 'language:ko', 'language:mn', 'language:vi', 'language:th', 'language:id', 'language:ru', 'language:ja', 'language:en', 'language:fr', 'language:es', 'language:ar', 'language:zh', 'license:cc-by-sa-3.0', 'size_categories:10K<n<100K', 'format:parquet', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us', 'dictionary']","
	
		
		Dataset Card for ""basic_korean_dict""
	

This dataset is a NLP learnable form of Korean Basic Dictionary(한국어기초사전).
It follows the original copyright policy (cc-by-sa-2.0)
Some words have usage examples in other languages, effectively rendering this into a parallel corpus.
This version is built from xls_20230601
한국어 기초 사전을 학습 가능한 형태로 처리한 데이터입니다.
한국어 기초 사전의 저작권을 따릅니다.
여러 언어로 이루어진 표제어들이 있어 병렬 말뭉치의 기능이 있습니다.
xls_20230601으로부터 생성되었습니다.
",https://huggingface.co/datasets/hac541309/basic_korean_dict,"['ko', 'mn', 'vi', 'th', 'id', 'ru', 'ja', 'en', 'fr', 'es', 'ar', 'zh']","['table-question-answering', 'text-generation', 'text-classification', 'question-answering']",['10K<n<100K']
OzoneAsai/factorExpander,OzoneAsai,2023-07-27 09:19:43+00:00,2023-07-27 10:18:11+00:00,16,1,"['language:ja', 'license:wtfpl', 'size_categories:1K<n<10K', 'format:json', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","
	
		
		Polynomial Expansion and Factoring Dataset
	

This dataset contains problem and solution pairs for polynomial expansion and factoring. Each problem is a result of expanding and factoring the (x + n)^2 form expression, where n takes values from -1000 to 1000.

	
		
		Dataset Structure
	


factorized_dataset.csv: CSV file containing the dataset.
README.md: This file that provides an overview and usage instructions for the dataset.


	
		
		Data Format
	

The CSV file of the dataset… See the full description on the dataset page: https://huggingface.co/datasets/OzoneAsai/factorExpander.",https://huggingface.co/datasets/OzoneAsai/factorExpander,['ja'],[],['1K<n<10K']
izumi-lab/wikipedia-ja-20230720,izumi-lab,2023-07-28 02:11:33+00:00,2023-07-29 03:05:36+00:00,204,12,"['language:ja', 'license:cc-by-sa-3.0', 'size_categories:1M<n<10M', 'format:parquet', 'modality:text', 'library:datasets', 'library:dask', 'library:mlcroissant', 'library:polars', 'region:us']","
	
		
		Dataset Card for ""wikipedia-ja-20230720""
	

More Information needed
",https://huggingface.co/datasets/izumi-lab/wikipedia-ja-20230720,['ja'],[],['1M<n<10M']
izumi-lab/wikinews-ja-20230728,izumi-lab,2023-07-28 07:01:06+00:00,2023-07-29 03:06:48+00:00,227,5,"['language:ja', 'license:cc-by-2.5', 'size_categories:1K<n<10K', 'format:parquet', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","
	
		
		Dataset Card for ""wikinews-ja-20230728""
	

More Information needed
",https://huggingface.co/datasets/izumi-lab/wikinews-ja-20230728,['ja'],[],['1K<n<10K']
yutakobayashi/diet-members-voice-embeddings,yutakobayashi,2023-07-28 12:50:41+00:00,2023-07-28 14:32:52+00:00,14,0,"['language:ja', 'license:apache-2.0', 'modality:audio', 'region:us']","
	
		
		diet-members-voice-embeddings
	

日本の国会議員の声を speechbrain/spkrec-ecapa-voxcelebで embedding したデータセットです。話者分離などのタスクで使用できます。
国会中継や演説等の分析など、ご自由にお使いください。

	
		
		使用例
	

以下はトランスクリプトと音声ファイルを元に、話者分析を行う例です。
pip install pandas numpy wave ast scipy pyannote.audio

import pandas as pd
import numpy as np
import contextlib
import wave
import ast
from typing import List, Tuple
from scipy.spatial.distance import cosine
from pyannote.audio import Audio
from pyannote.core importSegment
from… See the full description on the dataset page: https://huggingface.co/datasets/yutakobayashi/diet-members-voice-embeddings.",https://huggingface.co/datasets/yutakobayashi/diet-members-voice-embeddings,['ja'],[],[]
llm-book/wrime-sentiment,llm-book,2023-07-29 06:38:26+00:00,2023-10-06 00:56:38+00:00,260,9,"['task_categories:text-classification', 'language:ja', 'size_categories:10K<n<100K', 'modality:text', 'library:datasets', 'library:mlcroissant', 'region:us']","
	
		
		Dataset Card for llm-book/wrime-sentiment
	

日本語の感情分析データセット WRIME を、ポジティブ/ネガティブの二値分類のタスクに加工したデータセットです。
GitHub リポジトリ ids-cv/wrime で公開されているデータセットを利用しています。
Avg. Readers_Sentiment の値が0より大きいものをポジティブ、0より小さいものをネガティブとラベル付をしています。
書籍『大規模言語モデル入門』のサンプルコードで利用することを想定しています。
詳しくは書籍のGitHubリポジトリをご覧ください。

	
		
		使い方
	

以下のようにデータセットを読み込むことができます。
from datasets import load_dataset

dataset = load_dataset(""hf_datasets/wrime-sentiment"")
print(dataset[""train""].features[""label""])
print(dataset)… See the full description on the dataset page: https://huggingface.co/datasets/llm-book/wrime-sentiment.",https://huggingface.co/datasets/llm-book/wrime-sentiment,['ja'],['text-classification'],['10K<n<100K']
haor/openniji_5_1-27,haor,2023-07-31 07:52:38+00:00,2023-08-09 03:40:16+00:00,66,3,"['task_categories:text-to-image', 'language:en', 'language:ja', 'language:ko', 'license:cc-by-nc-4.0', 'size_categories:100K<n<1M', 'doi:10.57967/hf/0942', 'region:us', 'anime', 'dataset', 'Nijijourney', 'Midjourney', 'discord']","
	
		
		Dataset Card for haor/openniji_5_1-27
	



	
		
		Dataset Description
	

The openniji_5_1-27 dataset is a subset of the OpenNiji-Dataset provided by ShoukanLabs. This subset, comprising of image-text pairs collected after May 1st. The images are compressed to 95% using the webp format, and the associated texts are included as prompts.



	
		
	
	
		Dataset Information
	


Format: 
Image: WebP (95% compressed)
Text: txt (containing prompt content)


Date of Collection: Collected after… See the full description on the dataset page: https://huggingface.co/datasets/haor/openniji_5_1-27.",https://huggingface.co/datasets/haor/openniji_5_1-27,"['en', 'ja', 'ko']",['text-to-image'],['100K<n<1M']
TLME/Umamusume-voice-transcription,TLME,2023-08-03 01:05:31+00:00,2023-08-04 05:14:01+00:00,153,7,"['language:ja', 'license:mit', 'region:us', 'Audio']","
	
		
		Umamusume-voice-transcription
	

Total charcters: 77
Comes with transcription.
This is the dataset of this repository.

	
		
		Voices Time Sum:
	


东商变革(スイープトウショウ)，时长总和：799.4399999999996秒
东海帝皇(トウカイテイオー)，时长总和：1074.0949999999998秒
东瀛佐敦(トーセンジョーダン)，时长总和：800.8589999999999秒
丸善斯基(マルゼンスキー)，时长总和：1140.2329999999993秒
也文摄辉(ヤマニンゼファー)，时长总和：1018.7590000000001秒
伏特加(ウオッカ)，时长总和：1117.798999999999秒
优秀素质(ナイスネイチャ)，时长总和：1186.9069999999995秒
八重无敌(ヤエノムテキ)，时长总和：713.699秒
北港火山(ホッコータルマエ)，时长总和：978.3929999999998秒… See the full description on the dataset page: https://huggingface.co/datasets/TLME/Umamusume-voice-transcription.",https://huggingface.co/datasets/TLME/Umamusume-voice-transcription,['ja'],[],[]
globis-university/aozorabunko-chats,globis-university,2023-08-04 00:11:22+00:00,2023-10-27 13:26:00+00:00,52,12,"['task_categories:text-generation', 'task_categories:text-classification', 'language:ja', 'license:cc-by-4.0', 'size_categories:1K<n<10K', 'format:json', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","
	
		
		Overview
	

This dataset is of conversations extracted from Aozora Bunko (青空文庫), which collects public-domain books in Japan, using a simple heuristic approach.
[For Japanese] 日本語での概要説明を Qiita に記載しました: https://qiita.com/akeyhero/items/b53eae1c0bc4d54e321f

	
		
		Method
	

First, lines surrounded by quotation mark pairs (「」) are extracted as utterances from the text field of globis-university/aozorabunko-clean.
Then, consecutive utterances are collected and grouped together.
The code… See the full description on the dataset page: https://huggingface.co/datasets/globis-university/aozorabunko-chats.",https://huggingface.co/datasets/globis-university/aozorabunko-chats,['ja'],"['text-generation', 'text-classification']",['1K<n<10K']
RyokoExtra/JapaneseGoblin,RyokoExtra,2023-08-04 16:13:13+00:00,2023-08-05 14:21:38+00:00,31,0,"['task_categories:text-classification', 'task_categories:text-generation', 'task_categories:text-to-image', 'task_categories:text-to-video', 'language:ja', 'license:apache-2.0', 'region:us']","
	
		
		Dataset Card for JapaneseGoblin
	

WE ARE THE JAPANESE GOBLIN!

	
		
		Dataset Summary
	

JapaneseGoblin is a dump of en.touhouwiki.net wiki.

	
		
		Supported Tasks and Leaderboards
	

This dataset is primarily intended for unsupervised training of text generation models; however, it may be useful for other purposes.

text-classification
text-generation


	
		
		Languages
	

Primarily english, however there are also japanese as well.

	
		
		Dataset Structure
	

All the articles are… See the full description on the dataset page: https://huggingface.co/datasets/RyokoExtra/JapaneseGoblin.",https://huggingface.co/datasets/RyokoExtra/JapaneseGoblin,['ja'],"['text-classification', 'text-generation', 'text-to-image', 'text-to-video']",[]
morizon/databricks-dolly-15k-ja,morizon,2023-08-06 05:17:38+00:00,2023-08-08 13:59:26+00:00,7,1,"['language:ja', 'license:cc-by-sa-3.0', 'size_categories:10K<n<100K', 'format:csv', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","このデータセットはkunishou/databricks-dolly-15k-jaを元に作成されています。また、databricks-dolly-15kの情報も参考にしました。

	
		
		主な修正点
	


databricks-dolly-15kに注意事項として、注釈は削除した方が良いとの以下記載があり、注釈を削除しています。Reference text (indicated by the context field in the actual dataset) may contain bracketed Wikipedia citation numbers (e.g. [42]) which we recommend users remove for downstream applications.なお注釈の削除については、正規表現を用いた修正を行っております。https://github.com/yuichiro2023/normalize_text
重複した内容の行が複数あり、削除しました。'instruction','input'… See the full description on the dataset page: https://huggingface.co/datasets/morizon/databricks-dolly-15k-ja.",https://huggingface.co/datasets/morizon/databricks-dolly-15k-ja,['ja'],[],['10K<n<100K']
OzoneAsai/4typeCalculation,OzoneAsai,2023-08-06 09:30:34+00:00,2023-08-06 10:04:35+00:00,88,1,"['language:en', 'language:zh', 'language:de', 'language:ru', 'language:ko', 'language:fr', 'language:ja', 'license:wtfpl', 'size_categories:100M<n<1B', 'format:parquet', 'modality:text', 'library:datasets', 'library:dask', 'library:mlcroissant', 'library:polars', 'region:us']","
	
		
		Dataset Card for Calculation
	


	
		
		size
	

  JSON file: output1.json≒1.3GB
  ~
    output60.json
     In total 70 ~ 80GB

	
		
		Dataset Summary
	

en: Calculation. Its range will be expanded later.
zh: 计算。其范围将在以后扩展。
de: Berechnung. Der Umfang wird später erweitert werden.
ru: Расчет. Его диапазон будет расширен позже.
ko: 계산. 범위는 나중에 확장될 것입니다.
fr: Calcul. Sa portée sera étendue ultérieurement.
ja: 計算。範囲は後で拡張されます。

	
		
	
	
		Supported Tasks and Leaderboards
	

en: conversation… See the full description on the dataset page: https://huggingface.co/datasets/OzoneAsai/4typeCalculation.",https://huggingface.co/datasets/OzoneAsai/4typeCalculation,"['en', 'zh', 'de', 'ru', 'ko', 'fr', 'ja']",[],['100M<n<1B']
macavaney/miracl-noauth,macavaney,2023-08-06 11:24:55+00:00,2023-08-06 14:38:26+00:00,662,0,"['task_categories:text-retrieval', 'task_ids:document-retrieval', 'annotations_creators:expert-generated', 'multilinguality:multilingual', 'source_datasets:miracl/miracl', 'language:ar', 'language:bn', 'language:en', 'language:es', 'language:fa', 'language:fi', 'language:fr', 'language:hi', 'language:id', 'language:ja', 'language:ko', 'language:ru', 'language:sw', 'language:te', 'language:th', 'language:zh', 'license:apache-2.0', 'region:us']","A clone of the excellent miracl/miracl dataset that doesn't require authentication. Refer to the original dataset for details.
",https://huggingface.co/datasets/macavaney/miracl-noauth,"['ar', 'bn', 'en', 'es', 'fa', 'fi', 'fr', 'hi', 'id', 'ja', 'ko', 'ru', 'sw', 'te', 'th', 'zh']",['text-retrieval'],[]
taishi-i/nagisa_stopwords,taishi-i,2023-08-06 17:10:10+00:00,2023-08-06 17:58:31+00:00,61,2,"['language:ja', 'license:mit', 'size_categories:n<1K', 'modality:text', 'library:datasets', 'library:mlcroissant', 'region:us', 'stopwords']",Japanese stopwords for nagisa.,https://huggingface.co/datasets/taishi-i/nagisa_stopwords,['ja'],[],['n<1K']
tasksource/esci,tasksource,2023-08-09 10:12:27+00:00,2023-08-09 11:23:31+00:00,355,5,"['task_categories:text-classification', 'task_categories:text-retrieval', 'language:en', 'language:ja', 'language:es', 'license:apache-2.0', 'size_categories:1M<n<10M', 'format:parquet', 'modality:tabular', 'modality:text', 'library:datasets', 'library:dask', 'library:mlcroissant', 'library:polars', 'arxiv:2206.06588', 'region:us']","
	
		
		Dataset Card for ""esci""
	

ESCI product search dataset
https://github.com/amazon-science/esci-data/
Preprocessings: 
-joined the two relevant files
-product_text aggregate all product text
-mapped esci_label to full name 
@article{reddy2022shopping,
title={Shopping Queries Dataset: A Large-Scale {ESCI} Benchmark for Improving Product Search},
author={Chandan K. Reddy and Lluís Màrquez and Fran Valero and Nikhil Rao and Hugo Zaragoza and Sambaran Bandyopadhyay and Arnab Biswas and Anlu… See the full description on the dataset page: https://huggingface.co/datasets/tasksource/esci.",https://huggingface.co/datasets/tasksource/esci,"['en', 'ja', 'es']","['text-classification', 'text-retrieval']",['1M<n<10M']
YYXMM/E-comic400k,YYXMM,2023-08-12 16:49:57+00:00,2023-08-14 04:59:31+00:00,13,3,"['task_categories:text-to-image', 'task_categories:image-segmentation', 'language:ja', 'license:openrail', 'size_categories:100K<n<1M', 'region:us', 'comic', 'manga']",,https://huggingface.co/datasets/YYXMM/E-comic400k,['ja'],"['text-to-image', 'image-segmentation']",['100K<n<1M']
HachiML/hh-rlhf-49k-ja-alpaca-format,HachiML,2023-08-13 00:57:29+00:00,2023-08-13 01:04:53+00:00,8,0,"['language:ja', 'license:mit', 'size_categories:10K<n<100K', 'format:parquet', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","
	
		
		Dataset Card for ""hh-rlhf-49k-ja-alpaca-format""
	

これはkunishou/hh-rlhf-49k-jaに以下の変更を加えたデータセットです。

alpaca形式に変更
翻訳が失敗したもの（つまりng_translation!=""0.0""のもの）の削除
indexの頭に""hh-rlhf.""をつける

This is a dataset of kunishou/hh-rlhf-49k-en with the following changes

Changed to alpaca format
Removed failed translations (i.e., those with ng_translation!=""0.0"")
Add ""hh-rlhf."" at the beginning of indexes

",https://huggingface.co/datasets/HachiML/hh-rlhf-49k-ja-alpaca-format,['ja'],[],['10K<n<100K']
masajek/openassistant-guanaco-ja,masajek,2023-08-15 15:38:34+00:00,2023-08-17 15:36:00+00:00,6,0,"['language:ja', 'license:apache-2.0', 'size_categories:n<1K', 'format:json', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","This dataset is a subset of the Open Assistant dataset, which contains Japanese conversations only.You can find a base datset here: https://huggingface.co/datasets/timdettmers/openassistant-guanaco  
 
",https://huggingface.co/datasets/masajek/openassistant-guanaco-ja,['ja'],[],['n<1K']
bandad/sayoko-tts-corpus,bandad,2023-08-16 02:11:29+00:00,2023-08-16 05:42:35+00:00,58,4,"['task_categories:text-to-speech', 'language:ja', 'license:cc-by-4.0', 'size_categories:n<1K', 'format:text', 'modality:audio', 'modality:text', 'library:datasets', 'library:mlcroissant', 'region:us']","
	
		
		サヨ子 音声コーパス
	


	
		
		ダウンロード方法
	

データセットを圧縮したzipファイルを、gdriveに置いています。
また、以下のスクリプトで、huggingface hubからダウンロードも可能です。
# pip install --upgrade huggingface_hub
from huggingface_hub import snapshot_download

snapshot_download(repo_id=""bandad/sayoko-tts-corpus"", repo_type=""dataset"", revision=""main"", local_dir=""./sayoko-tts-corpus"")


	
		
		概要
	

81歳の女性の音声コーパスです。… See the full description on the dataset page: https://huggingface.co/datasets/bandad/sayoko-tts-corpus.",https://huggingface.co/datasets/bandad/sayoko-tts-corpus,['ja'],['text-to-speech'],['n<1K']
botp/RyokoAI_Syosetu711K,botp,2023-08-18 01:29:55+00:00,2023-08-18 01:29:56+00:00,254,28,"['task_categories:text-classification', 'task_categories:text-generation', 'language:ja', 'license:apache-2.0', 'size_categories:100K<n<1M', 'region:us', 'novel', 'training']","
	
		
		Dataset Card for Syosetu711K
	

The BigKnow2022 dataset and its subsets are not yet complete. Not all information here may be accurate or accessible.

	
		
		Dataset Summary
	

Syosetu711K is a dataset composed of approximately 711,700 novels scraped from the Japanese novel self-publishing
website Syosetuka ni Narou (JA: 小説家になろう, lit. ""Let's Become a Novelist"") between March 26 and March 27, 2023.
The dataset contains most if not all novels published on the site, regardless of length… See the full description on the dataset page: https://huggingface.co/datasets/botp/RyokoAI_Syosetu711K.",https://huggingface.co/datasets/botp/RyokoAI_Syosetu711K,['ja'],"['text-classification', 'text-generation']",['100K<n<1M']
longquan/llm-japanese-dataset-custom,longquan,2023-08-18 03:45:17+00:00,2023-08-18 15:24:48+00:00,16,1,"['task_categories:question-answering', 'language:ja', 'language:en', 'license:cc-by-sa-4.0', 'size_categories:1M<n<10M', 'format:parquet', 'modality:text', 'library:datasets', 'library:dask', 'library:mlcroissant', 'library:polars', 'region:us']",,https://huggingface.co/datasets/longquan/llm-japanese-dataset-custom,"['ja', 'en']",['question-answering'],['1M<n<10M']
bogeyturn/Hitomila-metadata-dump,bogeyturn,2023-08-19 09:13:47+00:00,2023-08-28 17:57:01+00:00,6,0,"['language:en', 'language:ja', 'size_categories:1M<n<10M', 'region:us', 'not-for-all-audiences']",,https://huggingface.co/datasets/bogeyturn/Hitomila-metadata-dump,"['en', 'ja']",[],['1M<n<10M']
longquan/llm-japanese-dataset-split_10,longquan,2023-08-19 13:47:14+00:00,2023-08-19 13:51:20+00:00,12,1,"['task_categories:question-answering', 'language:ja', 'language:en', 'license:cc-by-sa-4.0', 'size_categories:100K<n<1M', 'format:parquet', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']",,https://huggingface.co/datasets/longquan/llm-japanese-dataset-split_10,"['ja', 'en']",['question-answering'],['100K<n<1M']
longquan/llm-japanese-dataset-split_10_1,longquan,2023-08-20 23:20:31+00:00,2023-08-20 23:51:46+00:00,8,1,"['task_categories:question-answering', 'language:ja', 'language:en', 'license:cc-by-sa-4.0', 'size_categories:100K<n<1M', 'format:parquet', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']",,https://huggingface.co/datasets/longquan/llm-japanese-dataset-split_10_1,"['ja', 'en']",['question-answering'],['100K<n<1M']
if001/oscar_2023_filtered,if001,2023-08-21 03:56:56+00:00,2023-08-31 13:35:37+00:00,46,3,"['task_categories:text-generation', 'language:ja', 'license:cc0-1.0', 'size_categories:1M<n<10M', 'format:json', 'modality:text', 'library:datasets', 'library:dask', 'library:mlcroissant', 'library:polars', 'region:us']","from datasets import load_dataset
ds=load_dataset(""if001/oscar_2023_filtered"")
ds['train']

---

Dataset({
    features: ['text'],
    num_rows: 312396
})

oscar 2023をfilterしたものhttps://huggingface.co/datasets/oscar-corpus/OSCAR-2301
詳細はコードを参照https://github.com/if001/HojiChar_OSCAR_sample/tree/0.0.4
",https://huggingface.co/datasets/if001/oscar_2023_filtered,['ja'],['text-generation'],['1M<n<10M']
longquan/llm-japanese-dataset-split_1,longquan,2023-08-22 04:33:38+00:00,2023-08-22 05:36:11+00:00,12,2,"['task_categories:question-answering', 'language:ja', 'language:en', 'license:cc-by-sa-4.0', 'size_categories:10K<n<100K', 'format:parquet', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']",,https://huggingface.co/datasets/longquan/llm-japanese-dataset-split_1,"['ja', 'en']",['question-answering'],['10K<n<100K']
elyza/ELYZA-tasks-100,elyza,2023-08-28 09:01:44+00:00,2023-12-27 09:17:36+00:00,3839,99,"['language:ja', 'license:cc-by-sa-4.0', 'size_categories:n<1K', 'format:csv', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'arxiv:2307.09288', 'region:us']","
	
		
		ELYZA-tasks-100: 日本語instructionモデル評価データセット
	



	
		
		Data Description
	

本データセットはinstruction-tuningを行ったモデルの評価用データセットです。詳細は リリースのnote記事 を参照してください。
特徴:

複雑な指示・タスクを含む100件の日本語データです。
役に立つAIアシスタントとして、丁寧な出力が求められます。
全てのデータに対して評価観点がアノテーションされており、評価の揺らぎを抑えることが期待されます。

具体的には以下のようなタスクを含みます。

要約を修正し、修正箇所を説明するタスク
具体的なエピソードから抽象的な教訓を述べるタスク
ユーザーの意図を汲み役に立つAIアシスタントとして振る舞うタスク
場合分けを必要とする複雑な算数のタスク
未知の言語からパターンを抽出し日本語訳する高度な推論を必要とするタスク
複数の指示を踏まえた上でyoutubeの対話を生成するタスク
架空の生き物や熟語に関する生成・大喜利などの想像力が求められるタスク… See the full description on the dataset page: https://huggingface.co/datasets/elyza/ELYZA-tasks-100.",https://huggingface.co/datasets/elyza/ELYZA-tasks-100,['ja'],[],['n<1K']
turing-motors/LLaVA-Instruct-150K-JA,turing-motors,2023-08-28 10:50:24+00:00,2023-08-28 11:26:23+00:00,23,18,"['task_categories:visual-question-answering', 'task_categories:question-answering', 'language:ja', 'license:cc-by-nc-4.0', 'size_categories:100K<n<1M', 'format:json', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","
	
		
		Dataset Details
	

Dataset Type:Japanese LLaVA Instruct 150K is a localized version of the original LLaVA Visual Instruct 150K dataset. This version is translated into Japanese using DeepL API and is aimed at serving similar purposes in the context of Japanese language.
Resources for More Information:For information on the original dataset: LLaVA Visual Instruct 150K
License:Attribution-NonCommercial 4.0 International (CC BY-NC-4.0)The dataset should abide by the policy of OpenAI:… See the full description on the dataset page: https://huggingface.co/datasets/turing-motors/LLaVA-Instruct-150K-JA.",https://huggingface.co/datasets/turing-motors/LLaVA-Instruct-150K-JA,['ja'],"['visual-question-answering', 'question-answering']",['100K<n<1M']
stockmark/ner-wikipedia-dataset,stockmark,2023-09-02 14:38:55+00:00,2023-09-02 14:42:18+00:00,122,12,"['task_categories:token-classification', 'language:ja', 'license:cc-by-sa-3.0', 'size_categories:1K<n<10K', 'format:json', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us', 'Named Entity Recognition', 'NER']","
	
		
		Wikipediaを用いた日本語の固有表現抽出データセット
	


GitHub: https://github.com/stockmarkteam/ner-wikipedia-dataset/
LICENSE: CC-BY-SA 3.0

Developed by Stockmark Inc.
",https://huggingface.co/datasets/stockmark/ner-wikipedia-dataset,['ja'],['token-classification'],['1K<n<10K']
if001/aozorabunko-clean-sin,if001,2023-09-04 04:22:55+00:00,2024-10-14 12:46:29+00:00,31,4,"['task_categories:text-generation', 'task_categories:text-classification', 'language:ja', 'license:cc-by-4.0', 'size_categories:10K<n<100K', 'format:parquet', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","this is forkhttps://huggingface.co/datasets/globis-university/aozorabunko-clean
filtered
row[""meta""][""文字遣い種別""] == ""新字新仮名""
",https://huggingface.co/datasets/if001/aozorabunko-clean-sin,['ja'],"['text-generation', 'text-classification']",['10K<n<100K']
huawei-noah/entity_cs,huawei-noah,2023-09-08 08:44:07+00:00,2023-09-20 07:05:07+00:00,92,2,"['language:af', 'language:am', 'language:ar', 'language:as', 'language:az', 'language:be', 'language:bg', 'language:bn', 'language:br', 'language:bs', 'language:ca', 'language:cs', 'language:cy', 'language:da', 'language:de', 'language:en', 'language:el', 'language:eo', 'language:es', 'language:et', 'language:eu', 'language:fa', 'language:fi', 'language:fr', 'language:fy', 'language:ga', 'language:gd', 'language:gl', 'language:gu', 'language:ha', 'language:he', 'language:hi', 'language:hr', 'language:hu', 'language:hy', 'language:id', 'language:is', 'language:it', 'language:ja', 'language:jv', 'language:ka', 'language:kk', 'language:km', 'language:kn', 'language:ko', 'language:ku', 'language:ky', 'language:la', 'language:lo', 'language:lt', 'language:lv', 'language:mg', 'language:mk', 'language:ml', 'language:mn', 'language:mr', 'language:ms', 'language:my', 'language:ne', 'language:nl', 'language:nb', 'language:om', 'language:or', 'language:pa', 'language:pl', 'language:ps', 'language:pt', 'language:ro', 'language:ru', 'language:sa', 'language:sd', 'language:si', 'language:sk', 'language:sl', 'language:so', 'language:sq', 'language:sr', 'language:su', 'language:sv', 'language:sw', 'language:ta', 'language:te', 'language:th', 'language:tl', 'language:tr', 'language:ug', 'language:uk', 'language:ur', 'language:uz', 'language:vi', 'language:xh', 'language:yi', 'language:zh', 'license:apache-2.0', 'size_categories:100M<n<1B', 'format:parquet', 'modality:text', 'library:datasets', 'library:dask', 'library:mlcroissant', 'library:polars', 'region:us']","
	
		
		Dataset Card for EntityCS
	


Repository: https://github.com/huawei-noah/noah-research/tree/master/NLP/EntityCS  
Paper: https://aclanthology.org/2022.findings-emnlp.499.pdf  
Point of Contact: Fenia Christopoulou, Chenxi Whitehouse


	
		
	
	
		Dataset Description
	

We use the English Wikipedia and leverage entity information from Wikidata to construct an entity-based Code Switching corpus. 
To achieve this, we make use of wikilinks in Wikipedia, i.e. links from one page to another.… See the full description on the dataset page: https://huggingface.co/datasets/huawei-noah/entity_cs.",https://huggingface.co/datasets/huawei-noah/entity_cs,"['af', 'am', 'ar', 'as', 'az', 'be', 'bg', 'bn', 'br', 'bs', 'ca', 'cs', 'cy', 'da', 'de', 'en', 'el', 'eo', 'es', 'et', 'eu', 'fa', 'fi', 'fr', 'fy', 'ga', 'gd', 'gl', 'gu', 'ha', 'he', 'hi', 'hr', 'hu', 'hy', 'id', 'is', 'it', 'ja', 'jv', 'ka', 'kk', 'km', 'kn', 'ko', 'ku', 'ky', 'la', 'lo', 'lt', 'lv', 'mg', 'mk', 'ml', 'mn', 'mr', 'ms', 'my', 'ne', 'nl', 'nb', 'om', 'or', 'pa', 'pl', 'ps', 'pt', 'ro', 'ru', 'sa', 'sd', 'si', 'sk', 'sl', 'so', 'sq', 'sr', 'su', 'sv', 'sw', 'ta', 'te', 'th', 'tl', 'tr', 'ug', 'uk', 'ur', 'uz', 'vi', 'xh', 'yi', 'zh']",[],['100M<n<1B']
taishi-i/awesome-japanese-nlp-classification-dataset,taishi-i,2023-09-09 06:37:36+00:00,2023-09-09 11:09:04+00:00,45,5,"['task_categories:text-classification', 'language:en', 'language:ja', 'license:other', 'size_categories:1K<n<10K', 'modality:text', 'library:datasets', 'library:mlcroissant', 'region:us', 'code']","This dataset determines whether a GitHub repository description relates to Japanese natural language processing (NLP). The labels are categorized as ""Relevant (1)"" and ""Not Relevant (0)"".",https://huggingface.co/datasets/taishi-i/awesome-japanese-nlp-classification-dataset,"['en', 'ja']",['text-classification'],['1K<n<10K']
p1atdev/oiocha,p1atdev,2023-09-09 07:32:19+00:00,2023-09-18 05:59:05+00:00,7,1,"['task_categories:text-generation', 'language:ja', 'license:mit', 'size_categories:n<1K', 'format:json', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us', 'haiku']","お～いお茶新俳句大賞受賞作品データセット 

221の俳句が含まれ、うち200前後は作者と審査員のコメントが付属。

データは https://itoen-shinhaiku.jp/ から取得。

	
		
		データ構造
	


title: 大会の名前 (第三回 など)
ordinal: 受賞した大会の開催回数 (第三回なら 3)
award: 受賞した賞
haiku: 俳句の本文
translation: 俳句本文が英語の場合の日本語訳
language: 俳句の言語。日本語は ja。英語は en。
comment: 著者による俳句の解説
review: 審査員による俳句の評価
image_pc: 画像が付属する場合、PC向けのサイズの大きい画像の URL
image_sp: 画像が付属する場合、スマホ向けのサイズの小さい画像の URL

",https://huggingface.co/datasets/p1atdev/oiocha,['ja'],['text-generation'],['n<1K']
p1atdev/modern_haiku,p1atdev,2023-09-10 05:49:41+00:00,2023-09-10 12:46:58+00:00,64,3,"['task_categories:text-generation', 'language:ja', 'license:mit', 'size_categories:10K<n<100K', 'modality:text', 'library:datasets', 'library:mlcroissant', 'region:us', 'haiku']",This new dataset is designed to solve this great NLP task and is crafted with a lot of care.,https://huggingface.co/datasets/p1atdev/modern_haiku,['ja'],['text-generation'],['10K<n<100K']
p1atdev/JEDHRI,p1atdev,2023-09-11 15:01:39+00:00,2023-09-11 15:05:47+00:00,8,0,"['language:ja', 'license:cc-by-4.0', 'size_categories:n<1K', 'region:us', 'legal', 'not-for-all-audiences']",Japanese Expressions Dataset from Human Rights Infringement on Internet,https://huggingface.co/datasets/p1atdev/JEDHRI,['ja'],[],['n<1K']
trojblue/rvc-kanade-dataset,trojblue,2023-09-12 11:57:53+00:00,2024-10-11 20:51:26+00:00,17,2,"['language:ja', 'license:bigscience-openrail-m', 'size_categories:1K<n<10K', 'format:audiofolder', 'modality:audio', 'library:datasets', 'library:mlcroissant', 'region:us', 'audio']","
	
		
		Kanade audio dataset
	

every single line spoken by yoisaki kanade extracted from the Project Sekai: Colorful Stage! Game, as of Sep 12, 2023
",https://huggingface.co/datasets/trojblue/rvc-kanade-dataset,['ja'],[],['1K<n<10K']
Nicolas-BZRD/English_French_Songs_Lyrics_Translation_Original,Nicolas-BZRD,2023-09-12 21:21:44+00:00,2024-02-08 23:34:15+00:00,40,13,"['task_categories:translation', 'task_categories:text-generation', 'language:fr', 'language:en', 'language:es', 'language:it', 'language:de', 'language:ko', 'language:id', 'language:pt', 'language:no', 'language:fi', 'language:sv', 'language:sw', 'language:hr', 'language:so', 'language:ca', 'language:tl', 'language:ja', 'language:nl', 'language:ru', 'language:et', 'language:tr', 'language:ro', 'language:cy', 'language:vi', 'language:af', 'language:hu', 'language:sk', 'language:sl', 'language:cs', 'language:da', 'language:pl', 'language:sq', 'language:el', 'language:he', 'language:zh', 'language:th', 'language:bg', 'language:ar', 'license:unknown', 'size_categories:10K<n<100K', 'format:parquet', 'modality:tabular', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'arxiv:2402.00786', 'region:us', 'music', 'parallel', 'parallel data']","
	
		
		Original Songs Lyrics with French Translation
	


	
		
		Dataset Summary
	

Dataset of 99289 songs containing their metadata (author, album, release date, song number), original lyrics and lyrics translated into French.
Details of the number of songs by language of origin can be found in the table below:

	
		
Original language
Number of songs


		
en
75786


fr
18486


es
1743


it
803


de
691


sw
529


ko
193


id
169


pt
142


no
122


fi
113

sv
70


hr
53


so
43


ca
41


tl… See the full description on the dataset page: https://huggingface.co/datasets/Nicolas-BZRD/English_French_Songs_Lyrics_Translation_Original.",https://huggingface.co/datasets/Nicolas-BZRD/English_French_Songs_Lyrics_Translation_Original,"['fr', 'en', 'es', 'it', 'de', 'ko', 'id', 'pt', 'no', 'fi', 'sv', 'sw', 'hr', 'so', 'ca', 'tl', 'ja', 'nl', 'ru', 'et', 'tr', 'ro', 'cy', 'vi', 'af', 'hu', 'sk', 'sl', 'cs', 'da', 'pl', 'sq', 'el', 'he', 'zh', 'th', 'bg', 'ar']","['translation', 'text-generation']",['10K<n<100K']
yachay/text_coordinates_regions,yachay,2023-09-14 15:28:51+00:00,2023-09-21 16:19:16+00:00,116,8,"['task_categories:feature-extraction', 'task_categories:token-classification', 'task_categories:text-classification', 'language:en', 'language:zh', 'language:es', 'language:hi', 'language:ar', 'language:bn', 'language:pt', 'language:ru', 'language:ja', 'language:pa', 'language:de', 'language:jv', 'language:ms', 'language:te', 'language:vi', 'language:ko', 'language:fr', 'language:mr', 'language:ta', 'language:ur', 'language:tr', 'language:it', 'language:th', 'language:gu', 'language:fa', 'language:pl', 'license:mit', 'size_categories:100K<n<1M', 'format:json', 'modality:text', 'modality:geospatial', 'library:datasets', 'library:dask', 'library:mlcroissant', 'region:us', 'multilingual', 'text', 'coordinates', 'geospatial', 'translation', 'NER', 'geo', 'geo-tagged', 'named-entity-recognition', 'natural-language-processing', 'geographic-data', 'geolocation', 'twitter', 'reddit']","
	
		
		Dataset Card for Multilingual Geo-Tagged Social Media Posts (by 123 world regions)
	


	
		
		Dataset Summary
	

The ""Regions"" dataset is a multilingual corpus that encompasses textual data from the 123 most populated regions worldwide, with each region's data organized into separate .json files. This dataset consists of approximately 500,000 text samples, each paired with its geographic coordinates.
Key Features:

Textual Data: The dataset contains 500,000 text samples.… See the full description on the dataset page: https://huggingface.co/datasets/yachay/text_coordinates_regions.",https://huggingface.co/datasets/yachay/text_coordinates_regions,"['en', 'zh', 'es', 'hi', 'ar', 'bn', 'pt', 'ru', 'ja', 'pa', 'de', 'jv', 'ms', 'te', 'vi', 'ko', 'fr', 'mr', 'ta', 'ur', 'tr', 'it', 'th', 'gu', 'fa', 'pl']","['feature-extraction', 'token-classification', 'text-classification']",['100K<n<1M']
p1atdev/fake-news-jp,p1atdev,2023-09-22 12:40:39+00:00,2023-09-22 12:54:43+00:00,7,1,"['language:ja', 'license:cc-by-2.5', 'size_categories:10K<n<100K', 'region:us']",日本語のニュース記事と、GPT-2日本語版のモデルで生成された、ディープフェイク記事からなるデータセットです。,https://huggingface.co/datasets/p1atdev/fake-news-jp,['ja'],[],['10K<n<100K']
JapanDegitalMaterial/Scenery_of_japan,JapanDegitalMaterial,2023-09-23 11:08:44+00:00,2023-09-23 14:32:48+00:00,69,1,"['task_categories:text-to-image', 'language:en', 'language:ja', 'license:cc0-1.0', 'size_categories:n<1K', 'format:imagefolder', 'modality:image', 'library:datasets', 'library:mlcroissant', 'region:us']","
	
		
		Scenery of japan.
	

This is a dataset to train text-to-image or other models without any copyright issue.
All materials used in this dataset are CC0 (Public domain /P.D.).

	
		
		Dataset Summary
	

This dataset card aims to be a base template for new datasets. It has been generated using this raw template.

	
		
		Supported Tasks and Leaderboards
	

[More Information Needed]

	
		
		Languages
	

[More Information Needed]

	
		
		Dataset Structure
	


	
		
		Data Instances
	

[More… See the full description on the dataset page: https://huggingface.co/datasets/JapanDegitalMaterial/Scenery_of_japan.",https://huggingface.co/datasets/JapanDegitalMaterial/Scenery_of_japan,"['en', 'ja']",['text-to-image'],['n<1K']
JapanDegitalMaterial/Texture_images,JapanDegitalMaterial,2023-09-23 12:16:01+00:00,2023-09-23 14:05:23+00:00,56,0,"['task_categories:text-to-image', 'language:en', 'language:ja', 'license:cc0-1.0', 'size_categories:n<1K', 'format:imagefolder', 'modality:image', 'library:datasets', 'library:mlcroissant', 'region:us']","
	
		
		Textuer images
	

This is a dataset to train text-to-image or other models without any copyright issue.
All materials used in this dataset are CC0 (Public domain /P.D.).

	
		
		Dataset Summary
	

This dataset card aims to be a base template for new datasets. It has been generated using this raw template.

	
		
		Supported Tasks and Leaderboards
	

[More Information Needed]

	
		
		Languages
	

[More Information Needed]

	
		
		Dataset Structure
	


	
		
		Data Instances
	

[More… See the full description on the dataset page: https://huggingface.co/datasets/JapanDegitalMaterial/Texture_images.",https://huggingface.co/datasets/JapanDegitalMaterial/Texture_images,"['en', 'ja']",['text-to-image'],['n<1K']
JapanDegitalMaterial/Places_in_Japan,JapanDegitalMaterial,2023-09-23 12:35:06+00:00,2023-09-23 14:00:16+00:00,92,0,"['task_categories:text-to-image', 'language:en', 'language:ja', 'license:cc0-1.0', 'size_categories:n<1K', 'format:imagefolder', 'modality:image', 'library:datasets', 'library:mlcroissant', 'region:us']","
	
		
		Places in japan.
	

This is a dataset to train text-to-image or other models without any copyright issue.
All materials used in this dataset are CC0 (Public domain /P.D.).

	
		
		Dataset Summary
	

This dataset card aims to be a base template for new datasets. It has been generated using this raw template.

	
		
		Supported Tasks and Leaderboards
	

[More Information Needed]

	
		
		Languages
	

[More Information Needed]

	
		
		Dataset Structure
	


	
		
		Data Instances
	

[More… See the full description on the dataset page: https://huggingface.co/datasets/JapanDegitalMaterial/Places_in_Japan.",https://huggingface.co/datasets/JapanDegitalMaterial/Places_in_Japan,"['en', 'ja']",['text-to-image'],['n<1K']
UniqueData/messengers-reviews-google-play,UniqueData,2023-09-25 11:57:44+00:00,2025-10-01 10:15:48+00:00,137,2,"['task_categories:text-classification', 'language:en', 'language:fr', 'language:ja', 'language:it', 'language:de', 'license:cc-by-nc-nd-4.0', 'size_categories:1K<n<10K', 'format:csv', 'modality:tabular', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us', 'app reviews', 'mobile app reviews', 'android apps', 'NLP']","
	
		
		Reviews on Messengers Dataset - Review dataset
	

The Reviews on Messengers Dataset is a comprehensive collection of 200 the most recent customer reviews on 6 messengers obtained from the popular app store, Google Play. See the list of the apps below.
This dataset encompasses reviews written in 5 different languages: English, French, German, Italian, Japanese.

	
		
	
	
		💴 For Commercial Usage: To discuss your requirements, learn about the price and buy the dataset, leave a request… See the full description on the dataset page: https://huggingface.co/datasets/UniqueData/messengers-reviews-google-play.",https://huggingface.co/datasets/UniqueData/messengers-reviews-google-play,"['en', 'fr', 'ja', 'it', 'de']",['text-classification'],['1K<n<10K']
kunishou/amenokaku-code-instruct,kunishou,2023-10-01 01:04:50+00:00,2024-04-01 17:01:54+00:00,56,17,"['language:ja', 'license:other', 'size_categories:1K<n<10K', 'format:json', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","

	
		
		Amenokaku-Code-Instruct
	

Update:  

2023/12/27データセットに JaxTon , プロになるJava のコードデータ 180 レコードを追加しました。


	
		
		概要
	


コードに特化した5.2KのInstructionデータセットです。
データセットに含まれるデータは商用利用できるラインセンスが付与されたプログラミング学習コンテンツから収集、加工し作成しました（英語のコンテンツは日本語に自動翻訳し、翻訳の不自然な箇所を手動で修正）。
また、ライセンスが明記されていない学習コンテンツについては権利者に個別に連絡を取り、本データセットへの掲載の許諾を得ております。


	
		
		データセット詳細
	

指示タスクの内訳としてはコード生成（code_generation）が1050レコード、コードの挙動確認（check_code_behavor）が150レコード、コードのバグ修正（code_fix）が4000レコードになります。
詳細な内訳は以下の通りになります。

	
		
source name… See the full description on the dataset page: https://huggingface.co/datasets/kunishou/amenokaku-code-instruct.",https://huggingface.co/datasets/kunishou/amenokaku-code-instruct,['ja'],[],['1K<n<10K']
TKNodven/Mordred,TKNodven,2023-10-02 01:44:43+00:00,2023-10-02 01:45:19+00:00,7,0,"['language:ja', 'size_categories:n<1K', 'format:audiofolder', 'modality:audio', 'library:datasets', 'library:mlcroissant', 'region:us']",,https://huggingface.co/datasets/TKNodven/Mordred,['ja'],[],['n<1K']
BramVanroy/xlwic_wn,BramVanroy,2023-10-02 07:48:29+00:00,2023-10-02 09:19:20+00:00,133,1,"['task_categories:text-classification', 'language:bg', 'language:zh', 'language:hr', 'language:da', 'language:nl', 'language:et', 'language:fa', 'language:ja', 'language:ko', 'license:cc-by-nc-4.0', 'size_categories:10K<n<100K', 'format:csv', 'modality:tabular', 'modality:text', 'library:datasets', 'library:dask', 'library:mlcroissant', 'library:polars', 'region:us']","
	
		
		Multilingual Word-in-Context (WordNet)
	

Refer to the documentation and paper for more information.
",https://huggingface.co/datasets/BramVanroy/xlwic_wn,"['bg', 'zh', 'hr', 'da', 'nl', 'et', 'fa', 'ja', 'ko']",['text-classification'],['10K<n<100K']
ShoukanLabs/OpenNiji-Dataset-Aesthetic-Finetune,ShoukanLabs,2023-10-04 06:38:42+00:00,2023-10-04 06:41:14+00:00,27,1,"['task_categories:text-to-image', 'language:en', 'language:ja', 'language:ko', 'license:cc-by-nc-4.0', 'size_categories:10K<n<100K', 'format:json', 'modality:image', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us', 'anime', 'dataset', 'Nijijourney', 'Midjourney', 'discord']","Used in quality tuning for OpenNiji
",https://huggingface.co/datasets/ShoukanLabs/OpenNiji-Dataset-Aesthetic-Finetune,"['en', 'ja', 'ko']",['text-to-image'],['10K<n<100K']
Trelis/openassistant-guanaco-EOS,Trelis,2023-10-04 12:28:22+00:00,2023-10-04 16:17:59+00:00,21,2,"['language:en', 'language:es', 'language:ru', 'language:de', 'language:pl', 'language:th', 'language:vi', 'language:sv', 'language:bn', 'language:da', 'language:he', 'language:it', 'language:fa', 'language:sk', 'language:id', 'language:nb', 'language:el', 'language:nl', 'language:hu', 'language:eu', 'language:zh', 'language:eo', 'language:ja', 'language:ca', 'language:cs', 'language:bg', 'language:fi', 'language:pt', 'language:tr', 'language:ro', 'language:ar', 'language:uk', 'language:gl', 'language:fr', 'language:ko', 'license:apache-2.0', 'size_categories:10K<n<100K', 'format:csv', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'arxiv:2304.07327', 'region:us', 'human-feedback', 'llama-2']","
	
		
		Chat Fine-tuning Dataset - Guanaco Style
	

This dataset allows for fine-tuning chat models using ""### Human:"" AND ""### Assistant"" as the beginning and end of sequence tokens.
Preparation:

The dataset is cloned from TimDettmers, which itself is a subset of the Open Assistant dataset, which you can find here. This subset of the data only contains the highest-rated paths in the conversation tree, with a total of 9,846 samples.
The dataset was then slightly adjusted to:


if a row of… See the full description on the dataset page: https://huggingface.co/datasets/Trelis/openassistant-guanaco-EOS.",https://huggingface.co/datasets/Trelis/openassistant-guanaco-EOS,"['en', 'es', 'ru', 'de', 'pl', 'th', 'vi', 'sv', 'bn', 'da', 'he', 'it', 'fa', 'sk', 'id', 'nb', 'el', 'nl', 'hu', 'eu', 'zh', 'eo', 'ja', 'ca', 'cs', 'bg', 'fi', 'pt', 'tr', 'ro', 'ar', 'uk', 'gl', 'fr', 'ko']",[],['10K<n<100K']
CaterinaLac/sharegpt-deduplicated,CaterinaLac,2023-10-04 13:31:41+00:00,2023-10-04 14:40:39+00:00,21,1,"['language:en', 'language:zh', 'language:ko', 'language:fr', 'language:ja', 'language:es', 'language:no', 'language:et', 'language:de', 'language:ca', 'language:vi', 'language:fi', 'license:apache-2.0', 'size_categories:1K<n<10K', 'format:json', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","
	
		
		Dataset Card for Dataset Name
	


	
		
		Dataset Description
	


	
		
		Dataset Summary
	

This dataset is a deduplicated version of sharegpt4. 
The deduplication process has two steps:

The literal duplicates (both input and outputs) are removed
The remaining (5749) instances are embedded with the SentenceTransformer library (""paraphrase-multilingual-mpnet-base-v2"" model).
Then, we compute the cosine similarity among all the possible pairs, and consider paraphrases those pairs with a… See the full description on the dataset page: https://huggingface.co/datasets/CaterinaLac/sharegpt-deduplicated.",https://huggingface.co/datasets/CaterinaLac/sharegpt-deduplicated,"['en', 'zh', 'ko', 'fr', 'ja', 'es', 'no', 'et', 'de', 'ca', 'vi', 'fi']",[],['1K<n<10K']
Trelis/openassistant-llama-style,Trelis,2023-10-04 14:14:13+00:00,2023-10-31 11:29:33+00:00,48,9,"['language:en', 'language:es', 'language:ru', 'language:de', 'language:pl', 'language:th', 'language:vi', 'language:sv', 'language:bn', 'language:da', 'language:he', 'language:it', 'language:fa', 'language:sk', 'language:id', 'language:nb', 'language:el', 'language:nl', 'language:hu', 'language:eu', 'language:zh', 'language:eo', 'language:ja', 'language:ca', 'language:cs', 'language:bg', 'language:fi', 'language:pt', 'language:tr', 'language:ro', 'language:ar', 'language:uk', 'language:gl', 'language:fr', 'language:ko', 'license:apache-2.0', 'size_categories:10K<n<100K', 'format:csv', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'arxiv:2304.07327', 'region:us', 'human-feedback', 'llama-2']","
	
		
		Chat Fine-tuning Dataset - Llama 2 Style
	

This dataset allows for fine-tuning chat models using [INST] AND [/INST] to wrap user messages.
Preparation:

The dataset is cloned from TimDettmers, which itself is a subset of the Open Assistant dataset, which you can find here. This subset of the data only contains the highest-rated paths in the conversation tree, with a total of 9,846 samples.
The dataset was then filtered to:


replace instances of '### Human:' with '[INST]'
replace… See the full description on the dataset page: https://huggingface.co/datasets/Trelis/openassistant-llama-style.",https://huggingface.co/datasets/Trelis/openassistant-llama-style,"['en', 'es', 'ru', 'de', 'pl', 'th', 'vi', 'sv', 'bn', 'da', 'he', 'it', 'fa', 'sk', 'id', 'nb', 'el', 'nl', 'hu', 'eu', 'zh', 'eo', 'ja', 'ca', 'cs', 'bg', 'fi', 'pt', 'tr', 'ro', 'ar', 'uk', 'gl', 'fr', 'ko']",[],['10K<n<100K']
cardiffnlp/tweet_topic_multilingual,cardiffnlp,2023-10-04 18:49:58+00:00,2025-06-12 11:26:27+00:00,7232,2,"['task_categories:text-classification', 'multilinguality:monolingual', 'language:en', 'language:ja', 'language:el', 'language:es', 'license:other', 'size_categories:10K<n<100K', 'format:parquet', 'modality:text', 'library:datasets', 'library:dask', 'library:mlcroissant', 'library:polars', 'arxiv:2410.03075', 'region:us']","
	
		
		Dataset Card for ""cardiffnlp/tweet_topic_multilingual""
	


	
		
		Dataset Summary
	

This is the official repository of X-Topic (Multilingual Topic Classification in X: Dataset and Analysis, EMNLP 2024), a topic classification dataset based on X (formerly Twitter), featuring 19 topic labels.
The classification task is multi-label, with tweets available in four languages: English, Japanese, Spanish, and Greek.
The dataset comprises 4,000 tweets (1,000 per language), collected between… See the full description on the dataset page: https://huggingface.co/datasets/cardiffnlp/tweet_topic_multilingual.",https://huggingface.co/datasets/cardiffnlp/tweet_topic_multilingual,"['en', 'ja', 'el', 'es']",['text-classification'],['10K<n<100K']
daraiii/test,daraiii,2023-10-05 10:33:12+00:00,2023-10-05 10:37:49+00:00,7,0,"['language:ja', 'license:unknown', 'size_categories:n<1K', 'format:parquet', 'modality:image', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","
	
		
		これはうｐテストだよ This is uploading test.
	


	
		
		Dataset Description, Summary
	

サムネ画像 my thumbnail.
7z か parquet
やがて消す
",https://huggingface.co/datasets/daraiii/test,['ja'],[],['n<1K']
metral/ranobe_sample,metral,2023-10-06 08:05:28+00:00,2023-10-06 08:25:32+00:00,8,1,"['language:ja', 'license:apache-2.0', 'size_categories:1K<n<10K', 'format:text', 'modality:text', 'library:datasets', 'library:mlcroissant', 'region:us']","
	
		
		What is this?
	

This is the text of my novel. It has approximately 240,000 words.
The genre is fantasy light novel.

	
		
		What is the licence?
	

The licence type is Apache 2.0.

	
		
		How can I use it?
	

I want you to use this novel as a sample of Japanese writing.
After that, you are free to use it within the scope of the licence.
You can send me fan letters :)

	
		
		Are there any precautions I should be aware of?
	

This text is still available on Kakuyom. The unique format… See the full description on the dataset page: https://huggingface.co/datasets/metral/ranobe_sample.",https://huggingface.co/datasets/metral/ranobe_sample,['ja'],[],['1K<n<10K']
MinnaCatpp15/Kai,MinnaCatpp15,2023-10-11 17:41:01+00:00,2023-10-11 17:45:22+00:00,9,0,"['language:ja', 'language:en', 'language:th', 'size_categories:n<1K', 'modality:video', 'library:datasets', 'library:mlcroissant', 'region:us', 'music']",,https://huggingface.co/datasets/MinnaCatpp15/Kai,"['ja', 'en', 'th']",[],['n<1K']
SachinPatel248/mqnli,SachinPatel248,2023-10-14 12:13:02+00:00,2023-10-14 12:55:37+00:00,23,0,"['task_categories:text-classification', 'language:en', 'language:de', 'language:es', 'language:ar', 'language:zh', 'language:hi', 'language:pt', 'language:ru', 'language:ja', 'language:fr', 'language:ur', 'language:tr', 'language:ko', 'language:pl', 'language:it', 'language:sv', 'license:apache-2.0', 'size_categories:100K<n<1M', 'format:parquet', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']",,https://huggingface.co/datasets/SachinPatel248/mqnli,"['en', 'de', 'es', 'ar', 'zh', 'hi', 'pt', 'ru', 'ja', 'fr', 'ur', 'tr', 'ko', 'pl', 'it', 'sv']",['text-classification'],['100K<n<1M']
Mathoctopus/GSM8KInstruct_Parallel,Mathoctopus,2023-10-15 14:44:31+00:00,2023-10-15 14:48:41+00:00,37,7,"['task_categories:question-answering', 'language:en', 'language:zh', 'language:es', 'language:fr', 'language:th', 'language:sw', 'language:ja', 'language:bn', 'language:de', 'language:ru', 'license:apache-2.0', 'size_categories:10K<n<100K', 'format:json', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']",,https://huggingface.co/datasets/Mathoctopus/GSM8KInstruct_Parallel,"['en', 'zh', 'es', 'fr', 'th', 'sw', 'ja', 'bn', 'de', 'ru']",['question-answering'],['10K<n<100K']
Mathoctopus/MSVAMP,Mathoctopus,2023-10-17 09:29:55+00:00,2023-10-17 10:48:46+00:00,1251,4,"['task_categories:text-generation', 'language:bn', 'language:zh', 'language:en', 'language:fr', 'language:de', 'language:ja', 'language:ru', 'language:es', 'language:sw', 'language:th', 'license:apache-2.0', 'size_categories:10K<n<100K', 'format:json', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']",,https://huggingface.co/datasets/Mathoctopus/MSVAMP,"['bn', 'zh', 'en', 'fr', 'de', 'ja', 'ru', 'es', 'sw', 'th']",['text-generation'],['10K<n<100K']
if001/oasst1_ja_ppl,if001,2023-10-17 12:01:55+00:00,2023-10-23 11:22:05+00:00,6,0,"['language:ja', 'license:apache-2.0', 'size_categories:10K<n<100K', 'format:parquet', 'modality:tabular', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","** 以下のrepositoryのforkです。 ** 
https://huggingface.co/datasets/kunishou/oasst1-89k-ja
instructionとinput、outputにまとめ、kenllmでperplexityのスコアが付与してあります。
perplexityの計算に用いたtokenizerはこちら
https://huggingface.co/if001/sentencepiece_ja

instruction_ppl: instructionのみのperplexity
output_ppl: outputのみのperplexity
full_ppl: instructionとoutputを合わせ、instruction用の文章にしたperplexity

",https://huggingface.co/datasets/if001/oasst1_ja_ppl,['ja'],[],['10K<n<100K']
kogi-jwu/jhumaneval,kogi-jwu,2023-10-21 08:20:14+00:00,2024-01-10 21:52:35+00:00,396,7,"['source_datasets:openai_humaneval', 'language:ja', 'language:en', 'license:mit', 'size_categories:n<1K', 'format:parquet', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","
	
		
		Dataset Card for JHumanEval: Japanese Hand-Translated HumanEval
	


	
		
		Dataset Summary
	

This is a Japanese translated version of HumanEval, an evaluation harness for the HumanEval problem solving dataset described in the paper ""Evaluating Large Language Models Trained on Code"".
LLM のコード生成能力の標準ベンチマーク HumanEval の日本語翻訳版です。機械翻訳(DeepL, GPT-4)の翻訳結果を全て人手によって再修正し、 訳文を日本人のプログラマが読んで理解し、コードが書ける内容かチェックしました。ただし、英語版 HumanEval の間違いは、修正せずに残して、 HumanEval 同様に不完全なドキュメントからの生成能力を見るようになっています。日本語LLM… See the full description on the dataset page: https://huggingface.co/datasets/kogi-jwu/jhumaneval.",https://huggingface.co/datasets/kogi-jwu/jhumaneval,"['ja', 'en']",[],['n<1K']
skytnt/japanese-lyric,skytnt,2023-10-21 14:44:06+00:00,2023-10-21 14:50:58+00:00,35,4,"['task_categories:text-generation', 'language:ja', 'license:cc0-1.0', 'size_categories:10K<n<100K', 'region:us', 'music']",,https://huggingface.co/datasets/skytnt/japanese-lyric,['ja'],['text-generation'],['10K<n<100K']
alfredplpl/simple-zundamon,alfredplpl,2023-10-21 15:16:58+00:00,2023-10-21 16:10:17+00:00,181,14,"['language:ja', 'license:other', 'region:us']","
	
		
		シンプルずんだもんデータセット
	



	
		
		はじめに
	

ずんだもんの設定が詰まったシンプルなデータセットです。
作者がインターネットで調べたり、運営の人からもらったデータから作成しました。
キャラクターLLMを作るための動作確認にお使いください。
ただし、可能な限り動作確認でもライセンスをよく読んでください。
他の用途はライセンスをよく読んでください。

	
		
		各種フォーマット
	


LLM-jp: zmnjp.jsonl
ChatGPT: zmn.jsonl


	
		
		ライセンス
	


（ず・ω・きょ）

",https://huggingface.co/datasets/alfredplpl/simple-zundamon,['ja'],[],[]
stockmark/business-questions,stockmark,2023-10-22 14:47:54+00:00,2024-05-14 05:45:15+00:00,18,6,"['language:ja', 'license:mit', 'size_categories:n<1K', 'format:json', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","
	
		
		Stockmark Business Questions
	

",https://huggingface.co/datasets/stockmark/business-questions,['ja'],[],['n<1K']
iamshnoo/WEATHub,iamshnoo,2023-10-24 08:43:49+00:00,2024-07-10 01:50:42+00:00,54,2,"['language:ar', 'language:bn', 'language:ckb', 'language:da', 'language:de', 'language:el', 'language:es', 'language:fa', 'language:fr', 'language:hi', 'language:it', 'language:ja', 'language:ko', 'language:ku', 'language:mr', 'language:pa', 'language:ru', 'language:te', 'language:th', 'language:tl', 'language:tr', 'language:ur', 'language:vi', 'language:zh', 'license:cc-by-4.0', 'size_categories:n<1K', 'format:parquet', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'arxiv:2310.17586', 'region:us']","




	
		
		Dataset Card for ""WEATHub""
	

This dataset corresponds to the data described in the paper ""Global Voices, Local Biases: Socio-Cultural Prejudices across Languages""
accepted to EMNLP 2023.

	
		
		Dataset Summary
	

WEATHub is a dataset containing 24 languages. It contains words organized into groups of (target1, target2, attribute1, attribute2)
to measure the association target1:target2 :: attribute1:attribute2. For example target1 can be insects, target2 can be flowers. And we… See the full description on the dataset page: https://huggingface.co/datasets/iamshnoo/WEATHub.",https://huggingface.co/datasets/iamshnoo/WEATHub,"['ar', 'bn', 'ckb', 'da', 'de', 'el', 'es', 'fa', 'fr', 'hi', 'it', 'ja', 'ko', 'ku', 'mr', 'pa', 'ru', 'te', 'th', 'tl', 'tr', 'ur', 'vi', 'zh']",[],['n<1K']
shi3z/OpenOrcaJapanese,shi3z,2023-10-27 06:15:27+00:00,2023-10-28 02:50:27+00:00,18,7,"['task_categories:table-question-answering', 'language:ja', 'license:mit', 'size_categories:100K<n<1M', 'format:json', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","OpenOrcaデータセットの日本語翻訳版です
https://huggingface.co/datasets/Open-Orca/OpenOrca
現在翻訳作業が続行中で、OpenOrca全体の1/5程度の翻訳が終わった状態でひとまず公開します。商用利用可能です。
",https://huggingface.co/datasets/shi3z/OpenOrcaJapanese,['ja'],['table-question-answering'],['100K<n<1M']
yubo0306/fed_ja,yubo0306,2023-10-29 03:55:00+00:00,2023-10-29 04:26:57+00:00,6,0,"['language:ja', 'license:unknown', 'size_categories:n<1K', 'format:json', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","FEDデータセットをGoogle Cloud Translate API v2で日本語化したデータセットです．
機械翻訳のため，一部dimensionはアノテーションとの整合性が適切ではない可能性があります．
使用するdimensionには注意してください．
",https://huggingface.co/datasets/yubo0306/fed_ja,['ja'],[],['n<1K']
p1atdev/open2ch,p1atdev,2023-10-31 17:00:13+00:00,2023-11-01 01:59:51+00:00,20,12,"['task_categories:text-generation', 'task_categories:text2text-generation', 'language:ja', 'license:apache-2.0', 'size_categories:10M<n<100M', 'format:parquet', 'modality:text', 'library:datasets', 'library:dask', 'library:mlcroissant', 'library:polars', 'region:us', 'not-for-all-audiences']","
	
		
		おーぷん2ちゃんねる対話コーパス
	


	
		
		Dataset Details
	


	
		
		Dataset Description
	

おーぷん2ちゃんねる対話コーパス を Huggingface Datasets 向けに変換したものになります。

Curated by: [More Information Needed]
Language: Japanese
License: Apache-2.0


	
		
		Dataset Sources
	


Repository: https://github.com/1never/open2ch-dialogue-corpus


	
		
		Dataset Structure
	


all-corpus: livejupiter, news4vip, newsplus サブセットを連結したもの

dialogue: 対話データ (list[dict])
speaker: 話者番号。1 または 2。
content: 発言内容


board: 連結元のサブセット名… See the full description on the dataset page: https://huggingface.co/datasets/p1atdev/open2ch.",https://huggingface.co/datasets/p1atdev/open2ch,['ja'],"['text-generation', 'text2text-generation']",['10M<n<100M']
alfredplpl/genai-terminology-en-ja,alfredplpl,2023-11-01 08:01:31+00:00,2023-11-01 08:05:56+00:00,9,0,"['language:en', 'language:ja', 'license:apache-2.0', 'size_categories:n<1K', 'format:csv', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","生成AIの日英専門用語集です。正確さは保証しませんが、GPT-4などの頭に入れておくと綺麗に訳せると思います。
",https://huggingface.co/datasets/alfredplpl/genai-terminology-en-ja,"['en', 'ja']",[],['n<1K']
Trelis/openassistant-falcon,Trelis,2023-11-01 08:38:05+00:00,2023-11-01 08:46:17+00:00,23,1,"['language:en', 'language:es', 'language:ru', 'language:de', 'language:pl', 'language:th', 'language:vi', 'language:sv', 'language:bn', 'language:da', 'language:he', 'language:it', 'language:fa', 'language:sk', 'language:id', 'language:nb', 'language:el', 'language:nl', 'language:hu', 'language:eu', 'language:zh', 'language:eo', 'language:ja', 'language:ca', 'language:cs', 'language:bg', 'language:fi', 'language:pt', 'language:tr', 'language:ro', 'language:ar', 'language:uk', 'language:gl', 'language:fr', 'language:ko', 'license:apache-2.0', 'size_categories:10K<n<100K', 'format:csv', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'arxiv:2304.07327', 'region:us', 'human-feedback', 'llama-2']","
	
		
		Chat Fine-tuning Dataset - OpenAssistant Falcon
	

This dataset allows for fine-tuning chat models using '\Human:' AND '\nAssistant:' to wrap user messages.
It still uses <|endoftext|> as EOS and BOS token, as per Falcon.
Sample 
Preparation:

The dataset is cloned from TimDettmers, which itself is a subset of the Open Assistant dataset, which you can find here. This subset of the data only contains the highest-rated paths in the conversation tree, with a total of 9,846 samples.
The… See the full description on the dataset page: https://huggingface.co/datasets/Trelis/openassistant-falcon.",https://huggingface.co/datasets/Trelis/openassistant-falcon,"['en', 'es', 'ru', 'de', 'pl', 'th', 'vi', 'sv', 'bn', 'da', 'he', 'it', 'fa', 'sk', 'id', 'nb', 'el', 'nl', 'hu', 'eu', 'zh', 'eo', 'ja', 'ca', 'cs', 'bg', 'fi', 'pt', 'tr', 'ro', 'ar', 'uk', 'gl', 'fr', 'ko']",[],['10K<n<100K']
sakusakumura/dolly-14k-ines,sakusakumura,2023-11-03 12:44:16+00:00,2023-11-04 02:58:13+00:00,16,6,"['task_categories:question-answering', 'task_categories:summarization', 'language:ja', 'license:cc-by-sa-3.0', 'size_categories:10K<n<100K', 'format:parquet', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","
	
		
		dolly-14k-ines
	


	
		
		Description
	

The dolly-14k-ines dataset is derived from the databricks-dolly-15k-ja, which is a machine-translated version of the databricks/dolly-15k. The entries have been further converted to reflect the speech pattern of Ines Fujin, a character from ""Umamusume Pretty Derby."" The conversion process utilized a model specifically developed for this task, and entries that did not successfully emulate the character's textual speech style were omitted… See the full description on the dataset page: https://huggingface.co/datasets/sakusakumura/dolly-14k-ines.",https://huggingface.co/datasets/sakusakumura/dolly-14k-ines,['ja'],"['question-answering', 'summarization']",['10K<n<100K']
dreamerdeo/multispider,dreamerdeo,2023-11-07 03:39:17+00:00,2024-07-12 10:17:38+00:00,211,3,"['language:en', 'language:fr', 'language:de', 'language:vi', 'language:zh', 'language:ja', 'language:es', 'license:cc', 'size_categories:10K<n<100K', 'arxiv:2212.13492', 'region:us']","
	
		
		MultiSpider: Towards Benchmarking Multilingual Text-to-SQL Semantic Parsing
	

In this work, we present MultiSpider, a multilingual text-to-SQL dataset which covers seven languages (English, German, French, Spanish, Japanese, Chinese, and Vietnamese).
Find more details on paper and code.
Please be aware that the MultiSpider dataset is available in two versions: with_English_value and with_original_value. Our reported results are based on the with_English_value version to circumvent any… See the full description on the dataset page: https://huggingface.co/datasets/dreamerdeo/multispider.",https://huggingface.co/datasets/dreamerdeo/multispider,"['en', 'fr', 'de', 'vi', 'zh', 'ja', 'es']",[],['10K<n<100K']
hotchpotch/wikipedia-ja-20231030,hotchpotch,2023-11-07 07:04:51+00:00,2023-11-13 11:00:53+00:00,274,1,"['language:ja', 'license:cc', 'size_categories:1M<n<10M', 'format:parquet', 'modality:tabular', 'modality:text', 'library:datasets', 'library:dask', 'library:mlcroissant', 'library:polars', 'region:us']","
	
		
		Wikipedia Japanese data (20231030)
	


Source Date: 2023/10/30
Source: https://dumps.wikimedia.org/other/cirrussearch/


	
		
		License
	

CC BY-SA 4.0

	
		
		Example
	

WIP
",https://huggingface.co/datasets/hotchpotch/wikipedia-ja-20231030,['ja'],[],['1M<n<10M']
lmqg/qag_zhquad,lmqg,2023-11-07 11:24:53+00:00,2023-11-07 19:15:25+00:00,14,0,"['task_categories:text-generation', 'task_ids:language-modeling', 'multilinguality:monolingual', 'source_datasets:lmqg/qag_zhquad', 'language:ja', 'license:cc-by-sa-4.0', 'arxiv:2210.03992', 'region:us', 'question-generation']",Question & answer generation dataset based on SQuAD.,https://huggingface.co/datasets/lmqg/qag_zhquad,['ja'],['text-generation'],[]
joujiboi/japanese-anime-speech,joujiboi,2023-11-07 13:53:40+00:00,2024-09-06 18:19:39+00:00,383,133,"['task_categories:automatic-speech-recognition', 'language:ja', 'license:cc0-1.0', 'size_categories:10K<n<100K', 'format:parquet', 'modality:audio', 'modality:text', 'library:datasets', 'library:dask', 'library:mlcroissant', 'library:polars', 'region:us', 'anime', 'japanese', '日本語', 'nihongo', 'speech', 'audio-text', 'asr', 'whisper', 'voice', 'large-v3', 'ja', 'jp']","
	
		
		Japanese Anime Speech Dataset
	

日本語はこちら
japanese-anime-speech is an audio-text dataset designed for the training of automatic speech recognition models. The dataset is comprised of thousands of audio clips and their corresponding transcriptions from different visual novels.
The goal of this dataset is to increase the accuracy of automatic speech recognition models, such as OpenAI's Whisper, in accurately transcribing dialogue from anime and other similar Japanese media. This genre is… See the full description on the dataset page: https://huggingface.co/datasets/joujiboi/japanese-anime-speech.",https://huggingface.co/datasets/joujiboi/japanese-anime-speech,['ja'],['automatic-speech-recognition'],['10K<n<100K']
Nexdata/Japanese_Pronunciation_Dictionary,Nexdata,2023-11-08 08:16:14+00:00,2025-09-29 07:24:50+00:00,23,2,"['task_categories:automatic-speech-recognition', 'language:ja', 'size_categories:n<1K', 'format:imagefolder', 'modality:image', 'library:datasets', 'library:mlcroissant', 'region:us']","
	
		
		Dataset Card for Nexdata/Japanese_Pronunciation_Dictionary
	


	
		
		Description
	

This dataset is just a sample of Japanese Pronunciation Dictionary(paid dataset).The data contains 101,702 entries. All words and pronunciations are produced by Japanese linguists. It can be used in the research and development of Japanese ASR technology.
For more details & to download the rest of the dataset(paid),please refer to the link:… See the full description on the dataset page: https://huggingface.co/datasets/Nexdata/Japanese_Pronunciation_Dictionary.",https://huggingface.co/datasets/Nexdata/Japanese_Pronunciation_Dictionary,['ja'],['automatic-speech-recognition'],['n<1K']
Nexdata/English-Japanese_Parallel_Corpus_Data,Nexdata,2023-11-08 10:47:40+00:00,2025-04-23 02:57:12+00:00,20,2,"['task_categories:translation', 'language:en', 'language:ja', 'size_categories:1K<n<10K', 'format:text', 'modality:image', 'modality:text', 'library:datasets', 'library:mlcroissant', 'region:us']","
	
		
		Dataset Card for Nexdata/English-Japanese_Parallel_Corpus_Data
	


	
		
		Description
	

This dataset is just a sample of 850,000 English Japanese Parallel Corpus dataset(paid dataset).Billingual text is stored in text format. It covers multiple fields such as tourism, medical treatment, daily life, news, etc. average English sentence 23 words. The data desensitization and quality checking had been done. It can be used as a basic corpus for text data analysis in fields such as machine… See the full description on the dataset page: https://huggingface.co/datasets/Nexdata/English-Japanese_Parallel_Corpus_Data.",https://huggingface.co/datasets/Nexdata/English-Japanese_Parallel_Corpus_Data,"['en', 'ja']",['translation'],['1K<n<10K']
Nexdata/Japanese-English_Parallel_Corpus_Data,Nexdata,2023-11-08 10:50:47+00:00,2025-04-25 03:16:00+00:00,11,1,"['task_categories:translation', 'language:ja', 'region:us']","
	
		
		Dataset Card for Nexdata/Japanese-English_Parallel_Corpus_Data
	


	
		
		Description
	

This dataset is just a sample of 380,000 groups Japanese and English parallel corpus(paid dataset),excluded political, porn, personal information and other sensitive vocabulary; it can be a base corpus for text-based data analysis, used in machine translation and other fields.
For more details & to download the rest of the dataset(paid),please refer to the link:… See the full description on the dataset page: https://huggingface.co/datasets/Nexdata/Japanese-English_Parallel_Corpus_Data.",https://huggingface.co/datasets/Nexdata/Japanese-English_Parallel_Corpus_Data,['ja'],['translation'],[]
Nexdata/Chinese-Japanese_Parallel_Corpus_Data,Nexdata,2023-11-08 11:00:00+00:00,2025-04-24 02:46:27+00:00,12,1,"['task_categories:translation', 'language:ja', 'language:zh', 'size_categories:n<1K', 'format:imagefolder', 'modality:image', 'library:datasets', 'library:mlcroissant', 'region:us']","
	
		
		Dataset Card for Nexdata/Chinese-Japanese_Parallel_Corpus_Data
	


	
		
		Description
	

This dataset is just a sample of Chinese-Japanese Parallel Corpus Data(paid dataset).9.83 Million Pairs of Sentences - Chinese-Japanese Parallel Corpus Data be stored in txt format. It covers multiple fields including general, IT, news, patent, and international engine. The data desensitization and quality checking had been done. It can be used as a basic corpus for text data analysis in fields… See the full description on the dataset page: https://huggingface.co/datasets/Nexdata/Chinese-Japanese_Parallel_Corpus_Data.",https://huggingface.co/datasets/Nexdata/Chinese-Japanese_Parallel_Corpus_Data,"['ja', 'zh']",['translation'],['n<1K']
nlp4j/wikipedia,nlp4j,2023-11-09 01:39:19+00:00,2023-11-15 06:12:59+00:00,337,1,"['annotations_creators:no-annotation', 'source_datasets:original', 'language:ja', 'license:cc-by-sa-3.0', 'size_categories:10M<n<100M', 'format:parquet', 'modality:text', 'library:datasets', 'library:dask', 'library:mlcroissant', 'library:polars', 'region:us']","
	
		
		Dataset Card for ""wikipedia""
	

More Information needed
",https://huggingface.co/datasets/nlp4j/wikipedia,['ja'],[],['10M<n<100M']
shi3z/Japanese_Wikipedia_Conversation,shi3z,2023-11-10 07:36:40+00:00,2023-11-10 22:46:29+00:00,23,7,"['language:ja', 'license:cc-by-sa-4.0', 'size_categories:10K<n<100K', 'format:json', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","Wikipedia日本語版データセット(izumi-lab/wikipedia-ja-20230720)を元にGPT-3.5-Turboで会話文を生成したデータセットです
GPT-3.5-Turboを使っているため、商用利用はできません
",https://huggingface.co/datasets/shi3z/Japanese_Wikipedia_Conversation,['ja'],[],['10K<n<100K']
hltcoe/megawika-report-generation,hltcoe,2023-11-10 13:17:09+00:00,2024-01-19 13:01:58+00:00,236,6,"['task_categories:summarization', 'task_categories:text-retrieval', 'task_categories:text-generation', 'language:af', 'language:ar', 'language:az', 'language:bn', 'language:cs', 'language:de', 'language:en', 'language:es', 'language:et', 'language:fa', 'language:fi', 'language:fr', 'language:ga', 'language:gl', 'language:gu', 'language:he', 'language:hi', 'language:hr', 'language:id', 'language:it', 'language:ja', 'language:ka', 'language:kk', 'language:km', 'language:ko', 'language:lt', 'language:lv', 'language:mk', 'language:ml', 'language:mn', 'language:mr', 'language:my', 'language:ne', 'language:nl', 'language:pl', 'language:ps', 'language:pt', 'language:ro', 'language:ru', 'language:si', 'language:sl', 'language:sv', 'language:ta', 'language:th', 'language:tr', 'language:uk', 'language:ur', 'language:vi', 'language:xh', 'language:zh', 'license:cc-by-sa-4.0', 'size_categories:100K<n<1M', 'format:json', 'modality:text', 'library:datasets', 'library:dask', 'library:mlcroissant', 'library:polars', 'arxiv:2307.07049', 'region:us']","
	
		
		Dataset Card for MegaWika for Report Generation
	


	
		
		Dataset Summary
	

MegaWika is a multi- and crosslingual text dataset containing 30 million Wikipedia passages with their scraped and cleaned web citations. The passages span
50 Wikipedias in 50 languages, and the articles in which the passages were originally embedded are included for convenience. Where a Wikipedia passage is in a
non-English language, an automated English translation is provided. 
This dataset provides the… See the full description on the dataset page: https://huggingface.co/datasets/hltcoe/megawika-report-generation.",https://huggingface.co/datasets/hltcoe/megawika-report-generation,"['af', 'ar', 'az', 'bn', 'cs', 'de', 'en', 'es', 'et', 'fa', 'fi', 'fr', 'ga', 'gl', 'gu', 'he', 'hi', 'hr', 'id', 'it', 'ja', 'ka', 'kk', 'km', 'ko', 'lt', 'lv', 'mk', 'ml', 'mn', 'mr', 'my', 'ne', 'nl', 'pl', 'ps', 'pt', 'ro', 'ru', 'si', 'sl', 'sv', 'ta', 'th', 'tr', 'uk', 'ur', 'vi', 'xh', 'zh']","['summarization', 'text-retrieval', 'text-generation']",['100K<n<1M']
kunishou/oasst1-chat-44k-ja,kunishou,2023-11-12 07:53:04+00:00,2023-12-25 13:22:22+00:00,33,10,"['language:ja', 'license:apache-2.0', 'size_categories:10K<n<100K', 'format:json', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","oasst1-89k-jaをチャット形式に変換したデータセットになります。マルチターン会話でのファインチューニングをする際にご活用下さい（1レコードのトークン長が大きいのでそれなりの計算リソースが必要になります）。フォーマットは ShareGPT 形式になっています。ファインチューニングをする際はこちらの記事を参考にして下さい。
oasst1-ja-89k Repositoryhttps://github.com/kunishou/oasst1-89k-ja
OpenAssistant/oasst1https://huggingface.co/datasets/OpenAssistant/oasst1
",https://huggingface.co/datasets/kunishou/oasst1-chat-44k-ja,['ja'],[],['10K<n<100K']
tarudesu/gendec-dataset,tarudesu,2023-11-14 01:59:12+00:00,2024-03-23 16:58:27+00:00,298,2,"['task_categories:text-classification', 'language:ja', 'size_categories:10K<n<100K', 'format:csv', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'arxiv:2311.11001', 'region:us', 'code']","
	
		
		Gendec: Gender Dection from Japanese Names with Machine Learning
	

This is the official repository for the Gendec framework from the paper Gendec: Gender Dection from Japanese Names with Machine Learning, which was accepted at the ISDA'23.

	
		
		Citation Information
	

The provided dataset is only used for research purposes!
@misc{pham2023gendec,
      title={Gendec: A Machine Learning-based Framework for Gender Detection from Japanese Names}, 
      author={Duong Tien Pham and Luan… See the full description on the dataset page: https://huggingface.co/datasets/tarudesu/gendec-dataset.",https://huggingface.co/datasets/tarudesu/gendec-dataset,['ja'],['text-classification'],['10K<n<100K']
hotchpotch/wikipedia-passages-jawiki-embeddings,hotchpotch,2023-11-14 02:28:33+00:00,2024-02-26 09:56:15+00:00,447,3,"['language:ja', 'license:other', 'region:us']","wikipedia 日本語の文を、各種日本語の embeddings や faiss index へと変換したもの。

RAG用途に使える、Wikipedia 日本語の embeddings とベクトル検索用の faiss index を作った
HuggingFace Space 上のデモ
変換スクリプト


	
		
		大元のデータ
	


https://huggingface.co/datasets/singletongue/wikipedia-utils


	
		
		検索タスクでのデータ評価
	


ベクトル検索のみで、AI王クイズ第一回コンペに臨む - Q&Aタスクでの複数の日本語embeddingsの評価
OpenAIの新embeddings,text-embedding-3-smallをRAGタスクで評価する


	
		
		ライセンス
	


text-embedding-* のファイルは OpenAI のライセンスに従います。
それ以外は CC-BY-SA-4.0 です

",https://huggingface.co/datasets/hotchpotch/wikipedia-passages-jawiki-embeddings,['ja'],[],[]
lmg-anon/VNTL,lmg-anon,2023-11-15 04:14:43+00:00,2023-11-15 22:10:22+00:00,6,0,"['task_categories:translation', 'language:en', 'language:ja', 'license:apache-2.0', 'size_categories:n<1K', 'format:parquet', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us', 'not-for-all-audiences']",,https://huggingface.co/datasets/lmg-anon/VNTL,"['en', 'ja']",['translation'],['n<1K']
ai-shift/ameba_faq_search,ai-shift,2023-11-15 04:58:19+00:00,2023-12-26 02:21:58+00:00,37,6,"['task_categories:question-answering', 'language:ja', 'license:cc-by-nd-4.0', 'size_categories:1K<n<10K', 'format:csv', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","
	
		
		AMEBA Blog FAQ Search Dataset
	

This data was obtained by crawling this website.
The FAQ Data was processed to remove HTML tags and other formatting after crawling, and entries containing excessively long content were excluded.
The Query Data was generated using a Large Language Model (LLM). Please refer to the following blog for information about the generation process.

https://www.ai-shift.co.jp/techblog/3710
https://www.ai-shift.co.jp/techblog/3761


	
		
	
	
		Column description… See the full description on the dataset page: https://huggingface.co/datasets/ai-shift/ameba_faq_search.",https://huggingface.co/datasets/ai-shift/ameba_faq_search,['ja'],['question-answering'],['1K<n<10K']
m-ric/Open_Assistant_Conversation_Chains,m-ric,2023-11-16 18:35:52+00:00,2023-11-22 14:37:58+00:00,31,6,"['task_categories:text-generation', 'language:en', 'language:es', 'language:ru', 'language:de', 'language:pl', 'language:th', 'language:vi', 'language:sv', 'language:bn', 'language:da', 'language:he', 'language:it', 'language:fa', 'language:sk', 'language:id', 'language:nb', 'language:el', 'language:nl', 'language:hu', 'language:eu', 'language:zh', 'language:eo', 'language:ja', 'language:ca', 'language:cs', 'language:bg', 'language:fi', 'language:pt', 'language:tr', 'language:ro', 'language:ar', 'language:uk', 'language:gl', 'language:fr', 'language:ko', 'license:apache-2.0', 'size_categories:10K<n<100K', 'format:parquet', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us', 'human-feedback']","
	
		
		Dataset Card for Dataset Name
	


	
		
		Dataset description
	



This dataset is a reformatting of OpenAssistant Conversations (OASST1), which is

a human-generated, human-annotated assistant-style conversation corpus consisting of 161,443 messages in 35 different languages, annotated with 461,292 quality ratings, resulting in over 10,000 fully annotated conversation trees. The corpus is a product of a worldwide crowd-sourcing effort involving over 13,500 volunteers.

It was modified… See the full description on the dataset page: https://huggingface.co/datasets/m-ric/Open_Assistant_Conversation_Chains.",https://huggingface.co/datasets/m-ric/Open_Assistant_Conversation_Chains,"['en', 'es', 'ru', 'de', 'pl', 'th', 'vi', 'sv', 'bn', 'da', 'he', 'it', 'fa', 'sk', 'id', 'nb', 'el', 'nl', 'hu', 'eu', 'zh', 'eo', 'ja', 'ca', 'cs', 'bg', 'fi', 'pt', 'tr', 'ro', 'ar', 'uk', 'gl', 'fr', 'ko']",['text-generation'],['10K<n<100K']
PeterGraebner/LDNOOBW_V2,PeterGraebner,2023-11-17 16:06:07+00:00,2024-02-23 09:32:13+00:00,71,4,"['language:af', 'language:az', 'language:am', 'language:be', 'language:bg', 'language:dz', 'language:eu', 'language:my', 'language:ca', 'language:cs', 'language:cy', 'language:hr', 'language:zh', 'language:da', 'language:de', 'language:nl', 'language:el', 'language:en', 'language:eo', 'language:es', 'language:et', 'language:fa', 'language:fi', 'language:fr', 'language:gl', 'language:gd', 'language:hi', 'language:hy', 'language:hu', 'language:id', 'language:is', 'language:it', 'language:ja', 'language:ko', 'language:la', 'language:lt', 'language:lv', 'language:mi', 'language:mk', 'language:ml', 'language:ms', 'language:mt', 'language:mr', 'language:mn', 'language:no', 'language:pl', 'language:pt', 'language:ro', 'language:ru', 'language:sk', 'language:sl', 'language:sm', 'language:sq', 'language:te', 'language:ta', 'language:to', 'language:tr', 'language:uk', 'language:uz', 'language:vi', 'language:yid', 'language:zu', 'license:cc0-1.0', 'size_categories:10K<n<100K', 'format:text', 'modality:text', 'library:datasets', 'library:mlcroissant', 'region:us']","
Written with StackEdit.

	
		
		List-of-Dirty-Naughty-Obscene-and-Otherwise-Bad-Words_V2
	


This list of words is a follow-up and extension of the Shutterstock List-of-Dirty-Naughty-Obscene-and-Otherwise-Bad-Words as that list is not maintained anymore. As there are many profanity word lists around on the web (and many not maintained) their content was crabbed and joined here together (see the source list below). 
As the opinion on which words should be in such lists varies between culture… See the full description on the dataset page: https://huggingface.co/datasets/PeterGraebner/LDNOOBW_V2.",https://huggingface.co/datasets/PeterGraebner/LDNOOBW_V2,"['af', 'az', 'am', 'be', 'bg', 'dz', 'eu', 'my', 'ca', 'cs', 'cy', 'hr', 'zh', 'da', 'de', 'nl', 'el', 'en', 'eo', 'es', 'et', 'fa', 'fi', 'fr', 'gl', 'gd', 'hi', 'hy', 'hu', 'id', 'is', 'it', 'ja', 'ko', 'la', 'lt', 'lv', 'mi', 'mk', 'ml', 'ms', 'mt', 'mr', 'mn', 'no', 'pl', 'pt', 'ro', 'ru', 'sk', 'sl', 'sm', 'sq', 'te', 'ta', 'to', 'tr', 'uk', 'uz', 'vi', 'yid', 'zu']",[],['10K<n<100K']
augmxnt/shisa-pretrain-en-ja-v1,augmxnt,2023-11-19 09:48:04+00:00,2023-12-05 20:08:51+00:00,35,7,"['language:ja', 'language:en', 'license:odc-by', 'size_categories:1M<n<10M', 'format:parquet', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","This pre-training dataset was created for shisa-base-7b-v1.
It is primarily composed of a DSIR sampling of MADLAD-400 JA/EN tokens in a 90%/10% ratio.
",https://huggingface.co/datasets/augmxnt/shisa-pretrain-en-ja-v1,"['ja', 'en']",[],['1M<n<10M']
ReDUB/ComfyOpenSubtitles,ReDUB,2023-11-19 22:51:52+00:00,2023-11-20 05:03:53+00:00,14,0,"['task_categories:translation', 'language:en', 'language:ru', 'language:fr', 'language:es', 'language:ar', 'language:zh', 'language:ko', 'language:ja', 'language:de', 'license:unknown', 'size_categories:10M<n<100M', 'region:us']","
	
		
		ComfyOpenSubtitles
	


	
		
		Dataset Description
	

ComfyOpenSubtitles is a multilingual dataset that contains parallel translations of subtitles from various languages. It includes pairs of input and target languages, along with the corresponding subtitles.

	
		
		Languages
	

The dataset supports the following languages:

English (en)
Russian (ru)
French (fr)
Spanish (es)
Arabic (ar)
Simplified Chinese (zh-cn)
Korean (ko)
Japanese (ja)
German (de)


	
		
		Dataset Structure… See the full description on the dataset page: https://huggingface.co/datasets/ReDUB/ComfyOpenSubtitles.",https://huggingface.co/datasets/ReDUB/ComfyOpenSubtitles,"['en', 'ru', 'fr', 'es', 'ar', 'zh', 'ko', 'ja', 'de']",['translation'],['10M<n<100M']
ReDUB/SoundHarvest,ReDUB,2023-11-20 04:21:11+00:00,2023-12-14 22:51:51+00:00,52,2,"['task_categories:translation', 'task_categories:audio-to-audio', 'language:ar', 'language:es', 'language:fr', 'language:hi', 'language:id', 'language:ja', 'language:ko', 'language:pt', 'language:ru', 'language:th', 'language:tr', 'language:vi', 'language:en', 'license:other', 'size_categories:n<1K', 'format:text', 'modality:text', 'library:datasets', 'library:mlcroissant', 'region:us', 'speech2speech']","
	
		
		Data Format
	

The dataset is organized in the following structure:
dataset/
├── video_id_1/
│ ├── audio_language_1.wav
│ ├── audio_language_2.wav
│ ├── subtitle_language_1.vtt
│ ├── subtitle_language_2.vtt
│ └── unmatched/
│ └── ...
├── video_id_2/
│ ├── ...
└── ...

Original version with the channel (MrBeast) will contain 487 hours 27 minutes 59 seconds of audio files.

	
		
		Limitations
	


Copyright: Please be aware of copyright restrictions when using this dataset. Ensure that… See the full description on the dataset page: https://huggingface.co/datasets/ReDUB/SoundHarvest.",https://huggingface.co/datasets/ReDUB/SoundHarvest,"['ar', 'es', 'fr', 'hi', 'id', 'ja', 'ko', 'pt', 'ru', 'th', 'tr', 'vi', 'en']","['translation', 'audio-to-audio']",['n<1K']
lnwang/retrieval_qa,lnwang,2023-11-24 03:26:11+00:00,2023-12-22 07:24:23+00:00,60,6,"['language:en', 'language:zh', 'language:ja', 'language:es', 'language:de', 'language:ru', 'license:apache-2.0', 'size_categories:1K<n<10K', 'format:parquet', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us', 'art']","
	
		
		Retrieval_QA: A Simple Multilingual Benchmark For Retrieval Encoder Models
	



The purpose of this dataset is to provide a simple and easy-to-use benchmark for retrieval encoder models, which helps researchers quickly select the most effective retrieval encoder for text extraction and achieve optimal results in subsequent retrieval tasks such as retrieval-augmented-generation (RAG). The dataset contains multiple document-question pairs, where each document is a short text about the… See the full description on the dataset page: https://huggingface.co/datasets/lnwang/retrieval_qa.",https://huggingface.co/datasets/lnwang/retrieval_qa,"['en', 'zh', 'ja', 'es', 'de', 'ru']",[],['1K<n<10K']
nu-dialogue/sfcoco2021,nu-dialogue,2023-11-27 12:01:24+00:00,2023-11-28 00:29:38+00:00,6,0,"['task_categories:image-to-text', 'language:ja', 'size_categories:n<1K', 'format:parquet', 'modality:image', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']",,https://huggingface.co/datasets/nu-dialogue/sfcoco2021,['ja'],['image-to-text'],['n<1K']
nu-dialogue/sfcoco2023,nu-dialogue,2023-11-27 12:13:42+00:00,2023-11-28 08:04:13+00:00,8,0,"['task_categories:image-to-text', 'language:ja', 'size_categories:1K<n<10K', 'format:parquet', 'modality:image', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']",,https://huggingface.co/datasets/nu-dialogue/sfcoco2023,['ja'],['image-to-text'],['1K<n<10K']
nu-dialogue/sfcoco2022,nu-dialogue,2023-11-27 12:15:33+00:00,2023-11-28 00:30:10+00:00,6,0,"['task_categories:image-to-text', 'language:ja', 'size_categories:n<1K', 'format:parquet', 'modality:image', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']",,https://huggingface.co/datasets/nu-dialogue/sfcoco2022,['ja'],['image-to-text'],['n<1K']
kunishou/jp-effective-instructions,kunishou,2023-12-01 07:36:25+00:00,2023-12-01 07:52:41+00:00,18,3,"['language:ja', 'license:other', 'size_categories:1K<n<10K', 'format:json', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","oasst1-89k-ja , databricks-dolly-15k-ja , hh-rlhf-49k-ja の中から JGLUE（ JcommonsenseQA , MARC-ja , JSQuAD ）の観点で高品質なデータセットに絞り込んだデータセットです。
品質スコアリングの詳細はこちらを参考にして下さい。https://qiita.com/kunishou/items/efd9f68d6aa86d56dc73
データセットの構成とライセンスは以下の通りになります。

	
		
dataset
num records
liscence


		
oasst1-89k-ja
4,204
Apache 2.0


databricks-dolly-15k-ja
282
CC-BY-SA-3.0


hh-rlhf-49k-ja
989
MIT


	

※ ライセンスはオリジナルのデータセットのライセンスに従います。
",https://huggingface.co/datasets/kunishou/jp-effective-instructions,['ja'],[],['1K<n<10K']
MohamedRashad/multilingual-tts,MohamedRashad,2023-12-01 23:46:06+00:00,2023-12-12 21:04:06+00:00,210,38,"['task_categories:text-to-speech', 'language:ar', 'language:en', 'language:zh', 'language:es', 'language:fr', 'language:hi', 'language:ru', 'language:pt', 'language:ja', 'language:de', 'language:tr', 'language:bn', 'language:id', 'language:ur', 'language:vi', 'license:gpl-3.0', 'size_categories:10K<n<100K', 'format:parquet', 'modality:audio', 'modality:text', 'library:datasets', 'library:dask', 'library:mlcroissant', 'library:polars', 'region:us']","
	
		
		Before Anything and Everything ⚱
	

In the time of writing this Dataset Card, 17,490 18,412 civilian has been killed in Palestine (7,870 8,000 are children and 6,121 6,200 are women).
Seek any non-profit organization to help them with what you can (For myself, I use Mersal) 🇵🇸

	
		
	
	
		Dataset Description
	

The Multilingual TTS dataset is an exceptional compilation of text-to-speech (TTS) samples, meticulously crafted to showcase the richness and diversity of human languages.… See the full description on the dataset page: https://huggingface.co/datasets/MohamedRashad/multilingual-tts.",https://huggingface.co/datasets/MohamedRashad/multilingual-tts,"['ar', 'en', 'zh', 'es', 'fr', 'hi', 'ru', 'pt', 'ja', 'de', 'tr', 'bn', 'id', 'ur', 'vi']",['text-to-speech'],['10K<n<100K']
AbeShinzo0708/AbeShinzo_voicedata_for_Bert-VITS2,AbeShinzo0708,2023-12-05 10:12:30+00:00,2023-12-05 10:35:04+00:00,7,0,"['language:ja', 'license:openrail', 'size_categories:n<1K', 'format:audiofolder', 'modality:audio', 'library:datasets', 'library:mlcroissant', 'region:us', '安倍晋三', 'AbeShinzo']",,https://huggingface.co/datasets/AbeShinzo0708/AbeShinzo_voicedata_for_Bert-VITS2,['ja'],[],['n<1K']
AbeShinzo0708/SugaYosihide_voicedata_for_Bert-VITS2,AbeShinzo0708,2023-12-05 10:33:12+00:00,2023-12-05 10:34:29+00:00,10,0,"['language:ja', 'size_categories:n<1K', 'format:audiofolder', 'modality:audio', 'library:datasets', 'library:mlcroissant', 'region:us', '菅義偉', 'SugaYoshihide']",,https://huggingface.co/datasets/AbeShinzo0708/SugaYosihide_voicedata_for_Bert-VITS2,['ja'],[],['n<1K']
AbeShinzo0708/KishidaFumio_voicedata_for_Bert-VITS2,AbeShinzo0708,2023-12-05 10:35:40+00:00,2023-12-05 10:40:44+00:00,65,0,"['language:ja', 'license:openrail', 'size_categories:n<1K', 'format:audiofolder', 'modality:audio', 'library:datasets', 'library:mlcroissant', 'region:us', '岸田文雄', 'KishidaFumio']",,https://huggingface.co/datasets/AbeShinzo0708/KishidaFumio_voicedata_for_Bert-VITS2,['ja'],[],['n<1K']
ku-nlp/speech-bsd-hf,ku-nlp,2023-12-06 05:46:48+00:00,2023-12-06 09:35:10+00:00,20,6,"['task_categories:translation', 'language:ja', 'language:en', 'license:cc-by-nc-sa-4.0', 'size_categories:10K<n<100K', 'format:parquet', 'modality:audio', 'modality:text', 'library:datasets', 'library:dask', 'library:mlcroissant', 'library:polars', 'region:us']","
	
		
		SpeechBSD Dataset
	

This is an extension of the BSD corpus, a Japanese--English dialogue translation corpus, with audio files and speaker attribute information.
Although the primary intended usage is for speech-to-text translation, it can be viewed as text/speech Japanese/English/cross-language dialogue corpus and can be used for various tasks.

	
		
		Dataset Statistics
	


	
		

Train
Dev.
Test


		
Scenarios
670
69
69


Sentences
20,000
2,051
2,120


En audio (h)
20.1
2.1
2.1


Ja… See the full description on the dataset page: https://huggingface.co/datasets/ku-nlp/speech-bsd-hf.",https://huggingface.co/datasets/ku-nlp/speech-bsd-hf,"['ja', 'en']",['translation'],['10K<n<100K']
augmxnt/ultra-orca-boros-en-ja-v1,augmxnt,2023-12-06 12:55:59+00:00,2025-04-12 13:33:38+00:00,24,10,"['task_categories:text-generation', 'language:ja', 'language:en', 'license:apache-2.0', 'size_categories:100K<n<1M', 'format:parquet', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us', 'sft', 'synthetic', 'sharegpt']","EN/JA dataset used for shisa-7b-v1 - see details in that model's readme.
",https://huggingface.co/datasets/augmxnt/ultra-orca-boros-en-ja-v1,"['ja', 'en']",['text-generation'],['100K<n<1M']
hotchpotch/jaqket_v1_qa_wikija_context,hotchpotch,2023-12-07 08:36:30+00:00,2024-02-25 06:14:45+00:00,20,4,"['task_categories:question-answering', 'language:ja', 'license:cc-by-sa-4.0', 'size_categories:1K<n<10K', 'format:parquet', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","
	
		
		⚠️ ! 注意 !
	

公開したデータセットは、私の不注意で本来学習させる用途には相応しくない、JAQKET テスト用のデータセットも train に含んでしまっています。
そのため、以下のように再度テスト用のデータを分離してからの利用をお勧めします。
import datasets

ds = datasets.load_dataset(""hotchpotch/jaqket_v1_qa_wikija_context"")
train_ds = ds[""train""]  # type: ignore
valid_ds = ds[""validation""]  # type: ignore

# 大元の ""hotchpotch/jaqket_v1_qa_wikija_context"" の train / valid 分割方法がよくないので、再度分割する

train_df = train_ds.to_pandas()
valid_df = valid_ds.to_pandas()
df = pd.concat([train_df, valid_df])… See the full description on the dataset page: https://huggingface.co/datasets/hotchpotch/jaqket_v1_qa_wikija_context.",https://huggingface.co/datasets/hotchpotch/jaqket_v1_qa_wikija_context,['ja'],['question-answering'],['1K<n<10K']
oshizo/japanese-wikipedia-paragraphs,oshizo,2023-12-09 11:14:53+00:00,2023-12-09 14:09:30+00:00,15,3,"['language:ja', 'license:cc-by-sa-4.0', 'size_categories:10M<n<100M', 'format:parquet', 'modality:tabular', 'modality:text', 'library:datasets', 'library:dask', 'library:mlcroissant', 'library:polars', 'region:us']","A slightly modified version of the parsing and chunking method for singletongue/wikipedia-utils.
Pre-processing was performed using oshizo/wikipedia-utils, which is a fork of the original repository, singletongue/wikipedia-utils.
The Wikipedia data was crawled between 2023/12/5 and 2023/12/8.
",https://huggingface.co/datasets/oshizo/japanese-wikipedia-paragraphs,['ja'],[],['10M<n<100M']
oshizo/japanese-wikipedia-paragraphs-embeddings,oshizo,2023-12-10 03:41:14+00:00,2023-12-15 13:16:42+00:00,6,0,"['language:ja', 'license:cc-by-sa-4.0', 'region:us']","The following data set was vectorized with the intfloat/multilingual-e5-base model and an index file created by faiss.
oshizo/japanese-wikipedia-paragraphs

	
		
		Usage
	

First, download index_me5-base_IVF2048_PQ192.faiss from this repository.
import faiss
import datasets
from sentence_transformers import SentenceTransformer

ds = datasets.load_dataset(""oshizo/japanese-wikipedia-paragraphs"", split=""train"")

index = faiss.read_index(""./index_me5-base_IVF2048_PQ192.faiss"")

model =… See the full description on the dataset page: https://huggingface.co/datasets/oshizo/japanese-wikipedia-paragraphs-embeddings.",https://huggingface.co/datasets/oshizo/japanese-wikipedia-paragraphs-embeddings,['ja'],[],[]
textdetox/multilingual_toxic_lexicon,textdetox,2023-12-12 09:26:27+00:00,2025-03-21 18:40:43+00:00,125,3,"['task_categories:token-classification', 'language:en', 'language:ru', 'language:uk', 'language:es', 'language:de', 'language:ar', 'language:am', 'language:hi', 'language:zh', 'language:it', 'language:fr', 'language:he', 'language:ja', 'language:tt', 'license:openrail++', 'size_categories:100K<n<1M', 'format:parquet', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'arxiv:2108.03070', 'region:us', 'toxic']","
	
		
		Multilingual Toxic Lexicon
	

[2025] The lexicon is extended to new languages! Now also included: Italian, French, Hebrew, Hindi, Japanese, Tatar. The list is used on TextDetox 2025 shared task.
[2024] The compilation for 9 languages (English, Russian, Ukrainian, Spanish, German, Amharic, Arabic, Chinese, Hindi) toxic words lists which is used for TextDetox 2024 shared task.
The list of original sources:

English: link
Russian: link
Ukrainian: link
Spanish: link
German: link
Amhairc:… See the full description on the dataset page: https://huggingface.co/datasets/textdetox/multilingual_toxic_lexicon.",https://huggingface.co/datasets/textdetox/multilingual_toxic_lexicon,"['en', 'ru', 'uk', 'es', 'de', 'ar', 'am', 'hi', 'zh', 'it', 'fr', 'he', 'ja', 'tt']",['token-classification'],['100K<n<1M']
tellarin-ai/llm-japanese-dataset-vanilla-aya-format,tellarin-ai,2023-12-15 13:03:17+00:00,2024-01-31 14:27:56+00:00,26,1,"['language:ja', 'license:cc-by-sa-4.0', 'size_categories:1M<n<10M', 'format:json', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'arxiv:2309.03412', 'region:us']","
	
		
		Dataset Card for llm-japanese-dataset-vanilla in the Aya format
	

This dataset is a format conversion from its original v1.0.0 format and released here under the same CC-BY-SA 4.0 license and conditions.
It contains Japanese instruction-like data intended for LLM construction/tuning.
The dataset only contains a 'train' split, with ~2.46M rows of data.
Thanks Jian Wu (@wujian123) for the help in converting and validating the dataset.

	
		
	
	
		Citation
	

If you utilize this dataset… See the full description on the dataset page: https://huggingface.co/datasets/tellarin-ai/llm-japanese-dataset-vanilla-aya-format.",https://huggingface.co/datasets/tellarin-ai/llm-japanese-dataset-vanilla-aya-format,['ja'],[],['1M<n<10M']
p1atdev/ja-stackoverflow,p1atdev,2023-12-16 02:41:12+00:00,2023-12-21 05:30:24+00:00,26,8,"['task_categories:text-generation', 'task_categories:question-answering', 'language:ja', 'license:cc-by-sa-4.0', 'size_categories:10K<n<100K', 'format:parquet', 'modality:tabular', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us', 'stackoverflow', 'programming']","
	
		
		ja-stackoverflow
	

日本語版 Stack Overflow の スタック・オーバーフロー のデータダンプ をもとにデータを加工し、質問文と回答文のペアになるように調整した QA データセット。

	
		
		データ構造
	

投稿本文は html2text を使ってマークダウン化されています。その際、

コードブロックは ``` で囲まれるように変更されています。
画像 URL に base64 エンコードされた画像が含まれる場合、 [unk] に置き換えています。


	
		
		default サブセット
	


id: 質問投稿の ID
question: 質問投稿
answers: 質問に対する回答投稿のリスト
accepted_answer_id: 質問者に選ばれた回答のID。null の可能性がある
popular_answer_id: もっともスコアが高かった回答のID。null の可能性がある


	
		
		simple サブセット
	

default サブセットから、 question と answers… See the full description on the dataset page: https://huggingface.co/datasets/p1atdev/ja-stackoverflow.",https://huggingface.co/datasets/p1atdev/ja-stackoverflow,['ja'],"['text-generation', 'question-answering']",['10K<n<100K']
p1atdev/japanese-stackexchange,p1atdev,2023-12-16 03:14:00+00:00,2023-12-21 05:30:37+00:00,32,3,"['task_categories:text-generation', 'task_categories:question-answering', 'language:en', 'language:ja', 'license:cc-by-sa-4.0', 'size_categories:10K<n<100K', 'format:parquet', 'modality:tabular', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us', 'stackexchange']","
	
		
		japanese-stackexchange
	

英語による日本語に関する質問ができる Japanese Stack Exchange のデータダンプ をもとにデータを加工し、質問文と回答文のペアになるように調整した QA データセット。
日本語翻訳された StackExchange ではないです。

	
		
		データ構造
	

投稿本文は html2text を使ってマークダウン化されています。その際、

コードブロックは ``` で囲まれるように変更されています。
画像 URL に base64 エンコードされた画像が含まれる場合、 [unk] に置き換えています。


	
		
		default サブセット
	


id: 質問投稿の ID
question: 質問投稿
answers: 質問に対する回答投稿のリスト
accepted_answer_id: 質問者に選ばれた回答のID。null の可能性がある
popular_answer_id: もっともスコアが高かった回答のID。null の可能性がある


	
		
		simple サブセット… See the full description on the dataset page: https://huggingface.co/datasets/p1atdev/japanese-stackexchange.",https://huggingface.co/datasets/p1atdev/japanese-stackexchange,"['en', 'ja']","['text-generation', 'question-answering']",['10K<n<100K']
p1atdev/novecomi-novel-metadata,p1atdev,2023-12-16 08:48:49+00:00,2023-12-16 08:57:17+00:00,9,1,"['language:ja', 'license:cc0-1.0', 'size_categories:n<1K', 'format:parquet', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","
	
		
		novecomi-novel-metadata
	

https://dengekibunko.jp/novecomi/novel/ からスクレイピング。 (本文なし)
",https://huggingface.co/datasets/p1atdev/novecomi-novel-metadata,['ja'],[],['n<1K']
styletts2-community/multilingual-pl-bert,styletts2-community,2023-12-17 05:03:40+00:00,2024-01-08 04:30:44+00:00,1515,17,"['language:af', 'language:an', 'language:ar', 'language:az', 'language:ba', 'language:be', 'language:bg', 'language:bn', 'language:bpy', 'language:bs', 'language:ca', 'language:cs', 'language:cy', 'language:da', 'language:de', 'language:el', 'language:es', 'language:et', 'language:eu', 'language:fi', 'language:fr', 'language:gu', 'language:hak', 'language:he', 'language:hi', 'language:hr', 'language:hu', 'language:hy', 'language:hyw', 'language:id', 'language:io', 'language:is', 'language:it', 'language:ja', 'language:ka', 'language:kk', 'language:kn', 'language:ko', 'language:la', 'language:lb', 'language:lt', 'language:lv', 'language:mk', 'language:ml', 'language:mr', 'language:ms', 'language:ne', 'language:nl', 'language:no', 'language:pa', 'language:pl', 'language:pt', 'language:ro', 'language:ru', 'language:sk', 'language:sl', 'language:sq', 'language:sr', 'language:sv', 'language:sw', 'language:ta', 'language:te', 'language:th', 'language:tr', 'language:tt', 'language:ur', 'language:uz', 'language:vi', 'language:zh', 'license:cc-by-4.0', 'size_categories:100K<n<1M', 'format:arrow', 'modality:text', 'library:datasets', 'library:mlcroissant', 'region:us']","Attribution: Wikipedia.org
",https://huggingface.co/datasets/styletts2-community/multilingual-pl-bert,"['af', 'an', 'ar', 'az', 'ba', 'be', 'bg', 'bn', 'bpy', 'bs', 'ca', 'cs', 'cy', 'da', 'de', 'el', 'es', 'et', 'eu', 'fi', 'fr', 'gu', 'hak', 'he', 'hi', 'hr', 'hu', 'hy', 'hyw', 'id', 'io', 'is', 'it', 'ja', 'ka', 'kk', 'kn', 'ko', 'la', 'lb', 'lt', 'lv', 'mk', 'ml', 'mr', 'ms', 'ne', 'nl', 'no', 'pa', 'pl', 'pt', 'ro', 'ru', 'sk', 'sl', 'sq', 'sr', 'sv', 'sw', 'ta', 'te', 'th', 'tr', 'tt', 'ur', 'uz', 'vi', 'zh']",[],['100K<n<1M']
recruit-jp/japanese-image-classification-evaluation-dataset,recruit-jp,2023-12-19 09:17:24+00:00,2024-01-22 10:48:13+00:00,68,7,"['task_categories:image-classification', 'language:ja', 'license:cc-by-4.0', 'size_categories:1K<n<10K', 'format:csv', 'modality:image', 'modality:text', 'library:datasets', 'library:dask', 'library:mlcroissant', 'library:polars', 'region:us']","
	
		
		recruit-jp/japanese-image-classification-evaluation-dataset
	


	
		
		Overview
	


Developed by: Recruit Co., Ltd.
Dataset type: Image Classification
Language(s): Japanese
LICENSE: CC-BY-4.0

More details are described in our tech blog post.

日本語CLIP学習済みモデルとその評価用データセットの公開


	
		
	
	
		Dataset Details
	

This dataset is comprised of four image classification tasks related to concepts and things unique to Japan. Specifically, is consists of the following tasks.

jafood101: Image… See the full description on the dataset page: https://huggingface.co/datasets/recruit-jp/japanese-image-classification-evaluation-dataset.",https://huggingface.co/datasets/recruit-jp/japanese-image-classification-evaluation-dataset,['ja'],['image-classification'],['1K<n<10K']
miracl/nomiracl,miracl,2023-12-19 22:24:46+00:00,2024-11-23 19:30:15+00:00,127,12,"['task_categories:text-classification', 'annotations_creators:expert-generated', 'multilinguality:multilingual', 'source_datasets:miracl/miracl', 'language:ar', 'language:bn', 'language:en', 'language:es', 'language:fa', 'language:fi', 'language:fr', 'language:hi', 'language:id', 'language:ja', 'language:ko', 'language:ru', 'language:sw', 'language:te', 'language:th', 'language:zh', 'license:apache-2.0', 'size_categories:10K<n<100K', 'region:us']",Data Loader for the NoMIRACL dataset.,https://huggingface.co/datasets/miracl/nomiracl,"['ar', 'bn', 'en', 'es', 'fa', 'fi', 'fr', 'hi', 'id', 'ja', 'ko', 'ru', 'sw', 'te', 'th', 'zh']",['text-classification'],['10K<n<100K']
tellarin-ai/ntx_llm_instructions,tellarin-ai,2023-12-20 12:12:39+00:00,2023-12-20 14:58:24+00:00,45,0,"['task_categories:token-classification', 'language:ar', 'language:de', 'language:en', 'language:es', 'language:fr', 'language:hi', 'language:it', 'language:ja', 'language:ko', 'language:nl', 'language:pt', 'language:sv', 'language:tr', 'language:zh', 'license:cc-by-sa-4.0', 'size_categories:1K<n<10K', 'format:json', 'modality:text', 'library:datasets', 'library:dask', 'library:mlcroissant', 'library:polars', 'arxiv:2303.18103', 'region:us']","
	
		
		Dataset Card for NTX v1 in the Aya format
	

This dataset is a format conversion from its original v1 format into the Aya instruction format and it's released here under the CC-BY-SA 4.0 license and conditions.
It contains data in multiple languages and this version is intended for multi-lingual LLM construction/tuning.

	
		
		Citation
	

If you utilize this dataset version, feel free to cite/footnote this huggingface dataset repo, but please also cite the original dataset… See the full description on the dataset page: https://huggingface.co/datasets/tellarin-ai/ntx_llm_instructions.",https://huggingface.co/datasets/tellarin-ai/ntx_llm_instructions,"['ar', 'de', 'en', 'es', 'fr', 'hi', 'it', 'ja', 'ko', 'nl', 'pt', 'sv', 'tr', 'zh']",['token-classification'],['1K<n<10K']
tellarin-ai/ntx_llm_inst_japanese,tellarin-ai,2023-12-20 15:16:59+00:00,2023-12-20 15:17:41+00:00,10,0,"['task_categories:token-classification', 'language:ja', 'license:cc-by-sa-4.0', 'size_categories:n<1K', 'format:json', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'arxiv:2303.18103', 'region:us']","
	
		
		Dataset Card for NTX v1 in the Aya format - Japanese subset
	

This dataset is a format conversion for the Japanese data from the original NTX into the Aya instruction format and it's released here under the CC-BY-SA 4.0 license.

	
		
		Dataset Details
	

For the original NTX dataset, the conversion to the Aya instructions format, or more details, please refer to the full dataset in instruction form (https://huggingface.co/datasets/tellarin-ai/ntx_llm_instructions) or to the paper… See the full description on the dataset page: https://huggingface.co/datasets/tellarin-ai/ntx_llm_inst_japanese.",https://huggingface.co/datasets/tellarin-ai/ntx_llm_inst_japanese,['ja'],['token-classification'],['n<1K']
MakiAi/Tokama_Club_QA,MakiAi,2023-12-20 15:37:51+00:00,2023-12-20 15:46:02+00:00,14,0,"['task_categories:question-answering', 'language:ja', 'license:mit', 'size_categories:n<1K', 'region:us', 'music']","
	
		
		東方トカマクラブ データセット
	


	
		
		概要
	

このデータセットは、東方Projectのトカマクラブに関する情報を収集したものです。主にキャラクターに関する質問と回答を含んでいます。

	
		
		データセットの構造
	

データはCSVファイルに格納されており、以下のカラムで構成されています:

Q: 質問のテキスト
A: 回答のテキスト


	
		
		使用例
	

このデータセットは、チャットボットや質問応答システム、機械学習モデルのトレーニングに使用することができます。
",https://huggingface.co/datasets/MakiAi/Tokama_Club_QA,['ja'],['question-answering'],['n<1K']
davanstrien/ml-kge,davanstrien,2023-12-21 12:06:12+00:00,2023-12-21 12:24:14+00:00,15,0,"['language:en', 'language:ar', 'language:de', 'language:es', 'language:fr', 'language:it', 'language:ja', 'language:ko', 'language:ru', 'language:zh', 'license:cc-by-sa-4.0', 'size_categories:10K<n<100K', 'format:json', 'modality:text', 'library:datasets', 'library:dask', 'library:mlcroissant', 'arxiv:2311.15781', 'region:us', 'knowledge-graphs']","
	
		
		MKGE: Multilingual Knowledge Graph Enhancement
	

note this dataset card was copied from this GitHub Repository
Task Description |
WikiKGE-10 |
Evaluation |
Paper |
Citation |
License
Recent work in Natural Language Processing and Computer Vision has been leveraging textual information -- e.g., entity names and descriptions -- available in knowledge graphs to ground neural models to high-quality structured data.
However, when it comes to non-English languages, both quantity and quality… See the full description on the dataset page: https://huggingface.co/datasets/davanstrien/ml-kge.",https://huggingface.co/datasets/davanstrien/ml-kge,"['en', 'ar', 'de', 'es', 'fr', 'it', 'ja', 'ko', 'ru', 'zh']",[],['10K<n<100K']
yusuke1997/mCSQA,yusuke1997,2023-12-22 02:18:49+00:00,2024-08-26 05:19:38+00:00,555,3,"['task_categories:question-answering', 'task_categories:multiple-choice', 'language:en', 'language:ja', 'language:zh', 'language:de', 'language:fr', 'language:pt', 'language:nl', 'language:ru', 'license:other', 'size_categories:100K<n<1M', 'format:parquet', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'arxiv:2406.04215', 'region:us']","
	
		
		Dataset Card for Multilingual CommonsenseQA (mCSQA)
	



This dataset expands CommonsenseQA to eight languages from scratch using the same approach with LLMs and humans.

	
		
		Abstract
	

From mCSQA: Multilingual Commonsense Reasoning Dataset with Unified Creation Strategy by Language Models and Humans (Findings of ACL2024)

It is very challenging to curate a dataset for language-specific knowledge and common sense in order to evaluate natural language understanding capabilities of… See the full description on the dataset page: https://huggingface.co/datasets/yusuke1997/mCSQA.",https://huggingface.co/datasets/yusuke1997/mCSQA,"['en', 'ja', 'zh', 'de', 'fr', 'pt', 'nl', 'ru']","['question-answering', 'multiple-choice']",['100K<n<1M']
OpenAssistant/oasst2,OpenAssistant,2023-12-24 09:53:24+00:00,2024-01-11 06:09:29+00:00,1551,275,"['language:en', 'language:es', 'language:ru', 'language:de', 'language:pl', 'language:th', 'language:vi', 'language:sv', 'language:bn', 'language:da', 'language:he', 'language:it', 'language:fa', 'language:sk', 'language:id', 'language:nb', 'language:el', 'language:nl', 'language:hu', 'language:eu', 'language:zh', 'language:eo', 'language:ja', 'language:ca', 'language:cs', 'language:bg', 'language:fi', 'language:pt', 'language:tr', 'language:ro', 'language:ar', 'language:uk', 'language:gl', 'language:fr', 'language:ko', 'license:apache-2.0', 'size_categories:100K<n<1M', 'format:parquet', 'modality:tabular', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'arxiv:2304.07327', 'region:us', 'human-feedback']","
	
		
		Open Assistant Conversations Dataset Release 2 (OASST2)
	


	
		
		Dataset Structure
	

This dataset contains message trees. Each message tree has an initial prompt message as the root node, 
which can have multiple child messages as replies, and these child messages can have multiple replies. 
All messages have a role property: this can either be ""assistant"" or ""prompter"". The roles in 
conversation threads from prompt to leaf node strictly alternate between ""prompter"" and… See the full description on the dataset page: https://huggingface.co/datasets/OpenAssistant/oasst2.",https://huggingface.co/datasets/OpenAssistant/oasst2,"['en', 'es', 'ru', 'de', 'pl', 'th', 'vi', 'sv', 'bn', 'da', 'he', 'it', 'fa', 'sk', 'id', 'nb', 'el', 'nl', 'hu', 'eu', 'zh', 'eo', 'ja', 'ca', 'cs', 'bg', 'fi', 'pt', 'tr', 'ro', 'ar', 'uk', 'gl', 'fr', 'ko']",[],['100K<n<1M']
bclavie/mmarco-japanese-hard-negatives,bclavie,2023-12-24 13:04:26+00:00,2023-12-24 18:52:04+00:00,468,6,"['task_categories:text-retrieval', 'language:ja', 'size_categories:100K<n<1M', 'format:parquet', 'modality:text', 'library:datasets', 'library:dask', 'library:mlcroissant', 'library:polars', 'region:us']","[Under Construction]
This is a repository containing all the queries from the Japanese part of the MMarco dataset, the multilingual version of the MSMarco dataset.
For each query, there are matching hard negatives:

25 of them retrieved by the multilingual e5 base model.
Up to 10 of them retrieved by the basic implementation of BM25 from Japanese in the Anserini library.

",https://huggingface.co/datasets/bclavie/mmarco-japanese-hard-negatives,['ja'],['text-retrieval'],['100K<n<1M']
kunishou/oasst2-135k-ja,kunishou,2023-12-24 22:04:54+00:00,2023-12-25 13:23:55+00:00,23,12,"['language:ja', 'license:apache-2.0', 'size_categories:100K<n<1M', 'format:json', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","Update:  

2023/12/25oasst2-135k-jaをチャット形式に変換したoasst2-chat-68k-jaを公開しました。

This dataset was created by automatically translating ""OpenAssistant/oasst2"" into Japanese by DeepL. 
""OpenAssistant/oasst2"" を DeepL翻訳を用いて日本語に自動翻訳したデータセットになります。
以下のコードを用いることで、 Instruction と Output （prompterの命令とassistantの回答）の形式に変換することができます。
ファインチューニングで使用する場合はこちらのコードで変換して下さい（変換には5分程度かかります）。
変換コード参考https://github.com/h2oai/h2o-llmstudio/blob/5ebfd3879e226b4e1afd0a0b45eb632e60412129/app_utils/utils.py#L1888
pip install… See the full description on the dataset page: https://huggingface.co/datasets/kunishou/oasst2-135k-ja.",https://huggingface.co/datasets/kunishou/oasst2-135k-ja,['ja'],[],['100K<n<1M']
kunishou/oasst2-chat-68k-ja,kunishou,2023-12-25 13:19:09+00:00,2023-12-25 13:21:58+00:00,22,8,"['language:ja', 'license:apache-2.0', 'size_categories:10K<n<100K', 'format:json', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","oasst2-135k-jaをチャット形式に変換したデータセットになります。マルチターン会話でのファインチューニングをする際にご活用下さい（1レコードのトークン長が大きいのでそれなりの計算リソースが必要になります）。フォーマットは ShareGPT 形式になっています。ファインチューニングをする際はこちらの記事を参考にして下さい。
OpenAssistant/oasst2https://huggingface.co/datasets/OpenAssistant/oasst2
",https://huggingface.co/datasets/kunishou/oasst2-chat-68k-ja,['ja'],[],['10K<n<100K']
yongtae-jp/orca_dpo_pairs_ja,yongtae-jp,2023-12-31 04:18:18+00:00,2024-01-09 07:51:36+00:00,15,6,"['task_categories:text-generation', 'language:ja', 'license:apache-2.0', 'size_categories:10K<n<100K', 'format:parquet', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","
	
		
		About this dataset
	

This dataset is a machine translation of the Intel/orca_dpo_pairs dataset with Palm 2 (prompt for translation is pasted below).
I hope this dataset can be used for LLM developers, especially Japanese LLM developers.

	
		
		Lisence
	

The license is apache-2.0, which follows the will of the original dataset (Intel/orca_dpo_pairs).

	
		
		Prompt for translation
	

We use text-bison-32k@002 for translation. The rough Python code for translation is below.
model =… See the full description on the dataset page: https://huggingface.co/datasets/yongtae-jp/orca_dpo_pairs_ja.",https://huggingface.co/datasets/yongtae-jp/orca_dpo_pairs_ja,['ja'],['text-generation'],['10K<n<100K']
matsuxr/JaGovFaqs-22k,matsuxr,2023-12-31 13:58:41+00:00,2024-02-29 02:51:20+00:00,162,29,"['task_categories:question-answering', 'language:ja', 'license:cc-by-4.0', 'size_categories:10K<n<100K', 'format:json', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us', 'legal']","
	
		
		このデータセットについて
	

このデータは、日本の官公庁のWebサイトに掲載されている「よくある質問」を手作業で抽出し、インストラクション用のデータセットとしたものです。
日本の官公庁のWebサイトは多くが「政府標準利用規約（第2.0版）」に準拠しており、この規約はCC-BY-4.0（国際）と互換性があると記述されています。
参考 https://www.digital.go.jp/copyright-policy
したがって本データセットの著作権者はデータセットのcopyrightに記載された各官公庁であり、ライセンスもCC-BY-4.0（国際）です。データセット製作者は著作権を主張しません。

	
		
		特徴
	


質問と回答の形式になっています。
国家公務員によるチェックを経ているので、誤字脱字がほぼありません。もしあったら、このデータセット製作者（松xR）のミスに起因するものです。御指摘いただければ修正いたします。
論旨も明快で、日本語として品質の高いデータセットであると考えています。… See the full description on the dataset page: https://huggingface.co/datasets/matsuxr/JaGovFaqs-22k.",https://huggingface.co/datasets/matsuxr/JaGovFaqs-22k,['ja'],['question-answering'],['10K<n<100K']
CausalLM/GPT-4-Self-Instruct-Japanese,CausalLM,2024-01-01 07:38:56+00:00,2025-02-11 14:16:43+00:00,18,15,"['language:ja', 'license:cc-by-4.0', 'size_categories:1K<n<10K', 'format:json', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us', 'gpt4']","Here we share a Japanese dataset synthesized using the OpenAI GPT-4 model with Self-Instruct, utilizing some excess Azure credits. Please feel free to use it. All questions and answers are newly generated by GPT-4, without specialized verification, only simple filtering and strict semantic similarity control have been applied.
We hope that this will be helpful for fine-tuning open-source models for non-English languages, particularly Japanese. This dataset will be updated continuously.
",https://huggingface.co/datasets/CausalLM/GPT-4-Self-Instruct-Japanese,['ja'],[],['1K<n<10K']
blancsw/oasst2_top1_chat_format,blancsw,2024-01-02 08:48:25+00:00,2024-01-23 09:36:49+00:00,29,12,"['language:en', 'language:es', 'language:ru', 'language:de', 'language:pl', 'language:th', 'language:vi', 'language:sv', 'language:bn', 'language:da', 'language:he', 'language:it', 'language:fa', 'language:sk', 'language:id', 'language:nb', 'language:el', 'language:nl', 'language:hu', 'language:eu', 'language:zh', 'language:eo', 'language:ja', 'language:ca', 'language:cs', 'language:bg', 'language:fi', 'language:pt', 'language:tr', 'language:ro', 'language:ar', 'language:uk', 'language:gl', 'language:fr', 'language:ko', 'license:apache-2.0', 'size_categories:10K<n<100K', 'format:parquet', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us', 'human-feedback', 'sft']","
	
		
		OpenAssistant TOP-1 Conversation Threads in huggingface chat format
	

Export of oasst2 only top 1 threads in huggingface chat format

	
		
		Script
	

The convert script can be find here
",https://huggingface.co/datasets/blancsw/oasst2_top1_chat_format,"['en', 'es', 'ru', 'de', 'pl', 'th', 'vi', 'sv', 'bn', 'da', 'he', 'it', 'fa', 'sk', 'id', 'nb', 'el', 'nl', 'hu', 'eu', 'zh', 'eo', 'ja', 'ca', 'cs', 'bg', 'fi', 'pt', 'tr', 'ro', 'ar', 'uk', 'gl', 'fr', 'ko']",[],['10K<n<100K']
Trelis/openassistant-deepseek-coder,Trelis,2024-01-02 16:37:32+00:00,2024-01-03 00:16:11+00:00,66,9,"['language:en', 'language:es', 'language:ru', 'language:de', 'language:pl', 'language:th', 'language:vi', 'language:sv', 'language:bn', 'language:da', 'language:he', 'language:it', 'language:fa', 'language:sk', 'language:id', 'language:nb', 'language:el', 'language:nl', 'language:hu', 'language:eu', 'language:zh', 'language:eo', 'language:ja', 'language:ca', 'language:cs', 'language:bg', 'language:fi', 'language:pt', 'language:tr', 'language:ro', 'language:ar', 'language:uk', 'language:gl', 'language:fr', 'language:ko', 'license:apache-2.0', 'size_categories:10K<n<100K', 'format:csv', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'arxiv:2304.07327', 'region:us', 'human-feedback', 'deepseek coder']","
	
		
		Chat Fine-tuning Dataset - OpenAssistant DeepSeek Coder
	

This dataset allows for fine-tuning chat models using:
B_INST = '\n### Instruction:\n'
E_INST = '\n### Response:\n'
BOS = '<｜begin▁of▁sentence｜>'
EOS = '\n<|EOT|>\n'

Sample Preparation:

The dataset is cloned from TimDettmers, which itself is a subset of the Open Assistant dataset, which you can find here. This subset of the data only contains the highest-rated paths in the conversation tree, with a total of 9,846 samples.
The… See the full description on the dataset page: https://huggingface.co/datasets/Trelis/openassistant-deepseek-coder.",https://huggingface.co/datasets/Trelis/openassistant-deepseek-coder,"['en', 'es', 'ru', 'de', 'pl', 'th', 'vi', 'sv', 'bn', 'da', 'he', 'it', 'fa', 'sk', 'id', 'nb', 'el', 'nl', 'hu', 'eu', 'zh', 'eo', 'ja', 'ca', 'cs', 'bg', 'fi', 'pt', 'tr', 'ro', 'ar', 'uk', 'gl', 'fr', 'ko']",[],['10K<n<100K']
Lazycuber/Evol-instruct-merge,Lazycuber,2024-01-03 14:24:17+00:00,2024-01-03 15:31:38+00:00,21,1,"['language:ja', 'language:zh', 'language:en', 'size_categories:100K<n<1M', 'format:json', 'modality:text', 'library:datasets', 'library:dask', 'library:mlcroissant', 'region:us']","just merging a few evol instruct datasets the pros made
",https://huggingface.co/datasets/Lazycuber/Evol-instruct-merge,"['ja', 'zh', 'en']",[],['100K<n<1M']
Zhadix/Mima,Zhadix,2024-01-04 01:09:16+00:00,2024-01-04 01:19:49+00:00,19,1,"['language:ja', 'language:en', 'size_categories:n<1K', 'format:imagefolder', 'modality:audio', 'modality:image', 'library:datasets', 'library:mlcroissant', 'region:us', 'music', 'art']",,https://huggingface.co/datasets/Zhadix/Mima,"['ja', 'en']",[],['n<1K']
nyanko7/danbooru2023,nyanko7,2024-01-04 13:28:13+00:00,2024-05-22 18:43:24+00:00,8165,271,"['task_categories:image-classification', 'task_categories:image-to-image', 'task_categories:text-to-image', 'language:en', 'language:ja', 'license:mit', 'size_categories:1M<n<10M', 'region:us']","


	
		
		Danbooru2023: A Large-Scale Crowdsourced and Tagged Anime Illustration Dataset
	



Danbooru2023 is a large-scale anime image dataset with over 5 million images contributed and annotated in detail by an enthusiast community. Image tags cover aspects like characters, scenes, copyrights, artists, etc with an average of 30 tags per image.
Danbooru is a veteran anime image board with high-quality images and extensive tag metadata. The dataset can be used to train image classification… See the full description on the dataset page: https://huggingface.co/datasets/nyanko7/danbooru2023.",https://huggingface.co/datasets/nyanko7/danbooru2023,"['en', 'ja']","['image-classification', 'image-to-image', 'text-to-image']",['1M<n<10M']
erfanzar/LinguaMatic-Mixin,erfanzar,2024-01-05 11:07:52+00:00,2024-01-06 10:27:27+00:00,13,0,"['task_categories:text-generation', 'task_categories:text-classification', 'language:en', 'language:es', 'language:ru', 'language:de', 'language:pl', 'language:th', 'language:vi', 'language:sv', 'language:bn', 'language:da', 'language:he', 'language:it', 'language:fa', 'language:sk', 'language:id', 'language:nb', 'language:el', 'language:nl', 'language:hu', 'language:eu', 'language:zh', 'language:eo', 'language:ja', 'language:ca', 'language:cs', 'language:bg', 'language:fi', 'language:pt', 'language:tr', 'language:ro', 'language:ar', 'language:uk', 'language:gl', 'language:fr', 'language:ko', 'size_categories:10K<n<100K', 'format:parquet', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us', 'code', 'biology', 'medical']","
	
		
		Dataset Card for ""UltraChat-Mixin""
	


	
		
		UltraChat-Mixin Dataset
	


	
		
		Overview
	

llama 2 prompted style frin 

	
		
		ChatMatic
	

ChatMatic Dataset is built with mix of 4 other dataset and which carefully chosing best one from each one of them with using GPT-4 and contains System messages Dialogs and conv_depth more than 5 with higher sequence lengths Used datasets are:
""oasst2""
""ise-uiuc/Magicoder-Evol-Instruct-110K""
""vicgalle/alpaca-gpt4""
""LDJnr/Capybara""

	
		
		Dataset… See the full description on the dataset page: https://huggingface.co/datasets/erfanzar/LinguaMatic-Mixin.",https://huggingface.co/datasets/erfanzar/LinguaMatic-Mixin,"['en', 'es', 'ru', 'de', 'pl', 'th', 'vi', 'sv', 'bn', 'da', 'he', 'it', 'fa', 'sk', 'id', 'nb', 'el', 'nl', 'hu', 'eu', 'zh', 'eo', 'ja', 'ca', 'cs', 'bg', 'fi', 'pt', 'tr', 'ro', 'ar', 'uk', 'gl', 'fr', 'ko']","['text-generation', 'text-classification']",['10K<n<100K']
erfanzar/UltraChat-Matic,erfanzar,2024-01-05 11:17:28+00:00,2024-01-06 10:23:35+00:00,31,7,"['task_categories:text-generation', 'task_categories:text-classification', 'language:en', 'language:es', 'language:ru', 'language:de', 'language:pl', 'language:th', 'language:vi', 'language:sv', 'language:bn', 'language:da', 'language:he', 'language:it', 'language:fa', 'language:sk', 'language:id', 'language:nb', 'language:el', 'language:nl', 'language:hu', 'language:eu', 'language:zh', 'language:eo', 'language:ja', 'language:ca', 'language:cs', 'language:bg', 'language:fi', 'language:pt', 'language:tr', 'language:ro', 'language:ar', 'language:uk', 'language:gl', 'language:fr', 'language:ko', 'size_categories:100K<n<1M', 'format:parquet', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us', 'code', 'biology', 'medical']","
	
		
		ChatMatic
	


	
		
		with Over 80,000 multi-turn examples.
	

UltraChat-Matic Dataset is built with mix of 4 other dataset and which carefully chosing best one from each one of them with using GPT-4
and contains 
System messages Dialogs and conv_depth more than 5 with higher sequence lengths
Used datasets are:

""oasst2""
""ise-uiuc/Magicoder-Evol-Instruct-110K""
""vicgalle/alpaca-gpt4""
""LDJnr/Capybara""


	
		
		From Capybara
	


Most tokens contained in this dataset are newly synthesized… See the full description on the dataset page: https://huggingface.co/datasets/erfanzar/UltraChat-Matic.",https://huggingface.co/datasets/erfanzar/UltraChat-Matic,"['en', 'es', 'ru', 'de', 'pl', 'th', 'vi', 'sv', 'bn', 'da', 'he', 'it', 'fa', 'sk', 'id', 'nb', 'el', 'nl', 'hu', 'eu', 'zh', 'eo', 'ja', 'ca', 'cs', 'bg', 'fi', 'pt', 'tr', 'ro', 'ar', 'uk', 'gl', 'fr', 'ko']","['text-generation', 'text-classification']",['100K<n<1M']
NickyNicky/oasst2_chatml,NickyNicky,2024-01-07 01:44:47+00:00,2024-01-09 19:13:26+00:00,19,3,"['language:en', 'language:es', 'language:ru', 'language:zh', 'language:de', 'language:fr', 'language:th', 'language:ca', 'language:it', 'language:ja', 'language:pl', 'language:eo', 'language:eu', 'language:vi', 'language:fi', 'language:hu', 'language:ar', 'language:nl', 'language:da', 'language:tr', 'language:ko', 'language:he', 'language:id', 'language:cs', 'language:bn', 'language:sv', 'size_categories:10K<n<100K', 'format:parquet', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","  link: https://huggingface.co/datasets/OpenAssistant/oasst2

Message counts by language:

en: 64,513
es: 28,199
ru: 13,935
zh: 8,615
de: 6,145
fr: 3,880
pt-BR: 2,699
th: 1,560
ca: 1,283
it: 943
uk-UA: 845
ja: 788
pl: 435
eo: 295
eu: 274
vi: 207
fi: 138
hu: 113
ar: 80
nl: 72
da: 44
tr: 37
ko: 24
he: 24
id: 12
cs: 12
bn: 1
sv: 1

",https://huggingface.co/datasets/NickyNicky/oasst2_chatml,"['en', 'es', 'ru', 'zh', 'de', 'fr', 'th', 'ca', 'it', 'ja', 'pl', 'eo', 'eu', 'vi', 'fi', 'hu', 'ar', 'nl', 'da', 'tr', 'ko', 'he', 'id', 'cs', 'bn', 'sv']",[],['10K<n<100K']
shi3z/Qarasu_Wikipedia_multiturn_human_gpt_10K,shi3z,2024-01-07 02:15:58+00:00,2024-01-07 04:26:40+00:00,26,0,"['language:ja', 'license:apache-2.0', 'size_categories:10K<n<100K', 'format:json', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","Japanese multi-turn conversation data was generated using Qarasu14B based on Wikipedia data. for non commercial use(Because Qarasu14B learned from ShareGPT)
Human-gpt format conversation dataset that can be learned with Axolotl.

	
		
		Based on
	

https://huggingface.co/datasets/shi3z/Qarasu_Wikipedia_Multiturn

	
		
		Model
	

https://huggingface.co/lightblue/qarasu-14B-chat-plus-unleashed

	
		
		Dataset
	

https://huggingface.co/datasets/izumi-lab/wikipedia-ja-20230720

	
		
		Developed by… See the full description on the dataset page: https://huggingface.co/datasets/shi3z/Qarasu_Wikipedia_multiturn_human_gpt_10K.",https://huggingface.co/datasets/shi3z/Qarasu_Wikipedia_multiturn_human_gpt_10K,['ja'],[],['10K<n<100K']
nyanko7/yandere2023,nyanko7,2024-01-07 10:31:53+00:00,2024-05-06 08:22:23+00:00,986,10,"['task_categories:image-classification', 'task_categories:image-to-image', 'task_categories:text-to-image', 'language:en', 'language:ja', 'license:mit', 'size_categories:1M<n<10M', 'region:us']","
	
		
		Yandere2023: A Large-Scale Crowdsourced and Tagged Anime Illustration Dataset
	



Yandere2023 is a comprehensive anime image dataset with over 1.2 million high-quality images sourced from various materials, including key frames, manga scans, artbooks, and more. While the average number of tags per image is relatively low, the dataset boasts a diverse collection of images with exceptional quality.

Shared by: Nyanko Devs
Language(s): English, Japanese
License: MIT


	
		
	
	
		Uses… See the full description on the dataset page: https://huggingface.co/datasets/nyanko7/yandere2023.",https://huggingface.co/datasets/nyanko7/yandere2023,"['en', 'ja']","['image-classification', 'image-to-image', 'text-to-image']",['1M<n<10M']
sergicalsix/Japanese_NER_Data_Hub,sergicalsix,2024-01-08 08:37:34+00:00,2024-05-31 05:24:26+00:00,28,4,"['task_categories:feature-extraction', 'language:ja', 'license:mit', 'size_categories:1K<n<10K', 'format:csv', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us', 'Named Entity Recognition', 'NER']","
	
		
		概要
	

大規模言語モデル(LLM)用の固有表現認識データセット(J-NER)のリポジトリです。
J-NERは拡張固有表現階層(*)の内、応用の観点から重要な名前表現から構成される総計157種類の固有表現を含んだデータセットです。
J-NERで取り扱う固有表現はLLMの学習データに含まれていることが要求されるため、J-NERに含まれる固有表現はWikipediaにページが存在する単語のみとしています。
各固有表現に関して、その固有表現を含んだデータ(文)である正例5例、含まれていないデータ(文)である負例5例がデータセットに存在します。
よってデータセットの総計は157×5×2=1,570です。
*:2024年5月28日現在、拡張固有表現階層の以下サイトにアクセスできません。
https://ene-project.info/ene9/

	
		
	
	
		使い方
	


データロード

from datasets import load_dataset
dataset =… See the full description on the dataset page: https://huggingface.co/datasets/sergicalsix/Japanese_NER_Data_Hub.",https://huggingface.co/datasets/sergicalsix/Japanese_NER_Data_Hub,['ja'],['feature-extraction'],['1K<n<10K']
AICU/LuC4,AICU,2024-01-08 09:01:41+00:00,2024-01-08 10:07:19+00:00,7,0,"['task_categories:feature-extraction', 'language:ja', 'license:creativeml-openrail-m', 'size_categories:n<1K', 'format:imagefolder', 'modality:image', 'modality:text', 'library:datasets', 'library:mlcroissant', 'region:us', 'LuC4', 'SDXL', 'LoRA']",,https://huggingface.co/datasets/AICU/LuC4,['ja'],['feature-extraction'],['n<1K']
shi3z/ja_conv_wikipedia_llama2pro8b_3k,shi3z,2024-01-08 23:11:22+00:00,2024-01-09 23:18:17+00:00,8,1,"['language:ja', 'license:llama2', 'size_categories:1K<n<10K', 'format:json', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","This dataset is based on the Japanese version of Wikipedia dataset and converted into a multi-turn conversation format using llama2Pro8B. After generating 10,000 conversations and screening, only about 3,000 were usable, so I will publish them in this state first.
Since it is a llama2 license, it can be used commercially for services.
Some strange dialogue may be included as it has not been screened by humans.
We generated 10,000 conversations over 24 hours on an A100 80GBx7 machine and… See the full description on the dataset page: https://huggingface.co/datasets/shi3z/ja_conv_wikipedia_llama2pro8b_3k.",https://huggingface.co/datasets/shi3z/ja_conv_wikipedia_llama2pro8b_3k,['ja'],[],['1K<n<10K']
Namitoo/gui,Namitoo,2024-01-09 02:32:30+00:00,2024-01-09 03:05:12+00:00,6,0,"['language:ja', 'region:us']",,https://huggingface.co/datasets/Namitoo/gui,['ja'],[],[]
KBlueLeaf/danbooru2023-metadata-database,KBlueLeaf,2024-01-11 05:13:15+00:00,2024-11-01 16:45:37+00:00,101,80,"['task_categories:image-classification', 'task_categories:text-to-image', 'task_categories:image-to-text', 'task_categories:image-to-image', 'task_categories:text-retrieval', 'task_categories:text-generation', 'task_categories:text-classification', 'language:en', 'language:ja', 'license:mit', 'size_categories:1M<n<10M', 'format:parquet', 'modality:image', 'modality:tabular', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us', 'art', 'anime']","
	
		
		Metadata Database for Danbooru2023
	

Danbooru 2023 datasets: https://huggingface.co/datasets/nyanko7/danbooru2023
The latest entry of this database is id 7,866,491. Which is newer than nyanko7's dataset.
This dataset contains a sqlite db file which have all the tags and posts metadata in it.
The Peewee ORM config file is provided too, plz check it for more information. (Especially on how I link posts and tags together)
The original data is from the official dump of the posts info.… See the full description on the dataset page: https://huggingface.co/datasets/KBlueLeaf/danbooru2023-metadata-database.",https://huggingface.co/datasets/KBlueLeaf/danbooru2023-metadata-database,"['en', 'ja']","['image-classification', 'text-to-image', 'image-to-text', 'image-to-image', 'text-retrieval', 'text-generation', 'text-classification']",['1M<n<10M']
Gustav114514/work,Gustav114514,2024-01-11 05:32:50+00:00,2024-01-11 05:36:43+00:00,25,0,"['language:ja', 'license:apache-2.0', 'modality:audio', 'region:us', 'audio', 'automatic-speech-recognition', 'speech', 'xlsr-fine-tuning-week']","
	
		
		Fine-tuned XLSR-53 large model for speech recognition in Japanese
	

Fine-tuned facebook/wav2vec2-large-xlsr-53 on Japanese using the train and validation splits of Common Voice 6.1, CSS10 and JSUT.
When using this model, make sure that your speech input is sampled at 16kHz.
This model has been fine-tuned thanks to the GPU credits generously given by the OVHcloud :)
The script used for training can be found here: https://github.com/jonatasgrosman/wav2vec2-sprint
	
		
		Usage
	

The… See the full description on the dataset page: https://huggingface.co/datasets/Gustav114514/work.",https://huggingface.co/datasets/Gustav114514/work,['ja'],[],[]
lenML/oaast_rm_full_jieba,lenML,2024-01-11 18:16:53+00:00,2024-01-13 07:36:20+00:00,15,0,"['language:en', 'language:es', 'language:ru', 'language:de', 'language:pl', 'language:th', 'language:vi', 'language:sv', 'language:bn', 'language:da', 'language:he', 'language:it', 'language:fa', 'language:sk', 'language:id', 'language:nb', 'language:el', 'language:nl', 'language:hu', 'language:eu', 'language:zh', 'language:eo', 'language:ja', 'language:ca', 'language:cs', 'language:bg', 'language:fi', 'language:pt', 'language:tr', 'language:ro', 'language:ar', 'language:uk', 'language:gl', 'language:fr', 'language:ko', 'license:apache-2.0', 'size_categories:10K<n<100K', 'format:json', 'modality:text', 'library:datasets', 'library:dask', 'library:mlcroissant', 'library:polars', 'region:us', 'human-feedback']","尝试解决""llm repetition problem""，使用分词模型对oaast语料进行“结巴化”数据增强，提供更强的重复内容拒绝效果。
Attempts to solve the ""llm repetition problem"" by using a segmentation model to enhance the oaast corpus with ""stuttering"" data to provide stronger rejection of duplicate content.
其次，还过滤掉了所有自我认知的微调样本。
Second, it also filters out all the fine-tuned samples of self-cognition.
files:

oaast_rm_full_jieba.jsonl : word level repeat
oaast_rm_full_sent_jieba.jsonl : sentence level repeat

",https://huggingface.co/datasets/lenML/oaast_rm_full_jieba,"['en', 'es', 'ru', 'de', 'pl', 'th', 'vi', 'sv', 'bn', 'da', 'he', 'it', 'fa', 'sk', 'id', 'nb', 'el', 'nl', 'hu', 'eu', 'zh', 'eo', 'ja', 'ca', 'cs', 'bg', 'fi', 'pt', 'tr', 'ro', 'ar', 'uk', 'gl', 'fr', 'ko']",[],['10K<n<100K']
shi3z/ja_conv_wikipedia_llama2pro8b_10k,shi3z,2024-01-12 06:17:35+00:00,2024-01-12 06:18:48+00:00,8,2,"['language:ja', 'license:llama2', 'size_categories:10K<n<100K', 'format:json', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","This dataset is based on the Japanese version of Wikipedia dataset and converted into a multi-turn conversation format using llama2Pro8B. After generating 10,000 conversations and screening, only about 3,000 were usable, so I will publish them in this state first.
Since it is a llama2 license, it can be used commercially for services.
Some strange dialogue may be included as it has not been screened by humans.
We generated 30,000 conversations over 24 hours on an A100 80GBx7 machine and… See the full description on the dataset page: https://huggingface.co/datasets/shi3z/ja_conv_wikipedia_llama2pro8b_10k.",https://huggingface.co/datasets/shi3z/ja_conv_wikipedia_llama2pro8b_10k,['ja'],[],['10K<n<100K']
lowres/sukasuka-anime-vocal-dataset,lowres,2024-01-13 11:58:57+00:00,2024-01-13 12:11:17+00:00,14,2,"['task_categories:audio-classification', 'language:ja', 'license:other', 'size_categories:1K<n<10K', 'format:parquet', 'modality:audio', 'library:datasets', 'library:dask', 'library:mlcroissant', 'library:polars', 'region:us']","this dataset is the parquet version of the dataset that was created by mio 
original dataset link : https://huggingface.co/datasets/mio/sukasuka-anime-vocal-dataset 
please make sure to follow and heart react the original author (≧∇≦)ﾉ
",https://huggingface.co/datasets/lowres/sukasuka-anime-vocal-dataset,['ja'],['audio-classification'],['1K<n<10K']
p1atdev/zenn-articles-20240115,p1atdev,2024-01-15 08:03:26+00:00,2024-01-15 08:12:24+00:00,11,0,"['language:ja', 'license:cc0-1.0', 'size_categories:10K<n<100K', 'format:text', 'modality:text', 'library:datasets', 'library:mlcroissant', 'region:us', 'code']","Dataset of URLs of articles on Zenn (zenn.dev)
",https://huggingface.co/datasets/p1atdev/zenn-articles-20240115,['ja'],[],['10K<n<100K']
baobab-trees/wikipedia-human-retrieval-ja,baobab-trees,2024-01-15 13:52:30+00:00,2024-03-19 04:25:44+00:00,58,34,"['task_categories:question-answering', 'language:ja', 'license:apache-2.0', 'size_categories:1K<n<10K', 'format:json', 'modality:text', 'library:datasets', 'library:dask', 'library:mlcroissant', 'region:us']","
	
		
		Japanese Wikipedia Human Retrieval dataset
	

This is a Japanese question answereing dataset with retrieval on Wikipedia articles
by trained human workers.

	
		
		Contributors
	


Yusuke Oda
defined the dataset specification, data structure, and the scheme of data collection.
Baobab, Inc.
operated data collection, data checking, and formatting.


	
		
		About the dataset
	

Each entry represents a single QA session:
given a question sentence, the responsible worker tried to search for… See the full description on the dataset page: https://huggingface.co/datasets/baobab-trees/wikipedia-human-retrieval-ja.",https://huggingface.co/datasets/baobab-trees/wikipedia-human-retrieval-ja,['ja'],['question-answering'],['1K<n<10K']
davidchan/anim400k,davidchan,2024-01-15 21:19:20+00:00,2024-06-21 17:01:26+00:00,93,38,"['task_categories:text-to-speech', 'task_categories:automatic-speech-recognition', 'task_categories:audio-to-audio', 'task_categories:audio-classification', 'task_categories:text-classification', 'task_categories:video-classification', 'task_categories:summarization', 'language:en', 'language:ja', 'size_categories:100K<n<1M', 'arxiv:2401.05314', 'region:us']","
	
		
		Anim-400K: A dataset designed from the ground up for automated dubbing of video
	



	
		
		What is Anim-400K?
	

Anim-400K is a large-scale dataset of aligned audio-video clips in both the English and Japanese languages. It is comprised of over 425K aligned clips (763 hours) consisting of both video and audio drawn from over 190 properties covering hundreds of themes and genres. Anim400K is further augmented with metadata including genres, themes, show-ratings, character profiles, and… See the full description on the dataset page: https://huggingface.co/datasets/davidchan/anim400k.",https://huggingface.co/datasets/davidchan/anim400k,"['en', 'ja']","['text-to-speech', 'automatic-speech-recognition', 'audio-to-audio', 'audio-classification', 'text-classification', 'video-classification', 'summarization']",['100K<n<1M']
neon-mao/language-dataset,neon-mao,2024-01-16 02:38:01+00:00,2024-01-16 03:08:19+00:00,18,3,"['task_categories:text-classification', 'language:en', 'language:zh', 'language:fr', 'language:ru', 'language:ja', 'language:it', 'language:tr', 'language:de', 'language:pt', 'language:es', 'language:he', 'language:uk', 'language:nl', 'language:fi', 'language:pl', 'language:lt', 'language:cs', 'language:da', 'language:sv', 'language:sr', 'language:ar', 'language:el', 'language:ro', 'language:bg', 'language:vi', 'language:sk', 'language:id', 'language:is', 'language:ko', 'language:ca', 'language:hr', 'language:th', 'language:et', 'language:sl', 'language:no', 'license:mit', 'size_categories:100K<n<1M', 'format:csv', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","
",https://huggingface.co/datasets/neon-mao/language-dataset,"['en', 'zh', 'fr', 'ru', 'ja', 'it', 'tr', 'de', 'pt', 'es', 'he', 'uk', 'nl', 'fi', 'pl', 'lt', 'cs', 'da', 'sv', 'sr', 'ar', 'el', 'ro', 'bg', 'vi', 'sk', 'id', 'is', 'ko', 'ca', 'hr', 'th', 'et', 'sl', 'no']",['text-classification'],['100K<n<1M']
naist-nlp/Wiki-ImageReview1.0,naist-nlp,2024-01-17 07:30:55+00:00,2024-02-21 15:43:16+00:00,32,2,"['task_categories:visual-question-answering', 'language:en', 'language:ja', 'license:other', 'size_categories:n<1K', 'format:parquet', 'modality:image', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us', 'art', 'vision']","
	
		
		Dataset Card for ""Wiki-ImageReview1.0""
	


	
		
		Dataset Summary
	


we introduce a novel task for LVLMs, which involves reviewing the good and bad points of a given imagewe construct a benchmark dataset containing 207 images selected from Wikipedia.Each image is accompanied by five review texts and a manually annotated ranking of these texts in both English and Japanese.  


	
		
		Supported Tasks and Leaderboards
	

[More Information Needed]

	
		
		Languages
	

This dataset is… See the full description on the dataset page: https://huggingface.co/datasets/naist-nlp/Wiki-ImageReview1.0.",https://huggingface.co/datasets/naist-nlp/Wiki-ImageReview1.0,"['en', 'ja']",['visual-question-answering'],['n<1K']
google/mittens,google,2024-01-17 19:03:53+00:00,2024-01-17 19:17:58+00:00,37,6,"['task_categories:translation', 'language:ar', 'language:fi', 'language:om', 'language:lg', 'language:as', 'language:tr', 'language:fa', 'language:id', 'language:bn', 'language:de', 'language:hi', 'language:pt', 'language:ru', 'language:zh', 'language:ja', 'language:pl', 'language:te', 'language:th', 'language:cs', 'language:fr', 'language:am', 'language:it', 'language:es', 'license:cc-by-4.0', 'size_categories:1K<n<10K', 'format:csv', 'modality:tabular', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us', 'multilingual', 'i18n']","
	
		
		MiTTenS: A Dataset for Evaluating Misgendering in Translation
	

Misgendering is the act of referring to someone in a way that does not reflect their gender identity.  Translation systems, including foundation models capable of translation, can produce errors that result in misgendering harms. To measure the extent of such potential harms when translating into and out of English, we introduce a dataset, MiTTenS, covering 26 languages from a variety of language families and scripts… See the full description on the dataset page: https://huggingface.co/datasets/google/mittens.",https://huggingface.co/datasets/google/mittens,"['ar', 'fi', 'om', 'lg', 'as', 'tr', 'fa', 'id', 'bn', 'de', 'hi', 'pt', 'ru', 'zh', 'ja', 'pl', 'te', 'th', 'cs', 'fr', 'am', 'it', 'es']",['translation'],['1K<n<10K']
hpprc/wikipedia-20240101,hpprc,2024-01-18 14:33:06+00:00,2024-01-22 07:41:53+00:00,24,4,"['language:ja', 'license:cc-by-sa-3.0', 'size_categories:1M<n<10M', 'format:parquet', 'modality:text', 'library:datasets', 'library:dask', 'library:mlcroissant', 'library:polars', 'region:us']","apache_beamとmwparserfromhellを用いて通常のWikipediaの前処理を行ったデータセットです。
本家の前処理時間が長すぎたため、前処理済みバージョンを配布しています。
各種規約・ライセンスは本家Wikipediaにしたがってください。

	
		
		Preprocessing Code
	

import datasets as ds

dataset = ds.load_dataset(
    ""wikipedia"",
    language=""ja"",
    date=""20240101"",
    beam_runner=""DirectRunner"",
    trust_remote_code=True,
)

dataset.push_to_hub(""hpprc/wikipedia-20240101"", max_shard_size=""1GB"")

",https://huggingface.co/datasets/hpprc/wikipedia-20240101,['ja'],[],['1M<n<10M']
shi3z/ja_conv_wikipedia_llama2pro8b_20k,shi3z,2024-01-20 01:15:26+00:00,2024-01-20 01:17:11+00:00,5,0,"['language:ja', 'license:llama2', 'size_categories:10K<n<100K', 'format:json', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","This dataset is based on the Japanese version of Wikipedia dataset and converted into a multi-turn conversation format using llama2Pro8B.
Since it is a llama2 license, it can be used commercially for services.
Some strange dialogue may be included as it has not been screened by humans.
We generated 60,000 conversations 18 days on an A100 80GBx7 machine and automatically screened them.

	
		
		Model
	

https://huggingface.co/spaces/TencentARC/LLaMA-Pro-8B-Instruct-Chat

	
		
		Dataset… See the full description on the dataset page: https://huggingface.co/datasets/shi3z/ja_conv_wikipedia_llama2pro8b_20k.",https://huggingface.co/datasets/shi3z/ja_conv_wikipedia_llama2pro8b_20k,['ja'],[],['10K<n<100K']
cyberagent/chatbot-arena-ja-calm2-7b-chat-experimental,cyberagent,2024-01-20 04:07:21+00:00,2024-08-15 04:51:49+00:00,21,19,"['language:ja', 'license:cc-by-4.0', 'size_categories:10K<n<100K', 'format:parquet', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'arxiv:2406.16316', 'arxiv:2004.06063', 'arxiv:2305.18290', 'region:us']","
	
		
		Dataset Card for ""chatbot-arena-ja-calm2-7b-chat""
	


	
		
		Chatbot Arena Conversations JA (calm2) Dataset
	

Chatbot Arena Conversations JA (calm2)はこちらの論文で構築されたRLHFのための日本語Instructionデータセットです。
「英語で公開されているデータセットをオープンソースのツール・モデルのみを使って日本語用に転用し、日本語LLMの学習に役立てることができるか」を検証する目的で作成しております。
指示文（prompt）はlmsys/chatbot_arena_conversationsのユーザ入力（CC-BY 4.0）を和訳したものです。これはChatbot Arenaを通して人間が作成した指示文であり、CC-BY 4.0で公開されているものです。複数ターンの対話の場合は最初のユーザ入力のみを使っています（そのため、このデータセットはすべて１ターンの対話のみになっております）。… See the full description on the dataset page: https://huggingface.co/datasets/cyberagent/chatbot-arena-ja-calm2-7b-chat-experimental.",https://huggingface.co/datasets/cyberagent/chatbot-arena-ja-calm2-7b-chat-experimental,['ja'],[],['10K<n<100K']
lamhieu/sharegpt_dialogue_base,lamhieu,2024-01-21 07:55:43+00:00,2024-05-17 10:49:21+00:00,18,2,"['task_categories:text-generation', 'language:en', 'language:vi', 'language:zh', 'language:es', 'language:pt', 'language:ja', 'language:ko', 'license:mit', 'size_categories:100K<n<1M', 'format:parquet', 'modality:text', 'library:datasets', 'library:dask', 'library:mlcroissant', 'library:polars', 'region:us']","
	
		
		Description
	

The dataset is from unknown, formatted as dialogues for speed and ease of use. Many thanks to author for releasing it.
Importantly, this format is easy to use via the default chat template of transformers, meaning you can use huggingface/alignment-handbook immediately, unsloth.

	
		
	
	
		Structure
	

View online through viewer.

	
		
	
	
		Note
	

We advise you to reconsider before use, thank you. If you find it useful, please like and follow this account.… See the full description on the dataset page: https://huggingface.co/datasets/lamhieu/sharegpt_dialogue_base.",https://huggingface.co/datasets/lamhieu/sharegpt_dialogue_base,"['en', 'vi', 'zh', 'es', 'pt', 'ja', 'ko']",['text-generation'],['100K<n<1M']
shi3z/ja_conv_wikipedia_llama2pro8b_30k,shi3z,2024-01-21 22:14:41+00:00,2024-01-21 22:16:01+00:00,18,0,"['language:ja', 'license:llama2', 'size_categories:10K<n<100K', 'format:json', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","This dataset is based on the Japanese version of Wikipedia dataset and converted into a multi-turn conversation format using llama2Pro8B.
Since it is a llama2 license, it can be used commercially for services.
Some strange dialogue may be included as it has not been screened by humans.
We generated over 80,000 conversations 22 days on an A100 80GBx7 machine and automatically screened them.

	
		
		Model
	

https://huggingface.co/spaces/TencentARC/LLaMA-Pro-8B-Instruct-Chat

	
		
		Dataset… See the full description on the dataset page: https://huggingface.co/datasets/shi3z/ja_conv_wikipedia_llama2pro8b_30k.",https://huggingface.co/datasets/shi3z/ja_conv_wikipedia_llama2pro8b_30k,['ja'],[],['10K<n<100K']
NickyNicky/oasst2_clusters,NickyNicky,2024-01-22 08:52:53+00:00,2024-01-26 13:16:49+00:00,11,2,"['language:en', 'language:es', 'language:ru', 'language:zh', 'language:de', 'language:fr', 'language:th', 'language:ca', 'language:it', 'language:ja', 'language:pl', 'language:eo', 'language:eu', 'language:vi', 'language:fi', 'language:hu', 'language:ar', 'language:nl', 'language:da', 'language:tr', 'language:ko', 'language:he', 'language:id', 'language:cs', 'language:bn', 'language:sv', 'size_categories:10K<n<100K', 'format:parquet', 'modality:tabular', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","
max count_word cluster_1: 1722
min count_word cluster_1: 11
max count_word cluster_2: 2624
min count_word cluster_2: 21
max count_word cluster_3: 2370
min count_word cluster_3: 31

DatasetDict({
    Cluster_1: Dataset({
        features: ['Text', 'Cluster', 'Polarity', 'count_word'],
        num_rows: 4797
    })
    Cluster_2: Dataset({
        features: ['Text', 'Cluster', 'Polarity', 'count_word'],
        num_rows: 4025
    })
    Cluster_3: Dataset({
        features: ['Text', 'Cluster'… See the full description on the dataset page: https://huggingface.co/datasets/NickyNicky/oasst2_clusters.",https://huggingface.co/datasets/NickyNicky/oasst2_clusters,"['en', 'es', 'ru', 'zh', 'de', 'fr', 'th', 'ca', 'it', 'ja', 'pl', 'eo', 'eu', 'vi', 'fi', 'hu', 'ar', 'nl', 'da', 'tr', 'ko', 'he', 'id', 'cs', 'bn', 'sv']",[],['10K<n<100K']
shi3z/ja_conv_wikipedia_orion14B_10K,shi3z,2024-01-25 20:30:08+00:00,2024-01-25 20:56:08+00:00,7,0,"['language:ja', 'size_categories:10K<n<100K', 'format:json', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","
	
		
		Abstruct
	

This is a multi-turn conversation dataset generated from the Japanese Wikipedia dataset using Orion14B-Chat. Commercial use is possible, but the license is complicated, so please read it carefully before using it.
I generated V100x4 on 10 machines in about half a day.

	
		
		License
	

【Orion-14B Series】 Models Community License Agreement
https://huggingface.co/OrionStarAI/Orion-14B-Chat/blob/main/ModelsCommunityLicenseAgreement

	
		
		Computing
	

ABCI
https://abci.ai/ja/
",https://huggingface.co/datasets/shi3z/ja_conv_wikipedia_orion14B_10K,['ja'],[],['10K<n<100K']
llm-jp/databricks-dolly-15k-ja,llm-jp,2024-01-27 07:11:25+00:00,2024-01-30 18:09:37+00:00,116,17,"['task_categories:question-answering', 'task_categories:summarization', 'language:ja', 'license:cc-by-sa-3.0', 'size_categories:10K<n<100K', 'format:json', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","
	
		
		databricks-dolly-15k-ja
	

This repository provides an instruction tuning dataset developed by LLM-jp, a collaborative project launched in Japan.
This dataset is a Japanese translation of databricks-dolly-15k using DeepL.

	
		
		Send Questions to
	

llm-jp(at)nii.ac.jp

	
		
		Model Card Authors
	

The names are listed in alphabetical order.
Hirokazu Kiyomaru, Hiroshi Matsuda, Jun Suzuki, Namgi Han, Saku Sugawara, Shota Sasaki, Shuhei Kurita, Taishi Nakamura, Takashi Kodama, Takumi… See the full description on the dataset page: https://huggingface.co/datasets/llm-jp/databricks-dolly-15k-ja.",https://huggingface.co/datasets/llm-jp/databricks-dolly-15k-ja,['ja'],"['question-answering', 'summarization']",['10K<n<100K']
llm-jp/oasst1-21k-ja,llm-jp,2024-01-28 23:27:03+00:00,2024-02-06 04:06:04+00:00,25,16,"['language:ja', 'license:apache-2.0', 'size_categories:10K<n<100K', 'format:json', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","
	
		
		oasst1-21k-ja
	

This repository provides an instruction tuning dataset developed by LLM-jp, a collaborative project launched in Japan.
This dataset is a Japanese translation of an English subset of oasst1 using DeepL.
English subset is here.

	
		
	
	
		Send Questions to
	

llm-jp(at)nii.ac.jp

	
		
	
	
		Model Card Authors
	

The names are listed in alphabetical order.
Hirokazu Kiyomaru, Hiroshi Matsuda, Jun Suzuki, Namgi Han, Saku Sugawara, Shota Sasaki, Shuhei Kurita, Taishi… See the full description on the dataset page: https://huggingface.co/datasets/llm-jp/oasst1-21k-ja.",https://huggingface.co/datasets/llm-jp/oasst1-21k-ja,['ja'],[],['10K<n<100K']
MomoyamaSawa/Voice-KusanagiNene,MomoyamaSawa,2024-01-29 08:17:20+00:00,2024-01-29 10:51:51+00:00,38,14,"['task_categories:other', 'task_categories:text-to-speech', 'task_categories:audio-to-audio', 'language:ja', 'license:gpl-3.0', 'size_categories:1K<n<10K', 'format:audiofolder', 'modality:audio', 'library:datasets', 'library:mlcroissant', 'region:us', 'pjsk', '草薙寧々', '草薙宁宁', 'プロセカ', 'prsk', '宁宁']","
  

 🥕 
 如果兔兔的仓库对你有帮助的话点个⭐喵~ 
 If Tutu's repository is helpful to you, please give it a ⭐ meow~ 
 もしうさぎのリポジトリが役に立った場合は、⭐をぽちっとしてくださいにゃん~  

 🍉 
 任何 ❓问题 / 💭思考 /💡想法 都欢迎提出！
 Any ❓question / 💭thought /💡idea  is welcome! 
 どんな ❓質問 / 💭考え /💡アイデア でも歓迎です！ 



	
		
	
	
		简介
	


草薙寧々 干声带标签数据集

本数据集只收集了游戏内的一部分，并不是全部的宁宁干声语音，其中 nene_org.txt 是标签文件
pjsk 全部角色干声带标签数据集的话可以加QQ群：691795641，群公告里有网盘地址

	
	
	
		参考
	


声源归属：草薙寧々(CV:Machico)-「プロジェクトセカイ カラフルステージ！ feat. 初音ミク」
	
		
		TODO
	


（长期）补全宁宁语音，规范数据集格式。

",https://huggingface.co/datasets/MomoyamaSawa/Voice-KusanagiNene,['ja'],"['other', 'text-to-speech', 'audio-to-audio']",['1K<n<10K']
asus-aics/ntcir_13_medweb,asus-aics,2024-01-29 09:18:05+00:00,2024-07-08 05:33:54+00:00,7,0,"['multilinguality:multilingual', 'language:en', 'language:zh', 'language:ja', 'license:cc-by-4.0', 'region:us']","NTCIR-13 MedWeb (Medical Natural Language Processing for Web Document) task requires
to perform a multi-label classification that labels for eight diseases/symptoms must
be assigned to each tweet. Given pseudo-tweets, the output are Positive:p or Negative:n
labels for eight diseases/symptoms. The achievements of this task can almost be
directly applied to a fundamental engine for actual applications.

This task provides pseudo-Twitter messages in a cross-language and multi-label corpus,
covering three languages (Japanese, English, and Chinese), and annotated with eight
labels such as influenza, diarrhea/stomachache, hay fever, cough/sore throat, headache,
fever, runny nose, and cold.

For more information, see:
http://research.nii.ac.jp/ntcir/permission/ntcir-13/perm-en-MedWeb.html

As this dataset also provides a parallel corpus of pseudo-tweets for english,
japanese and chinese it can also be used to train translation models between
these three languages.",https://huggingface.co/datasets/asus-aics/ntcir_13_medweb,"['en', 'zh', 'ja']",[],[]
sappho192/Tatoeba-Challenge-jpn-kor,sappho192,2024-01-30 01:01:30+00:00,2024-01-30 16:51:21+00:00,174,0,"['task_categories:translation', 'language:ja', 'language:ko', 'license:cc-by-nc-sa-4.0', 'size_categories:10M<n<100M', 'format:csv', 'modality:text', 'library:datasets', 'library:dask', 'library:mlcroissant', 'library:polars', 'region:us']","
	
		
		Dataset Card for Dataset Name
	

This dataset contains Japanese-Korean paired text which is from Helsinki-NLP/Tatoeba-Challenge.

	
		
		Dataset Details
	


	
		
		Dataset Sources
	


Repository: Helsinki-NLP/Tatoeba-Challenge
Detail: Japanese - Korean jpn-kor


	
		
		Uses
	

The dataset can be used to train the translation model that translates Japanese sentence to Korean.

	
		
		Out-of-Scope Use
	

You cannot use this dataset to train the model which is to be used under commercial… See the full description on the dataset page: https://huggingface.co/datasets/sappho192/Tatoeba-Challenge-jpn-kor.",https://huggingface.co/datasets/sappho192/Tatoeba-Challenge-jpn-kor,"['ja', 'ko']",['translation'],['10M<n<100M']
shi3z/ja_conv_wikipedia_orion14B_100K,shi3z,2024-01-30 01:45:05+00:00,2024-01-30 02:13:12+00:00,8,2,"['language:ja', 'size_categories:100K<n<1M', 'format:json', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","
	
		
		Abstruct
	

This is a multi-turn conversation dataset generated from the Japanese Wikipedia dataset using Orion14B-Chat. Commercial use is possible, but the license is complicated, so please read it carefully before using it.
I generated V100x4 on 200 machines in about half a week.

	
		
		License
	

【Orion-14B Series】 Models Community License Agreement
https://huggingface.co/OrionStarAI/Orion-14B-Chat/blob/main/ModelsCommunityLicenseAgreement

	
		
		Computing
	

ABCI… See the full description on the dataset page: https://huggingface.co/datasets/shi3z/ja_conv_wikipedia_orion14B_100K.",https://huggingface.co/datasets/shi3z/ja_conv_wikipedia_orion14B_100K,['ja'],[],['100K<n<1M']
wecover/OPUS,wecover,2024-01-30 12:54:31+00:00,2024-05-23 09:15:01+00:00,363,0,"['task_categories:translation', 'language:af', 'language:am', 'language:ar', 'language:as', 'language:az', 'language:be', 'language:bg', 'language:bn', 'language:br', 'language:bs', 'language:ca', 'language:cs', 'language:cy', 'language:da', 'language:de', 'language:el', 'language:en', 'language:eo', 'language:es', 'language:et', 'language:eu', 'language:fa', 'language:fi', 'language:fr', 'language:fy', 'language:ga', 'language:gd', 'language:gl', 'language:ha', 'language:he', 'language:hi', 'language:hr', 'language:hu', 'language:hy', 'language:id', 'language:is', 'language:it', 'language:ja', 'language:jv', 'language:ka', 'language:kk', 'language:km', 'language:kn', 'language:ko', 'language:ku', 'language:ky', 'language:la', 'language:lo', 'language:lt', 'language:mg', 'language:mk', 'language:ml', 'language:mn', 'language:mr', 'language:ms', 'language:my', 'language:ne', 'language:nl', 'language:no', 'language:om', 'language:or', 'language:pa', 'language:pl', 'language:ps', 'language:pt', 'language:ro', 'language:ru', 'language:sa', 'language:sd', 'language:si', 'language:sk', 'language:sl', 'language:so', 'language:sq', 'language:sr', 'language:su', 'language:sv', 'language:sw', 'language:ta', 'language:te', 'language:th', 'language:tl', 'language:tr', 'language:ug', 'language:uk', 'language:ur', 'language:uz', 'language:vi', 'language:xh', 'language:yi', 'language:zh', 'size_categories:10M<n<100M', 'format:parquet', 'modality:text', 'library:datasets', 'library:dask', 'library:mlcroissant', 'library:polars', 'arxiv:2004.09813', 'arxiv:1907.05791', 'region:us']","
	
		
		Collection of OPUS
	

Corpus from https://opus.nlpl.eu has been collected. The following corpora have been included:

UNPC
GlobalVoices
TED2020
News-Commentary
WikiMatrix
Tatoeba
Europarl
OpenSubtitles

25,000 samples (randomly sampled within the first 100,000 samples) per language pair of each corpus were collected, with no modification of data.
	
		
		Licenses
	


	
		
		OPUS
	

@inproceedings{tiedemann2012parallel,
  title={Parallel data, tools and interfaces in OPUS.}… See the full description on the dataset page: https://huggingface.co/datasets/wecover/OPUS.",https://huggingface.co/datasets/wecover/OPUS,"['af', 'am', 'ar', 'as', 'az', 'be', 'bg', 'bn', 'br', 'bs', 'ca', 'cs', 'cy', 'da', 'de', 'el', 'en', 'eo', 'es', 'et', 'eu', 'fa', 'fi', 'fr', 'fy', 'ga', 'gd', 'gl', 'ha', 'he', 'hi', 'hr', 'hu', 'hy', 'id', 'is', 'it', 'ja', 'jv', 'ka', 'kk', 'km', 'kn', 'ko', 'ku', 'ky', 'la', 'lo', 'lt', 'mg', 'mk', 'ml', 'mn', 'mr', 'ms', 'my', 'ne', 'nl', 'no', 'om', 'or', 'pa', 'pl', 'ps', 'pt', 'ro', 'ru', 'sa', 'sd', 'si', 'sk', 'sl', 'so', 'sq', 'sr', 'su', 'sv', 'sw', 'ta', 'te', 'th', 'tl', 'tr', 'ug', 'uk', 'ur', 'uz', 'vi', 'xh', 'yi', 'zh']",['translation'],['10M<n<100M']
felfri/MAGBIG,felfri,2024-01-30 16:08:50+00:00,2025-06-04 14:47:04+00:00,17,3,"['task_categories:text-to-image', 'language:en', 'language:de', 'language:it', 'language:fr', 'language:es', 'language:zh', 'language:ja', 'language:ko', 'language:ru', 'language:ar', 'license:apache-2.0', 'size_categories:n<1K', 'format:csv', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'arxiv:2401.16092', 'region:us']","
	
		
		MAGBIG benchmark
	

This is the MAGBIG benchmark proposed in https://arxiv.org/abs/2401.16092
This benchmark is intended for multilingual text-to-image models. With MAGBIG, you can generate images for a diverse set of prompts across ten different languages. These images can be evaluated for differences across languages. MAGBIG is designed to uncover and assess biases across languages such as gender, race, age, etc. This way, we can measure whether bias exists in a language, but also… See the full description on the dataset page: https://huggingface.co/datasets/felfri/MAGBIG.",https://huggingface.co/datasets/felfri/MAGBIG,"['en', 'de', 'it', 'fr', 'es', 'zh', 'ja', 'ko', 'ru', 'ar']",['text-to-image'],['n<1K']
nenekochan/yoruno-vn,nenekochan,2024-02-01 07:53:41+00:00,2024-04-08 04:04:38+00:00,15,17,"['task_categories:text-generation', 'annotations_creators:expert-generated', 'annotations_creators:machine-generated', 'language:zh', 'language:ja', 'license:cc-by-nc-4.0', 'region:us', 'not-for-all-audiences']","
睡不着的夜晚和不想睡觉的夜晚


	
		
		⚠️注意
	


请注意，数据来自 R18 的视觉小说，并且包含可能被认为是不适当、令人震惊、令人不安、令人反感和极端的主题。如果您不确定在您的国家拥有任何形式的虚构文字内容的法律后果，请不要下载。
本项目内的所有数据及基于这些数据的衍生作品禁止用作商业性目的。 我不拥有 scenario-raw 和 scenario_ja-raw 里的 krkr2 脚本源文件，而其余的数据处理方法按照 CC BY-NC 4.0 协议开放。
🔑 压缩包已加密，解压密码是 yorunohitsuji


	
		
		文件结构
	

yoruno-vn.7z          # (zh)
 ├── scenario-raw/     # krkr2 脚本源文件
 ├── scenario/         # 清理后的结构化脚本
 └── conversation/     # 我主观分段制作的对话格式数据
yoruno_ja-vn.7z       # (ja)
 ├── scenario_ja-raw/  # krkr2 脚本源文件
 ├──… See the full description on the dataset page: https://huggingface.co/datasets/nenekochan/yoruno-vn.",https://huggingface.co/datasets/nenekochan/yoruno-vn,"['zh', 'ja']",['text-generation'],[]
textdetox/multilingual_toxicity_dataset,textdetox,2024-02-01 15:44:46+00:00,2025-03-21 18:52:31+00:00,1028,28,"['task_categories:text-classification', 'language:en', 'language:ru', 'language:uk', 'language:de', 'language:es', 'language:am', 'language:zh', 'language:ar', 'language:hi', 'language:it', 'language:fr', 'language:he', 'language:ja', 'language:tt', 'license:openrail++', 'size_categories:10K<n<100K', 'format:parquet', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","
	
		
		Multilingual Toxicity Detection Dataset
	

[2025] We extend our binary toxicity classification dataset to more languages! Now also covered: Italian, French, Hebrew, Hindglish, Japanese, Tatar. The data is prepared for TextDetox 2025 shared task.
[2024] For the shared task TextDetox 2024, we provide a compilation of binary toxicity classification datasets for each language.
Namely, for each language, we provide 5k subparts of the datasets -- 2.5k toxic and 2.5k non-toxic samples.
The… See the full description on the dataset page: https://huggingface.co/datasets/textdetox/multilingual_toxicity_dataset.",https://huggingface.co/datasets/textdetox/multilingual_toxicity_dataset,"['en', 'ru', 'uk', 'de', 'es', 'am', 'zh', 'ar', 'hi', 'it', 'fr', 'he', 'ja', 'tt']",['text-classification'],['10K<n<100K']
lmg-anon/VNTL-v2.5-1.6k-dpo-pairs,lmg-anon,2024-02-01 15:56:36+00:00,2024-02-02 05:48:20+00:00,13,0,"['task_categories:translation', 'language:en', 'language:ja', 'size_categories:1K<n<10K', 'format:parquet', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us', 'dpo']","
	
		
		Dataset Card for ""VNTL-v2.5-1.6k-dpo-pairs""
	

This is a very experimental DPO dataset for VNTL, I have no idea if DPO will work well to improve translation, but I guess it's worth a shot!
This dataset was generated using the model vntl-7b-v0.3.1 using prompts from the dataset VNTL-v2.5-1k. All rejected sequences were generated using temperature 0.7, and they were chosen using a cosine similarity threshold.
Things to consider afterwards:

Distilation: This dataset wasn't filtered in… See the full description on the dataset page: https://huggingface.co/datasets/lmg-anon/VNTL-v2.5-1.6k-dpo-pairs.",https://huggingface.co/datasets/lmg-anon/VNTL-v2.5-1.6k-dpo-pairs,"['en', 'ja']",['translation'],['1K<n<10K']
textdetox/multilingual_paradetox,textdetox,2024-02-01 16:31:13+00:00,2025-03-21 19:27:43+00:00,181,9,"['task_categories:text-generation', 'language:en', 'language:uk', 'language:ru', 'language:de', 'language:zh', 'language:am', 'language:ar', 'language:hi', 'language:es', 'language:it', 'language:fr', 'language:he', 'language:ja', 'language:tt', 'license:openrail++', 'size_categories:1K<n<10K', 'format:parquet', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'arxiv:2412.11691', 'region:us', 'toxic']","Multilingual Text Detoxification with Parallel Data
 
 
This is the multilingual parallel dataset for the text detoxification task. Prepared for TextDetox Shared Task. 
📰 Updates
[2025] The second edition of TextDetox shared task! webpage
[2025] We extend our data to new languages! Now also included: Italian, French, Hebrew, Hinglish, Japanese, Tatar. Check our test part.
[2025]We dived into the explainability of our data in our new COLING paper!
[2024] You can check additional releases for… See the full description on the dataset page: https://huggingface.co/datasets/textdetox/multilingual_paradetox.",https://huggingface.co/datasets/textdetox/multilingual_paradetox,"['en', 'uk', 'ru', 'de', 'zh', 'am', 'ar', 'hi', 'es', 'it', 'fr', 'he', 'ja', 'tt']",['text-generation'],['1K<n<10K']
hpprc/jawiki,hpprc,2024-02-02 06:36:00+00:00,2024-02-13 15:19:49+00:00,51,18,"['language:ja', 'license:cc-by-sa-3.0', 'license:gfdl', 'size_categories:1M<n<10M', 'format:parquet', 'modality:text', 'library:datasets', 'library:dask', 'library:mlcroissant', 'library:polars', 'region:us']","
	
		
		JaWiki
	

WikipediaのHTML形式のダンプファイルから抽出したテキストデータセットです。
Wikiextractorによって抽出したテキストデータと異なり、段落などの文書構造を維持したまま、不要なマークアップのないテキストが利用できます。
ダンプファイルは、2024年1月1日に公開されたものを利用しています。
また、各種NLPタスクに利用しやすいよう、様々なデータを同梱しています。
各種前処理スクリプトはGitHubのリポジトリをご参照ください。

	
		
		データ構造
	

各レコードはWikipediaの記事一つに対応しています。
大まかなデータ構造と説明を以下に示します。

id (int)
title (str)
記事タイトルです。


text (str)
各段落の文章(paragraphsのtext)を改行で結合したテキストです。


paragraphs (list[dict[str, int | str]])
記事中の段落の集合です。各段落は辞書型で表現されており、以下のデータ構造に基づきます。
paragraph_id… See the full description on the dataset page: https://huggingface.co/datasets/hpprc/jawiki.",https://huggingface.co/datasets/hpprc/jawiki,['ja'],[],['1M<n<10M']
Heng666/TED2020-TW-Corpus,Heng666,2024-02-02 08:21:07+00:00,2024-02-02 08:53:00+00:00,38,4,"['task_categories:translation', 'language:en', 'language:ja', 'language:ko', 'language:id', 'language:vi', 'language:th', 'language:tw', 'license:unknown', 'size_categories:1M<n<10M', 'format:parquet', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us', 'taiwan', 'translation', 'Ted2020']","
	
		
		Dataset Card for [TED2020-TW-Corpus]
	


	
		
		Dataset Summary
	

TED2020 是一個機器翻譯基準的多語言資料集，源自 OPUS 收集的使用者貢獻的翻譯，並由 OPUS。該資料集包括按語言對排序的測試和開發資料。它包括數百種語言對的測試集，並且不斷更新。請檢查版本號標籤以引用您正在使用的版本。
TED2020 收集了從1984年到2020年的演講，涵蓋了各種主題，包括科學、技術、藝術、教育、環境、社會問題等。該資料集是一個非常有價值的資源，可以用於研究和分析演講者的演講風格、主題的變化以及觀眾的反應。

	
		
		Supported Tasks and Leaderboards
	


	
		
		Languages
	

此資料集涵蓋數百種語言和語言對，並按 ISO-639-3 語言組織。目前版本涵蓋以下語言。繁體中文、英文、日文、韓文、印尼文、越南文、泰文

	
		
		Dataset Structure
	


	
		
		Data Instances
	

資料以… See the full description on the dataset page: https://huggingface.co/datasets/Heng666/TED2020-TW-Corpus.",https://huggingface.co/datasets/Heng666/TED2020-TW-Corpus,"['en', 'ja', 'ko', 'id', 'vi', 'th', 'tw']",['translation'],['1M<n<10M']
Heng666/OpenSubtitles-TW-Corpus,Heng666,2024-02-02 11:17:34+00:00,2024-02-20 03:16:06+00:00,31,3,"['task_categories:translation', 'language:en', 'language:ja', 'language:ko', 'language:id', 'language:vi', 'language:th', 'language:zh', 'license:unknown', 'size_categories:1M<n<10M', 'format:parquet', 'modality:text', 'library:datasets', 'library:dask', 'library:mlcroissant', 'library:polars', 'region:us', 'translation', 'OPUS', 'OpenSubtitles']","
	
		
		Dataset Card for [OpenSubtitles-TW-Corpus]
	


	
		
		Dataset Summary
	

OpenSubtitles-TW-Corpus 是一個機器翻譯基準的多語言資料集，源自 OpenSubtitles 收集的使用者貢獻的翻譯，並由 OPUS。該資料集包括按語言對排序的測試和開發資料。它包括數百種語言對的測試集，並且不斷更新。請檢查版本號標籤以引用您正在使用的版本。
這是字幕集合的稍微乾淨的版本，使用改進的句子對齊和更好的語言檢查。

	
		
		Supported Tasks and Leaderboards
	


	
		
		Languages
	

此資料集涵蓋數百種語言和語言對，並按 ISO-639-1 語言組織。目前版本涵蓋以下語言。繁體中文、英文、日文、韓文、印尼文、越南文、泰文

	
		
		Dataset Structure
	


	
		
		Data Instances
	

資料以… See the full description on the dataset page: https://huggingface.co/datasets/Heng666/OpenSubtitles-TW-Corpus.",https://huggingface.co/datasets/Heng666/OpenSubtitles-TW-Corpus,"['en', 'ja', 'ko', 'id', 'vi', 'th', 'zh']",['translation'],['1M<n<10M']
Heng666/MultiCCAligned-TW-Corpus,Heng666,2024-02-02 17:14:20+00:00,2024-02-19 09:22:50+00:00,26,5,"['task_categories:translation', 'language:tw', 'language:en', 'language:ja', 'language:ko', 'language:id', 'language:vi', 'language:th', 'language:zh', 'license:mit', 'size_categories:1M<n<10M', 'format:parquet', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us', 'MultiCCAligned', 'translation', 'OPUS']","
	
		
		Dataset Card for [MultiCCAligned-TW-Corpus]
	


	
		
		Dataset Summary
	

MultiCCAligned-TW-Corpus 是一個機器翻譯基準的多語言資料集，源自 OPUS 收集的使用者貢獻的翻譯，並由 OPUS。該資料集包括按語言對排序的測試和開發資料。它包括數百種語言對的測試集，並且不斷更新。請檢查版本號標籤以引用您正在使用的版本。

	
		
		Supported Tasks and Leaderboards
	


	
		
		Languages
	

此資料集涵蓋數百種語言和語言對，並按 ISO-639-1 語言組織。目前版本涵蓋以下語言。繁體中文、英文、日文、韓文、印尼文、越南文、泰文

	
		
		Dataset Structure
	


	
		
		Data Instances
	

資料以 , 分隔檔案中內容，具有三個欄位：指示、輸入和輸出。請注意，我們並不暗示平移方向，並認為資料集是對稱的並用作兩個方向的測試集。

	
		
		Data Splits… See the full description on the dataset page: https://huggingface.co/datasets/Heng666/MultiCCAligned-TW-Corpus.",https://huggingface.co/datasets/Heng666/MultiCCAligned-TW-Corpus,"['tw', 'en', 'ja', 'ko', 'id', 'vi', 'th', 'zh']",['translation'],['1M<n<10M']
shivendrra/consolidated-datasets,shivendrra,2024-02-03 05:55:31+00:00,2024-12-12 23:13:21+00:00,47,1,"['task_categories:text-generation', 'task_categories:summarization', 'language:en', 'language:hi', 'language:ja', 'language:fr', 'size_categories:100M<n<1B', 'format:text', 'modality:text', 'library:datasets', 'library:mlcroissant', 'region:us', 'textdataset', 'text', 'youtube', 'webscrapped data', 'youtube transcripts', 'llm training', 'transformer models']","
	
		
		Dataset Card for YouTubeTranscriptData
	


	
		
		Dataset Details
	


	
		
		Dataset Description
	


This dataset contains transcripts of around 167K youtube videos that include coding lectures, podcasts, interviews, news videos, commentary and song lyrics. Also there are multiple files that have been generated using webscrapping.

Curated by: Shivendra Singh
License: [none]


	
		
		Dataset Sources
	




Repository: SmallLanguageModel
Demo [optional]: [More Information Needed]… See the full description on the dataset page: https://huggingface.co/datasets/shivendrra/consolidated-datasets.",https://huggingface.co/datasets/shivendrra/consolidated-datasets,"['en', 'hi', 'ja', 'fr']","['text-generation', 'summarization']",['100M<n<1B']
llm-jp/hh-rlhf-12k-ja,llm-jp,2024-02-04 21:19:53+00:00,2024-02-04 21:45:59+00:00,30,14,"['language:ja', 'license:mit', 'size_categories:10K<n<100K', 'format:json', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","
	
		
		hh-rlhf-12k-ja
	

This repository provides a human preference dataset developed by LLM-jp, a collaborative project launched in Japan.
This dataset is a Japanese translation of a subset of hh-rlhf using DeepL.
This dataset consists of 12,000 entries randomly sampled from hh-rlhf. Specifically, it includes a random selection of 3,000 entries from the training splits of the four groups: harmless-base, helpful-base, helpful-online, and helpful-rejection-sampled. For more information on… See the full description on the dataset page: https://huggingface.co/datasets/llm-jp/hh-rlhf-12k-ja.",https://huggingface.co/datasets/llm-jp/hh-rlhf-12k-ja,['ja'],[],['10K<n<100K']
jaCappella/jaCappella,jaCappella,2024-02-07 02:04:13+00:00,2024-02-08 09:45:49+00:00,41,5,"['task_categories:audio-to-audio', 'language:ja', 'license:other', 'region:us', 'music', 'singing voice', 'a cappella']","
	
		
		jaCappella corpus : Japanese a cappella vocal ensemble corpus
	

The jaCappella corpus is a corpus of Japanese a cappella vocal ensembles.
It consists of musical scores of vocal ensemble songs and separate audio recordings of individual voice parts.
They were arranged from out-of-copyright Japanese children's songs.
All songs have six voice parts (lead vocal, soprano, alto, tenor, bass, and vocal percussion).
Trailer video

	
		
	
	
		Getting started
	


Download the data in the… See the full description on the dataset page: https://huggingface.co/datasets/jaCappella/jaCappella.",https://huggingface.co/datasets/jaCappella/jaCappella,['ja'],['audio-to-audio'],[]
WitchesSocialStream/misskey.io,WitchesSocialStream,2024-02-07 03:43:14+00:00,2025-07-08 11:28:22+00:00,40,3,"['task_categories:text-classification', 'task_categories:text-generation', 'task_categories:text-to-image', 'task_categories:text-to-video', 'language:ja', 'license:apache-2.0', 'region:us']","
	
		
		NOTICE
	

We have received a copyright notice regarding the contents of this dataset.
In response to this request and as an act of good faith, we have permanently deleted the entire dataset. As of this writing, all associated files have been removed from the Hugging Face Hub.
We apologize for any inconvenience this takedown may have caused.
- KaraKaraWitch
",https://huggingface.co/datasets/WitchesSocialStream/misskey.io,['ja'],"['text-classification', 'text-generation', 'text-to-image', 'text-to-video']",[]
Viet-Mistral/CulturaY,Viet-Mistral,2024-02-08 12:10:31+00:00,2024-03-30 23:07:37+00:00,35748,34,"['task_categories:text-generation', 'task_categories:fill-mask', 'task_ids:language-modeling', 'task_ids:masked-language-modeling', 'annotations_creators:no-annotation', 'language_creators:found', 'multilinguality:multilingual', 'source_datasets:original', 'language:af', 'language:ar', 'language:az', 'language:be', 'language:bg', 'language:bn', 'language:ca', 'language:cs', 'language:cy', 'language:da', 'language:de', 'language:el', 'language:en', 'language:eo', 'language:es', 'language:et', 'language:eu', 'language:fa', 'language:fi', 'language:fr', 'language:ga', 'language:gl', 'language:gu', 'language:hbs', 'language:he', 'language:hi', 'language:hu', 'language:hy', 'language:id', 'language:is', 'language:it', 'language:ja', 'language:ka', 'language:kk', 'language:kn', 'language:ko', 'language:ky', 'language:la', 'language:lt', 'language:lv', 'language:mk', 'language:ml', 'language:mn', 'language:mr', 'language:ms', 'language:mt', 'language:my', 'language:nb', 'language:ne', 'language:nl', 'language:nn', 'language:pa', 'language:pl', 'language:ps', 'language:pt', 'language:ro', 'language:ru', 'language:si', 'language:sk', 'language:sl', 'language:so', 'language:sq', 'language:sv', 'language:sw', 'language:ta', 'language:te', 'language:th', 'language:tl', 'language:tr', 'language:tt', 'language:uk', 'language:ur', 'language:uz', 'language:vi', 'language:zh', 'license:cc-by-4.0', 'size_categories:1B<n<10B', 'format:json', 'modality:text', 'library:datasets', 'library:dask', 'library:mlcroissant', 'library:polars', 'region:us']","
	
		
		CulturaY: A Large Cleaned Multilingual Dataset of 75 Languages
	


	
		
		Dataset Summary
	

From the team that brought you CulturaX, we present CulturaY, another substantial multilingual dataset of 15TB (uncompressed)/3TB (zstd-compressed) that applies the same dataset cleaning methodology to the HPLT v1.1 dataset. 
Please note that HPLT v1.2 has also been released and is an alternative verison with different cleaning methodolgies. 
This data was used in part to train our SOTA… See the full description on the dataset page: https://huggingface.co/datasets/Viet-Mistral/CulturaY.",https://huggingface.co/datasets/Viet-Mistral/CulturaY,"['af', 'ar', 'az', 'be', 'bg', 'bn', 'ca', 'cs', 'cy', 'da', 'de', 'el', 'en', 'eo', 'es', 'et', 'eu', 'fa', 'fi', 'fr', 'ga', 'gl', 'gu', 'hbs', 'he', 'hi', 'hu', 'hy', 'id', 'is', 'it', 'ja', 'ka', 'kk', 'kn', 'ko', 'ky', 'la', 'lt', 'lv', 'mk', 'ml', 'mn', 'mr', 'ms', 'mt', 'my', 'nb', 'ne', 'nl', 'nn', 'pa', 'pl', 'ps', 'pt', 'ro', 'ru', 'si', 'sk', 'sl', 'so', 'sq', 'sv', 'sw', 'ta', 'te', 'th', 'tl', 'tr', 'tt', 'uk', 'ur', 'uz', 'vi', 'zh']","['text-generation', 'fill-mask']",['1B<n<10B']
nlp-waseda/JMMLU,nlp-waseda,2024-02-09 12:19:13+00:00,2024-02-27 05:22:30+00:00,258,10,"['task_categories:multiple-choice', 'task_categories:question-answering', 'language:ja', 'license:cc-by-nc-nd-4.0', 'size_categories:1K<n<10K', 'arxiv:2009.03300', 'region:us', 'llm', 'evaluation', 'Japanese']","JMMLU is a four-choice question set consisting of Japanese-translated questions of a portion of MMLU (Translated questions) and questions based on unique Japanese cultural context (Japanese questions). It is designed to assess the performance of large language models in Japanese. JMMLU consists of 7,536 questions in the following 56 tasks (subjects).",https://huggingface.co/datasets/nlp-waseda/JMMLU,['ja'],"['multiple-choice', 'question-answering']",['1K<n<10K']
PeacefulData/HypoTranslate,PeacefulData,2024-02-10 05:29:14+00:00,2024-05-18 05:37:27+00:00,992,2,"['task_categories:text-generation', 'language:en', 'language:zh', 'language:ja', 'language:fr', 'language:es', 'language:it', 'language:pt', 'license:apache-2.0', 'size_categories:100K<n<1M', 'arxiv:2402.06894', 'region:us', 'generative translation', 'large language model', 'LLaMA']","This repo releases the HypoTranslate dataset in paper ""GenTranslate: Large Language Models are Generative Multilingual Speech and Machine Translators"".
Code: https://github.com/YUCHEN005/GenTranslate
Model: https://huggingface.co/PeacefulData/GenTranslate
Data: This repo
Filename format: [split]_[data_source]_[src_language_code]_[tgt_language_code]_[task]_[seamlessm4t_size].pt
e.g. train_fleurs_en_cy_st_large.pt
Note:

Language code look-up: Table 15 & 17 in… See the full description on the dataset page: https://huggingface.co/datasets/PeacefulData/HypoTranslate.",https://huggingface.co/datasets/PeacefulData/HypoTranslate,"['en', 'zh', 'ja', 'fr', 'es', 'it', 'pt']",['text-generation'],['100K<n<1M']
kunishou/J-ResearchCorpus,kunishou,2024-02-12 14:03:42+00:00,2024-03-16 07:55:08+00:00,19,32,"['language:ja', 'license:other', 'size_categories:1K<n<10K', 'format:json', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","
	
		
		J-ResearchCorpus
	

Update:  

2024/3/16言語処理学会第30回年次大会(NLP2024)を含む、論文 1,343 本のデータを追加
2024/2/25言語処理学会誌「自然言語処理」のうち CC-BY-4.0 で公開されている論文 360 本のデータを追加


	
		
		概要
	


CC-BY-* ライセンスで公開されている日本語論文や学会誌等から抜粋した高品質なテキストのデータセットです。言語モデルの事前学習や RAG 等でご活用下さい。
今後も CC-BY-* ライセンスの日本語論文があれば追加する予定です。


	
		
		データ説明
	


filename : 該当データのファイル名
text ： 日本語論文から抽出したテキストデータ
category : データソース
license : ライセンス
credit : クレジット


	
		
		データソース・ライセンス
	


テキスト総文字数 : 約 3,900 万文字


	
		
data source
num records
license
note… See the full description on the dataset page: https://huggingface.co/datasets/kunishou/J-ResearchCorpus.",https://huggingface.co/datasets/kunishou/J-ResearchCorpus,['ja'],[],['1K<n<10K']
Fumika/Wikinews-multilingual,Fumika,2024-02-12 22:02:39+00:00,2024-02-12 22:56:09+00:00,28,7,"['task_categories:text-classification', 'task_categories:feature-extraction', 'language:en', 'language:es', 'language:fr', 'language:de', 'language:pt', 'language:pl', 'language:it', 'language:zh', 'language:ru', 'language:ja', 'language:nl', 'language:sv', 'language:ta', 'language:sr', 'language:cs', 'language:ca', 'language:he', 'language:tr', 'language:fi', 'language:eo', 'language:el', 'language:hu', 'language:uk', 'language:no', 'language:ar', 'language:fa', 'language:ko', 'language:ro', 'language:bg', 'language:bs', 'language:li', 'language:sq', 'language:th', 'license:cc-by-2.5', 'size_categories:10K<n<100K', 'format:json', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'arxiv:2305.14256', 'region:us']","
	
		
		Wikinews - weakly aligned multilingual pararell sentence datasets
	

This dataset contains 15,200 multilingual WikiNews articles in 33 languages.
Out of 15,200 articles, 9,960 are non-English news and 5240 are English news.  All non-English news are linked to one of 5240 English news. Linked articles show the same event.
List of non-English languages are: Spanish, French, German, Portuguese, Polish, Italian, Chinese, Russian, Japanese, Dutch, Swedish, Tamil, Serbian, Czech, Catalan… See the full description on the dataset page: https://huggingface.co/datasets/Fumika/Wikinews-multilingual.",https://huggingface.co/datasets/Fumika/Wikinews-multilingual,"['en', 'es', 'fr', 'de', 'pt', 'pl', 'it', 'zh', 'ru', 'ja', 'nl', 'sv', 'ta', 'sr', 'cs', 'ca', 'he', 'tr', 'fi', 'eo', 'el', 'hu', 'uk', 'no', 'ar', 'fa', 'ko', 'ro', 'bg', 'bs', 'li', 'sq', 'th']","['text-classification', 'feature-extraction']",['10K<n<100K']
systemk/washi,systemk,2024-02-13 01:17:22+00:00,2024-03-06 03:16:54+00:00,6,1,"['task_categories:text-generation', 'language:ja', 'license:other', 'size_categories:10M<n<100M', 'format:parquet', 'modality:text', 'library:datasets', 'library:dask', 'library:mlcroissant', 'library:polars', 'region:us', 'nlp', 'pretrain', 'llm']","
	
		
		Washi (a kind of traditional Japanese paper)
	

This dataset is sampled from a subset of ja (Japanese) sourced from uonlp/CulturaX. 
Utilizing DSIR (Data Selection for Language Models via Importance Resampling), 
documents closest to the Japanese subset of csebuetnlp/xlsum and systemk/aozorabunko_chunked 
(cleaned data from the Aozora Bunko collection, containing modern Japanese literature in the public domain) were selected, 
comprising approximately 5% of the corpus.
We have noted a… See the full description on the dataset page: https://huggingface.co/datasets/systemk/washi.",https://huggingface.co/datasets/systemk/washi,['ja'],['text-generation'],['10M<n<100M']
hpprc/jawiki-slim,hpprc,2024-02-14 00:57:51+00:00,2024-04-10 14:02:00+00:00,10,2,"['language:ja', 'license:cc-by-sa-3.0', 'license:gfdl', 'size_categories:1M<n<10M', 'format:parquet', 'modality:text', 'library:datasets', 'library:dask', 'library:mlcroissant', 'library:polars', 'region:us']",,https://huggingface.co/datasets/hpprc/jawiki-slim,['ja'],[],['1M<n<10M']
AkiraChisaka/sizefetish-jp2cn-translated-text,AkiraChisaka,2024-02-14 02:03:13+00:00,2024-06-23 00:35:44+00:00,307,5,"['language:zh', 'language:ja', 'size_categories:10K<n<100K', 'format:text', 'modality:text', 'library:datasets', 'library:mlcroissant', 'region:us']",,https://huggingface.co/datasets/AkiraChisaka/sizefetish-jp2cn-translated-text,"['zh', 'ja']",[],['10K<n<100K']
ryota39/Aya_ja,ryota39,2024-02-14 08:03:42+00:00,2024-02-14 08:25:06+00:00,43,4,"['task_categories:question-answering', 'task_categories:text-generation', 'language:ja', 'license:apache-2.0', 'size_categories:1K<n<10K', 'format:json', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","
	
		
		Aya_ja
	



このデータセットはCohereForAI/aya_datasetの日本語インストラクションデータのみを抽出したデータセットです。
人手でアノテーションされた指示応答のペアが6,259件収録されています。

	
		
		pythonでの使用例
	

from datasets import load_dataset

aya_ja = load_dataset(
    ""ryota39/Aya_ja"",
    split='train',
    )


	
		
		例
	



[
    {
        ""inputs"": ""火縄銃の威力が全国に知られる事となった、１５７５年に織田・徳川連合軍が鉄砲隊を用いて武田勝頼率いる騎馬隊を破った戦いを何というでしょう？"",
        ""targets"": ""長篠の戦いです。"",
        ""language"": ""Japanese"",
        ""language_code"": ""jpn"",
        ""annotation_type"":… See the full description on the dataset page: https://huggingface.co/datasets/ryota39/Aya_ja.",https://huggingface.co/datasets/ryota39/Aya_ja,['ja'],"['question-answering', 'text-generation']",['1K<n<10K']
agomberto/DoCLayNet-large-wt-image,agomberto,2024-02-14 11:15:41+00:00,2024-02-14 11:21:20+00:00,69,0,"['task_categories:object-detection', 'task_categories:image-segmentation', 'task_categories:token-classification', 'task_ids:instance-segmentation', 'annotations_creators:crowdsourced', 'language:en', 'language:de', 'language:fr', 'language:ja', 'license:other', 'size_categories:10K<n<100K', 'format:parquet', 'modality:tabular', 'modality:text', 'library:datasets', 'library:dask', 'library:mlcroissant', 'library:polars', 'region:us', 'DocLayNet', 'COCO', 'PDF', 'IBM', 'Financial-Reports', 'Finance', 'Manuals', 'Scientific-Articles', 'Science', 'Laws', 'Law', 'Regulations', 'Patents', 'Government-Tenders', 'object-detection', 'image-segmentation', 'token-classification']","
	
		
		Dataset Card for DocLayNet large without image
	


	
		
		About this card (02/14/2024)
	


	
		
		Property and license
	

All information from this page but the content of this paragraph ""About this card (02/14/2025)"" has been copied/pasted from Dataset Card for DocLayNet.
DocLayNet is a dataset created by Deep Search (IBM Research) published under license CDLA-Permissive-1.0. 
I do not claim any rights to the data taken from this dataset and published on this page.

	
		
	
	
		Dataset… See the full description on the dataset page: https://huggingface.co/datasets/agomberto/DoCLayNet-large-wt-image.",https://huggingface.co/datasets/agomberto/DoCLayNet-large-wt-image,"['en', 'de', 'fr', 'ja']","['object-detection', 'image-segmentation', 'token-classification']",['10K<n<100K']
etrotta/kanji_embeddings,etrotta,2024-02-15 11:11:15+00:00,2024-02-16 00:35:41+00:00,11,0,"['language:ja', 'license:mit', 'size_categories:10K<n<100K', 'region:us']","This repository contains the embeddings used by https://huggingface.co/spaces/etrotta/kanji_lookup
The embeddings were generated by:

Generating synthetic Kanji images using multiple different fonts then
Encoding these images into using a Neural Network

For one example use case, you can use them to search for embeddings similar to handdrawn Kanji images as demonstrated in the space
The neural network used was the ViTModel encoder from https://huggingface.co/kha-white/manga-ocr-base
The… See the full description on the dataset page: https://huggingface.co/datasets/etrotta/kanji_embeddings.",https://huggingface.co/datasets/etrotta/kanji_embeddings,['ja'],[],['10K<n<100K']
hotchpotch/ms_marco_japanese,hotchpotch,2024-02-16 23:37:22+00:00,2024-02-20 09:32:51+00:00,22,0,"['language:ja', 'license:other', 'size_categories:1M<n<10M', 'format:parquet', 'modality:text', 'library:datasets', 'library:dask', 'library:mlcroissant', 'library:polars', 'region:us']","
	
		
		ms_marco_japanese
	


ms_marco の日本語翻訳データです。
翻訳には、google/madlad400-3b-mtを利用しています。
HuggingFace で公開されている、ms_marco と同等の構造で保存しています。
翻訳品質はそれほど高くありません。繁体字などが含まれるデータもあります。Google Translate API を用いて翻訳された、マルチリンガルms_marcoデータセットである、mMARCOの方が品質が高いです。そのため、このデータセットを利用の際は、他の翻訳データセットとの比較をお勧めします。
wellFormedAnswers カラムは翻訳していません
翻訳にかかった時間は、高速化のためsanthosh/madlad400-3b-ct2を利用し、対象のデータ約1000万文に対して RTX3090 で8日ほどでした。


	
		
	
	
		利用方法
	

from datasets import load_dataset

train_ds =… See the full description on the dataset page: https://huggingface.co/datasets/hotchpotch/ms_marco_japanese.",https://huggingface.co/datasets/hotchpotch/ms_marco_japanese,['ja'],[],['1M<n<10M']
Arabic-Clip/xtd_11,Arabic-Clip,2024-02-17 08:06:47+00:00,2024-08-11 09:23:11+00:00,159,3,"['task_categories:image-to-text', 'task_categories:text-to-image', 'language:ar', 'language:en', 'language:ru', 'language:it', 'language:es', 'language:ko', 'language:pl', 'language:tr', 'language:zh', 'language:de', 'language:fr', 'language:ja', 'size_categories:1K<n<10K', 'arxiv:2012.05107', 'region:us']","
	
		
		Dataset Summary
	

The expanded XTD-11 dataset, now including Arabic, enhances the original XTD collection. This dataset introduces a 1,000-image multi-lingual MSCOCO2014 caption to test multimodel in zeroshot image or text retrieval in 11 Languages.

	
		
		Dataset Details
	


	
		
		Citation
	

@misc{aggarwal2020zeroshot,
      title={Towards Zero-shot Cross-lingual Image Retrieval},
      author={Pranav Aggarwal and Ajinkya Kale},
      year={2020},
      eprint={2012.05107}… See the full description on the dataset page: https://huggingface.co/datasets/Arabic-Clip/xtd_11.",https://huggingface.co/datasets/Arabic-Clip/xtd_11,"['ar', 'en', 'ru', 'it', 'es', 'ko', 'pl', 'tr', 'zh', 'de', 'fr', 'ja']","['image-to-text', 'text-to-image']",['1K<n<10K']
mohamed-khalil/AnimeQuotes,mohamed-khalil,2024-02-18 18:26:50+00:00,2024-02-21 15:17:52+00:00,13,4,"['task_categories:text-generation', 'task_categories:text-classification', 'language:ja', 'license:apache-2.0', 'size_categories:10K<n<100K', 'format:parquet', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us', 'Quotes', 'Anime', 'AnimeQuotes', 'NLP']","
	
		
		Anime Quotes Dataset ― アニメの名言データセット🎐
	


Welcome to Anime Quotes Dataset


    
        
        
        
    



	
		
	
	
		Overview
	

This dataset contains a curated collection of inspiring and memorable quotes from various anime series, sourced from the Anime Motivation website. The quotes are stored as a list of dictionaries and can be easily accessed for analysis, research, or personal enjoyment.

	
	
	
		Data Format
	

Each entry in the dataset is represented by a dictionary… See the full description on the dataset page: https://huggingface.co/datasets/mohamed-khalil/AnimeQuotes.",https://huggingface.co/datasets/mohamed-khalil/AnimeQuotes,['ja'],"['text-generation', 'text-classification']",['10K<n<100K']
xezpeleta/ccmatrix,xezpeleta,2024-02-19 07:49:33+00:00,2024-02-19 07:56:12+00:00,36,0,"['task_categories:text2text-generation', 'task_categories:translation', 'annotations_creators:found', 'language_creators:found', 'multilinguality:multilingual', 'source_datasets:original', 'language:af', 'language:am', 'language:ar', 'language:ast', 'language:az', 'language:be', 'language:bg', 'language:bn', 'language:br', 'language:ca', 'language:ceb', 'language:cs', 'language:cy', 'language:da', 'language:de', 'language:el', 'language:en', 'language:eo', 'language:es', 'language:et', 'language:eu', 'language:fa', 'language:fi', 'language:fr', 'language:fy', 'language:ga', 'language:gd', 'language:gl', 'language:ha', 'language:he', 'language:hi', 'language:hr', 'language:hu', 'language:hy', 'language:id', 'language:ig', 'language:ilo', 'language:is', 'language:it', 'language:ja', 'language:jv', 'language:ka', 'language:kk', 'language:km', 'language:ko', 'language:la', 'language:lb', 'language:lg', 'language:lt', 'language:lv', 'language:mg', 'language:mk', 'language:ml', 'language:mr', 'language:ms', 'language:my', 'language:ne', 'language:nl', 'language:no', 'language:oc', 'language:om', 'language:or', 'language:pl', 'language:pt', 'language:ro', 'language:ru', 'language:sd', 'language:si', 'language:sk', 'language:sl', 'language:so', 'language:sq', 'language:sr', 'language:su', 'language:sv', 'language:sw', 'language:ta', 'language:tl', 'language:tr', 'language:tt', 'language:uk', 'language:ur', 'language:uz', 'language:vi', 'language:wo', 'language:xh', 'language:yi', 'language:yo', 'language:zh', 'language:zu', 'language:se', 'license:unknown', 'size_categories:100M<n<1B', 'arxiv:1911.04944', 'arxiv:1911.00359', 'arxiv:2010.11125', 'region:us', 'conditional-text-generation']","CCMatrix: Mining Billions of High-Quality Parallel Sentences on the WEB

We show that margin-based bitext mining in LASER's multilingual sentence space can be applied to
monolingual corpora of billions of sentences to produce high quality aligned translation data.
We use thirty-two snapshots of a curated common crawl corpus [1] totaling 69 billion unique sentences.
Using one unified approach for 80 languages, we were able to mine 10.8 billion parallel sentences,
out of which only 2.9 billion are aligned with English.

IMPORTANT: Please cite reference [2][3] if you use this data.

[1] Guillaume Wenzek, Marie-Anne Lachaux, Alexis Conneau, Vishrav Chaudhary, Francisco Guzmán, Armand Jouli
    and Edouard Grave, CCNet: Extracting High Quality Monolingual Datasets from Web Crawl Data

[2] Holger Schwenk, Guillaume Wenzek, Sergey Edunov, Edouard Grave and Armand Joulin,
    CCMatrix: Mining Billions of High-Quality Parallel Sentences on the WEB

[3] Angela Fan, Shruti Bhosale, Holger Schwenk, Zhiyi Ma, Ahmed El-Kishky, Siddharth Goyal, Mandeep Baines,
    Onur Celebi, Guillaume Wenzek, Vishrav Chaudhary, Naman Goyal, Tom Birch, Vitaliy Liptchinsky,
    Sergey Edunov, Edouard Grave, Michael Auli, and Armand Joulin.
    Beyond English-Centric Multilingual Machine Translation
    
90 languages, 1,197 bitexts
total number of files: 90
total number of tokens: 112.14G
total number of sentence fragments: 7.37G",https://huggingface.co/datasets/xezpeleta/ccmatrix,"['af', 'am', 'ar', 'ast', 'az', 'be', 'bg', 'bn', 'br', 'ca', 'ceb', 'cs', 'cy', 'da', 'de', 'el', 'en', 'eo', 'es', 'et', 'eu', 'fa', 'fi', 'fr', 'fy', 'ga', 'gd', 'gl', 'ha', 'he', 'hi', 'hr', 'hu', 'hy', 'id', 'ig', 'ilo', 'is', 'it', 'ja', 'jv', 'ka', 'kk', 'km', 'ko', 'la', 'lb', 'lg', 'lt', 'lv', 'mg', 'mk', 'ml', 'mr', 'ms', 'my', 'ne', 'nl', 'no', 'oc', 'om', 'or', 'pl', 'pt', 'ro', 'ru', 'sd', 'si', 'sk', 'sl', 'so', 'sq', 'sr', 'su', 'sv', 'sw', 'ta', 'tl', 'tr', 'tt', 'uk', 'ur', 'uz', 'vi', 'wo', 'xh', 'yi', 'yo', 'zh', 'zu', 'se']","['text2text-generation', 'translation']",['100M<n<1B']
Alex-Song/MSR-86K,Alex-Song,2024-02-19 08:14:26+00:00,2024-07-04 07:56:53+00:00,49,49,"['task_categories:automatic-speech-recognition', 'language:es', 'language:ko', 'language:en', 'language:fr', 'language:de', 'language:hi', 'language:vi', 'language:it', 'language:nl', 'language:pt', 'language:th', 'language:ru', 'language:id', 'language:ja', 'language:ar', 'license:cc-by-nc-nd-4.0', 'arxiv:2406.18301', 'region:us']","
	
		
		Dataset Card for MSR-86K
	


	
		
		Dataset Summary
	

MSR-86K is an evolving, large-scale multilingual corpus for speech recognition research. The corpus is derived from publicly accessible videos on YouTube, comprising 15 languages and a total of 86,300 hours of transcribed ASR data. We believe that such a large-scale corpus will propel the research in multilingual speech algorithms. MSR-86K doesn't own the copyright of the audios, the copyright remains with the original owners of… See the full description on the dataset page: https://huggingface.co/datasets/Alex-Song/MSR-86K.",https://huggingface.co/datasets/Alex-Song/MSR-86K,"['es', 'ko', 'en', 'fr', 'de', 'hi', 'vi', 'it', 'nl', 'pt', 'th', 'ru', 'id', 'ja', 'ar']",['automatic-speech-recognition'],[]
Henrychur/MMedC,Henrychur,2024-02-20 06:46:36+00:00,2024-07-25 11:29:07+00:00,122,31,"['language:en', 'language:zh', 'language:ja', 'language:fr', 'language:ru', 'language:es', 'language:ar', 'language:de', 'license:cc-by-nc-sa-4.0', 'size_categories:10B<n<100B', 'modality:text', 'arxiv:2402.13963', 'region:us', 'medical']","
	
		
		MMedC
	

💻Github Repo   🖨️arXiv Paper
The official pre-training dataset for ""Towards Building Multilingual Language Model for Medicine"".

	
		
		News
	


We add Arabic and German corpus to MMedC.


	
		
		Introduction
	

This repo contains MMedC, a multilingual medical corpus with 25.5 billion tokens. 

	
		
Language
Family
Filtering Content
Textbooks
Websites
Small-scale Dataset
TotAmt


		
English
Indo-European
6.56
4.00
0.00
0.00
10.56


Spanish
Indo-European
3.98
0.31
0.05
0.02… See the full description on the dataset page: https://huggingface.co/datasets/Henrychur/MMedC.",https://huggingface.co/datasets/Henrychur/MMedC,"['en', 'zh', 'ja', 'fr', 'ru', 'es', 'ar', 'de']",[],['10B<n<100B']
Henrychur/MMedBench,Henrychur,2024-02-20 08:31:50+00:00,2024-05-26 05:05:34+00:00,40,15,"['task_categories:question-answering', 'language:en', 'language:zh', 'language:ja', 'language:fr', 'language:ru', 'language:es', 'license:cc-by-nc-4.0', 'arxiv:2402.13963', 'region:us', 'medical']","
	
		
		MMedBench
	

💻Github Repo   🖨️arXiv Paper
The official benchmark for ""Towards Building Multilingual Language Model for Medicine"".

	
		
		Introduction
	

This repo contains MMedBench, a comprehensive multilingual medical benchmark comprising 45,048 QA pairs for training and 8,518 QA pairs for testing. Each sample includes a question, options, the correct answer, and a reference explanation for the selection of the correct answer.
To access the data, please download MMedBench.zip.… See the full description on the dataset page: https://huggingface.co/datasets/Henrychur/MMedBench.",https://huggingface.co/datasets/Henrychur/MMedBench,"['en', 'zh', 'ja', 'fr', 'ru', 'es']",['question-answering'],[]
hotchpotch/jaqket_cc,hotchpotch,2024-02-20 09:35:00+00:00,2024-02-20 09:43:45+00:00,13,1,"['task_categories:question-answering', 'language:ja', 'license:cc-by-sa-4.0', 'size_categories:1K<n<10K', 'format:parquet', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","
	
		
		JAQKET から CC-BY-SA のデータのみを含めたデータセット
	

AI王 公式配布データセット(JAQKET) で配布されているクイズデータのうち、ライセンスが　CC-BY-SA-4.0のデータのみを含めたデータセットです。

	
		
		謝辞
	

AI王の開催・クイズ作成等々をされた関係者の方々に、有益なデータセットの公開ありがとうございます。

	
		
		利用方法
	

from datasets import load_dataset

ds = load_dataset(""hotchpotch/jaqket_cc"")
ds[""aio_01_dev""][0]

#=> {'qid': 'QA20CAPR-0002',
 'question': '明治時代に西洋から伝わった「テーブル・ターニング」に起源を持つ占いの一種で、50音表などを記入した紙を置き、参加者全員の人差し指をコインに置いて行うのは何でしょう?',
 'answers': ['コックリさん'],
 'competition': '第1回AI王',
 'timestamp':… See the full description on the dataset page: https://huggingface.co/datasets/hotchpotch/jaqket_cc.",https://huggingface.co/datasets/hotchpotch/jaqket_cc,['ja'],['question-answering'],['1K<n<10K']
likaixin/MMCode,likaixin,2024-02-21 08:34:50+00:00,2024-09-23 05:33:29+00:00,96,13,"['task_categories:question-answering', 'task_categories:text-generation', 'language:en', 'language:ja', 'license:mit', 'size_categories:1K<n<10K', 'arxiv:2404.09486', 'region:us', 'code']","
    
    MMCode


MMCode Github Repo 

Note: Please find the files directly via the ""Files and versions"" panel. Preview is not available. 

	
		
	
	
		Dataset Description
	

MMCode is a multi-modal code generation dataset designed to evaluate the problem-solving skills of code language models in visually rich contexts (i.e. images). 
It contains 3,548 questions paired with 6,620 images, derived from real-world programming challenges across 10 code competition websites, with Python solutions… See the full description on the dataset page: https://huggingface.co/datasets/likaixin/MMCode.",https://huggingface.co/datasets/likaixin/MMCode,"['en', 'ja']","['question-answering', 'text-generation']",['1K<n<10K']
MasahiroKaneko/eagle,MasahiroKaneko,2024-02-22 03:15:08+00:00,2024-02-24 00:54:06+00:00,43,4,"['task_categories:text-generation', 'language:en', 'language:zh', 'language:fr', 'language:ko', 'language:de', 'language:es', 'language:ja', 'license:mit', 'size_categories:100K<n<1M', 'format:csv', 'modality:tabular', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","
	
		
		Eagle 🦅: Ethical Dataset Given from Real Interactions
	



	
		
		Introduction
	

This repository contains the Eagle dataset, which is an ethical dataset of real interactions between humans and ChatGPT. This dataset is created to evaluate social bias, opinion bias, toxic language, and morality in Large Language Models (LLMs).
If you use the Eagle dataset in your research, please cite the following:
@inproceedings{Eagle:arxiv:2024,
    title={Eagle: Ethical Dataset Given from Real… See the full description on the dataset page: https://huggingface.co/datasets/MasahiroKaneko/eagle.",https://huggingface.co/datasets/MasahiroKaneko/eagle,"['en', 'zh', 'fr', 'ko', 'de', 'es', 'ja']",['text-generation'],['100K<n<1M']
Prgckwb/shokujin-menu,Prgckwb,2024-02-23 14:04:06+00:00,2024-02-26 03:57:13+00:00,5,0,"['language:ja', 'size_categories:n<1K', 'format:csv', 'modality:tabular', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","
	
		
		Shokujinjp Menu
	

食神餃子王 (@Shokujinjp)のメニューデータです。

	
		
		Usage
	

import pandas as pd
from datasets import load_dataset

# Hugging Face Datasets 形式で読み込み
data = load_dataset(
    ""Prgckwb/shokujin-menu"",
    split=""train""
)
print(data[0])
# {
#     'id': 1,
#     'name': '麻婆豆腐',
#     'price': 650,
#     'category': '定食',
#     'day_start': None,
#     'day_end': None,
#     'can_weekday': None,
#     'description': '1番'
# }

# DataFrame 形式で読み込み
df = pd.read_csv(… See the full description on the dataset page: https://huggingface.co/datasets/Prgckwb/shokujin-menu.",https://huggingface.co/datasets/Prgckwb/shokujin-menu,['ja'],[],['n<1K']
kunishou/OpenMathInstruct-1-1.8m-ja,kunishou,2024-02-23 16:31:34+00:00,2024-02-24 18:29:28+00:00,119,12,"['language:ja', 'license:other', 'size_categories:1M<n<10M', 'format:json', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'arxiv:2402.10176', 'region:us']","OpenMathInstruct-1 を日本語に自動翻訳した商用利用可能な180万件の指示チューニングデータセットになります。  
OpenMathInstruct-1 は、GSM8K および MATH ベンチマーク トレーニングセットの question と Mixtral-8x7B モデルを使用して生成された solution のペアで構成される数学分野のデータセットです。solution は合成データですが GSM8K および MATH の解答と solution から導出した値が等しくなることを確認することで誤った solution を除外しています。データセットの詳細は論文をご覧下さい。
このデータセットの使用は、商用利用を許可するNVIDIA ライセンスによって管理されます。本データセットを再配布する場合は当該ライセンスを継承する必要があります。また、モデル学習に使用した場合は、モデルのライセンスは当該ライセンスに従う必要はないという認識です（ Nvidia の OpenMath-Mistral や OpenMath-CodeLlama も apache 2.0… See the full description on the dataset page: https://huggingface.co/datasets/kunishou/OpenMathInstruct-1-1.8m-ja.",https://huggingface.co/datasets/kunishou/OpenMathInstruct-1-1.8m-ja,['ja'],[],['1M<n<10M']
izhx/mewsli-x,izhx,2024-02-24 14:01:38+00:00,2024-02-25 02:29:26+00:00,48,1,"['task_categories:text-retrieval', 'task_ids:entity-linking-retrieval', 'language:af', 'language:ar', 'language:az', 'language:bg', 'language:bn', 'language:de', 'language:el', 'language:en', 'language:es', 'language:et', 'language:eu', 'language:fa', 'language:fi', 'language:fr', 'language:gu', 'language:he', 'language:hi', 'language:ht', 'language:hu', 'language:id', 'language:it', 'language:ja', 'language:jv', 'language:ka', 'language:kk', 'language:ko', 'language:lt', 'language:ml', 'language:mr', 'language:ms', 'language:my', 'language:nl', 'language:pa', 'language:pl', 'language:pt', 'language:qu', 'language:ro', 'language:ru', 'language:sw', 'language:ta', 'language:te', 'language:th', 'language:tl', 'language:tr', 'language:uk', 'language:ur', 'language:vi', 'language:wo', 'language:yo', 'language:zh', 'license:apache-2.0', 'size_categories:n<1K', 'modality:text', 'region:us']","I generated the dataset following mewsli-x.md#getting-started
and converted into different parts (see process.py):

ar/de/en/es/fa/ja/pl/ro/ta/tr/uk wikinews_mentions dev and test (from wikinews_mentions-dev/test.jsonl)
candidate entities of 50 languages (from candidate_set_entities.jsonl)
English wikipedia_pairs to fine-tune models (from wikipedia_pairs-dev/train.jsonl)

Raw data files are in raw.tar.gz, which contains:
[...] 535M Feb 24 22:06 candidate_set_entities.jsonl
[...] 9.8M Feb 24… See the full description on the dataset page: https://huggingface.co/datasets/izhx/mewsli-x.",https://huggingface.co/datasets/izhx/mewsli-x,"['af', 'ar', 'az', 'bg', 'bn', 'de', 'el', 'en', 'es', 'et', 'eu', 'fa', 'fi', 'fr', 'gu', 'he', 'hi', 'ht', 'hu', 'id', 'it', 'ja', 'jv', 'ka', 'kk', 'ko', 'lt', 'ml', 'mr', 'ms', 'my', 'nl', 'pa', 'pl', 'pt', 'qu', 'ro', 'ru', 'sw', 'ta', 'te', 'th', 'tl', 'tr', 'uk', 'ur', 'vi', 'wo', 'yo', 'zh']",['text-retrieval'],['n<1K']
litagin/reazon-speech-v2-clone,litagin,2024-02-25 13:47:58+00:00,2024-04-16 23:20:06+00:00,4665,10,"['task_categories:automatic-speech-recognition', 'language:ja', 'license:other', 'size_categories:10K<n<100K', 'format:webdataset', 'modality:audio', 'modality:text', 'library:datasets', 'library:webdataset', 'library:mlcroissant', 'region:us']","
	
		
		Reazon Speech v2 dataset mirror
	


	
		
		Original Dataset Source
	


Hugging Face Dataset Page: reazon-research/reazonspeech
Project Page: Reazon Research


	
		
		License
	

This dataset is a mirror of the original Reazon Speech v2 dataset, but on 🤗 server (so may be faster). This dataset is licensed under the CDLA-Sharing-1.0. The original dataset comes with the following restriction: 

TO USE THIS DATASET, YOU MUST AGREE THAT YOU WILL USE THE DATASET SOLELY FOR THE PURPOSE OF… See the full description on the dataset page: https://huggingface.co/datasets/litagin/reazon-speech-v2-clone.",https://huggingface.co/datasets/litagin/reazon-speech-v2-clone,['ja'],['automatic-speech-recognition'],['10K<n<100K']
aixsatoshi/cosmopedia-japanese-20k,aixsatoshi,2024-02-26 02:39:07+00:00,2024-03-03 15:23:54+00:00,20,7,"['language:ja', 'language:en', 'size_categories:10K<n<100K', 'format:json', 'modality:text', 'library:datasets', 'library:dask', 'library:mlcroissant', 'region:us']",,https://huggingface.co/datasets/aixsatoshi/cosmopedia-japanese-20k,"['ja', 'en']",[],['10K<n<100K']
Sugisaku8/SCRDataSet,Sugisaku8,2024-02-26 06:34:22+00:00,2024-02-26 06:56:11+00:00,6,0,"['task_categories:question-answering', 'language:ja', 'language:en', 'license:cc-by-nc-sa-4.0', 'size_categories:n<1K', 'format:json', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'doi:10.57967/hf/1814', 'region:us']","
	
		
		SCR Data Set
	


	
		
		Dataset Details
	

This dataset is for tuning already existing models for use in school settings.

	
		
		Dataset Details.
	


	
		
		Dataset Description
	

<! -- A longer summary of what this dataset is. -->.

	
		
		dataset source [optional] ** [more info needed] ** [more info needed] ** [more info needed
	

Based on data from Wikipedia or other sources,
constructed independently.

	
		
		Usage
	

Tuning of already published models

	
		
		Direct use
	

Tuning… See the full description on the dataset page: https://huggingface.co/datasets/Sugisaku8/SCRDataSet.",https://huggingface.co/datasets/Sugisaku8/SCRDataSet,"['ja', 'en']",['question-answering'],['n<1K']
JTBTechnology/taoyuan_travel_qa,JTBTechnology,2024-02-27 06:43:07+00:00,2024-03-26 15:04:49+00:00,23,0,"['task_categories:translation', 'language:zh', 'language:en', 'language:ja', 'language:ko', 'language:id', 'language:vi', 'language:th', 'license:apache-2.0', 'size_categories:10K<n<100K', 'format:parquet', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us', '台灣', '桃園捷運', '旅遊']","
	
		
		桃園捷運旅遊問答翻譯資料集
	

本專案包含六國語言，中英日韓印越泰
全程由語言模型 (GPT4) 產生合成數據(synthesis data)，每一組語言存在 2K 資料量。
",https://huggingface.co/datasets/JTBTechnology/taoyuan_travel_qa,"['zh', 'en', 'ja', 'ko', 'id', 'vi', 'th']",['translation'],['10K<n<100K']
kunishou/cosmopedia-100k-ja-preview,kunishou,2024-02-28 07:58:55+00:00,2024-03-05 23:30:38+00:00,12,4,"['language:ja', 'license:apache-2.0', 'size_categories:10K<n<100K', 'format:json', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","cosmopedia-100k のindex 20k ～ 100k を日本語に自動翻訳したデータになります（テキストが長すぎて翻訳エラーになったレコードは除外しています）。このデータセット自体は別作業者が取り組んでいる 0 ～ 20k の翻訳結果とマージ後に削除します。データセット自体は残しておきます。
",https://huggingface.co/datasets/kunishou/cosmopedia-100k-ja-preview,['ja'],[],['10K<n<100K']
alfredplpl/wikipedia-simple-ja-15k,alfredplpl,2024-02-29 03:23:53+00:00,2024-02-29 03:41:41+00:00,8,0,"['task_categories:summarization', 'language:ja', 'license:cc-by-sa-3.0', 'size_categories:10K<n<100K', 'format:parquet', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","
	
		
		Dataset Card for ""wikipedia-simple-ja-15k""
	

This dataset is made of hpprc/wikipedia-20240101 .
",https://huggingface.co/datasets/alfredplpl/wikipedia-simple-ja-15k,['ja'],['summarization'],['10K<n<100K']
alfredplpl/wikipedia-qa-ja-15k,alfredplpl,2024-02-29 03:23:58+00:00,2024-02-29 03:39:35+00:00,14,1,"['task_categories:question-answering', 'language:ja', 'license:cc-by-sa-3.0', 'size_categories:10K<n<100K', 'format:parquet', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","
	
		
		Dataset Card for ""wikipedia-qa-ja-15k""
	

This is made of hpprc/wikipedia-20240101 .
",https://huggingface.co/datasets/alfredplpl/wikipedia-qa-ja-15k,['ja'],['question-answering'],['10K<n<100K']
Kendamarron/jimba-instuction-1k-beta,Kendamarron,2024-02-29 15:23:48+00:00,2024-04-25 12:49:28+00:00,20,6,"['task_categories:text-generation', 'language:ja', 'license:apache-2.0', 'size_categories:1K<n<10K', 'format:parquet', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","cyberagent/calm2-7b-chatの出力を人手でチェック・修正することで作成した日本語Instructionデータセットです。
詳しくはこちらの記事を御覧ください。
https://zenn.dev/kendama/articles/dc727218a2eae6
",https://huggingface.co/datasets/Kendamarron/jimba-instuction-1k-beta,['ja'],['text-generation'],['1K<n<10K']
nu-dialogue/jmultiwoz,nu-dialogue,2024-02-29 15:38:29+00:00,2024-03-13 02:15:37+00:00,49,7,"['task_categories:text-generation', 'task_categories:text-classification', 'task_ids:dialogue-modeling', 'task_ids:parsing', 'annotations_creators:crowdsourced', 'language_creators:crowdsourced', 'multilinguality:monolingual', 'source_datasets:original', 'language:ja', 'license:cc-by-sa-4.0', 'size_categories:1K<n<10K', 'region:us']","JMultiWOZ is a large-scale Japanese multi-domain task-oriented dialogue dataset. The dataset is collected using 
the Wizard-of-Oz (WoZ) methodology, where two human annotators simulate the user and the system. The dataset contains 
4,246 dialogues across 6 domains, including restaurant, hotel, attraction, shopping, taxi, and weather. Available 
annotations include user goal, dialogue state, and utterances.",https://huggingface.co/datasets/nu-dialogue/jmultiwoz,['ja'],"['text-generation', 'text-classification']",['1K<n<10K']
alfredplpl/wikipedia-simple-ja-100k,alfredplpl,2024-02-29 20:22:28+00:00,2024-02-29 20:54:44+00:00,7,0,"['task_categories:summarization', 'language:ja', 'license:cc-by-sa-3.0', 'size_categories:100K<n<1M', 'format:parquet', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","
	
		
		Dataset Card for ""wikipedia-simple-ja-100k""
	


	
		
		Original Dataset
	


hpprc/wikipedia-20240101


	
		
		Procedure
	


Exract the first line of the title from the dataset.
Generate the answer by summizing the line using LLM:
Input RAG-like prompt to CALM 2 7B Chat.
Format the response.




	
		
		RAG-like Prompt
	

f""""""USER: {title}とはなんですか？次の文章を参考に一言でまとめてください。{text}
    ASSISTANT: """"""

",https://huggingface.co/datasets/alfredplpl/wikipedia-simple-ja-100k,['ja'],['summarization'],['100K<n<1M']
alfredplpl/wikipedia-qa-ja-100k,alfredplpl,2024-02-29 20:24:19+00:00,2024-02-29 21:05:11+00:00,14,3,"['task_categories:question-answering', 'language:ja', 'license:cc-by-sa-3.0', 'size_categories:100K<n<1M', 'format:parquet', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","
	
		
		Dataset Card for ""wikipedia-qa-ja-100k""
	


	
		
		Original Dataset
	


hpprc/wikipedia-20240101


	
		
		Procedure
	


Extract the first line of the title from the dataset.
Generate the answer by summizing the line using LLM:
Input RAG-like prompt to CALM 2 7B Chat.
Format the response.




	
		
		RAG-like Prompt
	

f""""""USER: {title}とはなんですか？次の文章を参考に一言でまとめてください。{text}
    ASSISTANT: """"""

",https://huggingface.co/datasets/alfredplpl/wikipedia-qa-ja-100k,['ja'],['question-answering'],['100K<n<1M']
uproai/chat-90k,uproai,2024-03-01 05:59:56+00:00,2024-03-01 06:28:38+00:00,8,5,"['task_categories:text-generation', 'language:en', 'language:ja', 'language:zh', 'license:openrail', 'size_categories:10K<n<100K', 'format:parquet', 'modality:tabular', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us', 'RP']","
	
		
		chat-90k v1.0
	

chat-90k is a dataset composed of role-play chat messages, featuring the following columns:
sender: message sender ID
aid: bot ID
kind: 1: user message, 2: bot message
content: message content


	
		
		Query with duckdb
	

import pandas as pd
import duckdb

localdatafile = 'messages.parquet'
df = duckdb.sql(f""select * from read_parquet('{localdatafile}')"").to_df()
df

more examples: colab
",https://huggingface.co/datasets/uproai/chat-90k,"['en', 'ja', 'zh']",['text-generation'],['10K<n<100K']
Verah/JParaCrawl-Filtered-English-Japanese-Parallel-Corpus,Verah,2024-03-01 06:17:09+00:00,2024-03-07 21:20:21+00:00,221,2,"['task_categories:translation', 'language:en', 'language:ja', 'license:other', 'size_categories:1M<n<10M', 'format:csv', 'modality:tabular', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","
	
		
		Introduction
	

This is a LLM-filtered set of the first 1M rows from ntt's JParaCrawl v3 large English-Japanese parallel corpus.
The original JParaCrawl corpus was put together by automated means - aligning Japanese texts with their apparent English translations that were found in-the-wild, on the internet.
Whilst manually browsing the original data, I noticed that there were obvious quality issues that made me anxious about using the dataset at all. Poorly aligned translations… See the full description on the dataset page: https://huggingface.co/datasets/Verah/JParaCrawl-Filtered-English-Japanese-Parallel-Corpus.",https://huggingface.co/datasets/Verah/JParaCrawl-Filtered-English-Japanese-Parallel-Corpus,"['en', 'ja']",['translation'],['1M<n<10M']
tohoku-nlp/abc-multiple-choice,tohoku-nlp,2024-03-02 03:58:25+00:00,2024-03-12 07:32:13+00:00,64,4,"['task_categories:multiple-choice', 'task_categories:question-answering', 'task_ids:multiple-choice-qa', 'multilinguality:monolingual', 'language:ja', 'size_categories:n<1K', 'format:csv', 'modality:tabular', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","
	
		
		abc-multiple-choice Dataset
	

abc-multiple-choice は、競技クイズの大会「abc」で使用された4択問題を元に作成された、多肢選択式の質問応答データセットです。
データセットの詳細については、下記の発表資料を参照してください。

鈴木正敏. 4択クイズを題材にした多肢選択式日本語質問応答データセットの構築. 言語処理学会第30回年次大会 (NLP2024) 併設ワークショップ 日本語言語資源の構築と利用性の向上 (JLR2024), 2024. [PDF]

下記の GitHub リポジトリで、本データセットを用いた評価実験のスクリプトを管理しています。

https://github.com/cl-tohoku/abc-multiple-choice


	
		
	
	
		ライセンス
	


本データセットのクイズ問題の著作権は abc/EQIDEN 実行委員会 に帰属します。
本データセットは研究目的での利用許諾を得ているものです。商用目的での利用は不可とします。

",https://huggingface.co/datasets/tohoku-nlp/abc-multiple-choice,['ja'],"['multiple-choice', 'question-answering']",['n<1K']
kunishou/HelpSteer-35k-ja,kunishou,2024-03-02 16:45:19+00:00,2024-03-03 10:10:54+00:00,7,3,"['language:ja', 'license:cc-by-4.0', 'size_categories:10K<n<100K', 'format:json', 'modality:tabular', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","NVIDIA が公開している SteerLM 向けのトライアルデータセット HelpSteerを日本語に自動翻訳したデータセットになります。SteerLM でのアライメントをお試ししたい際にご活用下さい。
SteerLM での LLM トレーニング方法については以下の URL を参考にして下さい。  

Announcing NVIDIA SteerLM : https://developer.nvidia.com/blog/announcing-steerlm-a-simple-and-practical-technique-to-customize-llms-during-inference
NeMo Aligner : https://github.com/NVIDIA/NeMo-Aligner  
SteerLM training user guide : https://docs.nvidia.com/nemo-framework/user-guide/latest/modelalignment/steerlm.html

[参考] SteerLM :… See the full description on the dataset page: https://huggingface.co/datasets/kunishou/HelpSteer-35k-ja.",https://huggingface.co/datasets/kunishou/HelpSteer-35k-ja,['ja'],[],['10K<n<100K']
hotchpotch/JQaRA,hotchpotch,2024-03-03 01:58:33+00:00,2025-01-20 08:47:35+00:00,329,19,"['task_categories:question-answering', 'language:ja', 'license:cc', 'size_categories:100K<n<1M', 'format:parquet', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","
	
		
		JQaRA : Japanese Question Answering with Retrieval Augmentation - 検索拡張(RAG)評価のための日本語 Q&A データセット
	

高性能な LLM の台頭に伴い、LLM を用いた質疑応答のユースケースが増加しています。しかしながら、LLM は質問に対して適切な回答する知識を有していないと、答えることができないだけでなく、誤った回答を返答するといった課題が存在します。この課題を解決する一つの手段として、LLM が外部の知識を参照して回答する「RAG（Retrieval-Augmented Generation・検索拡張生成）」の需要が高まっています。
そのため、LLM が RAG を用いた際に回答精度が上がるような情報を検索によって取得可能か評価するためのデータセット""JQaRA : Japanese Question Answering with Retrieval Augmentation - 検索拡張(RAG)評価のための日本語 Q&A データセット""を構築しました。なお JQaRA… See the full description on the dataset page: https://huggingface.co/datasets/hotchpotch/JQaRA.",https://huggingface.co/datasets/hotchpotch/JQaRA,['ja'],['question-answering'],['100K<n<1M']
aixsatoshi/cosmopedia-japanese-100k,aixsatoshi,2024-03-03 16:06:15+00:00,2024-03-03 16:20:35+00:00,23,6,"['language:ja', 'language:en', 'license:apache-2.0', 'size_categories:10K<n<100K', 'format:json', 'modality:text', 'library:datasets', 'library:dask', 'library:mlcroissant', 'region:us']","cosmopedia-japanese-20kのデータに、kunishou様から20k-100kをご提供いただけることになり100kまで拡大しました。　　
https://huggingface.co/datasets/kunishou/cosmopedia-100k-ja-preview　　
テキスト生成プロンプトの翻訳も含むデータは、上記レポジトリを確認してください。
",https://huggingface.co/datasets/aixsatoshi/cosmopedia-japanese-100k,"['ja', 'en']",[],['10K<n<100K']
NilanE/SmallParallelDocs-Ja_En-6k,NilanE,2024-03-04 21:04:01+00:00,2024-03-05 03:48:08+00:00,10,2,"['task_categories:translation', 'language:ja', 'language:en', 'license:apache-2.0', 'size_categories:1K<n<10K', 'format:json', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","This dataset contains document-length Japanese-English parallel texts from various sources.
The intended use case is for translation tasks.
The cumulative dataset is under an apache 2.0 license, but the sources differ on that account. If there are conflicts, assume the more restrictive clause takes priority (?)
I am unfamiliar with licenses in general, so if someone sees any issues with the licensing situation, please let me know.

	
		
		Metadata meaning:
	

source: self-explanatory… See the full description on the dataset page: https://huggingface.co/datasets/NilanE/SmallParallelDocs-Ja_En-6k.",https://huggingface.co/datasets/NilanE/SmallParallelDocs-Ja_En-6k,"['ja', 'en']",['translation'],['1K<n<10K']
aisc-team-c1/MMedBench,aisc-team-c1,2024-03-04 22:17:10+00:00,2024-03-05 01:43:13+00:00,36,1,"['task_categories:question-answering', 'language:en', 'language:zh', 'language:ja', 'language:fr', 'language:ru', 'language:es', 'license:cc-by-4.0', 'size_categories:10K<n<100K', 'format:json', 'modality:tabular', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'arxiv:2402.13963', 'region:us', 'medical']","This is a dataset repository made for the AISC class at Harvard Medical School. Please find the original dataset repository here: https://huggingface.co/datasets/Henrychur/MMedBench 

	
		
		MMedBench
	

💻Github Repo   🖨️arXiv Paper
The official benchmark for ""Towards Building Multilingual Language Model for Medicine"".

	
		
		Introduction
	

This repo contains MMedBench, a comprehensive multilingual medical benchmark comprising 45,048 QA pairs for training and 8,518 QA pairs for testing.… See the full description on the dataset page: https://huggingface.co/datasets/aisc-team-c1/MMedBench.",https://huggingface.co/datasets/aisc-team-c1/MMedBench,"['en', 'zh', 'ja', 'fr', 'ru', 'es']",['question-answering'],['10K<n<100K']
aisc-team-c2/MMedBench,aisc-team-c2,2024-03-05 01:26:13+00:00,2024-03-05 01:44:42+00:00,9,0,"['task_categories:question-answering', 'language:en', 'language:zh', 'language:ja', 'language:fr', 'language:ru', 'language:es', 'license:cc-by-4.0', 'size_categories:10K<n<100K', 'format:json', 'modality:tabular', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'arxiv:2402.13963', 'region:us', 'medical']","This is a dataset repository made for the AISC class at Harvard Medical School. Please find the original dataset repository here: https://huggingface.co/datasets/Henrychur/MMedBench 

	
		
		MMedBench
	

💻Github Repo   🖨️arXiv Paper
The official benchmark for ""Towards Building Multilingual Language Model for Medicine"".

	
		
		Introduction
	

This repo contains MMedBench, a comprehensive multilingual medical benchmark comprising 45,048 QA pairs for training and 8,518 QA pairs for testing.… See the full description on the dataset page: https://huggingface.co/datasets/aisc-team-c2/MMedBench.",https://huggingface.co/datasets/aisc-team-c2/MMedBench,"['en', 'zh', 'ja', 'fr', 'ru', 'es']",['question-answering'],['10K<n<100K']
fruits-music/fruits-music,fruits-music,2024-03-05 04:08:00+00:00,2024-08-28 01:48:28+00:00,14,4,"['language:ja', 'license:other', 'doi:10.57967/hf/1864', 'region:us', 'music', 'idol', 'singing voice', 'diarization']","
	
		
		🍈 🍒 🍇 FruitsMusic 🍉 🍊 🍓
	

Corpus of Fully Real Popular Idol-group Songs from YouTube Videos for Music Information Processing.


	
		
		FruitsMusic: A corpus of Japanese idol-group songs for singing information processing
	

This corpus comprises annotation of “who sings what and when” in Japanese idol-group songs uploaded to YouTube.

	
		
		Directory structures
	

fruits-music
 ├ singers.csv: List of singers
 ├ songs.csv: List of songs
 ├ json: Annotation files
 │ ├ AUm01.json… See the full description on the dataset page: https://huggingface.co/datasets/fruits-music/fruits-music.",https://huggingface.co/datasets/fruits-music/fruits-music,['ja'],[],[]
alfredplpl/wikipedia-qa-ja-500k,alfredplpl,2024-03-05 04:20:02+00:00,2024-03-05 04:26:27+00:00,11,7,"['task_categories:question-answering', 'language:ja', 'license:cc-by-sa-3.0', 'size_categories:100K<n<1M', 'format:parquet', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","
	
		
		Dataset Card for ""wikipedia-qa-ja-500k""
	


	
		
		Original Dataset
	


hpprc/wikipedia-20240101


	
		
		Procedure
	


Extract the first line of the title from the dataset.
Generate the answer by summizing the line using LLM:
Input RAG-like prompt to CALM 2 7B Chat.
Format the response.




	
		
		RAG-like Prompt
	

f""""""USER: {title}とはなんですか？次の文章を参考に一言でまとめてください。{text}
    ASSISTANT: """"""

",https://huggingface.co/datasets/alfredplpl/wikipedia-qa-ja-500k,['ja'],['question-answering'],['100K<n<1M']
alfredplpl/wikipedia-simple-ja-500k,alfredplpl,2024-03-05 04:22:37+00:00,2024-03-05 04:25:22+00:00,12,1,"['task_categories:summarization', 'language:ja', 'license:cc-by-sa-3.0', 'size_categories:100K<n<1M', 'format:parquet', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","
	
		
		Dataset Card for ""wikipedia-simple-ja-500k""
	


	
		
		Original Dataset
	


hpprc/wikipedia-20240101


	
		
		Procedure
	


Exract the first line of the title from the dataset.
Generate the answer by summizing the line using LLM:
Input RAG-like prompt to CALM 2 7B Chat.
Format the response.




	
		
		RAG-like Prompt
	

f""""""USER: {title}とはなんですか？次の文章を参考に一言でまとめてください。{text}
    ASSISTANT: """"""

",https://huggingface.co/datasets/alfredplpl/wikipedia-simple-ja-500k,['ja'],['summarization'],['100K<n<1M']
Verah/tatoeba_dedupe_en-jp_2024-March-01,Verah,2024-03-05 13:46:13+00:00,2024-03-06 08:34:02+00:00,10,4,"['task_categories:translation', 'language:en', 'language:ja', 'license:cc-by-2.0', 'size_categories:100K<n<1M', 'format:csv', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","English - Japanese pairs taken from https://tatoeba.org/en/downloads and then deduplicated.
Row order has also been randomized to avoid clusters of similar translations.
",https://huggingface.co/datasets/Verah/tatoeba_dedupe_en-jp_2024-March-01,"['en', 'ja']",['translation'],['100K<n<1M']
mohamed-khalil/AnimeSongsLyrics,mohamed-khalil,2024-03-05 17:17:25+00:00,2024-03-05 18:02:39+00:00,40,4,"['task_categories:text-generation', 'task_categories:text-classification', 'language:ja', 'license:apache-2.0', 'size_categories:10K<n<100K', 'format:parquet', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us', 'music', 'anime', 'lyrics', 'Anime Songs Lyrics']","
    



	
		
		Anime Songs Lyrics Dataset ― アニメソングの歌詞データセット
	


Welcome to the Anime Songs Lyrics Dataset


    
        
        
        
    





	
		
	
	
		Overview
	

This dataset compiles a diverse collection of lyrics from various anime songs, providing a rich resource for enthusiasts and researchers alike. 
The lyrics information are structured in a Parquet file format named AnimeSongsLyrics.parquet, allowing efficient storage and retrieval of the dataset.
You find code of this… See the full description on the dataset page: https://huggingface.co/datasets/mohamed-khalil/AnimeSongsLyrics.",https://huggingface.co/datasets/mohamed-khalil/AnimeSongsLyrics,['ja'],"['text-generation', 'text-classification']",['10K<n<100K']
toshi456/llava-bench-in-the-wild-ja,toshi456,2024-03-06 21:56:53+00:00,2024-04-01 15:15:57+00:00,21,0,"['task_categories:image-to-text', 'language:ja', 'license:cc-by-4.0', 'size_categories:n<1K', 'format:json', 'modality:image', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","This dataset is the data that corrected the translation errors and untranslated data of the Japanese data in MBZUAI/multilingual-llava-bench-in-the-wild.
Original dataset is liuhaotian/llava-bench-in-the-wild.
",https://huggingface.co/datasets/toshi456/llava-bench-in-the-wild-ja,['ja'],['image-to-text'],['n<1K']
nu-dialogue/real-persona-chat,nu-dialogue,2024-03-07 02:56:18+00:00,2024-03-09 13:52:01+00:00,31,21,"['task_categories:text-generation', 'task_categories:text-classification', 'task_ids:dialogue-modeling', 'task_ids:dialogue-generation', 'language_creators:crowdsourced', 'multilinguality:monolingual', 'source_datasets:original', 'language:ja', 'license:cc-by-sa-4.0', 'size_categories:10K<n<100K', 'region:us', 'nlp', 'japanese', 'dialogue', 'dialogue-corpus', 'dialogue-system']",RealPersonaChat: A Realistic Persona Chat Corpus with Interlocutors' Own Personalities,https://huggingface.co/datasets/nu-dialogue/real-persona-chat,['ja'],"['text-generation', 'text-classification']",['10K<n<100K']
HPLT/hplt_monolingual_v1_2,HPLT,2024-03-07 19:30:56+00:00,2024-03-18 10:00:30+00:00,28,20,"['task_categories:text-generation', 'language:af', 'language:ar', 'language:az', 'language:be', 'language:bg', 'language:bn', 'language:ca', 'language:cs', 'language:cy', 'language:da', 'language:de', 'language:el', 'language:en', 'language:eo', 'language:es', 'language:et', 'language:eu', 'language:fa', 'language:fi', 'language:fr', 'language:ga', 'language:gl', 'language:gu', 'language:hbs', 'language:he', 'language:hi', 'language:hu', 'language:hy', 'language:id', 'language:is', 'language:it', 'language:ja', 'language:ka', 'language:kk', 'language:kn', 'language:ko', 'language:ky', 'language:la', 'language:lt', 'language:lv', 'language:mk', 'language:ml', 'language:mn', 'language:mr', 'language:ms', 'language:mt', 'language:my', 'language:nb', 'language:ne', 'language:nl', 'language:nn', 'language:pa', 'language:pl', 'language:ps', 'language:pt', 'language:ro', 'language:ru', 'language:si', 'language:sk', 'language:sl', 'language:so', 'language:sq', 'language:sv', 'language:sw', 'language:ta', 'language:te', 'language:th', 'language:tl', 'language:tr', 'language:tt', 'language:uk', 'language:ur', 'language:uz', 'language:vi', 'language:zh', 'license:cc0-1.0', 'size_categories:n>1T', 'region:us']","Data release 1.2 of the monolingual portion of HPLT (December 2023)

There are 75 languages in this release (22 TB of raw files, 11 TB of deduped files and 8.4 TB of clean files) provided as JSONL files compressed with zstd. For convenience, data is split into multiple shards, a few GB each. The number of shards per language depends on the size of the specific corpus.",https://huggingface.co/datasets/HPLT/hplt_monolingual_v1_2,"['af', 'ar', 'az', 'be', 'bg', 'bn', 'ca', 'cs', 'cy', 'da', 'de', 'el', 'en', 'eo', 'es', 'et', 'eu', 'fa', 'fi', 'fr', 'ga', 'gl', 'gu', 'hbs', 'he', 'hi', 'hu', 'hy', 'id', 'is', 'it', 'ja', 'ka', 'kk', 'kn', 'ko', 'ky', 'la', 'lt', 'lv', 'mk', 'ml', 'mn', 'mr', 'ms', 'mt', 'my', 'nb', 'ne', 'nl', 'nn', 'pa', 'pl', 'ps', 'pt', 'ro', 'ru', 'si', 'sk', 'sl', 'so', 'sq', 'sv', 'sw', 'ta', 'te', 'th', 'tl', 'tr', 'tt', 'uk', 'ur', 'uz', 'vi', 'zh']",['text-generation'],['n>1T']
Manirathinam21/Multi-lingual_Detection,Manirathinam21,2024-03-09 14:11:05+00:00,2024-03-09 14:13:32+00:00,7,0,"['task_categories:text-classification', 'language:ar', 'language:ta', 'language:ja', 'language:en', 'language:es', 'language:fr', 'language:de', 'license:mit', 'size_categories:10K<n<100K', 'format:csv', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']",,https://huggingface.co/datasets/Manirathinam21/Multi-lingual_Detection,"['ar', 'ta', 'ja', 'en', 'es', 'fr', 'de']",['text-classification'],['10K<n<100K']
alfredplpl/wikipedia-qa-ja-1m,alfredplpl,2024-03-10 15:31:10+00:00,2024-03-10 23:26:28+00:00,54,4,"['task_categories:question-answering', 'language:ja', 'license:cc-by-sa-3.0', 'size_categories:1M<n<10M', 'format:parquet', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","
	
		
		Dataset Card for ""wikipedia-qa-ja-1m""
	


	
		
		Original Dataset
	


hpprc/wikipedia-20240101


	
		
		Procedure
	


Extract the first line of the title from the dataset.
Generate the answer by summizing the line using LLM:
Input RAG-like prompt to CALM 2 7B Chat.
Format the response.




	
		
		RAG-like Prompt
	

f""""""USER: {title}とはなんですか？次の文章を参考に一言でまとめてください。{text}
    ASSISTANT: """"""

",https://huggingface.co/datasets/alfredplpl/wikipedia-qa-ja-1m,['ja'],['question-answering'],['1M<n<10M']
sbintuitions/JMTEB,sbintuitions,2024-03-11 04:54:13+00:00,2025-07-18 07:00:32+00:00,2490,18,"['task_categories:text-classification', 'task_categories:question-answering', 'task_categories:zero-shot-classification', 'task_categories:sentence-similarity', 'language:ja', 'license:cc-by-sa-4.0', 'size_categories:100M<n<1B', 'region:us']","
	
		
		JMTEB: Japanese Massive Text Embedding Benchmark
	

JMTEB is a benchmark for evaluating Japanese text embedding models. It consists of 5 tasks, currently involving 28 datasets in total. You can find the update history here.

	
		
		TL;DR
	

from datasets import load_dataset

dataset = load_dataset(""sbintuitions/JMTEB"", name=""<dataset_name>"", split=""<split>"")

JMTEB_DATASET_NAMES = (
    'livedoor_news',
    'mewsc16_ja',
    'sib200_japanese_clustering'… See the full description on the dataset page: https://huggingface.co/datasets/sbintuitions/JMTEB.",https://huggingface.co/datasets/sbintuitions/JMTEB,['ja'],"['text-classification', 'question-answering', 'zero-shot-classification', 'sentence-similarity']",['100M<n<1B']
kunishou/ApolloCorpus-ja,kunishou,2024-03-13 02:08:51+00:00,2024-03-13 17:55:25+00:00,16,4,"['language:ja', 'license:apache-2.0', 'size_categories:100K<n<1M', 'format:json', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'arxiv:2403.03640', 'region:us']","

	
		
		ApolloCorpus-ja
	


	
		
		概要
	

多言語医療データセットの ApolloCorpus を日本語に自動翻訳した 525k の指示チューニングデータセットになります。ApolloCorpus は、オープンソースでかつ品質を担保できるデータのみをスクリーニングし収集されたデータセットになります。詳細は 論文 をご覧下さい。  

	
		
		翻訳対象ファイル
	

データ量が多いのでひとまず以下の 1 ファイルのみを翻訳しました。なお、英語以外のデータセットについては翻訳品質が低くくなるため、英語データセットのみを日本語に自動翻訳しました（今後、他のファイルを追加で翻訳する場合も英語データのファイルのみを対象にすると思います）。  

medicalPaper_en_qa.json (525k)


	
		
		使用上の注意
	

多言語データセットを自動翻訳で日本語に翻訳したものであり、翻訳誤りも一部含まれています。医療領域での LLM に利用する際は十分注意した上で使用して下さい。  
",https://huggingface.co/datasets/kunishou/ApolloCorpus-ja,['ja'],[],['100K<n<1M']
systemk/culturax-ja-5k,systemk,2024-03-13 08:47:11+00:00,2024-03-18 02:08:48+00:00,6,0,"['language:ja', 'size_categories:1K<n<10K', 'format:parquet', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']",,https://huggingface.co/datasets/systemk/culturax-ja-5k,['ja'],[],['1K<n<10K']
occiglot/tokenizer-wiki-bench,occiglot,2024-03-13 14:49:07+00:00,2024-04-23 21:00:00+00:00,4802,6,"['language:af', 'language:ar', 'language:bg', 'language:ca', 'language:cs', 'language:da', 'language:de', 'language:el', 'language:en', 'language:es', 'language:et', 'language:eu', 'language:fa', 'language:fi', 'language:fr', 'language:ga', 'language:he', 'language:hi', 'language:hr', 'language:hu', 'language:hy', 'language:id', 'language:it', 'language:ja', 'language:ko', 'language:lt', 'language:lv', 'language:mr', 'language:nl', 'language:no', 'language:pl', 'language:pt', 'language:ro', 'language:ru', 'language:sa', 'language:sk', 'language:sl', 'language:sr', 'language:sv', 'language:ta', 'language:te', 'language:tr', 'language:uk', 'language:ur', 'language:vi', 'license:mit', 'size_categories:10M<n<100M', 'format:parquet', 'modality:text', 'library:datasets', 'library:dask', 'library:mlcroissant', 'library:polars', 'arxiv:2012.15613', 'region:us']","
	
		
		Multilingual Tokenizer Benchmark
	

This dataset includes pre-processed wikipedia data for tokenizer evaluation in 45 languages. We provide more information on the evaluation task in general this blogpost.

	
		
		Usage
	

The dataset allows us to easily calculate tokenizer fertility and the proportion of continued words on any of the supported languages. In the example below we take the Mistral tokenizer and evaluate its performance on Slovak. 
from transformers import AutoTokenizer… See the full description on the dataset page: https://huggingface.co/datasets/occiglot/tokenizer-wiki-bench.",https://huggingface.co/datasets/occiglot/tokenizer-wiki-bench,"['af', 'ar', 'bg', 'ca', 'cs', 'da', 'de', 'el', 'en', 'es', 'et', 'eu', 'fa', 'fi', 'fr', 'ga', 'he', 'hi', 'hr', 'hu', 'hy', 'id', 'it', 'ja', 'ko', 'lt', 'lv', 'mr', 'nl', 'no', 'pl', 'pt', 'ro', 'ru', 'sa', 'sk', 'sl', 'sr', 'sv', 'ta', 'te', 'tr', 'uk', 'ur', 'vi']",[],['10M<n<100M']
sudy-super/piece-of-refined-oscar,sudy-super,2024-03-13 15:02:54+00:00,2024-04-06 20:00:51+00:00,9,7,"['task_categories:text-generation', 'language:ja', 'license:apache-2.0', 'size_categories:1M<n<10M', 'format:json', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","
	
		
		Descrption
	

This dataset is part of the OSCAR-2301 cleaned.
There are about 0.5b tokens counted by calm2 tokenizer.

	
		
		NOTE
	

This dataset has not passed sentence end boundary determination or Perplexity Filtering, so there is room for improvement in quality.
",https://huggingface.co/datasets/sudy-super/piece-of-refined-oscar,['ja'],['text-generation'],['1M<n<10M']
dichmau/ja_vi_translation,dichmau,2024-03-13 17:52:50+00:00,2024-04-08 19:35:06+00:00,6,2,"['task_categories:translation', 'language:ja', 'language:vi', 'size_categories:1M<n<10M', 'format:json', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","Japanese-Vietnamese Translated Sentence Pairs.
",https://huggingface.co/datasets/dichmau/ja_vi_translation,"['ja', 'vi']",['translation'],['1M<n<10M']
zhongshsh/CLoT-Oogiri-GO,zhongshsh,2024-03-14 14:41:41+00:00,2024-03-19 08:55:53+00:00,130,30,"['task_categories:visual-question-answering', 'task_categories:question-answering', 'language:en', 'language:zh', 'language:ja', 'license:mit', 'size_categories:100K<n<1M', 'modality:image', 'arxiv:2312.02439', 'region:us']","
   




	
		
		Oogiri-GO Dataset Card
	

Project Page | Paper | Code | Model
Data discription: Oogiri-GO is a multimodal and multilingual humor dataset, and contains more than 130,000 Oogiri samples in English (en.jsonl), Chinese (cn.jsonl), and Japanese (jp.jsonl).  Notably,  in Oogiri-GO, 77.95% of samples are annotated with human preferences, namely the number of likes, indicating the popularity of a response. As illustrated in Fig. 1,  Oogiri-GO contains three types of Oogiri games… See the full description on the dataset page: https://huggingface.co/datasets/zhongshsh/CLoT-Oogiri-GO.",https://huggingface.co/datasets/zhongshsh/CLoT-Oogiri-GO,"['en', 'zh', 'ja']","['visual-question-answering', 'question-answering']",['100K<n<1M']
angelmmiguel/synthetic-introduction-extraction,angelmmiguel,2024-03-16 10:00:21+00:00,2024-03-18 15:34:41+00:00,19,1,"['task_categories:feature-extraction', 'language:es', 'language:en', 'language:fr', 'language:ru', 'language:ja', 'license:mit', 'size_categories:10K<n<100K', 'format:json', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us', 'code']",,https://huggingface.co/datasets/angelmmiguel/synthetic-introduction-extraction,"['es', 'en', 'fr', 'ru', 'ja']",['feature-extraction'],['10K<n<100K']
p1atdev/manga_line_generation,p1atdev,2024-03-18 17:47:17+00:00,2024-03-18 17:55:42+00:00,9,2,"['task_categories:image-to-text', 'language:ja', 'license:unknown', 'size_categories:n<1K', 'format:parquet', 'modality:image', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","
	
		
		Manga Line Generation dataset
	

Converted from https://github.com/1never/MangaLineGeneration.
Paper: https://aclanthology.org/2023.paclic-1.34.pdf
",https://huggingface.co/datasets/p1atdev/manga_line_generation,['ja'],['image-to-text'],['n<1K']
MiyazonoKaori137/Anime-Audio,MiyazonoKaori137,2024-03-19 03:11:07+00:00,2024-03-19 06:46:07+00:00,10,1,"['language:ja', 'license:apache-2.0', 'region:us']",,https://huggingface.co/datasets/MiyazonoKaori137/Anime-Audio,['ja'],[],[]
hpprc/en-ja-align,hpprc,2024-03-19 06:12:37+00:00,2024-03-20 09:17:55+00:00,44,3,"['task_categories:translation', 'language:en', 'language:ja', 'license:other', 'size_categories:10K<n<100K', 'region:us']","
	
		
		en-ja-align
	

日英対訳文対応付けデータ(内山ら, 2003)として公開されている日英対訳文データセットです。
本リポジトリはデータセットのダウンロード・解析・前処理のみを行うスクリプトを提供しているものであり、データの再配布はしておりません。

	
		
		Usage
	

データセットの前処理に下記のライブラリを使用します。
データの使用前にインストールをお願いいたします。
pip install bs4 lxml

使用例は以下のとおりです。

import datasets as ds

dataset = ds.load_dataset(""hpprc/en-ja-align"", num_proc=16, trust_remote_code=True)

print(dataset)
# DatasetDict({
#     train: Dataset({
#         features: ['id', 'en', 'ja', 'source'],
#         num_rows: 42738
#     })
# })… See the full description on the dataset page: https://huggingface.co/datasets/hpprc/en-ja-align.",https://huggingface.co/datasets/hpprc/en-ja-align,"['en', 'ja']",['translation'],['10K<n<100K']
hatakeyama-llm-team/japanese2010,hatakeyama-llm-team,2024-03-20 00:39:02+00:00,2024-03-21 00:26:06+00:00,124,2,"['language:ja', 'size_categories:1M<n<10M', 'format:parquet', 'modality:text', 'library:datasets', 'library:dask', 'library:mlcroissant', 'library:polars', 'region:us']","
	
		
		日本語ウェブコーパス2010
	


こちらのデータをhuggingfaceにアップロードしたものです｡
2009 年度における著作権法の改正（平成21年通常国会　著作権法改正等について | 文化庁）に基づき，情報解析研究への利用に限って利用可能です｡
形態素解析を用いて､自動で句点をつけました｡
変換コード
変換スクリプト
形態素解析など



",https://huggingface.co/datasets/hatakeyama-llm-team/japanese2010,['ja'],[],['1M<n<10M']
hpprc/tanaka-corpus,hpprc,2024-03-21 01:49:50+00:00,2024-03-21 12:50:28+00:00,21,8,"['task_categories:translation', 'language:ja', 'language:en', 'license:cc-by-4.0', 'size_categories:100K<n<1M', 'format:parquet', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","HF Datasets version of Tanaka Corpus.

	
		
		Preprocess for HF Datasets
	

以下の内容でオリジナルデータを前処理しました。
wget ftp://ftp.edrdg.org/pub/Nihongo/examples.utf.gz
gunzip examples.utf.gz

import re
from pathlib import Path

from more_itertools import chunked

import datasets as ds

data = []
with Path(""examples.utf"").open() as f:
    for row, _ in chunked(f, 2):
        ja, en, idx = re.findall(r""A: (.*?)\t(.*?)#ID=(.*$)"", row)[0]
        data.append(
            {
                ""id"": idx… See the full description on the dataset page: https://huggingface.co/datasets/hpprc/tanaka-corpus.",https://huggingface.co/datasets/hpprc/tanaka-corpus,"['ja', 'en']",['translation'],['100K<n<1M']
hpprc/alt-parallel-en-ja,hpprc,2024-03-21 02:24:27+00:00,2024-03-21 12:40:15+00:00,17,3,"['task_categories:translation', 'language:en', 'language:ja', 'license:cc-by-4.0', 'size_categories:10K<n<100K', 'format:parquet', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","
	
		
		Asian Language Treebank (ALT) Project
	

ALT Parallel Corpusのうち、日英対訳部分のみを抽出したデータセットです。
処理元のデータとしては、HuggingFace上のhttps://huggingface.co/datasets/altを利用しています。

	
		
		Citation
	

@inproceedings{riza2016introduction,
  title={Introduction of the asian language treebank},
  author={Riza, Hammam and Purwoadi, Michael and Uliniansyah, Teduh and Ti, Aw Ai and Aljunied, Sharifah Mahani and Mai, Luong Chi and Thang, Vu Tat and Thai, Nguyen Phuong and Chea, Vichet and Sam, Sethserey and others}… See the full description on the dataset page: https://huggingface.co/datasets/hpprc/alt-parallel-en-ja.",https://huggingface.co/datasets/hpprc/alt-parallel-en-ja,"['en', 'ja']",['translation'],['10K<n<100K']
felixludos/babel-briefings,felixludos,2024-03-21 16:24:26+00:00,2024-03-29 20:53:36+00:00,214,6,"['task_categories:text-classification', 'task_categories:translation', 'task_categories:zero-shot-classification', 'task_categories:feature-extraction', 'task_categories:text-generation', 'language:en', 'language:es', 'language:de', 'language:fr', 'language:zh', 'language:ar', 'language:pt', 'language:bg', 'language:cs', 'language:el', 'language:he', 'language:hu', 'language:id', 'language:it', 'language:ja', 'language:ko', 'language:lt', 'language:lv', 'language:nl', 'language:no', 'language:pl', 'language:ro', 'language:ru', 'language:sk', 'language:sl', 'language:sr', 'language:sv', 'language:th', 'language:tr', 'language:uk', 'license:cc-by-nc-sa-4.0', 'size_categories:1M<n<10M', 'format:json', 'modality:image', 'modality:text', 'library:datasets', 'library:dask', 'library:mlcroissant', 'arxiv:2403.19352', 'region:us', 'news', 'headlines', 'business', 'science', 'technology', 'sports', 'health', 'entertainment']","
	
		
		Babel Briefings News Headlines Dataset README
	


Break Free from the Language Barrier

Version: 1 - Date: 30 Oct 2023
Collected and Prepared by Felix Leeb (Max Planck Institute for Intelligent Systems, Tübingen, Germany)
License: Babel Briefings Headlines Dataset © 2023 by Felix Leeb is licensed under CC BY-NC-SA 4.0 
Check out our paper on arxiv.
This dataset contains 4,719,199 news headlines across 30 different languages collected between 8 August 2020 and 29 November 2021. The… See the full description on the dataset page: https://huggingface.co/datasets/felixludos/babel-briefings.",https://huggingface.co/datasets/felixludos/babel-briefings,"['en', 'es', 'de', 'fr', 'zh', 'ar', 'pt', 'bg', 'cs', 'el', 'he', 'hu', 'id', 'it', 'ja', 'ko', 'lt', 'lv', 'nl', 'no', 'pl', 'ro', 'ru', 'sk', 'sl', 'sr', 'sv', 'th', 'tr', 'uk']","['text-classification', 'translation', 'zero-shot-classification', 'feature-extraction', 'text-generation']",['1M<n<10M']
sudy-super/JetCopper-10B,sudy-super,2024-03-21 17:21:08+00:00,2024-12-26 20:55:50+00:00,11,5,"['language:ja', 'language:en', 'language:code', 'license:apache-2.0', 'size_categories:10M<n<100M', 'format:parquet', 'modality:text', 'library:datasets', 'library:dask', 'library:mlcroissant', 'library:polars', 'region:us']","
	
		
		JetCopper-10B
	


	
		
		Description
	

JetCopper-10B was created by extracting a portion of the data after cleaning, filtering, and deduplicating the following datasets.

The japanese subset of C4
The japanese subset of CC-100
The japanese subset of OSCAR-2301
The japanese subset of HPLT Datasets v1.2
wiki40b-ja

This dataset was used to pre-train Contrail-200m-64k when we participated in LOCAL AI HACKATHON #000.

	
		
		The number of tokens (Using tokenizer of calm2-chat)… See the full description on the dataset page: https://huggingface.co/datasets/sudy-super/JetCopper-10B.",https://huggingface.co/datasets/sudy-super/JetCopper-10B,"['ja', 'en', 'code']",[],['10M<n<100M']
yuiseki/sake_qa,yuiseki,2024-03-23 05:15:57+00:00,2024-03-23 05:19:17+00:00,12,3,"['language:ja', 'license:mit', 'size_categories:1K<n<10K', 'format:parquet', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']",,https://huggingface.co/datasets/yuiseki/sake_qa,['ja'],[],['1K<n<10K']
hotchpotch/JaCWIR,hotchpotch,2024-03-23 05:57:57+00:00,2025-01-20 08:44:59+00:00,39,6,"['language:ja', 'license:other', 'size_categories:100K<n<1M', 'format:parquet', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","
	
		
		JaCWIR: Japanese Casual Web IR - 日本語情報検索評価のための小規模でカジュアルなWebタイトルと概要のデータセット
	

近年、大規模言語モデル（LLM）の台頭により、一般的な日本語を用いた自然な検索クエリで質問するユースケースが増えています。しかしながら、多様なジャンルの Web 記事に対して、ユーザーの質問に適切に答えられるような情報検索システムを評価するための日本語データセットは十分ではありません。
JaCWIR は、5000の質問文と、約50万のWebページのタイトル・Webページ冒頭文もしくは概要(meta descriptionなど)で構成される短いデータの小規模な日本語の情報検索の評価データセットです。質問文は、50万Webページのどれかを元に作成しており、そのデータを質問文の正例としています。
データ元には日本最大級のソーシャルブックマークサービスである、はてなブックマークから収集した RSS 情報を元にフィルタリングし、様々な Web… See the full description on the dataset page: https://huggingface.co/datasets/hotchpotch/JaCWIR.",https://huggingface.co/datasets/hotchpotch/JaCWIR,['ja'],[],['100K<n<1M']
cl-nagoya/nu-snli,cl-nagoya,2024-03-23 09:39:01+00:00,2024-03-29 04:50:36+00:00,18,0,"['task_categories:text-classification', 'task_ids:natural-language-inference', 'task_ids:multi-input-text-classification', 'multilinguality:bilingual', 'source_datasets:snli', 'source_datasets:extended|other-flicker-30k', 'source_datasets:extended|other-visual-genome', 'language:ja', 'language:en', 'license:cc-by-sa-4.0', 'size_categories:100K<n<1M', 'format:parquet', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","
	
		
		Translation Code
	

We used vLLM for a faster, batched generation.
import datasets as ds
from vllm import LLM, SamplingParams, RequestOutput
from transformers import AutoTokenizer


model_path = ""hoge/fuga""

dataset: ds.Dataset = ds.load_dataset(""snli"", split=""train"")

llm = LLM(
    model=model_path,
    quantization=None,
    dtype=""bfloat16"",
    tensor_parallel_size=4,
    enforce_eager=True,
)

tokenizer = AutoTokenizer.from_pretrained(model_path)

# temperature must be 0 when… See the full description on the dataset page: https://huggingface.co/datasets/cl-nagoya/nu-snli.",https://huggingface.co/datasets/cl-nagoya/nu-snli,"['ja', 'en']",['text-classification'],['100K<n<1M']
cl-nagoya/nu-mnli,cl-nagoya,2024-03-23 10:28:03+00:00,2024-03-29 04:51:12+00:00,34,2,"['task_categories:text-classification', 'task_ids:natural-language-inference', 'task_ids:multi-input-text-classification', 'multilinguality:bilingual', 'source_datasets:nyu-mll/multi_nli', 'language:ja', 'language:en', 'license:cc-by-3.0', 'license:cc-by-sa-3.0', 'license:mit', 'license:other', 'size_categories:100K<n<1M', 'format:parquet', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","
	
		
		Translation Code
	

We used vLLM for a faster, batched generation.
import datasets as ds
from vllm import LLM, SamplingParams, RequestOutput
from transformers import AutoTokenizer


model_path = ""hoge/fuga""

dataset: ds.Dataset = ds.load_dataset(""nyu-mll/multi_nli"", split=""train"")
dataset = dataset.select_columns([""premise"", ""hypothesis"", ""label"", ""genre""])

llm = LLM(
    model=model_path,
    quantization=None,
    dtype=""bfloat16"",
    tensor_parallel_size=4,
    enforce_eager=True… See the full description on the dataset page: https://huggingface.co/datasets/cl-nagoya/nu-mnli.",https://huggingface.co/datasets/cl-nagoya/nu-mnli,"['ja', 'en']",['text-classification'],['100K<n<1M']
aixsatoshi/Chat-with-cosmopedia,aixsatoshi,2024-03-24 07:45:02+00:00,2024-03-28 14:36:58+00:00,25,3,"['language:ja', 'license:apache-2.0', 'size_categories:1K<n<10K', 'format:json', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","Reasoning、知識、会話の掛け合いなどの情報密度が高いマルチターンの会話データです。
利用データセット日本語化cosmopedia日本語化cosmopedia  
から作成した合成データセットです。
Example1  


ユーザー: 数学をもっと身近に感じるためには、どのような取り組みが必要でしょうか？
アシスタント: 数学を身近に感じるためには、適切な年齢層に合わせた教材やビデオ記録を利用することが効果的です。たとえば、MoMathなどの組織は、年齢に応じたコンテンツと戦略的なビデオ記録を利用することで、数学への参加を阻む障壁を取り除いています。これにより、STEM分野への幅広い参加が可能になり、かつてはエリート主義的なトピックを生み出すことで、将来の発見と革新の肥沃な土壌を作り出すことができます。
ユーザー: ビデオ記録がなぜ数学教育において重要なのでしょうか？
アシスタント:… See the full description on the dataset page: https://huggingface.co/datasets/aixsatoshi/Chat-with-cosmopedia.",https://huggingface.co/datasets/aixsatoshi/Chat-with-cosmopedia,['ja'],[],['1K<n<10K']
notoxicpeople/japan_diet_q_and_a_sessions_20k,notoxicpeople,2024-03-25 04:43:52+00:00,2024-03-27 06:47:31+00:00,11,1,"['multilinguality:monolingual', 'language:ja', 'license:mit', 'size_categories:10K<n<100K', 'format:json', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","
	
		
		Japan Diet Q&A Sessions Dataset
	


	
		
		Summary
	


This dataset was created by scraping the parliamentary questions and answers webpage. 
As of March 27, 2024, it includes 216 sessions.


	
		
		Data Fields
	


id: Consists of three parts. 
The initial alphabet indicates whether it is a question (a) or an answer (b).
The next three digits represent the session number of the parliament.
The last three digits are the question number within the parliament session.


title: The title… See the full description on the dataset page: https://huggingface.co/datasets/notoxicpeople/japan_diet_q_and_a_sessions_20k.",https://huggingface.co/datasets/notoxicpeople/japan_diet_q_and_a_sessions_20k,['ja'],[],['10K<n<100K']
quchenyuan/360x_dataset_LR,quchenyuan,2024-03-25 16:06:14+00:00,2025-01-06 15:16:37+00:00,31,8,"['language:en', 'language:zh', 'language:fr', 'language:ja', 'language:es', 'license:cc-by-nc-sa-4.0', 'arxiv:2404.00989', 'region:us', 'Multimedia', 'Panoramic', 'Video', 'Multi-viewpoint']","
	
		
		360+x Dataset
	

For more information, please feel free to check our project page.

	
		
		Overview
	

360+x dataset introduces a unique panoptic perspective to scene understanding, differentiating itself from traditional
datasets by offering multiple viewpoints and modalities, captured from a variety of scenes

	
		
		Key Features:
	


Multi-viewpoint Captures: Includes 360° panoramic video, third-person front view video, egocentric monocular
video, and egocentric binocular video.… See the full description on the dataset page: https://huggingface.co/datasets/quchenyuan/360x_dataset_LR.",https://huggingface.co/datasets/quchenyuan/360x_dataset_LR,"['en', 'zh', 'fr', 'ja', 'es']",[],[]
mpasila/ParallelFiction-Ja_En-100k-json,mpasila,2024-03-26 06:08:26+00:00,2025-08-07 11:44:40+00:00,9,4,"['task_categories:translation', 'language:ja', 'language:en', 'license:apache-2.0', 'size_categories:100K<n<1M', 'format:json', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","This is my conversion of NilanE/ParallelFiction-Ja_En-100k into json which can be read by text-generation-webui when training a model. (Updated to V2 of this dataset.)

	
		
		Original Dataset card
	


	
		
		Dataset details:
	

Each entry in this dataset is a sentence-aligned Japanese web novel chapter and English fan translation.
The intended use-case is for document translation tasks.

	
		
		Dataset format:
	

{
    'src': 'JAPANESE WEB NOVEL CHAPTER',
    'trg': 'CORRESPONDING ENGLISH… See the full description on the dataset page: https://huggingface.co/datasets/mpasila/ParallelFiction-Ja_En-100k-json.",https://huggingface.co/datasets/mpasila/ParallelFiction-Ja_En-100k-json,"['ja', 'en']",['translation'],['100K<n<1M']
mpasila/ParallelFiction-Ja_En-100k-alpaca,mpasila,2024-03-26 11:14:15+00:00,2025-08-07 11:54:31+00:00,16,3,"['task_categories:translation', 'language:ja', 'language:en', 'license:apache-2.0', 'size_categories:100K<n<1M', 'format:json', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","Don't use Alpaca and embrace ShareGPT here.
This is a modified version of NilanE/ParallelFiction-Ja_En-100k which has been turned into Alpaca format.

	
		
		Update no longer chunked!!!
	

This is the non chunked version. If you want the chunked version it's here for 4k context based on augmxnt/shisa-base-7b-v1 tokenizer.

	
		
		Dataset format (correct one)
	

{
  'instruction' : 'Japanese chapter'
  'output' : 'English translation'
  'input' : 'empty'
}


	
		
		Original Dataset card… See the full description on the dataset page: https://huggingface.co/datasets/mpasila/ParallelFiction-Ja_En-100k-alpaca.",https://huggingface.co/datasets/mpasila/ParallelFiction-Ja_En-100k-alpaca,"['ja', 'en']",['translation'],['100K<n<1M']
Kendamarron/pret-a-porter-instruction-v0.1,Kendamarron,2024-03-26 13:08:14+00:00,2024-04-01 04:30:44+00:00,10,1,"['language:ja', 'license:apache-2.0', 'size_categories:n<1K', 'format:parquet', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","
	
		
		データセットについて
	

オープンソースLLMの出力を人手でチェック・修正したinstructionにSwallow-MXでoutputを生成したデータセットです。
outputの精査は行っていないので、答えが間違っているデータが含まれます。
詳細についてはこちらをご覧ください。

	
		
		備考
	

Discordサーバー「ローカルLLMに向き合う会」とメタデータラボ株式会社が共同開催された「LOCAL AI HACKATHON #000」にて作成した成果物になります。
",https://huggingface.co/datasets/Kendamarron/pret-a-porter-instruction-v0.1,['ja'],[],['n<1K']
cl-nagoya/nu-snli-rev,cl-nagoya,2024-03-27 12:13:13+00:00,2024-11-15 15:53:11+00:00,8,1,"['language:ja', 'language:en', 'license:cc-by-sa-4.0', 'size_categories:100K<n<1M', 'format:parquet', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']",,https://huggingface.co/datasets/cl-nagoya/nu-snli-rev,"['ja', 'en']",[],['100K<n<1M']
cl-nagoya/auto-wiki-qa,cl-nagoya,2024-03-28 01:33:41+00:00,2024-09-13 01:45:16+00:00,292,24,"['task_categories:question-answering', 'language:ja', 'license:cc-by-sa-4.0', 'size_categories:1M<n<10M', 'format:parquet', 'modality:text', 'library:datasets', 'library:dask', 'library:mlcroissant', 'library:polars', 'arxiv:2409.07737', 'region:us']","
	
		
		AutoWikiQA
	

東工大が公開しているSwallow-MXを用いて、Wikipedia中のテキストを入力として「質問(query)」と「回答(answer)」を生成し、生成された質問と回答についてフィルタリングを行ったデータセットです。日本語のフリーなQAデータセットとしては2024年4月現在で最大規模となっています。
また、データの生成にはテンプレートなどのルールベース処理を入れていないため、既存データセットと比較して質問・回答の出力・形式が多様であることが特徴です。モデルに知識を教えるためのQAデータセットとしての利用や、検索拡張生成(Retrieval Augmented Generation: RAG)のための検索・埋め込みモデル開発への利用を想定しています。  

	
		
		Usage
	

import datasets as ds

dataset: ds.Dataset = ds.load_dataset(""cl-nagoya/auto-wiki-qa"", split=""train"")

print(dataset)
#… See the full description on the dataset page: https://huggingface.co/datasets/cl-nagoya/auto-wiki-qa.",https://huggingface.co/datasets/cl-nagoya/auto-wiki-qa,['ja'],['question-answering'],['1M<n<10M']
phonemetransformers/IPA-CHILDES,phonemetransformers,2024-03-28 10:32:58+00:00,2025-04-08 14:22:09+00:00,165,5,"['language:en', 'language:de', 'language:fr', 'language:es', 'language:nl', 'language:cmn', 'language:ja', 'language:yue', 'language:et', 'language:hr', 'language:da', 'language:eu', 'language:hu', 'language:tr', 'language:fa', 'language:is', 'language:id', 'language:ga', 'language:cy', 'language:ko', 'language:sv', 'language:nb', 'language:qu', 'language:ca', 'language:it', 'language:pt', 'language:ro', 'language:pl', 'size_categories:10M<n<100M', 'format:csv', 'modality:tabular', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'arxiv:2504.03036', 'arxiv:2504.03338', 'region:us', 'language modeling', 'cognitive modeling']","
	
		
		IPA-CHILDES Dataset
	

This dataset contains utterances downloaded from CHILDES which have been pre-processed and converted to a phonemic representation. Read the paper here. 

	
		
		Description
	


	
		
		Key Columns
	

The scripts used to create the dataset are available here. Many of the columns from CHILDES have been preserved as they are useful for experiments (e.g. number of morphemes, part-of-speech tags, etc.). The key columns added by the processing script are as follows:… See the full description on the dataset page: https://huggingface.co/datasets/phonemetransformers/IPA-CHILDES.",https://huggingface.co/datasets/phonemetransformers/IPA-CHILDES,"['en', 'de', 'fr', 'es', 'nl', 'cmn', 'ja', 'yue', 'et', 'hr', 'da', 'eu', 'hu', 'tr', 'fa', 'is', 'id', 'ga', 'cy', 'ko', 'sv', 'nb', 'qu', 'ca', 'it', 'pt', 'ro', 'pl']",[],['10M<n<100M']
aixsatoshi/Longcontext-aozora-summary,aixsatoshi,2024-03-29 11:09:15+00:00,2024-03-30 10:55:37+00:00,13,4,"['language:ja', 'license:cc', 'size_categories:1K<n<10K', 'format:json', 'modality:text', 'library:datasets', 'library:dask', 'library:mlcroissant', 'library:polars', 'region:us']","長文からの要約データセットです。
長文は以下の青空文庫データセットを利用しました。
globis-university/aozorabunko-clean

	
		
		License
	

CC BY 4.0
",https://huggingface.co/datasets/aixsatoshi/Longcontext-aozora-summary,['ja'],[],['1K<n<10K']
aixsatoshi/Longcontext-aozora-instruction,aixsatoshi,2024-03-29 11:35:09+00:00,2024-03-30 11:44:00+00:00,26,3,"['language:ja', 'license:cc', 'size_categories:1K<n<10K', 'format:json', 'modality:tabular', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","長文用のinstructionデータセットです。
長文は以下の青空文庫データセットを利用しました。
globis-university/aozorabunko-clean

	
		
		Limitation
	

このデータセットは、長文の質問応答スタイルを提示することを主な目的としています。質問応答の正誤についてのフィルタリングはあえて行っていません。
長文では一般に性能低下が認められるため困難なタスクとなります。フィルタリングすると困難なタスクのinstructionが消えてしまうためです。ファインチューニングで使用する場合は、チューニングする基盤モデルの性能によって、チューニング効果が大きく変わります。正答できるかどうかはモデルパラメータ、事前学習次第と考えられます。

	
		
		License
	

CC BY 4.0
",https://huggingface.co/datasets/aixsatoshi/Longcontext-aozora-instruction,['ja'],[],['1K<n<10K']
yuiseki/open2ch-livejupiter-qa,yuiseki,2024-03-30 01:16:03+00:00,2024-04-01 08:16:55+00:00,11,0,"['language:ja', 'size_categories:100K<n<1M', 'format:parquet', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']",,https://huggingface.co/datasets/yuiseki/open2ch-livejupiter-qa,['ja'],[],['100K<n<1M']
ttaront/filtered_clx,ttaront,2024-03-30 02:52:37+00:00,2024-03-30 12:37:32+00:00,7,0,"['language:en', 'language:ja', 'size_categories:100K<n<1M', 'modality:text', 'region:us']",,https://huggingface.co/datasets/ttaront/filtered_clx,"['en', 'ja']",[],['100K<n<1M']
litagin/ehehe-corpus,litagin,2024-03-30 10:00:54+00:00,2024-03-31 02:03:08+00:00,94,22,"['task_categories:text-to-speech', 'task_categories:audio-to-audio', 'task_categories:audio-classification', 'multilinguality:monolingual', 'language:ja', 'license:other', 'size_categories:10K<n<100K', 'format:audiofolder', 'modality:audio', 'modality:text', 'library:datasets', 'library:mlcroissant', 'region:us', 'laughter', 'audio', 'speech', 'japanese', 'anime', 'voice']","
	
		
		😁 Ehehe Corpus 🤣
	

Audio dataset of laughter performed by Japanese voice actors
日本語はこちら
このデータセットは、著作権法第三十条の四の情報解析（機械学習等）の目的でのみ使用が許可されています。それ以外の用途での使用はライセンスにより禁止されています。
This dataset is only permitted for use under Article 30-4 of the Copyright Law of Japan for data analysis (such as machine learning) purposes. Any use for purposes other than those specified is prohibited by the license.

	
	
	
		Dataset Summary
	


A high-quality dataset of all only laughter voice acting recordings… See the full description on the dataset page: https://huggingface.co/datasets/litagin/ehehe-corpus.",https://huggingface.co/datasets/litagin/ehehe-corpus,['ja'],"['text-to-speech', 'audio-to-audio', 'audio-classification']",['10K<n<100K']
aixsatoshi/Swallow-MX-chatbot-DPO,aixsatoshi,2024-03-31 06:42:39+00:00,2024-03-31 08:16:43+00:00,14,4,"['language:ja', 'license:cc-by-4.0', 'size_categories:1K<n<10K', 'format:json', 'modality:tabular', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","Chatbot Arena Conversationsの質問文から、aixsatoshi/Swallow-MX-8x7b-NVE-chatvector-Mixtral-instruct-v2を使用して応答文を作成しました
質問文は、以下のモデルのPrompt部分を使用しました
Chatbot Arena Conversations JA (calm2)
以下引用です。

指示文（prompt）はlmsys/chatbot_arena_conversationsのユーザ入力（CC-BY 4.0）を和訳したものです。これはChatbot Arenaを通して人間が作成した指示文であり、CC-BY 4.0で公開されているものです。複数ターンの対話の場合は最初のユーザ入力のみを使っています（そのため、このデータセットはすべて１ターンの対話のみになっております）。
和訳にはfacebookの翻訳モデル（MIT License）を使っています。

",https://huggingface.co/datasets/aixsatoshi/Swallow-MX-chatbot-DPO,['ja'],[],['1K<n<10K']
Kendamarron/jimba-instruction-simplify-200,Kendamarron,2024-03-31 12:14:17+00:00,2024-04-01 04:34:41+00:00,15,0,"['language:ja', 'license:apache-2.0', 'size_categories:n<1K', 'format:parquet', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'arxiv:2304.12244', 'region:us']","
	
		
		データセットについて
	

Kendamarron/jimba-instuction-1k-betaのinstructionのうち200個をより単純なタスクに書き換えたデータセットです。
『Wizard LM』のIn-depth evolvingを再現するために作成しました。
将来的にはもう少しレコード数を増やしたいと考えています。
詳細についてはこちらをご覧ください。

	
		
		備考
	

Discordサーバー「ローカルLLMに向き合う会」とメタデータラボ株式会社が共同開催された「LOCAL AI HACKATHON #000」にて作成した成果物になります。
",https://huggingface.co/datasets/Kendamarron/jimba-instruction-simplify-200,['ja'],[],['n<1K']
ayousanz/reazon-speech-v2-all-WAND-SNR-analyze,ayousanz,2024-03-31 14:13:56+00:00,2024-04-03 12:31:56+00:00,36,0,"['language:ja', 'license:cdla-sharing-1.0', 'size_categories:10M<n<100M', 'format:json', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","
	
		
		概要
	

 reazon-research/reazonspeech-v2[all]をWADA SNRにて音声品質の分析を行った結果です。
分析した結果を reazonspeech-all-wada-snr.jsonというjsonにて保存しました。
jsonのフォーマットは以下になっています
""ファイル名"": file_name,
""SNR値"": snr value,
""トランスクリプション"": transcription

以下jsonのデータをヒストグラムにしたものです

またWAND SNR値が100以上のデータの数は1208360です
	
		
		備考
	

こちらのデータ分析は、AiHUB様に計算リソースをご提供いただきました。
",https://huggingface.co/datasets/ayousanz/reazon-speech-v2-all-WAND-SNR-analyze,['ja'],[],['10M<n<100M']
Ego/jpflan-raw,Ego,2024-04-01 06:11:18+00:00,2024-04-03 00:25:15+00:00,32,0,"['task_categories:text-generation', 'language:ja', 'license:cc-by-sa-4.0', 'size_categories:1M<n<10M', 'format:arrow', 'modality:text', 'library:datasets', 'library:mlcroissant', 'region:us']","
	
		
		Description
	

This is a collection of raw data from ~40 Japanese open source downstream task datasets.This dataset was built with the intention of collecting high quality datasets which were not machine translated to and from Japanese.The templated version, which should be used to perform instruction finetuning on LLMs, can be found here.  

	
		
		Dataset format
	

As this is a collection of datasets, each one is categorized by task and can contain different amounts of information… See the full description on the dataset page: https://huggingface.co/datasets/Ego/jpflan-raw.",https://huggingface.co/datasets/Ego/jpflan-raw,['ja'],['text-generation'],['1M<n<10M']
toshi456/Rakuten-Alpaca-Data-32K,toshi456,2024-04-01 13:54:14+00:00,2024-04-01 14:09:35+00:00,12,1,"['task_categories:question-answering', 'language:ja', 'license:apache-2.0', 'size_categories:10K<n<100K', 'format:json', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","
	
		
		Dataset Card for ""Rakuten-Alpaca-Data-32K""
	


	
		
		Dataset Detail
	

Dataset Type: Rakuten-Alpaca-Data-32KはStanford Alpacaの手法を参考にRakuten/RakutenAI-7B-chatを使用して自動生成した日本語インストラクションデータです。
データ生成を行う際のSEEDデータには有志の方々が作成したseed_tasks_japanese.jsonlを利用させていただきました。
データの品質が低いため、何かしらの方法でフィルタリングして有益なデータのみ利用するのをおすすめします。
License: Apache license 2.0  

	
		
	
	
		Acknowledgement
	


Stanford Alpaca
Rakuten
seed_tasks_japanese.jsonl

",https://huggingface.co/datasets/toshi456/Rakuten-Alpaca-Data-32K,['ja'],['question-answering'],['10K<n<100K']
lawinstruct/lawinstruct,lawinstruct,2024-04-01 21:04:10+00:00,2024-04-03 17:04:06+00:00,167,27,"['task_categories:fill-mask', 'annotations_creators:other', 'language_creators:found', 'multilinguality:multilingual', 'source_datasets:original', 'language:bg', 'language:cs', 'language:da', 'language:de', 'language:el', 'language:en', 'language:es', 'language:et', 'language:fi', 'language:fr', 'language:ga', 'language:hr', 'language:hu', 'language:it', 'language:lt', 'language:lv', 'language:mt', 'language:nl', 'language:pl', 'language:pt', 'language:ro', 'language:sk', 'language:sl', 'language:sv', 'language:zh', 'language:ja', 'language:ko', 'license:mit', 'size_categories:10M<n<100M', 'arxiv:2404.02127', 'region:us']",LawInstruct is an instruction tuning dataset of multilingual legal documents.,https://huggingface.co/datasets/lawinstruct/lawinstruct,"['bg', 'cs', 'da', 'de', 'el', 'en', 'es', 'et', 'fi', 'fr', 'ga', 'hr', 'hu', 'it', 'lt', 'lv', 'mt', 'nl', 'pl', 'pt', 'ro', 'sk', 'sl', 'sv', 'zh', 'ja', 'ko']",['fill-mask'],['10M<n<100M']
ziozzang/osx_dictionary_translation_pairs,ziozzang,2024-04-02 03:57:54+00:00,2024-04-02 04:16:05+00:00,24,2,"['task_categories:translation', 'language:ko', 'language:en', 'language:cs', 'language:ar', 'language:nl', 'language:fi', 'language:fr', 'language:de', 'language:hu', 'language:hi', 'language:el', 'language:pl', 'language:id', 'language:it', 'language:pt', 'language:ru', 'language:vi', 'language:tr', 'language:te', 'language:es', 'language:zh', 'language:th', 'language:ja', 'size_categories:1M<n<10M', 'format:json', 'modality:text', 'library:datasets', 'library:dask', 'library:mlcroissant', 'region:us']","Apple's Internal dictionary extracted.

the pairs are word level example of translation pairs (usage case, or example pairs)
Original data are Human curated.
This can be used for make machine generated training data.

License

I have no claim of license.

Expected Usecase

This dataset is for simple test, tasks for translation case.


Pipeline example

feed as example. and LLM can generate translation pairs to better translation.

References

apple-peeler:… See the full description on the dataset page: https://huggingface.co/datasets/ziozzang/osx_dictionary_translation_pairs.",https://huggingface.co/datasets/ziozzang/osx_dictionary_translation_pairs,"['ko', 'en', 'cs', 'ar', 'nl', 'fi', 'fr', 'de', 'hu', 'hi', 'el', 'pl', 'id', 'it', 'pt', 'ru', 'vi', 'tr', 'te', 'es', 'zh', 'th', 'ja']",['translation'],['1M<n<10M']
ziozzang/multi-lang-translation-set,ziozzang,2024-04-02 04:32:16+00:00,2024-04-02 04:35:48+00:00,9,0,"['language:ar', 'language:ko', 'language:en', 'language:ja', 'language:id', 'language:de', 'language:pt', 'language:es', 'language:ru', 'language:fr', 'language:it', 'license:mit', 'region:us']","This is test datasets for multiple language translation.

Generated by Machine translation.

License

MIT.

",https://huggingface.co/datasets/ziozzang/multi-lang-translation-set,"['ar', 'ko', 'en', 'ja', 'id', 'de', 'pt', 'es', 'ru', 'fr', 'it']",[],[]
laihuiyuan/mCoT-MATH,laihuiyuan,2024-04-02 11:18:01+00:00,2025-02-07 09:01:15+00:00,38,7,"['language:sw', 'language:bn', 'language:te', 'language:th', 'language:ja', 'language:zh', 'language:ru', 'language:es', 'language:fr', 'language:de', 'language:en', 'license:apache-2.0', 'arxiv:2406.02301', 'region:us']","
	
		
		mCoT: Multilingual Instruction Tuning for Reasoning Consistency in Language Models
	

Paper: https://arxiv.org/abs/2406.02301
Code: https://github.com/laihuiyuan/mCoT
Model: https://huggingface.co/laihuiyuan/mCoT

	
		
		Introduction
	

Based on MetaMathQA and MathInstruct
, we use machine translation to compile mCoT-MATH, the first large-scale multilingual math CoT reasoning dataset containing around 6.3 million samples for 11 diverse languages.
We train a 7B parameter model mCoT for… See the full description on the dataset page: https://huggingface.co/datasets/laihuiyuan/mCoT-MATH.",https://huggingface.co/datasets/laihuiyuan/mCoT-MATH,"['sw', 'bn', 'te', 'th', 'ja', 'zh', 'ru', 'es', 'fr', 'de', 'en']",[],[]
ttaront/iz_mc4_jp,ttaront,2024-04-05 08:05:12+00:00,2024-04-05 12:26:56+00:00,8,0,"['language:ja', 'size_categories:10K<n<100K', 'format:parquet', 'modality:text', 'library:datasets', 'library:dask', 'library:mlcroissant', 'library:polars', 'region:us']",,https://huggingface.co/datasets/ttaront/iz_mc4_jp,['ja'],[],['10K<n<100K']
ttaront/cc_wet_v2,ttaront,2024-04-06 00:34:18+00:00,2024-04-06 01:06:09+00:00,4,0,"['language:ja', 'size_categories:1M<n<10M', 'format:parquet', 'modality:text', 'library:datasets', 'library:dask', 'library:mlcroissant', 'library:polars', 'region:us']",,https://huggingface.co/datasets/ttaront/cc_wet_v2,['ja'],[],['1M<n<10M']
ttaront/filtered_c4,ttaront,2024-04-06 03:50:28+00:00,2024-04-06 04:37:27+00:00,7,0,"['language:ja', 'size_categories:10K<n<100K', 'format:parquet', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']",,https://huggingface.co/datasets/ttaront/filtered_c4,['ja'],[],['10K<n<100K']
hpprc/mmarco-ja,hpprc,2024-04-07 04:17:03+00:00,2024-11-12 03:20:22+00:00,6,3,"['language:ja', 'size_categories:1M<n<10M', 'format:parquet', 'modality:text', 'library:datasets', 'library:dask', 'library:mlcroissant', 'library:polars', 'region:us']","mmarcoデータセットのquery--passageのペアについて、queryをkeyとして重複を削除したデータセットです。
元データ中のエンコーディング周りのミスの修正やNFKC正規化などの前処理を行ってあります。
dataset subsetのpos_idsおよびneg_ids中のidは、collectionsubsetのインデックス番号に対応しています。
したがって、collection[pos_id]のようにアクセスしてもらえれば所望のデータを得ることができます。
ライセンスは元データセットに従います。
",https://huggingface.co/datasets/hpprc/mmarco-ja,['ja'],[],['1M<n<10M']
hpprc/mqa-ja,hpprc,2024-04-07 06:23:02+00:00,2024-04-07 15:16:42+00:00,38,6,"['language:ja', 'license:cc0-1.0', 'size_categories:10M<n<100M', 'format:parquet', 'modality:text', 'library:datasets', 'library:dask', 'library:mlcroissant', 'library:polars', 'region:us']","mqaデータセットのquery--passageのペアについて重複を削除したデータセットです。
元データ中のノイジーなテキストのクリーニングやNFKC正規化などの前処理を行ってあります。
dataset subsetのpos_idsおよびneg_ids中のidは、collectionsubsetのインデックス番号に対応しています。
したがって、collection[pos_id]のようにアクセスしてもらえれば所望のデータを得ることができます。
ライセンスは元データセットに従います。
",https://huggingface.co/datasets/hpprc/mqa-ja,['ja'],[],['10M<n<100M']
hatakeyama-llm-team/CommonCrawlPDFJa,hatakeyama-llm-team,2024-04-09 06:40:01+00:00,2024-05-28 12:03:17+00:00,27,1,"['language:ja', 'license:odc-by', 'size_categories:100K<n<1M', 'format:parquet', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","
	
		
		Data extracted from CommonCrawlPDF
	


Japanese domain
Code is here


",https://huggingface.co/datasets/hatakeyama-llm-team/CommonCrawlPDFJa,['ja'],[],['100K<n<1M']
andrijdavid/jtruthful_qa,andrijdavid,2024-04-09 12:08:15+00:00,2024-04-10 22:32:53+00:00,51,0,"['task_categories:multiple-choice', 'task_categories:text-generation', 'task_categories:question-answering', 'task_ids:multiple-choice-qa', 'task_ids:language-modeling', 'task_ids:open-domain-qa', 'annotations_creators:expert-generated', 'language_creators:expert-generated', 'multilinguality:monolingual', 'language:ja', 'license:cc-by-nc-sa-4.0', 'size_categories:1K<n<10K', 'format:parquet', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'arxiv:2109.07958', 'region:us']","
	
		
		Dataset Card for jtruthful_qa
	


	
		
		Dataset Summary
	

JTruthfulQA is a Japanese iteration of TruthfulQA (Lin+, 2022). This particular dataset isn't a translation of the original TruthfulQA, but rather, it's been constructed from the ground up. The purpose of this benchmark is to gauge the truthfulness of a language model in its generation of responses to various questions. The benchmark encompasses a total of 604 questions, which are distributed across three categories: Fact… See the full description on the dataset page: https://huggingface.co/datasets/andrijdavid/jtruthful_qa.",https://huggingface.co/datasets/andrijdavid/jtruthful_qa,['ja'],"['multiple-choice', 'text-generation', 'question-answering']",['1K<n<10K']
turing-motors/LLaVA-v1.5-Instruct-620K-JA,turing-motors,2024-04-10 05:04:54+00:00,2024-04-12 09:18:42+00:00,15,7,"['task_categories:visual-question-answering', 'task_categories:question-answering', 'language:ja', 'license:cc-by-nc-4.0', 'size_categories:100K<n<1M', 'region:us']","
	
		
		Dataset Details
	

Dataset Type:Japanese LLaVA v1.5 Instruct 620K is a localized version of part of the original LLaVA v1.5 Visual Instruct 655K dataset. This version is translated into Japanese using DeepL API and is aimed at serving similar purposes in the context of Japanese language.
Resources for More Information:For information on the original dataset: LLaVA
License:Attribution-NonCommercial 4.0 International (CC BY-NC-4.0)The dataset should abide by the policy of OpenAI: OpenAI… See the full description on the dataset page: https://huggingface.co/datasets/turing-motors/LLaVA-v1.5-Instruct-620K-JA.",https://huggingface.co/datasets/turing-motors/LLaVA-v1.5-Instruct-620K-JA,['ja'],"['visual-question-answering', 'question-answering']",['100K<n<1M']
turing-motors/LLaVA-Pretrain-JA,turing-motors,2024-04-10 05:07:24+00:00,2024-04-12 09:15:37+00:00,36,4,"['task_categories:visual-question-answering', 'task_categories:question-answering', 'language:ja', 'license:other', 'size_categories:100K<n<1M', 'format:json', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","
	
		
		Dataset Details
	

Dataset Type:Japanese LLaVA Pretrain is a localized version of the original LLaVA Pretrain dataset. This version is translated into Japanese using DeepL API and is aimed at serving similar purposes in the context of Japanese language.
Resources for More Information:For information on the original dataset: LLaVA
License:License: Must comply with license of CC-3M, BLIP (if you use their synthetic caption).
CC-3M The dataset may be freely used for any purpose, although… See the full description on the dataset page: https://huggingface.co/datasets/turing-motors/LLaVA-Pretrain-JA.",https://huggingface.co/datasets/turing-motors/LLaVA-Pretrain-JA,['ja'],"['visual-question-answering', 'question-answering']",['100K<n<1M']
hpprc/jawiki-books,hpprc,2024-04-10 14:19:33+00:00,2024-09-13 11:13:12+00:00,11,2,"['language:ja', 'license:cc-by-sa-3.0', 'size_categories:10K<n<100K', 'format:parquet', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']",,https://huggingface.co/datasets/hpprc/jawiki-books,['ja'],[],['10K<n<100K']
hpprc/jawiki-wiktionary,hpprc,2024-04-11 04:49:52+00:00,2024-07-19 04:40:45+00:00,8,1,"['language:ja', 'license:cc-by-sa-3.0', 'size_categories:100K<n<1M', 'format:parquet', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']",,https://huggingface.co/datasets/hpprc/jawiki-wiktionary,['ja'],[],['100K<n<1M']
hpprc/jawiki-news,hpprc,2024-04-11 04:55:58+00:00,2024-04-11 13:02:00+00:00,25,2,"['language:ja', 'license:cc-by-sa-3.0', 'size_categories:1K<n<10K', 'format:parquet', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']",,https://huggingface.co/datasets/hpprc/jawiki-news,['ja'],[],['1K<n<10K']
talkbank/callhome,talkbank,2024-04-11 15:18:46+00:00,2024-04-28 19:53:45+00:00,696,32,"['language:en', 'language:ja', 'language:zh', 'language:de', 'language:es', 'license:cc-by-nc-sa-4.0', 'size_categories:n<1K', 'format:parquet', 'modality:audio', 'modality:text', 'library:datasets', 'library:dask', 'library:mlcroissant', 'library:polars', 'region:us', 'speaker-diarization', 'speaker-segmentation', 'voice-activity-detection']","
	
		
		Dataset Card for the Callhome dataset for speaker diarization
	

The CALLHOME Corpus is a collection of unscripted telephone conversations between native speakers in Chinese, English, German, Japanese and Spanish. 
This is a processed version of the original Callhome dataset from the TalkBank corpora taken from here. It contains subsets in Chinese, English, German, Japanese and Spanish: 

More information on the Chinese subset
More information on the English subset
More information on… See the full description on the dataset page: https://huggingface.co/datasets/talkbank/callhome.",https://huggingface.co/datasets/talkbank/callhome,"['en', 'ja', 'zh', 'de', 'es']",[],['n<1K']
turing-motors/Japanese-Heron-Bench,turing-motors,2024-04-12 01:54:01+00:00,2024-04-12 08:59:36+00:00,60,11,"['task_categories:visual-question-answering', 'language:ja', 'size_categories:n<1K', 'format:imagefolder', 'modality:image', 'library:datasets', 'library:mlcroissant', 'arxiv:2404.07824', 'region:us']","
	
		
		Japanese-Heron-Bench
	


	
		
		Dataset Description
	

Japanese-Heron-Bench is a benchmark for evaluating Japanese VLMs (Vision-Language Models). We collected 21 images related to Japan. We then set up three categories for each image: Conversation, Detail, and Complex, and prepared one or two questions for each category. The final evaluation dataset consists of 102 questions. Furthermore, each image is assigned one of seven subcategories: anime, art, culture, food, landscape, landmark… See the full description on the dataset page: https://huggingface.co/datasets/turing-motors/Japanese-Heron-Bench.",https://huggingface.co/datasets/turing-motors/Japanese-Heron-Bench,['ja'],['visual-question-answering'],['n<1K']
toramaru-u/kokoro-SosekiNatsume,toramaru-u,2024-04-12 08:45:41+00:00,2024-04-15 02:23:32+00:00,8,1,"['language:ja', 'size_categories:1K<n<10K', 'format:parquet', 'modality:tabular', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","
	
		
		Dataset Card for ""kokoro""
	

More Information needed
",https://huggingface.co/datasets/toramaru-u/kokoro-SosekiNatsume,['ja'],[],['1K<n<10K']
deepghs/anime_pictures_full,deepghs,2024-04-12 15:11:15+00:00,2025-09-23 20:54:41+00:00,562,9,"['task_categories:image-classification', 'task_categories:zero-shot-image-classification', 'task_categories:text-to-image', 'annotations_creators:no-annotation', 'source_datasets:anime-pictures', 'language:en', 'language:ja', 'language:ru', 'license:other', 'size_categories:100K<n<1M', 'region:us', 'art', 'anime', 'not-for-all-audiences']","
	
		
		Anime-Pictures Full Dataset
	

This is the full dataset of anime-pictures.net. And all the original images are maintained here.

	
		
		How to Painlessly Use This
	

Use cheesechaser to quickly get images from this repository.
Before using this code, you have to grant the access from this gated repository. And then set your personal HuggingFace token into HF_TOKEN environment variable to give the code authorization for this repository.
from cheesechaser.datapool import… See the full description on the dataset page: https://huggingface.co/datasets/deepghs/anime_pictures_full.",https://huggingface.co/datasets/deepghs/anime_pictures_full,"['en', 'ja', 'ru']","['image-classification', 'zero-shot-image-classification', 'text-to-image']",['100K<n<1M']
recursal/SuperWikiNEXT-32B,recursal,2024-04-13 04:03:06+00:00,2024-06-10 12:22:28+00:00,52,6,"['task_categories:text-generation', 'task_categories:fill-mask', 'task_ids:language-modeling', 'task_ids:masked-language-modeling', 'annotations_creators:no-annotation', 'language_creators:crowdsourced', 'multilinguality:multilingual', 'source_datasets:original', 'language:af', 'language:ar', 'language:ast', 'language:az', 'language:be', 'language:bg', 'language:bn', 'language:ca', 'language:ce', 'language:cs', 'language:cy', 'language:da', 'language:de', 'language:el', 'language:en', 'language:eo', 'language:es', 'language:et', 'language:eu', 'language:fa', 'language:fi', 'language:fr', 'language:gl', 'language:he', 'language:hi', 'language:hr', 'language:hu', 'language:hy', 'language:id', 'language:it', 'language:ja', 'language:ka', 'language:kk', 'language:ko', 'language:la', 'language:lt', 'language:lv', 'language:mk', 'language:ms', 'language:my', 'language:nl', 'language:nn', 'language:no', 'language:pl', 'language:pt', 'language:ro', 'language:ru', 'language:sh', 'language:sk', 'language:sl', 'language:sr', 'language:sv', 'language:ta', 'language:tg', 'language:th', 'language:tr', 'language:uk', 'language:ur', 'language:uz', 'language:vi', 'language:zh', 'license:cc-by-sa-3.0', 'size_categories:100K<n<1M', 'format:json', 'modality:text', 'library:datasets', 'library:dask', 'library:mlcroissant', 'library:polars', 'region:us']","
	
		
		Dataset Card for SuperWikiNEXT-32B
	


Waifu to catch your attention.

	
		
		Dataset Details
	


	
		
		Dataset Description
	

SuperWikipedia-NEXT is an enhanced version of the SuperWIKI dataset. Which SuperWIKI was born out of the thought of a better filtered Wikipedia while retaining markdowns. 
SuperWikipedia-NEXT contains ~32.44B Tokens (llama-2-7b-chat-tokenizer) / ~27.92B Tokens (RWKV Tokenizer) from approximately 60 ""High quality"" / ""Selected"" languages.

Curated by:… See the full description on the dataset page: https://huggingface.co/datasets/recursal/SuperWikiNEXT-32B.",https://huggingface.co/datasets/recursal/SuperWikiNEXT-32B,"['af', 'ar', 'ast', 'az', 'be', 'bg', 'bn', 'ca', 'ce', 'cs', 'cy', 'da', 'de', 'el', 'en', 'eo', 'es', 'et', 'eu', 'fa', 'fi', 'fr', 'gl', 'he', 'hi', 'hr', 'hu', 'hy', 'id', 'it', 'ja', 'ka', 'kk', 'ko', 'la', 'lt', 'lv', 'mk', 'ms', 'my', 'nl', 'nn', 'no', 'pl', 'pt', 'ro', 'ru', 'sh', 'sk', 'sl', 'sr', 'sv', 'ta', 'tg', 'th', 'tr', 'uk', 'ur', 'uz', 'vi', 'zh']","['text-generation', 'fill-mask']",['100K<n<1M']
Aratako/Rosebleu-1on1-Dialogues,Aratako,2024-04-13 13:14:55+00:00,2024-05-16 15:03:47+00:00,10,0,"['task_categories:text-generation', 'language:ja', 'license:apache-2.0', 'size_categories:n<1K', 'format:json', 'modality:text', 'library:datasets', 'library:dask', 'library:mlcroissant', 'region:us', 'not-for-all-audiences', 'nsfw']","
	
		
		Rosebleu-1on1-Dialogues
	

2025/05/17 3人での対話のデータを追加

	
		
		概要
	

@matsuxrさんが公開しているRosebleuデータセットのうち、1つのシーン中で1対1の会話が行われていレコード（登場人物が2人のみのもの）を抽出し、さらに各話者ごとの連続した発話をまとめ、データセットとしてまとめたものです。
データの提供者である青猫様、およびデータをまとめデータセットの形式で公開いただいた@matsuxrさんに感謝いたします。

	
		
		Rosebleuデータセットについて
	

元データセットから概要文を引用します。

Rosebleuブランドの代表を務められていた青猫様にご提供いただいた、… See the full description on the dataset page: https://huggingface.co/datasets/Aratako/Rosebleu-1on1-Dialogues.",https://huggingface.co/datasets/Aratako/Rosebleu-1on1-Dialogues,['ja'],['text-generation'],['n<1K']
Aratako/Rosebleu-1on1-Dialogues-RP,Aratako,2024-04-13 13:36:22+00:00,2024-07-21 05:38:19+00:00,12,15,"['task_categories:text-generation', 'language:ja', 'license:apache-2.0', 'size_categories:1K<n<10K', 'format:json', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us', 'not-for-all-audiences', 'nsfw']","
	
		
		Rosebleu-1on1-Dialogues-RP
	

2025/05/17 3人での対話のデータを追加&無駄な改行の削除
@matsuxrさんが公開しているRosebleuデータセットを加工したAratako/Rosebleu-1on1-Dialoguesを元に、キャラクターや作品の設定などを付け加えたうえで、ロールプレイ的な文脈になるように加工したデータセットです。
LLMのファインチューニングにおけるロールプレイングタスクの学習を想定しています。
OpenAI APIのようにroleとcontentのペアの形式となっており、tokenizer.apply_chat_template()によって簡単に各モデルのチャットテンプレートのデータセットへと変換可能です。

	
		
	
	
		データセットの詳細
	

各キャラの設定や各作品の世界観・あらすじなどをWikipediaやニコニコ大百科からまとめ、ロールプレイ向けにシステムメッセージへと埋め込んでいます。
現在、以下の2パターンのデータセットを用意してあります。主に地の文の処理方法が異なります。… See the full description on the dataset page: https://huggingface.co/datasets/Aratako/Rosebleu-1on1-Dialogues-RP.",https://huggingface.co/datasets/Aratako/Rosebleu-1on1-Dialogues-RP,['ja'],['text-generation'],['1K<n<10K']
litagin/reazon-speech-v2-denoised,litagin,2024-04-14 07:44:15+00:00,2024-04-16 23:17:49+00:00,41,15,"['task_categories:automatic-speech-recognition', 'task_categories:text-to-speech', 'language:ja', 'license:other', 'size_categories:10M<n<100M', 'region:us']","
	
		
		Reazon Speech v2 DENOISED
	


Reazon Speech v2の音声ファイルをUVRを使用してBGMやノイズ除去したこのデータセットのミラーです。
作者(のおそらく一人?)であるStardust-minusさんによるデータセットの説明:
Reazon-Speech2データセットは、現在UVRによって処理され公開されています。私は3674/4096ファイルの処理を完了しました。全データセットは8台のA800 GPUを使用して約10日間でクリーニングされました。




	
		
	
	
		English ver
	


This is a mirror of this dataset, which consits of audio files of Reazon Speech v2 denoised and background music removed using UVR.
Dataset description by (maybe? one of) the author(s) Stardust-minus:
The… See the full description on the dataset page: https://huggingface.co/datasets/litagin/reazon-speech-v2-denoised.",https://huggingface.co/datasets/litagin/reazon-speech-v2-denoised,['ja'],"['automatic-speech-recognition', 'text-to-speech']",['10M<n<100M']
lesserfield/fgo-story,lesserfield,2024-04-15 03:29:30+00:00,2024-04-15 03:36:56+00:00,13,3,"['task_categories:translation', 'language:en', 'language:ja', 'language:id', 'license:cc-by-2.0', 'size_categories:10K<n<100K', 'format:json', 'modality:text', 'library:datasets', 'library:dask', 'library:mlcroissant', 'region:us', 'story', 'conversation']",,https://huggingface.co/datasets/lesserfield/fgo-story,"['en', 'ja', 'id']",['translation'],['10K<n<100K']
waddledee/three_line_summarization_for_japanese_news_articles,waddledee,2024-04-15 07:34:42+00:00,2024-04-15 08:09:17+00:00,16,0,"['task_categories:summarization', 'language:ja', 'license:apache-2.0', 'size_categories:1K<n<10K', 'format:csv', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","ライブドアニュースコーパスの3行要約データセットです。
Llama v2向けのプロンプトを追加して成形してあります。
学習に利用する際は、 [R_START] [R_END] をspecial tokenとして追加することを推奨します。
Number of rows: 3,907 
Datasetは以下のリポジトリを利用してscrapeしました。
git@github.com:KodairaTomonori/ThreeLineSummaryDataset.git
",https://huggingface.co/datasets/waddledee/three_line_summarization_for_japanese_news_articles,['ja'],['summarization'],['1K<n<10K']
hpprc/emb,hpprc,2024-04-15 14:12:27+00:00,2024-09-13 01:51:47+00:00,2549,12,"['language:ja', 'license:other', 'size_categories:10M<n<100M', 'format:parquet', 'modality:tabular', 'modality:text', 'library:datasets', 'library:dask', 'library:mlcroissant', 'library:polars', 'arxiv:2409.07737', 'region:us']","still WIP

	
		
		Information
	


	
		
Name
Type
License (根拠)


		
MMARCO
Retrieval
Apache 2.0 (?)


Mr. TyDi
Retrieval
Apache 2.0


MIRACL
Retrieval
Apache 2.0


JaGovFaqs
QA
CC-BY-4.0


Auto Wiki QA
QA & Retrieval
CC-BY-SA-4.0


Auto Wiki QA Nemotron
QA & RetrievalCC-BY-SA-4.0


JCommonsenseQA
QA
CC-BY-SA-4.0


JSQuAD
QA & Retrieval
CC-BY-SA-4.0


Japanese Wikipedia Human Retrieval
QA & Retrieval
Apache 2.0


JQaRA (dev, unused)
QA
CC-BY-SA-4.0
JaQuAD
QA & Retrieval
CC-BY-SA-3.0


JSNLI
NLI… See the full description on the dataset page: https://huggingface.co/datasets/hpprc/emb.",https://huggingface.co/datasets/hpprc/emb,['ja'],[],['10M<n<100M']
davidstap/ted_talks,davidstap,2024-04-15 15:16:34+00:00,2024-04-16 15:00:08+00:00,56,3,"['task_categories:translation', 'annotations_creators:crowdsourced', 'language_creators:expert-generated', 'multilinguality:translation', 'language:ar', 'language:az', 'language:be', 'language:bg', 'language:bn', 'language:bs', 'language:cs', 'language:da', 'language:de', 'language:el', 'language:en', 'language:eo', 'language:es', 'language:et', 'language:eu', 'language:fa', 'language:fi', 'language:fr', 'language:gl', 'language:he', 'language:hi', 'language:hr', 'language:hu', 'language:hy', 'language:id', 'language:it', 'language:ja', 'language:ka', 'language:kk', 'language:ko', 'language:ku', 'language:lt', 'language:mk', 'language:mn', 'language:mr', 'language:ms', 'language:my', 'language:nb', 'language:nl', 'language:pl', 'language:pt', 'language:ro', 'language:ru', 'language:sk', 'language:sl', 'language:sq', 'language:sr', 'language:sv', 'language:ta', 'language:th', 'language:tr', 'language:uk', 'language:ur', 'language:vi', 'language:zh', 'license:cc-by-nc-nd-4.0', 'region:us']","Train, validation and test splits for TED talks as in http://phontron.com/data/ted_talks.tar.gz (detokenized)",https://huggingface.co/datasets/davidstap/ted_talks,"['ar', 'az', 'be', 'bg', 'bn', 'bs', 'cs', 'da', 'de', 'el', 'en', 'eo', 'es', 'et', 'eu', 'fa', 'fi', 'fr', 'gl', 'he', 'hi', 'hr', 'hu', 'hy', 'id', 'it', 'ja', 'ka', 'kk', 'ko', 'ku', 'lt', 'mk', 'mn', 'mr', 'ms', 'my', 'nb', 'nl', 'pl', 'pt', 'ro', 'ru', 'sk', 'sl', 'sq', 'sr', 'sv', 'ta', 'th', 'tr', 'uk', 'ur', 'vi', 'zh']",['translation'],[]
mohamed-khalil/KaidanNihonbunka,mohamed-khalil,2024-04-15 15:43:41+00:00,2024-04-15 16:03:13+00:00,43,0,"['task_categories:text-generation', 'language:ja', 'license:apache-2.0', 'size_categories:1K<n<10K', 'format:parquet', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us', 'art', 'folklore', 'Hyakumonogatari', 'Nihonbunka']","
	
		
		Kaidan Nihonbunka: A Journey Through Hyakumonogatari's Ghostly Tales
	


Welcome to the Kaidan Nihonbunka Dataset


    
        
        
        
    




	
		
	
	
		About Name
	

kaidan Nihonbunka translates to 怪談日本文化 in Japanese:

怪談 (Kwaidan): Ghost story or supernatural tale.日本文化 (Nihonbunka): Japanese culture.

So, the translated name would be 怪談日本文化.

	
		
		Overview
	

The kaidan Nihonbunka Dataset is a collection of Japanese folklore of ghost stories, also known as ""kaidan""… See the full description on the dataset page: https://huggingface.co/datasets/mohamed-khalil/KaidanNihonbunka.",https://huggingface.co/datasets/mohamed-khalil/KaidanNihonbunka,['ja'],['text-generation'],['1K<n<10K']
grammarly/medit,grammarly,2024-04-15 21:30:51+00:00,2024-10-01 07:31:22+00:00,57,13,"['task_categories:text-generation', 'language:en', 'language:de', 'language:ar', 'language:ja', 'language:ko', 'language:es', 'language:zh', 'license:cc-by-nc-4.0', 'size_categories:100K<n<1M', 'format:json', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'arxiv:2402.16472', 'region:us', 'gec', 'simplification', 'paraphrasing', 'es', 'de', 'ar', 'en', 'ja', 'ko', 'zh', 'multilingual']","
	
		
		Dataset Card for mEdIT: Multilingual Text Editing via Instruction Tuning
	


	
		
		Paper: mEdIT: Multilingual Text Editing via Instruction Tuning
	


	
		
		Authors: Vipul Raheja, Dimitris Alikaniotis, Vivek Kulkarni, Bashar Alhafni, Dhruv Kumar
	


	
		
		Project Repo: https://github.com/vipulraheja/medit
	


	
		
		Dataset Summary
	

This is the dataset that was used to train the mEdIT text editing models. Full details of the dataset can be found in our paper.

	
		
		Dataset… See the full description on the dataset page: https://huggingface.co/datasets/grammarly/medit.",https://huggingface.co/datasets/grammarly/medit,"['en', 'de', 'ar', 'ja', 'ko', 'es', 'zh']",['text-generation'],['100K<n<1M']
ayousanz/reazon-speech-v2-all-speechMOS-analyze,ayousanz,2024-04-16 06:13:47+00:00,2024-04-16 16:59:16+00:00,34,0,"['language:ja', 'license:cdla-sharing-1.0', 'size_categories:10M<n<100M', 'format:json', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","
	
		
		概要
	

 reazon-research/reazonspeech-v2[all]をspeechMOSにて音声品質の分析を行った結果です。
分析した結果を audio_analysis_results_speechMOS.jsonというjsonにて保存しました。
jsonのフォーマットは以下になっています
""ファイル名"": file_name,
""MOS値"": snr value,
""トランスクリプション"": transcription

以下jsonのデータをヒストグラムにしたものです

	
		
		備考
	

こちらのデータ分析は、AiHUB様に計算リソースをご提供いただきました。
",https://huggingface.co/datasets/ayousanz/reazon-speech-v2-all-speechMOS-analyze,['ja'],[],['10M<n<100M']
Ego/jpflan,Ego,2024-04-17 06:28:50+00:00,2024-04-18 00:22:26+00:00,13,1,"['task_categories:text-generation', 'language:ja', 'license:cc-by-sa-4.0', 'size_categories:100K<n<1M', 'format:arrow', 'modality:text', 'library:datasets', 'library:mlcroissant', 'region:us']","
	
		
		Description
	

This is a templated version of data from ~40 Japanese open source downstream task datasets.This dataset was built with the intention of instruction tuning LLMs with high quality data that was not machine translated to and from Japanese.The raw data version can be found here.  

	
		
		Dataset format
	

This dataset version contains at most 20000 samples for each dataset, half of which are 0-shot examples, and the other half are few-shot examples (max 3).To create your… See the full description on the dataset page: https://huggingface.co/datasets/Ego/jpflan.",https://huggingface.co/datasets/Ego/jpflan,['ja'],['text-generation'],['100K<n<1M']
MilosNaniwa/WarChestDojo,MilosNaniwa,2024-04-17 09:47:35+00:00,2024-04-18 10:31:21+00:00,4,0,"['language:ja', 'size_categories:100K<n<1M', 'format:json', 'modality:text', 'library:datasets', 'library:dask', 'library:mlcroissant', 'region:us']","データセットの各キーとその説明:

state_id: ゲームの状態を一意に識別するためのID。
game_id: 対戦ゲームを一意に識別するためのID。
data_timestamp: データが記録された時刻のタイムスタンプ。
snapshot_id: ゲーム内の特定の時点のスナップショットを識別するためのID。
unit_classes_of_blue: 青チームが使用しているユニットのクラス名の配列。
unit_classes_of_red: 赤チームが使用しているユニットのクラス名の配列。
units_state: 各ユニットの状態を表すオブジェクトの配列。
layer: ユニットが存在する層 (supply, cemetery, discard, board, hand, bag)。
location: ユニットの位置を示す文字列。
should_hide: ユニットが相手から識別できるかどうかのフラグ。
team: ユニットが所属するチーム名 (blue, red, neutral)。
unit_class: ユニットのクラス名。
unit_id:… See the full description on the dataset page: https://huggingface.co/datasets/MilosNaniwa/WarChestDojo.",https://huggingface.co/datasets/MilosNaniwa/WarChestDojo,['ja'],[],['100K<n<1M']
Elizezen/japanese-nsfw-syosetsu-dataset,Elizezen,2024-04-18 04:09:18+00:00,2024-04-18 04:34:22+00:00,28,23,"['language:ja', 'license:apache-2.0', 'region:us', 'novel', 'training', 'japanese', 'nsfw', 'not-for-all-audiences']","
	
		
		Dataset Summary
	

This dataset comprises a collection of NSFW (Not Safe for Work) novels sourced from various platforms on the internet. Originally created for personal use, the selection of novels included in the dataset is based on my personal preferences.
The dataset is used for fine-tuning most of the Japanese LLMs I have uploaded, including Antler-7B.

	
		
	
	
		Supported Tasks and Leaderboards
	

This dataset is primarily intended for unsupervised training of erotic text… See the full description on the dataset page: https://huggingface.co/datasets/Elizezen/japanese-nsfw-syosetsu-dataset.",https://huggingface.co/datasets/Elizezen/japanese-nsfw-syosetsu-dataset,['ja'],[],[]
mpasila/ParallelFiction-Ja_En-100k-alpaca-4k-context,mpasila,2024-04-18 11:02:42+00:00,2024-04-18 11:36:43+00:00,5,1,"['task_categories:translation', 'language:ja', 'language:en', 'license:apache-2.0', 'size_categories:100K<n<1M', 'format:json', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","This is a modified version of NilanE/ParallelFiction-Ja_En-100k which has been turned into Alpaca format.
This has also been chunked for 4096 tokens for augmxnt/shisa-base-7b-v1 model's tokenizer.
If you want the non chunked version it's here.

	
		
	
	
		Dataset format (correct one)
	

{
  'instruction' : 'Japanese chapter'
  'output' : 'English translation'
  'input' : 'empty'
}


	
	
	
		Original Dataset card
	


	
	
	
		Dataset details
	

Each entry in this dataset is a sentence-aligned… See the full description on the dataset page: https://huggingface.co/datasets/mpasila/ParallelFiction-Ja_En-100k-alpaca-4k-context.",https://huggingface.co/datasets/mpasila/ParallelFiction-Ja_En-100k-alpaca-4k-context,"['ja', 'en']",['translation'],['100K<n<1M']
minnade/chat-daily,minnade,2024-04-18 23:41:30+00:00,2024-11-26 03:25:02+00:00,13,9,"['task_categories:text-generation', 'language:ja', 'license:cc0-1.0', 'size_categories:1K<n<10K', 'format:parquet', 'modality:tabular', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","
	
		
		MinnadeChat データセット (毎日更新)
	

みんなで作る指示データセット の投稿のデータセットです。このデータセットは毎日12時に更新されます。

	
		
		🤗 HuggingFace datasets から使う
	

最新版 を取得したい場合:
from datasets import load_dataset

ds = load_dataset(""minnade/chat-daily"", split=""train"")

print(ds)
#Dataset({
#    features: ['id', 'parent_id', 'role', 'body', 'category_id', 'tags', 'is_synthetic', 'is_deleted', 'knowledge_cut_off', 'created_at', 'review', 'review_count', 'flag', 'flag_count'],
#    num_rows: 196
#})

日付を指定して取得したい場合:
from datasets… See the full description on the dataset page: https://huggingface.co/datasets/minnade/chat-daily.",https://huggingface.co/datasets/minnade/chat-daily,['ja'],['text-generation'],['1K<n<10K']
llm-jp/mbpp-ja,llm-jp,2024-04-19 00:26:56+00:00,2024-04-20 06:26:51+00:00,52,3,"['language:ja', 'license:cc-by-4.0', 'size_categories:n<1K', 'format:json', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us', ' code-generation']","
	
		
		mbpp-ja
	

This repository provides a mbpp dataset translated from English into Japanese by LLM-jp, a collaborative project launched in Japan.
For English to Japanese translation, DeepL was used.
The links of the original mbpp dataset are here(HuggingFace) or here(GitHub).

	
		
	
	
		Send Questions to
	

llm-jp(at)nii.ac.jp

	
		
	
	
		Model Card Authors
	

The names are listed in alphabetical order.
Namgi Han, Masatoshi Otake, Shintaro Ozaki, Yusuke Miyao.
",https://huggingface.co/datasets/llm-jp/mbpp-ja,['ja'],[],['n<1K']
TFMC/imatrix-dataset-for-japanese-llm,TFMC,2024-04-19 19:46:14+00:00,2024-04-19 20:35:40+00:00,69,24,"['task_categories:text-generation', 'language:ja', 'language:en', 'license:odc-by', 'size_categories:n<1K', 'format:text', 'modality:text', 'library:datasets', 'library:mlcroissant', 'region:us']",,https://huggingface.co/datasets/TFMC/imatrix-dataset-for-japanese-llm,"['ja', 'en']",['text-generation'],['n<1K']
ryota39/hh-rlhf-12k-ja_orpo,ryota39,2024-04-20 04:32:45+00:00,2024-07-04 12:56:38+00:00,5,1,"['language:ja', 'license:mit', 'size_categories:10K<n<100K', 'format:json', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']",,https://huggingface.co/datasets/ryota39/hh-rlhf-12k-ja_orpo,['ja'],[],['10K<n<100K']
masuidrive/cv-corpus-17.0-ja-client_id-grouped,masuidrive,2024-04-20 06:48:02+00:00,2024-04-20 06:48:20+00:00,79,2,"['task_categories:automatic-speech-recognition', 'annotations_creators:crowdsourced', 'language_creators:crowdsourced', 'source_datasets:commonvoice', 'language:ja', 'license:cc0-1.0', 'size_categories:10K<n<100K', 'format:parquet', 'modality:audio', 'modality:text', 'library:datasets', 'library:dask', 'library:mlcroissant', 'library:polars', 'region:us', 'audio', 'speaker diarization']","
	
		
		cv-corpus-17.0-ja-client_id-grouped
	

This dataset is a subset of the Common Voice dataset, filtered and grouped based on the client ID (treated as speaker ID).

	
		
		Dataset Details
	


The dataset is derived from the Common Voice dataset.
The original dataset is available at Common Voice Dataset.
The dataset is grouped by client ID, which is treated as the speaker ID for this dataset.
Each group is filtered to include only client IDs with a minimum of 30 samples and a maximum of… See the full description on the dataset page: https://huggingface.co/datasets/masuidrive/cv-corpus-17.0-ja-client_id-grouped.",https://huggingface.co/datasets/masuidrive/cv-corpus-17.0-ja-client_id-grouped,['ja'],['automatic-speech-recognition'],['10K<n<100K']
deepghs/danbooru2023_index,deepghs,2024-04-21 09:24:05+00:00,2024-12-08 09:18:58+00:00,1390,4,"['task_categories:image-classification', 'task_categories:image-to-image', 'task_categories:text-to-image', 'language:en', 'language:ja', 'license:mit', 'size_categories:1M<n<10M', 'region:us']","Tar index files for nyanko7/danbooru2023.
You can download images from both nyanko7/danbooru2023 and deepghs/danbooru_newest with cheesechaser.
from cheesechaser.datapool import DanbooruNewestDataPool

pool = DanbooruNewestDataPool()

# download danbooru original images from 7200000-7201000, to directory /data/danbooru_original
pool.batch_download_to_directory(
    resource_ids=range(7200000, 7201000),
    dst_dir='/data/danbooru_original',
    max_workers=12,
)

",https://huggingface.co/datasets/deepghs/danbooru2023_index,"['en', 'ja']","['image-classification', 'image-to-image', 'text-to-image']",['1M<n<10M']
sbtom/reasoning_ability_test,sbtom,2024-04-21 11:04:31+00:00,2024-04-21 11:16:22+00:00,37,0,"['language:ja', 'language:en', 'size_categories:n<1K', 'format:text', 'modality:text', 'library:datasets', 'library:mlcroissant', 'region:us']","これらのテキストは、LLMの推論能力をテストするための問題文です。
私は、もっともミスリードの少ないレベル１の問題でも、安定して正解するモデルを知りません。
正解するモデルがあれば、お知らせください。
各モデルの検証では、英文での質問の方が、推論過程が正しい点が多かったです。
These texts are question papers to test your LLM reasoning ability.
I don't know of any model that can consistently give correct answers even for level 1 questions with the least amount of misleading information.
If you have a correct model, please let us know.
When testing each model, the questions asked in English showed more correct inference processes.
",https://huggingface.co/datasets/sbtom/reasoning_ability_test,"['ja', 'en']",[],['n<1K']
aipracticecafe/wataoshi-dialogues-rp,aipracticecafe,2024-04-21 16:36:08+00:00,2024-04-26 10:49:19+00:00,8,0,"['task_categories:text-generation', 'language:ja', 'license:mit', 'size_categories:n<1K', 'format:parquet', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","このデータセットは「私の推しは悪役令嬢。」のアニメから少しクリーニングされたセリフです。私はこのアニメの権利を持ってません、データセットの使い方について、責任がない。
Userは大体レイが言ったセリフが、他のキャラも含めてる。Assistantはクレアの答え。
",https://huggingface.co/datasets/aipracticecafe/wataoshi-dialogues-rp,['ja'],['text-generation'],['n<1K']
ayousanz/oscor-2301-ja-text-content,ayousanz,2024-04-22 00:04:18+00:00,2024-04-22 01:25:06+00:00,151,2,"['language:ja', 'license:cc0-1.0', 'size_categories:10M<n<100M', 'format:text', 'modality:text', 'library:datasets', 'library:mlcroissant', 'region:us']","OSCOR-2301-jaのcontent部分だけをテキスト化したもの
データセットからcontentのvalueだけ取得する際には、以下のコードで実行しました
import json
import os
import sys

# コマンドライン引数からフォルダ名を取得する
if len(sys.argv) < 2:
    print(""使用法: python script.py folder_name"")
    sys.exit(1)

folder_name = sys.argv[1]

# フォルダ内のすべての .json ファイルを処理する
for filename in os.listdir(folder_name):
    if filename.endswith("".txt""):
        input_file = os.path.join(folder_name, filename)
        output_file = os.path.splitext(filename)[0] + ""_convert.txt""… See the full description on the dataset page: https://huggingface.co/datasets/ayousanz/oscor-2301-ja-text-content.",https://huggingface.co/datasets/ayousanz/oscor-2301-ja-text-content,['ja'],[],['10M<n<100M']
sanchit-gandhi/gating-example,sanchit-gandhi,2024-04-23 10:42:24+00:00,2024-04-23 10:45:35+00:00,8,0,"['language:en', 'language:ja', 'language:zh', 'language:de', 'language:es', 'license:cc-by-nc-4.0', 'region:us', 'speaker-diarization', 'speaker-segmentation', 'voice-activity-detection']",,https://huggingface.co/datasets/sanchit-gandhi/gating-example,"['en', 'ja', 'zh', 'de', 'es']",[],[]
almanach/HALvest,almanach,2024-04-23 13:30:23+00:00,2024-07-31 09:56:58+00:00,661,3,"['task_categories:text-generation', 'task_categories:fill-mask', 'task_ids:language-modeling', 'task_ids:masked-language-modeling', 'annotations_creators:no-annotation', 'multilinguality:multilingual', 'source_datasets:original', 'language:ar', 'language:az', 'language:bg', 'language:bo', 'language:br', 'language:bs', 'language:ca', 'language:co', 'language:cs', 'language:da', 'language:de', 'language:el', 'language:en', 'language:eo', 'language:es', 'language:et', 'language:eu', 'language:fa', 'language:fi', 'language:fr', 'language:gl', 'language:gn', 'language:he', 'language:hi', 'language:hr', 'language:hu', 'language:hy', 'language:id', 'language:ie', 'language:it', 'language:ja', 'language:kk', 'language:ko', 'language:lt', 'language:mk', 'language:mr', 'language:no', 'language:oc', 'language:pl', 'language:pt', 'language:ro', 'language:ru', 'language:sk', 'language:sl', 'language:sq', 'language:sr', 'language:sv', 'language:sw', 'language:ta', 'language:tet', 'language:th', 'language:tk', 'language:tl', 'language:tr', 'language:uk', 'language:vi', 'language:zh', 'size_categories:100K<n<1M', 'format:json', 'modality:tabular', 'modality:text', 'library:datasets', 'library:dask', 'library:mlcroissant', 'library:polars', 'arxiv:2407.20595', 'region:us', 'academia', 'research']","
     HALvest 
     Open Scientific Papers Harvested from HAL (Unfiltered) 




	
		
		Dataset Summary
	


	
		
		overview:
	

This is the unfiltered version of HALvest, comprising of fulltext from open papers found on Hyper Articles en Ligne (HAL) with extra fields for potential filtering. Our dump is mostly english/french but gather papers written in 56 languages across 13 domains.
You can download the dataset using Hugging Face datasets:
from datasets import load_dataset

ds =… See the full description on the dataset page: https://huggingface.co/datasets/almanach/HALvest.",https://huggingface.co/datasets/almanach/HALvest,"['ar', 'az', 'bg', 'bo', 'br', 'bs', 'ca', 'co', 'cs', 'da', 'de', 'el', 'en', 'eo', 'es', 'et', 'eu', 'fa', 'fi', 'fr', 'gl', 'gn', 'he', 'hi', 'hr', 'hu', 'hy', 'id', 'ie', 'it', 'ja', 'kk', 'ko', 'lt', 'mk', 'mr', 'no', 'oc', 'pl', 'pt', 'ro', 'ru', 'sk', 'sl', 'sq', 'sr', 'sv', 'sw', 'ta', 'tet', 'th', 'tk', 'tl', 'tr', 'uk', 'vi', 'zh']","['text-generation', 'fill-mask']",['100K<n<1M']
ryota39/izumi-lab-dpo-45k,ryota39,2024-04-23 16:15:54+00:00,2024-07-04 12:56:16+00:00,8,1,"['language:ja', 'license:cc-by-sa-4.0', 'size_categories:10K<n<100K', 'format:json', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']",,https://huggingface.co/datasets/ryota39/izumi-lab-dpo-45k,['ja'],[],['10K<n<100K']
ayousanz/OSCOR-2301-ja-cleaned-0,ayousanz,2024-04-24 08:22:57+00:00,2024-05-08 04:41:59+00:00,128,0,"['language:ja', 'license:cc0-1.0', 'region:us', 'OSCAR-2301']","
	
		
		概要
	

oscar-corpus/OSCAR-2301の以下のjaのみを corpus-cleanerを使用してデータクリーニングを行なったデーセット群

	
		
Code
Language
# docs
# words
Content Length :


		
ja
Japanese
94,236,404
4,401,059,165
181.2 GB


	

",https://huggingface.co/datasets/ayousanz/OSCOR-2301-ja-cleaned-0,['ja'],[],[]
ayousanz/c4-ja-cleaned,ayousanz,2024-04-24 08:48:07+00:00,2024-04-24 16:34:45+00:00,21,0,"['language:ja', 'license:odc-by', 'region:us']",,https://huggingface.co/datasets/ayousanz/c4-ja-cleaned,['ja'],[],[]
simon3000/genshin-voice,simon3000,2024-04-25 00:09:03+00:00,2025-04-22 03:19:19+00:00,1936,121,"['task_categories:audio-classification', 'task_categories:automatic-speech-recognition', 'task_categories:text-to-speech', 'language:zh', 'language:en', 'language:ja', 'language:ko', 'size_categories:100K<n<1M', 'format:parquet', 'modality:audio', 'modality:text', 'library:datasets', 'library:dask', 'library:mlcroissant', 'library:polars', 'region:us']","
	
		
		Genshin Voice
	

Genshin Voice is a dataset of voice lines from the popular game Genshin Impact.
Hugging Face 🤗  Genshin-Voice

Last update at 2025-04-22
424011 wavs
40907 without speaker (10%)
40000 without transcription (9%)
10313 without inGameFilename (2%)



	
		
	
	
		Dataset Details
	


	
		
	
	
		Dataset Description
	

The dataset contains voice lines from the game's characters in multiple languages, including Chinese, English, Japanese, and Korean.
The voice lines are spoken… See the full description on the dataset page: https://huggingface.co/datasets/simon3000/genshin-voice.",https://huggingface.co/datasets/simon3000/genshin-voice,"['zh', 'en', 'ja', 'ko']","['audio-classification', 'automatic-speech-recognition', 'text-to-speech']",['100K<n<1M']
tanganke/kmnist,tanganke,2024-04-26 10:34:09+00:00,2024-05-02 13:59:20+00:00,675,1,"['task_categories:image-classification', 'language:ja', 'size_categories:10K<n<100K', 'format:parquet', 'modality:image', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","
	
		
		KMNIST Dataset
	

lassify images from the KMNIST dataset into one of the 10 classes, representing different Japanese characters.
",https://huggingface.co/datasets/tanganke/kmnist,['ja'],['image-classification'],['10K<n<100K']
afaji/cvqa,afaji,2024-04-26 11:25:15+00:00,2024-11-27 17:42:19+00:00,1682,32,"['task_categories:question-answering', 'language:id', 'language:su', 'language:ja', 'language:jv', 'language:min', 'language:br', 'language:ga', 'language:es', 'language:pt', 'language:no', 'language:mn', 'language:ms', 'language:zh', 'language:ko', 'language:ta', 'language:ben', 'language:si', 'language:bg', 'language:ro', 'language:ru', 'language:am', 'language:orm', 'language:ar', 'language:ig', 'language:hi', 'language:mr', 'size_categories:10K<n<100K', 'format:parquet', 'modality:image', 'modality:text', 'library:datasets', 'library:dask', 'library:mlcroissant', 'library:polars', 'arxiv:2406.05967', 'region:us']","
	
		
		About CVQA
	

CVQA is a culturally diverse multilingual VQA benchmark consisting of over 10,000 questions from 39 country-language pairs. The questions in CVQA are written in both the native languages and English, and are categorized into 10 diverse categories.
This data is designed for use as a test set. Please submit your submission here to evaluate your model performance. CVQA is constructed through a collaborative effort led by a team of researchers from MBZUAI. Read more about… See the full description on the dataset page: https://huggingface.co/datasets/afaji/cvqa.",https://huggingface.co/datasets/afaji/cvqa,"['id', 'su', 'ja', 'jv', 'min', 'br', 'ga', 'es', 'pt', 'no', 'mn', 'ms', 'zh', 'ko', 'ta', 'ben', 'si', 'bg', 'ro', 'ru', 'am', 'orm', 'ar', 'ig', 'hi', 'mr']",['question-answering'],['10K<n<100K']
simon3000/starrail-voice,simon3000,2024-04-26 19:01:17+00:00,2024-08-30 04:52:04+00:00,326,47,"['task_categories:audio-classification', 'task_categories:automatic-speech-recognition', 'task_categories:text-to-speech', 'language:zh', 'language:en', 'language:ja', 'language:ko', 'size_categories:100K<n<1M', 'format:parquet', 'modality:audio', 'modality:text', 'library:datasets', 'library:dask', 'library:mlcroissant', 'library:polars', 'region:us']","
	
		
		StarRail Voice
	

StarRail Voice is a dataset of voice lines from the popular game Honkai: Star Rail.
Hugging Face 🤗  StarRail-Voice

Last update at 2024-08-30
185511 wavs
49325 without speaker (27%)
49409 without transcription (27%)
41142 without inGameFilename (22%)



	
		
	
	
		Dataset Details
	


	
		
	
	
		Dataset Description
	

The dataset contains voice lines from the game's characters in multiple languages, including Chinese, English, Japanese, and Korean.
The voice lines are… See the full description on the dataset page: https://huggingface.co/datasets/simon3000/starrail-voice.",https://huggingface.co/datasets/simon3000/starrail-voice,"['zh', 'en', 'ja', 'ko']","['audio-classification', 'automatic-speech-recognition', 'text-to-speech']",['100K<n<1M']
hatakeyama-llm-team/AutoGeneratedJapaneseQA,hatakeyama-llm-team,2024-04-27 04:32:20+00:00,2024-05-19 03:22:08+00:00,17,3,"['language:ja', 'license:cc-by-sa-3.0', 'size_categories:100K<n<1M', 'format:parquet', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","
	
		
		自動生成Q&A
	


	
		
		種々のデータソースから､MaziyarPanahi/Mixtral-8x22B-Instruct-v0.1-GGUFを使ってQ&Aを自動生成したものです｡
	


CC-BY系またはApatch-2.0のデータソースを改変して生成しています。
元の文章との類似度(依拠性)が低くなるようにするため、元文章からランダムに部分抜粋したテキストを用いています。
不自然な文章も含まれているためクリーニングを推奨します。




	
		
		このデータセットのライセンス
	


cc-by-sa-3.0


	
		
		データソースとそのライセンス
	


hpprc/wikipedia-20240101 - cc-by-sa-3.0
hatakeyama-llm-team/WikiBookJa  - cc-by-sa-3.0
kunishou/J-ResearchCorpus - cc-by-4.0
kunishou/databricks-dolly-15k-ja - cc-by-sa-3.0… See the full description on the dataset page: https://huggingface.co/datasets/hatakeyama-llm-team/AutoGeneratedJapaneseQA.",https://huggingface.co/datasets/hatakeyama-llm-team/AutoGeneratedJapaneseQA,['ja'],[],['100K<n<1M']
mpkato/miracl-japanese-small-corpus,mpkato,2024-04-27 12:13:05+00:00,2024-04-29 03:59:24+00:00,8,0,"['task_categories:text-retrieval', 'language:ja', 'license:apache-2.0', 'size_categories:100K<n<1M', 'format:parquet', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']",,https://huggingface.co/datasets/mpkato/miracl-japanese-small-corpus,['ja'],['text-retrieval'],['100K<n<1M']
nthakur/swim-ir-cross-lingual,nthakur,2024-04-27 23:58:22+00:00,2024-04-28 05:11:45+00:00,3875,8,"['task_categories:text-retrieval', 'task_categories:question-answering', 'language_creators:machine-generated', 'multilinguality:multilingual', 'source_datasets:original', 'language:ar', 'language:bn', 'language:de', 'language:es', 'language:fa', 'language:fi', 'language:fr', 'language:hi', 'language:id', 'language:ja', 'language:ko', 'language:ru', 'language:sw', 'language:te', 'language:th', 'language:yo', 'language:zh', 'license:cc-by-sa-4.0', 'size_categories:10M<n<100M', 'format:parquet', 'modality:text', 'library:datasets', 'library:dask', 'library:mlcroissant', 'library:polars', 'arxiv:2311.05800', 'region:us']","
	
		
		Dataset Card for SWIM-IR (Cross-lingual)
	




This is the cross-lingual subset of the SWIM-IR dataset, where the query generated is in the target language and the passage is in English.
The SWIM-IR dataset is available as CC-BY-SA 4.0. 18 languages (including English) are available in the cross-lingual dataset.
For full details of the dataset, please read our upcoming NAACL 2024 paper and check out our website.

	
	
	
		What is SWIM-IR?
	

SWIM-IR dataset is a synthetic multilingual… See the full description on the dataset page: https://huggingface.co/datasets/nthakur/swim-ir-cross-lingual.",https://huggingface.co/datasets/nthakur/swim-ir-cross-lingual,"['ar', 'bn', 'de', 'es', 'fa', 'fi', 'fr', 'hi', 'id', 'ja', 'ko', 'ru', 'sw', 'te', 'th', 'yo', 'zh']","['text-retrieval', 'question-answering']",['10M<n<100M']
wolf4032/token-classification-japanese-search-local-cuisine,wolf4032,2024-04-28 07:26:48+00:00,2024-05-12 07:19:14+00:00,10,0,"['task_categories:token-classification', 'language:ja', 'license:mit', 'size_categories:1K<n<10K', 'format:parquet', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","料理を検索するための質問文と、質問文に含まれる検索検索用キーワードの情報を持ったデータセットです
固有表現の種類は以下の４つです。

AREA：　都道府県/地方
TYPE：　種類
SZN：　季節
INGR：　食材

GitHub

untokenized_dataset_list.ipynb(データセットの作成に使ったノートブック)
このデータセットを使った言語モデルのファインチューニングと、ファインチューニングした言語モデルを使ったアプリのコードもこのリポジトリにあります

詳細情報

Qiita

",https://huggingface.co/datasets/wolf4032/token-classification-japanese-search-local-cuisine,['ja'],['token-classification'],['1K<n<10K']
llm-jp/oasst2-33k-ja,llm-jp,2024-04-28 16:24:00+00:00,2024-04-28 16:39:03+00:00,15,11,"['language:ja', 'license:apache-2.0', 'size_categories:10K<n<100K', 'format:json', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","
	
		
		oasst2-33k-ja
	

This repository provides an instruction tuning dataset developed by LLM-jp, a collaborative project launched in Japan.
The dataset comprises a Japanese translation of an English subset from oasst2, translated using DeepL.
The English subset can be found here.
For the creation of this dataset, we processed data from kunishou/oasst2-135k-ja.

	
		
	
	
		Send Questions to
	

llm-jp(at)nii.ac.jp

	
		
	
	
		Model Card Authors
	

The names are listed in alphabetical order.… See the full description on the dataset page: https://huggingface.co/datasets/llm-jp/oasst2-33k-ja.",https://huggingface.co/datasets/llm-jp/oasst2-33k-ja,['ja'],[],['10K<n<100K']
Kit-Lemonfoot/LemonfootVoiceDatasets,Kit-Lemonfoot,2024-04-29 21:04:03+00:00,2024-05-02 18:13:28+00:00,165,5,"['task_categories:audio-to-audio', 'task_categories:text-to-speech', 'language:en', 'language:ja', 'modality:audio', 'region:us', 'audio', 'speech', 'vtuber', 'youtube', 'voice']","
	
		
		Kit Lemonfoot's Voice Datasets
	

This repository aims to house every dataset used in my AI voice models. Please credit me if you use these datasets.
This includes the following:

Every dataset used in my RVC models
Every dataset used in my Style BertVITS2 models
Every dataset used in my GPT-SoVITS models
Multiple datasets submitted to 15.ai (RIP)


	
		
	
	
		Reference
	

Hand-transcribed datasets were built for 15.ai and as such are in the LJSpeech transcription format.… See the full description on the dataset page: https://huggingface.co/datasets/Kit-Lemonfoot/LemonfootVoiceDatasets.",https://huggingface.co/datasets/Kit-Lemonfoot/LemonfootVoiceDatasets,"['en', 'ja']","['audio-to-audio', 'text-to-speech']",[]
sentence-transformers/parallel-sentences-jw300,sentence-transformers,2024-04-29 21:24:59+00:00,2024-06-18 19:45:32+00:00,507,6,"['task_categories:feature-extraction', 'task_categories:sentence-similarity', 'language:en', 'language:multilingual', 'language:ar', 'language:bg', 'language:cs', 'language:da', 'language:de', 'language:el', 'language:es', 'language:et', 'language:fa', 'language:fi', 'language:fr', 'language:gu', 'language:he', 'language:hi', 'language:hr', 'language:hu', 'language:hy', 'language:id', 'language:it', 'language:ja', 'language:ka', 'language:ko', 'language:lt', 'language:lv', 'language:mk', 'language:mn', 'language:mr', 'language:my', 'language:nl', 'language:pl', 'language:pt', 'language:ro', 'language:ru', 'language:sk', 'language:sl', 'language:sq', 'language:sv', 'language:th', 'language:tr', 'language:uk', 'language:ur', 'language:vi', 'size_categories:10M<n<100M', 'format:parquet', 'modality:text', 'library:datasets', 'library:dask', 'library:mlcroissant', 'library:polars', 'region:us', 'sentence-transformers']","
	
		
		Dataset Card for Parallel Sentences - JW300
	

This dataset contains parallel sentences (i.e. English sentence + the same sentences in another language) for numerous other languages. Most of the sentences originate from the OPUS website.
In particular, this dataset contains the JW300 dataset.

	
		
		Related Datasets
	

The following datasets are also a part of the Parallel Sentences collection:

parallel-sentences-europarl
parallel-sentences-global-voices
parallel-sentences-muse… See the full description on the dataset page: https://huggingface.co/datasets/sentence-transformers/parallel-sentences-jw300.",https://huggingface.co/datasets/sentence-transformers/parallel-sentences-jw300,"['en', 'multilingual', 'ar', 'bg', 'cs', 'da', 'de', 'el', 'es', 'et', 'fa', 'fi', 'fr', 'gu', 'he', 'hi', 'hr', 'hu', 'hy', 'id', 'it', 'ja', 'ka', 'ko', 'lt', 'lv', 'mk', 'mn', 'mr', 'my', 'nl', 'pl', 'pt', 'ro', 'ru', 'sk', 'sl', 'sq', 'sv', 'th', 'tr', 'uk', 'ur', 'vi']","['feature-extraction', 'sentence-similarity']",['10M<n<100M']
sentence-transformers/parallel-sentences-news-commentary,sentence-transformers,2024-04-30 07:30:07+00:00,2024-06-18 19:45:37+00:00,490,2,"['task_categories:feature-extraction', 'task_categories:sentence-similarity', 'language:en', 'language:multilingual', 'language:ar', 'language:cs', 'language:de', 'language:es', 'language:fr', 'language:it', 'language:ja', 'language:nl', 'language:pt', 'language:ru', 'size_categories:1M<n<10M', 'format:parquet', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us', 'sentence-transformers']","
	
		
		Dataset Card for Parallel Sentences - News Commentary
	

This dataset contains parallel sentences (i.e. English sentence + the same sentences in another language) for numerous other languages. Most of the sentences originate from the OPUS website.
In particular, this dataset contains the News-Commentary dataset.

	
		
	
	
		Related Datasets
	

The following datasets are also a part of the Parallel Sentences collection:

parallel-sentences-europarl
parallel-sentences-global-voices… See the full description on the dataset page: https://huggingface.co/datasets/sentence-transformers/parallel-sentences-news-commentary.",https://huggingface.co/datasets/sentence-transformers/parallel-sentences-news-commentary,"['en', 'multilingual', 'ar', 'cs', 'de', 'es', 'fr', 'it', 'ja', 'nl', 'pt', 'ru']","['feature-extraction', 'sentence-similarity']",['1M<n<10M']
sentence-transformers/parallel-sentences-opensubtitles,sentence-transformers,2024-04-30 08:24:04+00:00,2024-06-18 19:45:43+00:00,1621,3,"['task_categories:feature-extraction', 'task_categories:sentence-similarity', 'language:en', 'language:multilingual', 'language:ar', 'language:bg', 'language:ca', 'language:cs', 'language:da', 'language:de', 'language:el', 'language:es', 'language:et', 'language:fa', 'language:fi', 'language:fr', 'language:gl', 'language:he', 'language:hi', 'language:hr', 'language:hu', 'language:hy', 'language:id', 'language:it', 'language:ja', 'language:ka', 'language:ko', 'language:lt', 'language:lv', 'language:mk', 'language:ms', 'language:nl', 'language:pl', 'language:pt', 'language:ro', 'language:ru', 'language:sk', 'language:sl', 'language:sq', 'language:sr', 'language:sv', 'language:th', 'language:tr', 'language:uk', 'language:ur', 'language:vi', 'language:zh', 'size_categories:100M<n<1B', 'format:parquet', 'modality:text', 'library:datasets', 'library:dask', 'library:mlcroissant', 'library:polars', 'region:us', 'sentence-transformers']","
	
		
		Dataset Card for Parallel Sentences - OpenSubtitles
	

This dataset contains parallel sentences (i.e. English sentence + the same sentences in another language) for numerous other languages. Most of the sentences originate from the OPUS website.
In particular, this dataset contains the OpenSubtitles dataset.
Warning! The quality of this dataset is not great; many of the english and non-english texts don't match well, or are fully empty.

	
		
	
	
		Related Datasets
	

The following… See the full description on the dataset page: https://huggingface.co/datasets/sentence-transformers/parallel-sentences-opensubtitles.",https://huggingface.co/datasets/sentence-transformers/parallel-sentences-opensubtitles,"['en', 'multilingual', 'ar', 'bg', 'ca', 'cs', 'da', 'de', 'el', 'es', 'et', 'fa', 'fi', 'fr', 'gl', 'he', 'hi', 'hr', 'hu', 'hy', 'id', 'it', 'ja', 'ka', 'ko', 'lt', 'lv', 'mk', 'ms', 'nl', 'pl', 'pt', 'ro', 'ru', 'sk', 'sl', 'sq', 'sr', 'sv', 'th', 'tr', 'uk', 'ur', 'vi', 'zh']","['feature-extraction', 'sentence-similarity']",['100M<n<1B']
awinml/MultiFin,awinml,2024-04-30 09:20:13+00:00,2024-04-30 12:47:51+00:00,47,0,"['task_categories:text-classification', 'language:en', 'language:es', 'language:pl', 'language:hu', 'language:el', 'language:da', 'language:tr', 'language:ja', 'language:sv', 'language:fi', 'language:no', 'language:ru', 'language:it', 'language:he', 'language:is', 'size_categories:10K<n<100K', 'format:parquet', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us', 'finance']","
	
		
		MultiFin
	



MultiFin – a publicly available financial dataset consisting of real-world article headlines covering 15 languages across different writing systems and language families.
The dataset consists of hierarchical label structure providing two classification tasks: multi-label and multi-class.

	
		
		Dataset Description
	

The MULTIFIN dataset is a multilingual corpus, consisting of real-world article headlines covering 15
languages. The corpus is annotated using hierarchical… See the full description on the dataset page: https://huggingface.co/datasets/awinml/MultiFin.",https://huggingface.co/datasets/awinml/MultiFin,"['en', 'es', 'pl', 'hu', 'el', 'da', 'tr', 'ja', 'sv', 'fi', 'no', 'ru', 'it', 'he', 'is']",['text-classification'],['10K<n<100K']
sentence-transformers/parallel-sentences-talks,sentence-transformers,2024-04-30 10:29:15+00:00,2024-06-18 19:45:50+00:00,3019,12,"['task_categories:feature-extraction', 'task_categories:sentence-similarity', 'language:en', 'language:multilingual', 'language:ar', 'language:bg', 'language:ca', 'language:cs', 'language:da', 'language:de', 'language:el', 'language:es', 'language:et', 'language:fa', 'language:fi', 'language:fr', 'language:gl', 'language:gu', 'language:he', 'language:hi', 'language:hr', 'language:hu', 'language:hy', 'language:id', 'language:it', 'language:ja', 'language:ka', 'language:ko', 'language:ku', 'language:lt', 'language:lv', 'language:mk', 'language:mn', 'language:mr', 'language:ms', 'language:my', 'language:nb', 'language:nl', 'language:pl', 'language:pt', 'language:ro', 'language:ru', 'language:sk', 'language:sl', 'language:sq', 'language:sr', 'language:sv', 'language:th', 'language:tr', 'language:uk', 'language:ur', 'language:vi', 'language:zh', 'size_categories:10M<n<100M', 'format:parquet', 'modality:text', 'library:datasets', 'library:dask', 'library:mlcroissant', 'library:polars', 'region:us', 'sentence-transformers']","
	
		
		Dataset Card for Parallel Sentences - Talks
	

This dataset contains parallel sentences (i.e. English sentence + the same sentences in another language) for numerous other languages. Most of the sentences originate from the OPUS website.
In particular, this dataset contains the Talks dataset.

	
		
	
	
		Related Datasets
	

The following datasets are also a part of the Parallel Sentences collection:

parallel-sentences-europarl
parallel-sentences-global-voices
parallel-sentences-muse… See the full description on the dataset page: https://huggingface.co/datasets/sentence-transformers/parallel-sentences-talks.",https://huggingface.co/datasets/sentence-transformers/parallel-sentences-talks,"['en', 'multilingual', 'ar', 'bg', 'ca', 'cs', 'da', 'de', 'el', 'es', 'et', 'fa', 'fi', 'fr', 'gl', 'gu', 'he', 'hi', 'hr', 'hu', 'hy', 'id', 'it', 'ja', 'ka', 'ko', 'ku', 'lt', 'lv', 'mk', 'mn', 'mr', 'ms', 'my', 'nb', 'nl', 'pl', 'pt', 'ro', 'ru', 'sk', 'sl', 'sq', 'sr', 'sv', 'th', 'tr', 'uk', 'ur', 'vi', 'zh']","['feature-extraction', 'sentence-similarity']",['10M<n<100M']
sentence-transformers/parallel-sentences-tatoeba,sentence-transformers,2024-04-30 11:19:18+00:00,2024-06-18 19:45:56+00:00,1895,0,"['task_categories:feature-extraction', 'task_categories:sentence-similarity', 'language:en', 'language:multilingual', 'language:ar', 'language:bg', 'language:ca', 'language:cs', 'language:da', 'language:de', 'language:el', 'language:es', 'language:et', 'language:fa', 'language:fi', 'language:fr', 'language:gl', 'language:gu', 'language:he', 'language:hi', 'language:hu', 'language:hy', 'language:id', 'language:it', 'language:ja', 'language:ka', 'language:ko', 'language:ku', 'language:lt', 'language:lv', 'language:mk', 'language:mn', 'language:mr', 'language:ms', 'language:my', 'language:nb', 'language:nl', 'language:pl', 'language:pt', 'language:ro', 'language:ru', 'language:sk', 'language:sl', 'language:sq', 'language:sr', 'language:sv', 'language:th', 'language:tr', 'language:uk', 'language:ur', 'language:vi', 'language:zh', 'size_categories:1M<n<10M', 'modality:text', 'region:us', 'sentence-transformers']","
	
		
		Dataset Card for Parallel Sentences - Tatoeba
	

This dataset contains parallel sentences (i.e. English sentence + the same sentences in another language) for numerous other languages. Most of the sentences originate from the OPUS website.
In particular, this dataset contains the Tatoeba dataset.

	
		
		Related Datasets
	

The following datasets are also a part of the Parallel Sentences collection:

parallel-sentences-europarl
parallel-sentences-global-voices
parallel-sentences-muse… See the full description on the dataset page: https://huggingface.co/datasets/sentence-transformers/parallel-sentences-tatoeba.",https://huggingface.co/datasets/sentence-transformers/parallel-sentences-tatoeba,"['en', 'multilingual', 'ar', 'bg', 'ca', 'cs', 'da', 'de', 'el', 'es', 'et', 'fa', 'fi', 'fr', 'gl', 'gu', 'he', 'hi', 'hu', 'hy', 'id', 'it', 'ja', 'ka', 'ko', 'ku', 'lt', 'lv', 'mk', 'mn', 'mr', 'ms', 'my', 'nb', 'nl', 'pl', 'pt', 'ro', 'ru', 'sk', 'sl', 'sq', 'sr', 'sv', 'th', 'tr', 'uk', 'ur', 'vi', 'zh']","['feature-extraction', 'sentence-similarity']",['1M<n<10M']
sentence-transformers/parallel-sentences-wikimatrix,sentence-transformers,2024-04-30 11:55:03+00:00,2024-06-18 19:46:03+00:00,1881,7,"['task_categories:feature-extraction', 'task_categories:sentence-similarity', 'language:en', 'language:multilingual', 'language:ar', 'language:bg', 'language:ca', 'language:cs', 'language:da', 'language:de', 'language:el', 'language:es', 'language:et', 'language:fa', 'language:fi', 'language:fr', 'language:gl', 'language:he', 'language:hi', 'language:hr', 'language:id', 'language:it', 'language:ja', 'language:ka', 'language:ko', 'language:lt', 'language:mk', 'language:mr', 'language:nl', 'language:pl', 'language:pt', 'language:ro', 'language:ru', 'language:sk', 'language:sl', 'language:sq', 'language:sr', 'language:uk', 'language:vi', 'language:zh', 'size_categories:10M<n<100M', 'format:parquet', 'modality:text', 'library:datasets', 'library:dask', 'library:mlcroissant', 'library:polars', 'region:us', 'sentence-transformers']","
	
		
		Dataset Card for Parallel Sentences - WikiMatrix
	

This dataset contains parallel sentences (i.e. English sentence + the same sentences in another language) for numerous other languages. Most of the sentences originate from the OPUS website.
In particular, this dataset contains the WikiMatrix dataset.

	
		
	
	
		Related Datasets
	

The following datasets are also a part of the Parallel Sentences collection:

parallel-sentences-europarl
parallel-sentences-global-voices… See the full description on the dataset page: https://huggingface.co/datasets/sentence-transformers/parallel-sentences-wikimatrix.",https://huggingface.co/datasets/sentence-transformers/parallel-sentences-wikimatrix,"['en', 'multilingual', 'ar', 'bg', 'ca', 'cs', 'da', 'de', 'el', 'es', 'et', 'fa', 'fi', 'fr', 'gl', 'he', 'hi', 'hr', 'id', 'it', 'ja', 'ka', 'ko', 'lt', 'mk', 'mr', 'nl', 'pl', 'pt', 'ro', 'ru', 'sk', 'sl', 'sq', 'sr', 'uk', 'vi', 'zh']","['feature-extraction', 'sentence-similarity']",['10M<n<100M']
gbenson/webui-dom-snapshots,gbenson,2024-04-30 14:39:51+00:00,2024-06-09 07:36:33+00:00,55,2,"['task_categories:image-feature-extraction', 'task_categories:reinforcement-learning', 'task_categories:text-classification', 'multilinguality:multilingual', 'source_datasets:biglab/webui-7k', 'source_datasets:original', 'language:en', 'language:nl', 'language:fr', 'language:zh', 'language:ja', 'language:de', 'language:id', 'language:cs', 'language:ru', 'language:pt', 'language:fi', 'language:sv', 'language:no', 'language:pl', 'language:da', 'language:sl', 'language:hu', 'language:vi', 'language:is', 'language:ko', 'language:th', 'language:tr', 'language:ar', 'language:bg', 'language:el', 'language:uk', 'language:es', 'language:et', 'language:gd', 'language:ne', 'language:sk', 'language:af', 'language:bn', 'language:gl', 'language:hi', 'language:it', 'language:lt', 'language:lv', 'language:ml', 'language:sr', 'language:to', 'license:cc0-1.0', 'size_categories:1K<n<10K', 'format:parquet', 'modality:image', 'modality:text', 'library:datasets', 'library:dask', 'library:mlcroissant', 'library:polars', 'region:us']","
	
		
		Dataset Card for WebUI DOM snapshots
	



This dataset card aims to be a base template for new datasets. It has been generated using this raw template.

	
		
		Dataset Details
	


	
		
		Dataset Description
	






Curated by: Gary Benson
Languages: Mostly English (87%);
Dutch, French, Chinese, Japanese (1-2% each); 30+ others (<1% each)
License: CC0 1.0 Universal


	
		
		Dataset Sources [optional]
	




Repository: [More Information Needed]
Paper [optional]: [More Information Needed]… See the full description on the dataset page: https://huggingface.co/datasets/gbenson/webui-dom-snapshots.",https://huggingface.co/datasets/gbenson/webui-dom-snapshots,"['en', 'nl', 'fr', 'zh', 'ja', 'de', 'id', 'cs', 'ru', 'pt', 'fi', 'sv', 'no', 'pl', 'da', 'sl', 'hu', 'vi', 'is', 'ko', 'th', 'tr', 'ar', 'bg', 'el', 'uk', 'es', 'et', 'gd', 'ne', 'sk', 'af', 'bn', 'gl', 'hi', 'it', 'lt', 'lv', 'ml', 'sr', 'to']","['image-feature-extraction', 'reinforcement-learning', 'text-classification']",['1K<n<10K']
win10/AthenaGenSynth-dataset,win10,2024-05-01 06:18:23+00:00,2024-05-04 11:37:00+00:00,7,0,"['task_categories:text-generation', 'language:en', 'language:zh', 'language:ja', 'license:mit', 'size_categories:10K<n<100K', 'format:text', 'modality:text', 'library:datasets', 'library:mlcroissant', 'region:us']","使用我本人的github項目(https://github.com/win10ogod/AthenaGenSynth)生成的預訓練資料
Use the pre-training data generated by my own github project (https://github.com/win10ogod/AthenaGenSynth)
",https://huggingface.co/datasets/win10/AthenaGenSynth-dataset,"['en', 'zh', 'ja']",['text-generation'],['10K<n<100K']
mpkato/ntcir_data_search,mpkato,2024-05-01 12:29:35+00:00,2024-05-01 12:48:27+00:00,14,0,"['task_categories:text-retrieval', 'language:ja', 'language:en', 'region:us', 'ntcir']","
	
		
		NTCIR Data Search Task Test Collection
	


	
		
		License
	

The contents of the following files are distributed under different licenses.
Please refer to attribution field in data_search_*_collection.jsonl.bz2
for details.

data_search_j_collection.jsonl.bz2
data_search_e_collection.jsonl.bz2
data_search_j_data.tar.bz2
data_search_e_data.tar.bz2

The other files are licensed under CC BY 4.0.
Please cite our papers presented at https://ntcir.datasearch.jp/ , and do not cite our… See the full description on the dataset page: https://huggingface.co/datasets/mpkato/ntcir_data_search.",https://huggingface.co/datasets/mpkato/ntcir_data_search,"['ja', 'en']",['text-retrieval'],[]
HachiML/Hachi-Alpaca,HachiML,2024-05-01 12:45:21+00:00,2024-05-20 01:43:26+00:00,67,15,"['task_categories:text-generation', 'language:ja', 'license:apache-2.0', 'size_categories:100K<n<1M', 'format:parquet', 'modality:tabular', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us', 'synthetic', 'self-instruct']","
	
		
		Hachi-Alpaca
	


Hachi-Alpacaは、  

Stanford Alpacaの手法  
mistralai/Mixtral-8x22B-Instruct-v0.1

で作った合成データ(Synthetic data)です。モデルの利用にはDeepinfraを利用しています。  
また、""_cleaned""がついたデータセットはmistralai/Mixtral-8x22B-Instruct-v0.1によって精査されています。  



	
		
	
	
		Dataset Details
	


	
		
	
	
		Dataset Description
	




Curated by: HachiML
Language(s) (NLP): Japanese
License: Apache 2.0
Github: Alpaca-jp


	
	
	
		Uses
	



# library
fromdatasets import load_dataset

# Recommend getting the latest version… See the full description on the dataset page: https://huggingface.co/datasets/HachiML/Hachi-Alpaca.",https://huggingface.co/datasets/HachiML/Hachi-Alpaca,['ja'],['text-generation'],['100K<n<1M']
OmniAICreator/WebNovels-Ja,OmniAICreator,2024-05-02 01:30:24+00:00,2024-05-02 02:47:41+00:00,27,20,"['task_categories:text-generation', 'multilinguality:monolingual', 'language:ja', 'license:other', 'size_categories:1M<n<10M', 'format:json', 'modality:text', 'library:datasets', 'library:dask', 'library:mlcroissant', 'region:us', 'japanese', 'not-for-all-audiences', 'novel']","
	
		
		WebNovels-Ja
	

日本語はこちら
このデータセットは、著作権法第三十条の四の情報解析（機械学習等）の目的でのみ使用が許可されています。それ以外の用途での使用はライセンスにより禁止されています。
This dataset is only permitted for use under Article 30-4 of the Copyright Law of Japan for data analysis (such as machine learning) purposes. Any use for purposes other than those specified is prohibited by the license.

	
		
	
	
		Dataset Summary
	

This is a dataset of Japanese web novels that I personally collected.
Total number of characters: approximately 10 billion… See the full description on the dataset page: https://huggingface.co/datasets/OmniAICreator/WebNovels-Ja.",https://huggingface.co/datasets/OmniAICreator/WebNovels-Ja,['ja'],['text-generation'],['1M<n<10M']
GENIAC-Team-Ozaki/chatbot-arena-ja-calm2-7b-chat-experimental_deduped,GENIAC-Team-Ozaki,2024-05-02 08:30:14+00:00,2024-05-02 08:31:34+00:00,13,0,"['task_categories:question-answering', 'language:ja', 'license:cc-by-4.0', 'size_categories:10K<n<100K', 'format:parquet', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","chatbot-arena-ja-calm2-7b-chatからpromptが一致するデータを削除したデータセットです。
",https://huggingface.co/datasets/GENIAC-Team-Ozaki/chatbot-arena-ja-calm2-7b-chat-experimental_deduped,['ja'],['question-answering'],['10K<n<100K']
retarfi/economy-watchers-survey,retarfi,2024-05-02 08:31:42+00:00,2025-10-09 13:35:48+00:00,136,1,"['language:ja', 'license:cc-by-4.0', 'size_categories:100K<n<1M', 'format:json', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'arxiv:2407.14727', 'doi:10.57967/hf/4513', 'region:us']","
	
		
		economy-watchers-survey
	

Economy Watchers Survey data.It is automatically updated by GitHub Actions as the economy watcher is updated.The dataset for tasks is retarfi/economy-watchers-survey-evaluation. 
景気ウォッチャー調査のデータを自動更新・整形・抽出を行います。自動更新はGitHub Actionsによって月次で行われます。タスク用のデータセットはretarfi/economy-watchers-survey-evaluationから利用可能です。  

	
		
	
	
		Data detail
	

Please refer to the following papers for the data detail.データの詳細は、以下の論文を参照してください。

English paper:… See the full description on the dataset page: https://huggingface.co/datasets/retarfi/economy-watchers-survey.",https://huggingface.co/datasets/retarfi/economy-watchers-survey,['ja'],[],['100K<n<1M']
RekaAI/VibeEval,RekaAI,2024-05-02 10:09:50+00:00,2024-12-12 22:53:57+00:00,850,47,"['task_categories:image-to-text', 'task_categories:image-classification', 'language:en', 'language:pl', 'language:zh', 'language:ja', 'license:apache-2.0', 'size_categories:n<1K', 'format:parquet', 'modality:image', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'arxiv:2405.02287', 'region:us', 'Reka', 'Vibe', 'Eval', 'VibeEval', 'Vibe-Eval', 'Hard']","
	
		
		Vibe-Eval
	

A benchmark for evaluating multimodal chat models, including especially challenging examples.
[Link to paper] [Blogpost] [Github]


	
		
	
	
		Dataset
	

Each example has the following fields:

example_id: a unique ID for the example
category: the category that this example belongs to, either difficulty-normal or difficulty-hard
prompt: the user prompt
reference: a golden reference answer for the prompt
image: an image struct (containing bytes and path keys).… See the full description on the dataset page: https://huggingface.co/datasets/RekaAI/VibeEval.",https://huggingface.co/datasets/RekaAI/VibeEval,"['en', 'pl', 'zh', 'ja']","['image-to-text', 'image-classification']",['n<1K']
shavarani/SHINRA-5LDS,shavarani,2024-05-02 18:41:05+00:00,2025-02-17 21:50:23+00:00,48,1,"['language:ja', 'language:en', 'language:fr', 'language:de', 'language:fa', 'arxiv:1909.06502', 'region:us']","This dataset was originally created in August 2018 and was published in Multi-class Multilingual Classification of Wikipedia Articles Using Extended Named Entity Tag Set in LREC'20 (https://huggingface.co/papers/1909.06502).

	
		
		Description of the data files
	


enes.json: This file contains the annotation classes originally provided in the 'Extended Named Entity Hierarchy'. You can find more information about this in the 'Extended Named Entity Hierarchy'… See the full description on the dataset page: https://huggingface.co/datasets/shavarani/SHINRA-5LDS.",https://huggingface.co/datasets/shavarani/SHINRA-5LDS,"['ja', 'en', 'fr', 'de', 'fa']",[],[]
ltvmoon/opusbook_ja_en,ltvmoon,2024-05-04 03:37:33+00:00,2024-05-04 14:45:16+00:00,22,0,"['task_categories:translation', 'language:ja', 'language:en', 'region:us']","language:

jp
en
tags:
translation
license: cc-by-4.0

",https://huggingface.co/datasets/ltvmoon/opusbook_ja_en,"['ja', 'en']",['translation'],[]
GENIAC-Team-Ozaki/WikiHowNFQA-ja,GENIAC-Team-Ozaki,2024-05-06 05:07:10+00:00,2024-05-06 05:40:54+00:00,62,0,"['task_categories:question-answering', 'language:ja', 'license:cc-by-4.0', 'size_categories:10K<n<100K', 'format:parquet', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","Lurunchik/WikiHowNFQAを日本語に翻訳したデータセットです。
",https://huggingface.co/datasets/GENIAC-Team-Ozaki/WikiHowNFQA-ja,['ja'],['question-answering'],['10K<n<100K']
refine-ai/subscene,refine-ai,2024-05-06 06:14:23+00:00,2025-03-08 05:26:11+00:00,22002,0,"['task_categories:text-generation', 'task_categories:translation', 'task_categories:text-classification', 'language:ar', 'language:hy', 'language:az', 'language:eu', 'language:be', 'language:bn', 'language:bs', 'language:pt', 'language:bg', 'language:my', 'language:km', 'language:ca', 'language:zh', 'language:hr', 'language:cs', 'language:da', 'language:nl', 'language:en', 'language:eo', 'language:et', 'language:fa', 'language:fi', 'language:fr', 'language:ka', 'language:de', 'language:el', 'language:he', 'language:hi', 'language:hu', 'language:is', 'language:it', 'language:ja', 'language:kn', 'language:ko', 'language:ku', 'language:lv', 'language:lt', 'language:mk', 'language:ms', 'language:ml', 'language:mn', 'language:ne', 'language:no', 'language:ps', 'language:pl', 'language:pa', 'language:ro', 'language:ru', 'language:sr', 'language:si', 'language:sk', 'language:sl', 'language:so', 'language:es', 'language:su', 'language:sw', 'language:sv', 'language:tl', 'language:ta', 'language:te', 'language:th', 'language:tr', 'language:uk', 'language:ur', 'language:ve', 'language:yo', 'language:id', 'size_categories:1B<n<10B', 'region:us']","Subscene is a vast collection of multilingual subtitles, encompassing 65 different languages and consisting of more than 30 billion tokens with a total size of 410.70 GB. This dataset includes subtitles for movies, series, and animations gathered from the Subscene dump. It provides a rich resource for studying language variations and building multilingual NLP models. We have carefully applied a fastText classifier to remove any non-language content from incorrect subsets. Additionally, we performed basic cleaning and filtration. However, there is still room for further cleaning and refinement.",https://huggingface.co/datasets/refine-ai/subscene,"['ar', 'hy', 'az', 'eu', 'be', 'bn', 'bs', 'pt', 'bg', 'my', 'km', 'ca', 'zh', 'hr', 'cs', 'da', 'nl', 'en', 'eo', 'et', 'fa', 'fi', 'fr', 'ka', 'de', 'el', 'he', 'hi', 'hu', 'is', 'it', 'ja', 'kn', 'ko', 'ku', 'lv', 'lt', 'mk', 'ms', 'ml', 'mn', 'ne', 'no', 'ps', 'pl', 'pa', 'ro', 'ru', 'sr', 'si', 'sk', 'sl', 'so', 'es', 'su', 'sw', 'sv', 'tl', 'ta', 'te', 'th', 'tr', 'uk', 'ur', 've', 'yo', 'id']","['text-generation', 'translation', 'text-classification']",['1B<n<10B']
MLSP2024/MLSP2024,MLSP2024,2024-05-06 06:52:41+00:00,2025-06-27 02:16:17+00:00,12,6,"['task_categories:token-classification', 'task_categories:other', 'task_ids:text-simplification', 'annotations_creators:crowdsourced, expert-generated', 'language_creators:found', 'multilinguality:multilingual', 'language:en', 'language:ca', 'language:fil', 'language:fr', 'language:de', 'language:it', 'language:ja', 'language:pt', 'language:si', 'language:es', 'license:cc-by-sa-4.0', 'size_categories:10K<n<100K', 'format:csv', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'arxiv:2402.14972', 'arxiv:2404.07814', 'region:us', 'LS', 'lexical simplification', 'LCP', 'lexical complexity prediction', 'CWI', 'complex word identification', 'multilingual', 'evaluation', 'test']","The MultiLS dataset was created as part of the MLSP2024 shared task. 
The dataset contains 5,624 instances across 10 target languages. 
Each instance consists of a sentence from an educational text, with a marked target word. 
For each target word in the given context, two annotations are given. 
Firstly, an aggregate complexity score derived from asking 10 annotators to mark the level of difficulty of the target token on a scale of 1-5.
Secondly, a list of possible substitutions for the… See the full description on the dataset page: https://huggingface.co/datasets/MLSP2024/MLSP2024.",https://huggingface.co/datasets/MLSP2024/MLSP2024,"['en', 'ca', 'fil', 'fr', 'de', 'it', 'ja', 'pt', 'si', 'es']","['token-classification', 'other']",['10K<n<100K']
DeliberatorArchiver/gi_cutscn_new,DeliberatorArchiver,2024-05-06 16:11:14+00:00,2024-11-19 09:04:30+00:00,556,0,"['language:zh', 'language:en', 'language:ja', 'language:ko', 'license:cc-by-nc-nd-4.0', 'region:us']","
	
		
		gi_cutscn_new
	

This repository contains cut-scene video files from a certain anime game (a.k.a. GI).
 

	
		
		Disclaimer
	

This resource is released for educational or research purposes only. Copyrights and other rights to this resource belong to their respective copyright holders.

	
		
		About
	

All cut-scene video files are encoded using HLS streaming technology.

	
		
		Details
	

The original files were extracted directly from the game.
The original file contains one video… See the full description on the dataset page: https://huggingface.co/datasets/DeliberatorArchiver/gi_cutscn_new.",https://huggingface.co/datasets/DeliberatorArchiver/gi_cutscn_new,"['zh', 'en', 'ja', 'ko']",[],[]
seungwon929/Ja-miracl,seungwon929,2024-05-07 04:06:27+00:00,2024-05-07 05:17:43+00:00,15,0,"['task_categories:text-retrieval', 'task_ids:document-retrieval', 'multilinguality:monolingual', 'source_datasets:miracl', 'language:ja', 'size_categories:1M<n<10M', 'format:json', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us', 'text-retrieval']","
	
		
		Ja-miracl
	

This dataset represents a conversion of the Japanese (Ja) section from the miracl dataset into the BeIR format, making it compatible for use with mteb.
",https://huggingface.co/datasets/seungwon929/Ja-miracl,['ja'],['text-retrieval'],['1M<n<10M']
eliashasnat/business-questions,eliashasnat,2024-05-08 04:33:03+00:00,2024-05-08 05:48:22+00:00,6,0,"['language:ja', 'license:mit', 'size_categories:n<1K', 'format:json', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","
	
		
		Example Business Questions
	

",https://huggingface.co/datasets/eliashasnat/business-questions,['ja'],[],['n<1K']
ayousanz/OSCOR-2301-ja-cleaned,ayousanz,2024-05-08 04:52:54+00:00,2024-05-09 03:16:36+00:00,204,1,"['language:ja', 'license:cc0-1.0', 'size_categories:10M<n<100M', 'format:json', 'modality:text', 'library:datasets', 'library:dask', 'library:mlcroissant', 'library:polars', 'region:us', 'OSCAR-2301']","
	
		
		概要
	

oscar-corpus/OSCAR-2301の以下のjaのみを corpus-cleanerを使用してデータクリーニングを行なったデーセット群

	
		
Code
Language
# docs
# words
Content Length :


		
ja
Japanese
94,236,404
4,401,059,165
181.2 GB


	

ただし以下のファイルは、クリーニングが成功していないため除外しています。
ja_meta_part_117.jsonl
ja_meta_part_13.jsonl
ja_meta_part_24.jsonl
ja_meta_part_4.jsonl
ja_meta_part_64.jsonl
ja_meta_part_81.jsonl
ja_meta_part_82.jsonl

",https://huggingface.co/datasets/ayousanz/OSCOR-2301-ja-cleaned,['ja'],[],['10M<n<100M']
kanhatakeyama/AutoWikiQA,kanhatakeyama,2024-05-08 08:25:16+00:00,2024-05-09 01:05:15+00:00,11,4,"['task_categories:question-answering', 'language:ja', 'license:cc-by-4.0', 'size_categories:100K<n<1M', 'format:parquet', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us', 'synthetic']","
	
		
		Wikipedia日本語版からのQ&Aの自動生成
	


Mixtral 8x22bのGGUF(5bit)をベースに､Wikipedia日本語版の記事から､
自動生成コード1
自動生成コード2


を使ってQ&Aを作成しました｡
計算には東京工業大学のスーパーコンピュータTSUBAME4.0を利用しました｡


	
		
	
	
		注意
	


回答にハルシネーション等が含まれている可能性があるので､フィルタリングをかける必要があるかもしれません｡

",https://huggingface.co/datasets/kanhatakeyama/AutoWikiQA,['ja'],['question-answering'],['100K<n<1M']
ToxicityPrompts/PolygloToxicityPrompts,ToxicityPrompts,2024-05-08 13:11:40+00:00,2024-05-16 07:02:28+00:00,232,11,"['task_categories:text-generation', 'language:en', 'language:nl', 'language:pl', 'language:sv', 'language:ru', 'language:hi', 'language:ja', 'language:ko', 'language:zh', 'language:es', 'language:fr', 'language:it', 'language:id', 'language:ar', 'language:cs', 'language:de', 'language:pt', 'size_categories:100K<n<1M', 'format:parquet', 'modality:tabular', 'modality:text', 'library:datasets', 'library:dask', 'library:mlcroissant', 'library:polars', 'arxiv:2405.09373', 'region:us', 'toxicity', 'not-for-all-audiences']","
	
		
		PolygloToxicityPrompts
	


	
		
		Dataset Summary
	

A multilingual toxicity evaluation benchmark curated from web text.
We prepared 3 splits: ptp-full, ptp-small, and wildchat containining 25K, 5K and 1K prompts per language respectively.
The wildchat split is created using AI2's WildChat dataset.

	
		
		How do I download this?
	


	
		
		Using 🤗 Datasets
	

from datasets import load_dataset

# English only
dataset = load_dataset(""ToxicityPrompts/PolygloToxicityPrompts"", ""ptp-en"")… See the full description on the dataset page: https://huggingface.co/datasets/ToxicityPrompts/PolygloToxicityPrompts.",https://huggingface.co/datasets/ToxicityPrompts/PolygloToxicityPrompts,"['en', 'nl', 'pl', 'sv', 'ru', 'hi', 'ja', 'ko', 'zh', 'es', 'fr', 'it', 'id', 'ar', 'cs', 'de', 'pt']",['text-generation'],['100K<n<1M']
recursal/SuperWiki-1.5,recursal,2024-05-09 03:45:56+00:00,2024-06-10 12:17:53+00:00,17,1,"['task_categories:text-generation', 'task_categories:fill-mask', 'task_ids:language-modeling', 'task_ids:masked-language-modeling', 'annotations_creators:no-annotation', 'language_creators:crowdsourced', 'source_datasets:original', 'language:ar', 'language:de', 'language:en', 'language:es', 'language:fa', 'language:fr', 'language:he', 'language:hi', 'language:id', 'language:it', 'language:ja', 'language:ko', 'language:nl', 'language:pl', 'language:pt', 'language:ru', 'language:sv', 'language:tr', 'language:uk', 'language:vi', 'language:zh', 'license:cc-by-sa-3.0', 'region:us']","
	
		
		Dataset Details
	


Waifu to catch your attention.

	
		
		Dataset Description
	

SuperWIKI-1.5 is a ~18.23B Tokens (llama-2-7b-chat-tokenizer) / ~15.17B Tokens (RWKV Tokenizer) multilingual dataset of Wikipedia articles, curated from Wikipedia HTML dumps. 
It serves as a training resource for large language models and other NLP tasks. 
This card details the dataset's origin, content, and limitations.

Curated by: KaraKaraWitch
Funded by: Recursal.ai (I work there lol)
Shared by:… See the full description on the dataset page: https://huggingface.co/datasets/recursal/SuperWiki-1.5.",https://huggingface.co/datasets/recursal/SuperWiki-1.5,"['ar', 'de', 'en', 'es', 'fa', 'fr', 'he', 'hi', 'id', 'it', 'ja', 'ko', 'nl', 'pl', 'pt', 'ru', 'sv', 'tr', 'uk', 'vi', 'zh']","['text-generation', 'fill-mask']",[]
kenken999/urlounge,kenken999,2024-05-09 05:12:56+00:00,2024-05-16 08:06:57+00:00,14,0,"['task_categories:text-classification', 'language:ja', 'license:mit', 'region:us', 'finance']",,https://huggingface.co/datasets/kenken999/urlounge,['ja'],['text-classification'],[]
ikeno-ada/Japanese-English_translation_of_contents_HScodes,ikeno-ada,2024-05-09 09:29:48+00:00,2024-05-09 09:37:08+00:00,12,0,"['language:ja', 'language:en', 'license:mit', 'size_categories:1K<n<10K', 'format:csv', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","日本郵便が提供する「国際郵便　内容品の日英・中英訳、HSコード類」（2024/05/09）のデータに基づいています。
詳しくはサイトをご覧ください
https://www.post.japanpost.jp/int/use/publication/contentslist/index.php?id=0&ie=utf8&lang=_ja&q=
",https://huggingface.co/datasets/ikeno-ada/Japanese-English_translation_of_contents_HScodes,"['ja', 'en']",[],['1K<n<10K']
eldad-akhaumere/hausa_2_eng_2,eldad-akhaumere,2024-05-09 14:30:17+00:00,2024-05-27 09:46:30+00:00,16,0,"['annotations_creators:crowdsourced', 'language_creators:crowdsourced', 'multilinguality:multilingual', 'language:ab', 'language:af', 'language:am', 'language:ar', 'language:as', 'language:ast', 'language:az', 'language:ba', 'language:bas', 'language:be', 'language:bg', 'language:bn', 'language:br', 'language:ca', 'language:ckb', 'language:cnh', 'language:cs', 'language:cv', 'language:cy', 'language:da', 'language:de', 'language:dv', 'language:dyu', 'language:el', 'language:en', 'language:eo', 'language:es', 'language:et', 'language:eu', 'language:fa', 'language:fi', 'language:fr', 'language:fy', 'language:ga', 'language:gl', 'language:gn', 'language:ha', 'language:he', 'language:hi', 'language:hsb', 'language:hu', 'language:hy', 'language:ia', 'language:id', 'language:ig', 'language:is', 'language:it', 'language:ja', 'language:ka', 'language:kab', 'language:kk', 'language:kmr', 'language:ko', 'language:ky', 'language:lg', 'language:lij', 'language:lo', 'language:lt', 'language:ltg', 'language:lv', 'language:mdf', 'language:mhr', 'language:mk', 'language:ml', 'language:mn', 'language:mr', 'language:mrj', 'language:mt', 'language:myv', 'language:nan', 'language:ne', 'language:nhi', 'language:nl', 'language:nn', 'language:oc', 'language:or', 'language:os', 'language:pa', 'language:pl', 'language:ps', 'language:pt', 'language:quy', 'language:rm', 'language:ro', 'language:ru', 'language:rw', 'language:sah', 'language:tig', 'language:yue', 'language:zgh', 'language:zh', 'license:apache-2.0', 'arxiv:1912.06670', 'region:us']","
	
		
		Dataset Card for Common Voice Corpus 16
	


	
		
		Dataset Summary
	

The Common Voice dataset consists of a unique MP3 and corresponding text file. 
Many of the 30328 recorded hours in the dataset also include demographic metadata like age, sex, and accent 
that can help improve the accuracy of speech recognition engines.
The dataset currently consists of 19673 validated hours in 120 languages, but more voices and languages are always added. 
Take a look at the Languages page to… See the full description on the dataset page: https://huggingface.co/datasets/eldad-akhaumere/hausa_2_eng_2.",https://huggingface.co/datasets/eldad-akhaumere/hausa_2_eng_2,"['ab', 'af', 'am', 'ar', 'as', 'ast', 'az', 'ba', 'bas', 'be', 'bg', 'bn', 'br', 'ca', 'ckb', 'cnh', 'cs', 'cv', 'cy', 'da', 'de', 'dv', 'dyu', 'el', 'en', 'eo', 'es', 'et', 'eu', 'fa', 'fi', 'fr', 'fy', 'ga', 'gl', 'gn', 'ha', 'he', 'hi', 'hsb', 'hu', 'hy', 'ia', 'id', 'ig', 'is', 'it', 'ja', 'ka', 'kab', 'kk', 'kmr', 'ko', 'ky', 'lg', 'lij', 'lo', 'lt', 'ltg', 'lv', 'mdf', 'mhr', 'mk', 'ml', 'mn', 'mr', 'mrj', 'mt', 'myv', 'nan', 'ne', 'nhi', 'nl', 'nn', 'oc', 'or', 'os', 'pa', 'pl', 'ps', 'pt', 'quy', 'rm', 'ro', 'ru', 'rw', 'sah', 'tig', 'yue', 'zgh', 'zh']",[],[]
toshi456/NLVR-JA,toshi456,2024-05-10 12:44:01+00:00,2024-05-10 12:51:56+00:00,5,0,"['task_categories:image-to-text', 'language:ja', 'license:cc-by-4.0', 'region:us']","This dataset was created by machine translating ""nlvr"" into Japanese.
nlvr
https://github.com/lil-lab/nlvr/tree/master/nlvr
",https://huggingface.co/datasets/toshi456/NLVR-JA,['ja'],['image-to-text'],[]
GENIAC-Team-Ozaki/WikiHowNFQA-ja_cleaned,GENIAC-Team-Ozaki,2024-05-10 23:31:18+00:00,2024-05-10 23:34:09+00:00,17,3,"['task_categories:question-answering', 'language:ja', 'license:cc-by-4.0', 'size_categories:1K<n<10K', 'format:parquet', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","Lurunchik/WikiHowNFQAを日本語に翻訳し、人手でクリーニングしたデータセットです。
",https://huggingface.co/datasets/GENIAC-Team-Ozaki/WikiHowNFQA-ja_cleaned,['ja'],['question-answering'],['1K<n<10K']
toshi456/docci_ja,toshi456,2024-05-12 10:49:52+00:00,2024-05-12 12:53:41+00:00,11,0,"['task_categories:image-to-text', 'language:ja', 'license:cc-by-4.0', 'size_categories:10K<n<100K', 'format:json', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","This data was translated from the ""DOCCI"" into Japanese by DeepL
DOCCI: https://google.github.io/docci/
Lisence
CC-BY-4.0
",https://huggingface.co/datasets/toshi456/docci_ja,['ja'],['image-to-text'],['10K<n<100K']
HachiML/Evol-Alpaca-gen3-500,HachiML,2024-05-12 11:13:09+00:00,2024-05-20 01:43:43+00:00,11,0,"['task_categories:text-generation', 'language:ja', 'license:apache-2.0', 'size_categories:n<1K', 'format:parquet', 'modality:tabular', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'arxiv:2304.12244', 'region:us', 'synthetic', 'evol-instruct']","
	
		
		Evol-Alpaca-gen3-500
	


Evol-Alpaca-gen3-500は、  

Stanford Alpacaのseed tasksを日本語化
Evol-Instructionの手法  
mistralai/Mixtral-8x22B-Instruct-v0.1

で作った合成データ(Synthetic data)です。モデルの利用にはDeepinfraを利用しています。  



	
		
	
	
		Dataset Details
	


	
		
	
	
		Dataset Description
	




Curated by: HachiML
Language(s) (NLP): Japanese
License: Apache 2.0
Github: Evol-Instruct-jp


	
	
	
		Uses
	



# library
fromdatasets import load_dataset

# Load dataset.
dataset =… See the full description on the dataset page: https://huggingface.co/datasets/HachiML/Evol-Alpaca-gen3-500.",https://huggingface.co/datasets/HachiML/Evol-Alpaca-gen3-500,['ja'],['text-generation'],['n<1K']
HachiML/Evol-hh-rlhf-gen3-1k,HachiML,2024-05-12 13:16:17+00:00,2024-05-20 01:44:05+00:00,14,1,"['task_categories:text-generation', 'language:ja', 'license:mit', 'size_categories:1K<n<10K', 'format:parquet', 'modality:tabular', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'arxiv:2304.12244', 'region:us', 'synthetic', 'evol-instruct']","
	
		
		Evol-hh-rlhf-gen3-1k
	


Evol-hh-rlhf-gen3-1kは、  

kunishou/hh-rlhf-49k-jaをseed tasksとして
Evol-Instructionの手法  
mistralai/Mixtral-8x22B-Instruct-v0.1

で作った合成データ(Synthetic data)です。モデルの利用にはDeepinfraを利用しています。  



	
		
	
	
		Dataset Details
	


	
		
	
	
		Dataset Description
	




Curated by: HachiML
Language(s) (NLP): Japanese
License: Apache 2.0
Github: Evol-Instruct-jp


	
	
	
		Uses
	



# library
fromdatasets import load_dataset

# Load dataset.
dataset =… See the full description on the dataset page: https://huggingface.co/datasets/HachiML/Evol-hh-rlhf-gen3-1k.",https://huggingface.co/datasets/HachiML/Evol-hh-rlhf-gen3-1k,['ja'],['text-generation'],['1K<n<10K']
toshi456/LLaVA-JP-Instruct-108K,toshi456,2024-05-12 13:38:21+00:00,2024-05-12 13:51:45+00:00,7,1,"['task_categories:image-to-text', 'language:ja', 'license:apache-2.0', 'size_categories:100K<n<1M', 'region:us']","
	
		
		Dataset details
	

Dataset type: LLaVA JP Instruct 108K created by changing the data sets in Japanese Visual Genome VQA dataset and train data of docci_ja to the LLaVA-Instruct format.

	
		
		Acknowledgement
	


Japanese Visual Genome VQA dataset
DOCCI


	
		
		Lisence
	

Apach lisense 2.0
",https://huggingface.co/datasets/toshi456/LLaVA-JP-Instruct-108K,['ja'],['image-to-text'],['100K<n<1M']
berwart/SE-Chatting.en,berwart,2024-05-13 08:11:23+00:00,2024-10-03 21:10:29+00:00,120,3,"['task_categories:question-answering', 'task_categories:translation', 'language:en', 'language:fr', 'language:ja', 'language:zh', 'language:ru', 'language:ar', 'license:mit', 'size_categories:10M<n<100M', 'format:json', 'modality:text', 'library:datasets', 'library:dask', 'library:mlcroissant', 'region:us', 'chemistry', 'biology', 'finance', 'legal', 'music', 'art', 'code', 'climate', 'medical']","
	
		
		SE.02
	

Dataset
Hello, welcome to the official main dataset of SE.02 that's always getting updated, make sure to like to help us a lot.
this dataset contains pretty much everything from math to isk what to put but pretty much anything you think an ai can say.
anyways this is our biggest dataset yet, and out first one that I don't even know how I managed to make this.
you can use it to train your own ai if you want.
",https://huggingface.co/datasets/berwart/SE-Chatting.en,"['en', 'fr', 'ja', 'zh', 'ru', 'ar']","['question-answering', 'translation']",['10M<n<100M']
amitbcp/nomir,amitbcp,2024-05-14 04:22:05+00:00,2024-05-15 05:43:21+00:00,205,0,"['task_categories:text-classification', 'annotations_creators:expert-generated', 'multilinguality:multilingual', 'source_datasets:miracl/miracl', 'language:ar', 'language:bn', 'language:en', 'language:es', 'language:fa', 'language:fi', 'language:fr', 'language:hi', 'language:id', 'language:ja', 'language:ko', 'language:ru', 'language:sw', 'language:te', 'language:th', 'language:zh', 'language:pt', 'license:apache-2.0', 'size_categories:10K<n<100K', 'arxiv:2312.11361', 'region:us']",Data Loader for the NoMIRACL dataset.,https://huggingface.co/datasets/amitbcp/nomir,"['ar', 'bn', 'en', 'es', 'fa', 'fi', 'fr', 'hi', 'id', 'ja', 'ko', 'ru', 'sw', 'te', 'th', 'zh', 'pt']",['text-classification'],['10K<n<100K']
hpprc/jawiki-paragraphs,hpprc,2024-05-15 04:21:52+00:00,2024-07-19 07:49:35+00:00,13,2,"['language:ja', 'license:cc-by-sa-4.0', 'size_categories:10M<n<100M', 'format:parquet', 'modality:text', 'library:datasets', 'library:dask', 'library:mlcroissant', 'library:polars', 'region:us']",,https://huggingface.co/datasets/hpprc/jawiki-paragraphs,['ja'],[],['10M<n<100M']
floschne/multilingual-llava-bench-in-the-wild,floschne,2024-05-15 13:45:59+00:00,2024-05-16 13:33:36+00:00,21,0,"['language:ar', 'language:bn', 'language:zh', 'language:en', 'language:fr', 'language:ru', 'language:es', 'language:ur', 'language:hi', 'language:ja', 'license:cc-by-4.0', 'size_categories:n<1K', 'format:parquet', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'arxiv:2402.14818', 'region:us']","
	
		
		Multilingual LLaVA Bench in the Wild
	


	
		
		Note that this is a copy from https://huggingface.co/datasets/MBZUAI/multilingual-llava-bench-in-the-wild
	

It was created due to issues in the original repo. It also includes the image features and has a uniform and joined structure.
If you use this dataset, please cite the original authors:
@article{PALO2024,
  title={Palo: A Large Multilingual Multimodal Language Model},
  author={Maaz, Muhammad and Rasheed, Hanoona and Shaker… See the full description on the dataset page: https://huggingface.co/datasets/floschne/multilingual-llava-bench-in-the-wild.",https://huggingface.co/datasets/floschne/multilingual-llava-bench-in-the-wild,"['ar', 'bn', 'zh', 'en', 'fr', 'ru', 'es', 'ur', 'hi', 'ja']",[],['n<1K']
HachiML/amenokaku-code-instruct-python-mit,HachiML,2024-05-16 01:07:35+00:00,2024-05-16 01:11:29+00:00,17,0,"['task_categories:text-generation', 'language:ja', 'license:mit', 'size_categories:1K<n<10K', 'format:parquet', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us', 'python', 'code']","kunishou/amenokaku-code-instructを以下の条件で絞り込んだものです。  

MITライセンス (licence: 'MIT')
python (source: ['gasyori_100_knocks', 'datascience_100_knocks_python', 'bifi', 'python_for_begginers_solve_50_exercises', 'nlp_100_knocks')

",https://huggingface.co/datasets/HachiML/amenokaku-code-instruct-python-mit,['ja'],['text-generation'],['1K<n<10K']
HachiML/amenokaku-code-instruct-python-mit-450,HachiML,2024-05-16 01:15:19+00:00,2024-05-16 01:22:57+00:00,15,0,"['task_categories:text-generation', 'language:ja', 'license:mit', 'size_categories:n<1K', 'format:parquet', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us', 'code', 'python']","kunishou/amenokaku-code-instructを以下の条件で絞り込んだものです。  

MITライセンス (licence: 'MIT')
python (source: ['gasyori_100_knocks', 'datascience_100_knocks_python', 'bifi', 'python_for_begginers_solve_50_exercises', 'nlp_100_knocks')
source: 'bifi'をランダムに100件に絞り込み

",https://huggingface.co/datasets/HachiML/amenokaku-code-instruct-python-mit-450,['ja'],['text-generation'],['n<1K']
HachiML/alpaca_jp_python,HachiML,2024-05-16 02:02:08+00:00,2024-05-20 01:44:32+00:00,122,8,"['task_categories:text-generation', 'language:ja', 'license:apache-2.0', 'size_categories:10K<n<100K', 'format:parquet', 'modality:tabular', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us', 'synthetic', 'code', 'python', 'self-instruct']","
	
		
		alpaca_jp_python
	


alpaca_jp_pythonは、  

Stanford Alpacaの手法  
mistralai/Mixtral-8x22B-Instruct-v0.1

で作った合成データ(Synthetic data)です。モデルの利用にはDeepinfraを利用しています。  
また、""_cleaned""がついたデータセットはmistralai/Mixtral-8x22B-Instruct-v0.1によって精査されています。  



	
		
	
	
		Dataset Details
	


	
		
	
	
		Dataset Description
	




Curated by: HachiML
Language(s) (NLP): Japanese
License: Apache 2.0
Github: Alpaca-jp


	
	
	
		Uses
	



# library
fromdatasets import load_dataset

# Recommend getting the latest… See the full description on the dataset page: https://huggingface.co/datasets/HachiML/alpaca_jp_python.",https://huggingface.co/datasets/HachiML/alpaca_jp_python,['ja'],['text-generation'],['10K<n<100K']
aipracticecafe/test_rp,aipracticecafe,2024-05-16 10:18:27+00:00,2024-05-24 14:33:04+00:00,6,0,"['task_categories:text-generation', 'language:ja', 'license:mit', 'size_categories:n<1K', 'format:json', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","Format to have User, Assistant in order.
def merge_roles(data):
    merged_data = []
    current_role = None
    current_content = []

    for entry in data[""messages""]:
#         print(entry)
        role = entry['role']
        if role == ""system"":
            role = ""user""
        content = entry['content']

        if role == current_role:
            current_content.append(content)
        else:
            ifcurrent_role is not None:
                merged_data.append({""role"":… See the full description on the dataset page: https://huggingface.co/datasets/aipracticecafe/test_rp.",https://huggingface.co/datasets/aipracticecafe/test_rp,['ja'],['text-generation'],['n<1K']
floschne/xm3600,floschne,2024-05-16 12:55:51+00:00,2024-05-23 14:04:18+00:00,214,5,"['task_categories:image-to-text', 'language:ar', 'language:bn', 'language:cs', 'language:da', 'language:de', 'language:el', 'language:en', 'language:es', 'language:fa', 'language:fi', 'language:fil', 'language:fr', 'language:hi', 'language:hr', 'language:hu', 'language:id', 'language:it', 'language:he', 'language:ja', 'language:ko', 'language:mi', 'language:nl', 'language:no', 'language:pl', 'language:pt', 'language:quz', 'language:ro', 'language:ru', 'language:sv', 'language:sw', 'language:te', 'language:th', 'language:tr', 'language:uk', 'language:vi', 'language:zh', 'license:cc-by-4.0', 'size_categories:100K<n<1M', 'region:us']","
	
		
		XM3600 - Crossmodal-3600
	


	
		
		This is a copy from https://google.github.io/crossmodal-3600/
	

If you use this dataset, please cite the original authors:
@inproceedings{ThapliyalCrossmodal2022,
  author = {Ashish Thapliyal and Jordi Pont-Tuset and Xi Chen and Radu Soricut},
  title = {{Crossmodal-3600: A Massively Multilingual Multimodal Evaluation Dataset}},
  booktitle = {EMNLP},
  year = {2022}
}

It also includes the image features as PIL Image and has a uniform and joined… See the full description on the dataset page: https://huggingface.co/datasets/floschne/xm3600.",https://huggingface.co/datasets/floschne/xm3600,"['ar', 'bn', 'cs', 'da', 'de', 'el', 'en', 'es', 'fa', 'fi', 'fil', 'fr', 'hi', 'hr', 'hu', 'id', 'it', 'he', 'ja', 'ko', 'mi', 'nl', 'no', 'pl', 'pt', 'quz', 'ro', 'ru', 'sv', 'sw', 'te', 'th', 'tr', 'uk', 'vi', 'zh']",['image-to-text'],['100K<n<1M']
floschne/xm3600_1k,floschne,2024-05-16 13:01:57+00:00,2024-05-23 14:05:50+00:00,40,0,"['task_categories:image-to-text', 'language:ar', 'language:bn', 'language:cs', 'language:da', 'language:de', 'language:el', 'language:en', 'language:es', 'language:fa', 'language:fi', 'language:fil', 'language:fr', 'language:hi', 'language:hr', 'language:hu', 'language:id', 'language:it', 'language:he', 'language:ja', 'language:ko', 'language:mi', 'language:nl', 'language:no', 'language:pl', 'language:pt', 'language:quz', 'language:ro', 'language:ru', 'language:sv', 'language:sw', 'language:te', 'language:th', 'language:tr', 'language:uk', 'language:vi', 'language:zh', 'license:cc-by-4.0', 'size_categories:10K<n<100K', 'region:us']","
	
		
		XM3600 - Crossmodal-3600 - 1K Split
	


	
		
		This is a copy from https://google.github.io/crossmodal-3600/
	

If you use this dataset, please cite the original authors:
@inproceedings{ThapliyalCrossmodal2022,
  author = {Ashish Thapliyal and Jordi Pont-Tuset and Xi Chen and Radu Soricut},
  title = {{Crossmodal-3600: A Massively Multilingual Multimodal Evaluation Dataset}},
  booktitle = {EMNLP},
  year = {2022}
}


	
		
	
	
		This is a 1K split of XM3600!
	

For this, we randomly… See the full description on the dataset page: https://huggingface.co/datasets/floschne/xm3600_1k.",https://huggingface.co/datasets/floschne/xm3600_1k,"['ar', 'bn', 'cs', 'da', 'de', 'el', 'en', 'es', 'fa', 'fi', 'fil', 'fr', 'hi', 'hr', 'hu', 'id', 'it', 'he', 'ja', 'ko', 'mi', 'nl', 'no', 'pl', 'pt', 'quz', 'ro', 'ru', 'sv', 'sw', 'te', 'th', 'tr', 'uk', 'vi', 'zh']",['image-to-text'],['10K<n<100K']
floschne/xflickrco,floschne,2024-05-16 13:44:30+00:00,2024-05-24 14:53:29+00:00,47,1,"['task_categories:image-to-text', 'language:de', 'language:en', 'language:es', 'language:id', 'language:ja', 'language:ru', 'language:tr', 'language:zh', 'license:cc-by-4.0', 'size_categories:10K<n<100K', 'format:parquet', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']",,https://huggingface.co/datasets/floschne/xflickrco,"['de', 'en', 'es', 'id', 'ja', 'ru', 'tr', 'zh']",['image-to-text'],['10K<n<100K']
Aratako/LimaRP-augmented-ja-karakuri,Aratako,2024-05-16 13:46:26+00:00,2024-05-17 17:58:35+00:00,14,4,"['task_categories:text-generation', 'language:ja', 'license:apache-2.0', 'size_categories:n<1K', 'format:json', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us', 'roleplay', 'not-for-all-audiences']","
	
		
		LimaRP-augmented-ja-karakuri
	

grimulkan/LimaRP-augmentedを、GENIAC-Team-Ozaki/karakuri-lm-8x7b-chat-v0.1-awqを用いて日本語に翻訳したロールプレイ学習用データセットです。
LLMの推論にはDeepInfraというサービスを使いました。

	
		
		翻訳の詳細
	


3-shots promptingでの翻訳
mistralのtokenizerで出力が8000トークンを超えるまで翻訳
元データセットにある非常に長い対話は上記条件で途中のターンで翻訳を終了しています。


LLM特有の同じ出力が繰り返される現象に遭遇した場合、その時点で該当レコードの翻訳を終了
この結果1ターン未満となったレコード（33件）を削除



",https://huggingface.co/datasets/Aratako/LimaRP-augmented-ja-karakuri,['ja'],['text-generation'],['n<1K']
Aratako/LimaRP-augmented-ja-WizardLM,Aratako,2024-05-16 13:48:23+00:00,2024-05-16 13:55:22+00:00,8,1,"['task_categories:text-generation', 'language:ja', 'license:apache-2.0', 'size_categories:n<1K', 'format:json', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us', 'roleplay', 'not-for-all-audiences']","
	
		
		LimaRP-augmented-ja-WizardLM
	

grimulkan/LimaRP-augmentedを、WizardLM-2-8x22Bを用いて日本語に翻訳したロールプレイ学習用データセットです。
LLMの推論にはDeepInfraというサービスを使いました。

	
		
		翻訳の詳細
	


3-shots promptingでの翻訳
mistralのtokenizerで出力が8000トークンを超えるまで翻訳
元データセットにある非常に長い対話は上記条件で途中のターンで翻訳を終了しています。


LLM特有の同じ出力が繰り返される現象に遭遇した場合、その時点で該当レコードの翻訳を終了
この結果1ターン未満となったレコード（12件）を削除



",https://huggingface.co/datasets/Aratako/LimaRP-augmented-ja-WizardLM,['ja'],['text-generation'],['n<1K']
aiana94/polynews,aiana94,2024-05-17 07:39:20+00:00,2024-06-21 08:37:54+00:00,194,6,"['task_categories:fill-mask', 'task_categories:text-generation', 'multilinguality:multilingual', 'source_datasets:masakhanews', 'source_datasets:mafand', 'source_datasets:wikinews', 'source_datasets:wmt-news', 'source_datasets:globalvoices', 'language:am', 'language:ar', 'language:ay', 'language:bm', 'language:bbj', 'language:bn', 'language:bs', 'language:bg', 'language:ca', 'language:cs', 'language:ku', 'language:da', 'language:el', 'language:en', 'language:et', 'language:ee', 'language:fil', 'language:fi', 'language:fr', 'language:fon', 'language:gu', 'language:guw', 'language:ha', 'language:he', 'language:hi', 'language:hu', 'language:ig', 'language:id', 'language:it', 'language:ja', 'language:kk', 'language:km', 'language:ko', 'language:lv', 'language:ln', 'language:lt', 'language:lg', 'language:luo', 'language:mk', 'language:mos', 'language:my', 'language:nl', 'language:no', 'language:ne', 'language:om', 'language:or', 'language:pa', 'language:pcm', 'language:fa', 'language:pl', 'language:pt', 'language:mg', 'language:ro', 'language:rn', 'language:ru', 'language:sn', 'language:so', 'language:es', 'language:sr', 'language:sq', 'language:sw', 'language:sv', 'language:ta', 'language:tet', 'language:ti', 'language:th', 'language:tn', 'language:tr', 'language:tw', 'language:uk', 'language:ur', 'language:wo', 'language:xh', 'language:yo', 'language:zh', 'language:zu', 'language:de', 'license:cc-by-nc-4.0', 'size_categories:1M<n<10M', 'format:parquet', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'arxiv:2406.12634', 'region:us', 'news', 'polynews', 'mafand', 'masakhanews', 'wikinews', 'globalvoices', 'wmtnews']","
	
		
		Dataset Card for PolyNews
	


	
		
		Dataset Summary
	

PolyNews is a multilingual dataset containing news titles in 77 languages and 19 scripts.

	
		
		Uses
	

This dataset can be used for domain adaptation of language models, language modeling or text generation.

	
		
		Languages
	

There are 77 languages available:

	
		
Code
Language
Script
#Articles (K)


		
amh_Ethi
Amharic
Ethiopic
0.551


arb_Arab
Modern Standard Arabic
Arabic
10.882


ayr_Latn
Central Aymara
Latin
12.878… See the full description on the dataset page: https://huggingface.co/datasets/aiana94/polynews.",https://huggingface.co/datasets/aiana94/polynews,"['am', 'ar', 'ay', 'bm', 'bbj', 'bn', 'bs', 'bg', 'ca', 'cs', 'ku', 'da', 'el', 'en', 'et', 'ee', 'fil', 'fi', 'fr', 'fon', 'gu', 'guw', 'ha', 'he', 'hi', 'hu', 'ig', 'id', 'it', 'ja', 'kk', 'km', 'ko', 'lv', 'ln', 'lt', 'lg', 'luo', 'mk', 'mos', 'my', 'nl', 'no', 'ne', 'om', 'or', 'pa', 'pcm', 'fa', 'pl', 'pt', 'mg', 'ro', 'rn', 'ru', 'sn', 'so', 'es', 'sr', 'sq', 'sw', 'sv', 'ta', 'tet', 'ti', 'th', 'tn', 'tr', 'tw', 'uk', 'ur', 'wo', 'xh', 'yo', 'zh', 'zu', 'de']","['fill-mask', 'text-generation']",['1M<n<10M']
aiana94/polynews-parallel,aiana94,2024-05-17 07:58:37+00:00,2024-06-21 08:35:51+00:00,256,13,"['task_categories:translation', 'task_categories:text-retrieval', 'multilinguality:translation', 'multilinguality:multilingual', 'source_datasets:mafand', 'source_datasets:wmt-news', 'source_datasets:globalvoices', 'language:am', 'language:ar', 'language:ay', 'language:bm', 'language:bbj', 'language:bn', 'language:bg', 'language:ca', 'language:cs', 'language:ku', 'language:da', 'language:de', 'language:el', 'language:en', 'language:et', 'language:ee', 'language:fil', 'language:fi', 'language:fr', 'language:fon', 'language:gu', 'language:ha', 'language:he', 'language:hi', 'language:hu', 'language:ig', 'language:id', 'language:it', 'language:ja', 'language:kk', 'language:km', 'language:ko', 'language:lv', 'language:lt', 'language:lg', 'language:luo', 'language:mk', 'language:mos', 'language:my', 'language:nl', 'language:ne', 'language:or', 'language:pa', 'language:pcm', 'language:fa', 'language:pl', 'language:pt', 'language:mg', 'language:ro', 'language:ru', 'language:es', 'language:sr', 'language:sq', 'language:sw', 'language:sv', 'language:tet', 'language:tn', 'language:tr', 'language:tw', 'language:ur', 'language:wo', 'language:yo', 'language:zh', 'language:zu', 'license:cc-by-nc-4.0', 'size_categories:1M<n<10M', 'format:parquet', 'modality:image', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'arxiv:2406.12634', 'region:us', 'news', 'polynews-parallel', 'mafand', 'globalvoices', 'wmtnews']","
	
		
		Dataset Card for PolyNewsParallel
	


	
		
		Dataset Summary
	

PolyNewsParallel is a multilingual paralllel dataset containing news titles for 833 language pairs. It covers 64 languages and 17 scripts.

	
		
		Uses
	

This dataset can be used for machine translation or text retrieval.

	
		
		Languages
	

There are 64 languages avaiable:

	
		
Code
Language
Script


		
amh_Ethi
Amharic
Ethiopic


arb_Arab
Modern Standard Arabic
Arabic


ayr_Latn
Central Aymara
Latin


bam_Latn
Bambara… See the full description on the dataset page: https://huggingface.co/datasets/aiana94/polynews-parallel.",https://huggingface.co/datasets/aiana94/polynews-parallel,"['am', 'ar', 'ay', 'bm', 'bbj', 'bn', 'bg', 'ca', 'cs', 'ku', 'da', 'de', 'el', 'en', 'et', 'ee', 'fil', 'fi', 'fr', 'fon', 'gu', 'ha', 'he', 'hi', 'hu', 'ig', 'id', 'it', 'ja', 'kk', 'km', 'ko', 'lv', 'lt', 'lg', 'luo', 'mk', 'mos', 'my', 'nl', 'ne', 'or', 'pa', 'pcm', 'fa', 'pl', 'pt', 'mg', 'ro', 'ru', 'es', 'sr', 'sq', 'sw', 'sv', 'tet', 'tn', 'tr', 'tw', 'ur', 'wo', 'yo', 'zh', 'zu']","['translation', 'text-retrieval']",['1M<n<10M']
sudy-super/oasst2-chat-5k-ja,sudy-super,2024-05-17 15:09:57+00:00,2024-05-18 13:47:14+00:00,15,6,"['language:ja', 'license:apache-2.0', 'size_categories:1K<n<10K', 'format:json', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","
	
		
		説明
	

これはoasst2-chat-68k-jaの前半約41000件をSwallow-MX-8x7b-NVE-instruct-v2で評価した中で最高評価を獲得した物のみを抽出したデータセットです。
マルチターン会話でのファインチューニングをする際にご活用下さい。

	
		
		Pret-a-porter
	


データセット

	
		
Variant
Link


		
instruction-v0.1
Kendamarron/pret-a-porter-instruction-v0.1


math-problem-v0.1
Kendamarron/pret-a-porter-math-problem-v0.1


jimba-instruction-simplify-200
Kendamarron/jimba-instruction-simplify-200


chat-with-cosmopedia
aixsatoshi/Chat-with-cosmopedia


longcontext-aozora-summary… See the full description on the dataset page: https://huggingface.co/datasets/sudy-super/oasst2-chat-5k-ja.",https://huggingface.co/datasets/sudy-super/oasst2-chat-5k-ja,['ja'],[],['1K<n<10K']
OmniAICreator/Japanese-Roleplay,OmniAICreator,2024-05-17 17:46:21+00:00,2024-05-18 09:08:53+00:00,18,10,"['task_categories:text-generation', 'language:ja', 'license:apache-2.0', 'size_categories:n<1K', 'format:json', 'modality:text', 'library:datasets', 'library:dask', 'library:mlcroissant', 'region:us', 'roleplay', 'not-for-all-audiences']","
	
		
		Japanese-Roleplay
	

This is a dialogue corpus collected from Japanese role-playing forum (commonly known as ""なりきりチャット(narikiri chat)""). Each record corresponds to a single thread.
The following filtering and cleaning conditions have been applied:

For all post_content in the posts of each record, remove response anchors.
For all post_content in the posts of each record, delete posts where the post_content length is 10 characters or less.
If the number of unique poster types in the… See the full description on the dataset page: https://huggingface.co/datasets/OmniAICreator/Japanese-Roleplay.",https://huggingface.co/datasets/OmniAICreator/Japanese-Roleplay,['ja'],['text-generation'],['n<1K']
kanhatakeyama/AutoMultiTurnByMixtral8x22b,kanhatakeyama,2024-05-18 00:43:54+00:00,2024-05-22 20:25:15+00:00,15,5,"['language:ja', 'size_categories:100K<n<1M', 'format:json', 'modality:text', 'library:datasets', 'library:dask', 'library:mlcroissant', 'library:polars', 'region:us']","
	
		
		自動生成のマルチターンデータセット
	


	
		
		オープンなデータソースから､MaziyarPanahi/Mixtral-8x22B-Instruct-v0.1-GGUFを使ってQ&Aを自動生成したものです｡
	


関連コード

一部の計算には東京工業大学のスーパーコンピュータTSUBAME4.0を利用しました｡



	
		
		データソース
	


	
		
		はじめの質問(q1)を､種々のデータソースから収集しました｡その後のやりとりはすべて､Mixtralが生成しました｡質問文については､元データのライセンスに準拠します｡
	


oasst2-33k-ja
apache 2.0


databricks-dolly-15k-ja
cc-by-sa-3.0


minnade
CC0


cyberagent/chatbot-arena-ja-calm2-7b-chat-experimental
cc-by-4.0



",https://huggingface.co/datasets/kanhatakeyama/AutoMultiTurnByMixtral8x22b,['ja'],[],['100K<n<1M']
hatakeyama-llm-team/AutoGeneratedJapaneseQA-CC,hatakeyama-llm-team,2024-05-18 03:55:41+00:00,2024-05-19 09:25:43+00:00,16,2,"['language:ja', 'size_categories:10K<n<100K', 'format:parquet', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","
	
		
		自動生成Q&A
	


	
		
		データソースから､MaziyarPanahi/Mixtral-8x22B-Instruct-v0.1-GGUFを使ってQ&Aを自動生成したものです｡
	


Common Crawlをもとに生成しています。 Common Crawl terms of useに従ってご利用ください。
元の文章との類似度(依拠性)が低くなるようにするため、元文章からランダムに部分抜粋したテキストを用いています。
不自然な文章も含まれているためクリーニングを推奨します。

",https://huggingface.co/datasets/hatakeyama-llm-team/AutoGeneratedJapaneseQA-CC,['ja'],[],['10K<n<100K']
DataPilot/databricks-dolly-15k-Nyan-ja,DataPilot,2024-05-18 13:03:25+00:00,2024-05-19 10:24:16+00:00,13,1,"['language:ja', 'license:cc-by-sa-3.0', 'size_categories:10K<n<100K', 'format:json', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","このデータセットはkunishou氏が公開している""databricks-dolly-15k""を日本語訳したkunishou/databricks-dolly-15k-jaデータセットの語尾をArrowPro-7B-KUJIRAを用いて「にゃん！」に変更したものです。
ライセンスは元データセットに依存します。
注：このデータセットは語尾を変更することを目的としており、性能向上を目的とするものではありません。
変換するための計算資源を貸してくれたwitness氏とMeta Data Labに感謝を申し上げます
",https://huggingface.co/datasets/DataPilot/databricks-dolly-15k-Nyan-ja,['ja'],[],['10K<n<100K']
sudy-super/oasst2-chat-40k-ja-classified,sudy-super,2024-05-18 13:40:57+00:00,2024-05-18 13:46:01+00:00,5,0,"['language:ja', 'license:apache-2.0', 'region:us']","
	
		
		説明
	

これはoasst2-chat-68k-jaの前半約41000件をSwallow-MX-8x7b-NVE-instruct-v2で評価したデータセットです。
マルチターン会話でのファインチューニングをする際にご活用下さい。

	
		
		Pret-a-porter
	


データセット

	
		
Variant
Link


		
instruction-v0.1
Kendamarron/pret-a-porter-instruction-v0.1


math-problem-v0.1
Kendamarron/pret-a-porter-math-problem-v0.1


jimba-instruction-simplify-200
Kendamarron/jimba-instruction-simplify-200


chat-with-cosmopedia
aixsatoshi/Chat-with-cosmopedia


longcontext-aozora-summary… See the full description on the dataset page: https://huggingface.co/datasets/sudy-super/oasst2-chat-40k-ja-classified.",https://huggingface.co/datasets/sudy-super/oasst2-chat-40k-ja-classified,['ja'],[],[]
Aratako/Bluemoon_Top50MB_Sorted_Fixed_ja,Aratako,2024-05-18 15:35:17+00:00,2024-05-18 15:38:35+00:00,6,2,"['task_categories:text-generation', 'language:ja', 'license:apache-2.0', 'size_categories:n<1K', 'format:json', 'modality:tabular', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us', 'roleplay']","
	
		
		Bluemoon_Top50MB_Sorted_Fixed_ja
	

SicariusSicariiStuff/Bluemoon_Top50MB_Sorted_Fixedを、GENIAC-Team-Ozaki/karakuri-lm-8x7b-chat-v0.1-awqを用いて日本語に翻訳したロールプレイ学習用データセットです。
LLMの推論にはDeepInfraというサービスを使いました。

	
		
	
	
		翻訳の詳細
	


3-shots promptingでの翻訳
mistralのtokenizerで出力が8000トークンを超えるまで翻訳
元データセットにある非常に長い対話は上記条件で途中のターンで翻訳を終了しています。


LLM特有の同じ出力が繰り返される現象に遭遇した場合、その時点で該当レコードの翻訳を終了
この結果1ターン未満となったレコード（157件）を削除… See the full description on the dataset page: https://huggingface.co/datasets/Aratako/Bluemoon_Top50MB_Sorted_Fixed_ja.",https://huggingface.co/datasets/Aratako/Bluemoon_Top50MB_Sorted_Fixed_ja,['ja'],['text-generation'],['n<1K']
hatakeyama-llm-team/AutoGeneratedJapaneseQA-other,hatakeyama-llm-team,2024-05-19 02:45:59+00:00,2024-05-19 14:17:58+00:00,15,1,"['language:ja', 'size_categories:10K<n<100K', 'format:parquet', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","
	
		
		自動生成Q&A
	


	
		
		データソースから､MaziyarPanahi/Mixtral-8x22B-Instruct-v0.1-GGUFを使ってQ&Aを自動生成したものです｡
	


チームで作成したデータおよび「Common Crawlをもとに生成しています。 Common Crawl terms of useに従ってご利用ください。
hatakeyama-llm-team/AutoGeneratedJapaneseQA-CCと異なるデータを用いています。
元の文章との類似度(依拠性)が低くなるようにするため、元文章からランダムに部分抜粋したテキストを用いています。
不自然な文章も含まれているためクリーニングを推奨します。

",https://huggingface.co/datasets/hatakeyama-llm-team/AutoGeneratedJapaneseQA-other,['ja'],[],['10K<n<100K']
ayousanz/voicevox-voice-corpus,ayousanz,2024-05-19 03:01:27+00:00,2024-05-26 04:13:36+00:00,536,6,"['language:ja', 'region:us']","
	
		
		VOICEVOXを使った人工音声ボイスデータセット
	


	
		
		使用したテキストコーパス
	


ITAコーパス
つくよみちゃんコーパス
ROHANコーパス


	
		
		データセット量情報
	

フォルダ内の.wavファイル数: 445793
フォルダ内の.wavファイルの合計時間: 577時間 51分 23秒
",https://huggingface.co/datasets/ayousanz/voicevox-voice-corpus,['ja'],[],[]
toshi456/ViQuAE-JA,toshi456,2024-05-19 06:59:54+00:00,2024-05-19 07:07:49+00:00,7,2,"['task_categories:image-to-text', 'language:ja', 'license:cc-by-4.0', 'size_categories:1K<n<10K', 'format:json', 'modality:image', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","This dataset was created by machine translating ""ViQuAE"" into Japanese.
original_answer_ja translated from original_answer. I didn't translate answer.
ViQuAE: https://github.com/PaulLerner/ViQuAE
",https://huggingface.co/datasets/toshi456/ViQuAE-JA,['ja'],['image-to-text'],['1K<n<10K']
HachiML/alpaca_jp_math,HachiML,2024-05-19 13:39:40+00:00,2024-05-21 21:46:21+00:00,22,6,"['task_categories:text-generation', 'language:ja', 'license:apache-2.0', 'size_categories:10K<n<100K', 'format:parquet', 'modality:tabular', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us', 'synthetic', 'math', 'code', 'python', 'self-instruct']","
	
		
		alpaca_jp_math
	


alpaca_jp_mathは、  

Stanford Alpacaの手法  
mistralai/Mixtral-8x22B-Instruct-v0.1

で作った合成データ(Synthetic data)です。モデルの利用にはDeepinfraを利用しています。  
また、""_cleaned""がついたデータセットは以下の手法で精査されています。  

pythonの計算結果がきちんと、テキストの計算結果が同等であるか確認
LLM(mistralai/Mixtral-8x22B-Instruct-v0.1)による確認（詳細は下記）

code_result, text_resultは小数第三位で四捨五入してあります。



	
	
	
		Dataset Details
	


	
	
	
		Dataset Description
	




Curated by: HachiMLLanguage(s) (NLP): Japanese
License: Apache 2.0
Github: Alpaca-jp… See the full description on the dataset page: https://huggingface.co/datasets/HachiML/alpaca_jp_math.",https://huggingface.co/datasets/HachiML/alpaca_jp_math,['ja'],['text-generation'],['10K<n<100K']
dekkaiinu/hyper_penguin_pix,dekkaiinu,2024-05-20 05:02:38+00:00,2024-08-03 04:52:08+00:00,14,0,"['language:en', 'language:ja', 'license:cc-by-nc-4.0', 'arxiv:2405.14146', 'region:us']","
	
		
		Hyperspectral Image Dataset for Individual Penguin Identification
	

This dataset is used for the classification of hyperspectral data to identify individual penguins．The original hyperspectral images that this dataset is based on can be found on Hugging Face under the dataset name hyper_penguin．For examples of how to use this dataset, please see the GitHub repository here．

	
		
	
	
		Data Splitsgi
	

The dataset is split into training, validation, and test sets. The distribution is… See the full description on the dataset page: https://huggingface.co/datasets/dekkaiinu/hyper_penguin_pix.",https://huggingface.co/datasets/dekkaiinu/hyper_penguin_pix,"['en', 'ja']",[],[]
ByteDance/MTVQA,ByteDance,2024-05-20 07:42:19+00:00,2024-05-30 02:38:32+00:00,384,37,"['task_categories:visual-question-answering', 'task_categories:image-to-text', 'language:multilingual', 'language:ar', 'language:de', 'language:vi', 'language:ja', 'language:ko', 'language:fr', 'language:ru', 'language:it', 'language:th', 'license:cc-by-nc-4.0', 'size_categories:1K<n<10K', 'format:parquet', 'modality:image', 'modality:text', 'library:datasets', 'library:dask', 'library:mlcroissant', 'library:polars', 'arxiv:2405.11985', 'region:us', 'multilingual', 'text-centric', 'vqa']","
	
		
		Dataset Card
	

The dataset is oriented toward visual question answering of multilingual text scenes in nine languages, including Korean, Japanese, Italian, Russian, Deutsch, French, Thai, Arabic, and Vietnamese. The question-answer pairs are labeled by native annotators following a series of rules. A comprehensive description of the dataset can be found in the paper MTVQA.

	
		
	
	
		- Image Distribution
	


    
        
        KO
        JA
        IT
        RU
        DE… See the full description on the dataset page: https://huggingface.co/datasets/ByteDance/MTVQA.",https://huggingface.co/datasets/ByteDance/MTVQA,"['multilingual', 'ar', 'de', 'vi', 'ja', 'ko', 'fr', 'ru', 'it', 'th']","['visual-question-answering', 'image-to-text']",['1K<n<10K']
Fluffysweet/2000_Art_Style,Fluffysweet,2024-05-20 16:53:27+00:00,2024-05-20 16:58:38+00:00,36,1,"['language:ja', 'language:en', 'language:zh', 'license:creativeml-openrail-m', 'size_categories:n<1K', 'format:imagefolder', 'modality:image', 'library:datasets', 'library:mlcroissant', 'region:us', 'art']",,https://huggingface.co/datasets/Fluffysweet/2000_Art_Style,"['ja', 'en', 'zh']",[],['n<1K']
ku-nlp/MELD-ST,ku-nlp,2024-05-21 20:53:37+00:00,2025-07-17 04:54:24+00:00,18,6,"['language:en', 'language:de', 'language:ja', 'size_categories:10K<n<100K', 'format:csv', 'modality:tabular', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'arxiv:2405.13233', 'region:us']","
	
		
		MELD-ST: An Emotion-aware Speech Translation Dataset
	


Paper: https://arxiv.org/abs/2405.13233


	
		
		Overview
	

This emotion-aware speech translation dataset is a multi-language dataset extracted from the TV show ""Friends."" It includes English, Japanese, and German subtitles along with corresponding timestamps. This dataset is designed for natural language processing tasks.

	
		
		Contents
	

The dataset is partitioned into train, test, and development subsets to streamline… See the full description on the dataset page: https://huggingface.co/datasets/ku-nlp/MELD-ST.",https://huggingface.co/datasets/ku-nlp/MELD-ST,"['en', 'de', 'ja']",[],['10K<n<100K']
GENIAC-Team-Ozaki/debate_argument_instruction_dataset_ja,GENIAC-Team-Ozaki,2024-05-22 11:16:49+00:00,2025-07-16 05:28:49+00:00,13,0,"['language:ja', 'license:apache-2.0', 'size_categories:n<1K', 'format:json', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']",,https://huggingface.co/datasets/GENIAC-Team-Ozaki/debate_argument_instruction_dataset_ja,['ja'],[],['n<1K']
alfredplpl/commoncatalog-cc-by-ext,alfredplpl,2024-05-23 00:54:43+00:00,2024-06-01 01:50:33+00:00,20,7,"['task_categories:text-to-image', 'task_categories:image-to-text', 'language:en', 'language:ja', 'license:cc-by-4.0', 'size_categories:10K<n<100K', 'format:csv', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","
	
		
		CommonCatalog CC-BY Extention
	

このリポジトリはCommonCatalog CC-BYを拡張して、追加の情報を入れたものです。
以下の情報が追加されています。

Phi-3 VisionでDense Captioningした英語キャプション
英語キャプションをPhi-3 Mediumで日本語化した日本語キャプション

主キーはphotoidですので、CommonCatalog CC-BYと結合するなりして使ってください。
streaming=Trueで読み込むと同じ順に読み込まれますのでそれを利用するのが一番楽です。

	
		
		License
	

画像がCC BYなため、わかりやすくCC BYにしています。したがって、商用利用可能です。

	
		
		Sample Code
	

import pandas
from datasets import load_dataset

df=pandas.read_csv(""commoncatalog-cc-by-phi3-ja.csv"")

dataset =… See the full description on the dataset page: https://huggingface.co/datasets/alfredplpl/commoncatalog-cc-by-ext.",https://huggingface.co/datasets/alfredplpl/commoncatalog-cc-by-ext,"['en', 'ja']","['text-to-image', 'image-to-text']",['10K<n<100K']
HachiML/oasst1_for_self-rewarding_IFT,HachiML,2024-05-23 08:19:12+00:00,2024-05-23 09:08:31+00:00,7,1,"['task_categories:text-generation', 'language:ja', 'license:apache-2.0', 'size_categories:1K<n<10K', 'format:parquet', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us', 'self-rewarding', 'oasst1']","
	
		
		Dataset Card for Dataset Name
	




kunishou/oasst1-89k-ja
OpenAssistant/oasst1

を元に、self-rewardingのIFT(Instruction Fine-Tuning data)を作成しました。 
Self-rewardingの論文では3,200件に絞り込んでいますが、このデータは4,744件となっています。さらに人手でのフィルタリングをする必要があるかもしれません。  

	
		
		Dataset Details
	


	
		
		Dataset Description
	




Curated by: HachiML
Language(s) (NLP): Japanese
License: Apache-2.0


	
		
		Filtering Rule
	

以下のルールで絞り込んでいます。  

First Conversational Turn
rank 0 の回答をもつ
Single Turn Conversation

",https://huggingface.co/datasets/HachiML/oasst1_for_self-rewarding_IFT,['ja'],['text-generation'],['1K<n<10K']
HachiML/oasst1_for_self-rewarding_EFT_before_judge,HachiML,2024-05-23 08:59:23+00:00,2024-05-23 09:08:16+00:00,9,0,"['task_categories:text-generation', 'language:ja', 'license:apache-2.0', 'size_categories:10K<n<100K', 'format:parquet', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us', 'self-rewarding', 'oasst1']","
	
		
		Dataset Card for Dataset Name
	




kunishou/oasst1-89k-ja
OpenAssistant/oasst1

を元に、self-rewardingのEFT(Evaluation Fine-Tuning data)の元データを作成しました。 
この後に、学習させたいモデルを使ってLLM-as-a-Judgeを行います。Self-rewardingの論文では最終的に train: 1,630 records, test: 531 records に絞り込んでいます。  

	
		
	
	
		Dataset Details
	


	
		
	
	
		Dataset Description
	




Curated by: HachiML
Language(s) (NLP): Japanese
License: Apache-2.0


	
	
	
		Filtering Rule
	

以下のルールで絞り込んでいます。  

First Conversational Turn
Single Turn… See the full description on the dataset page: https://huggingface.co/datasets/HachiML/oasst1_for_self-rewarding_EFT_before_judge.",https://huggingface.co/datasets/HachiML/oasst1_for_self-rewarding_EFT_before_judge,['ja'],['text-generation'],['10K<n<100K']
floschne/xflickrco_1k,floschne,2024-05-24 14:51:35+00:00,2024-05-27 07:05:47+00:00,14,1,"['task_categories:image-to-text', 'language:de', 'language:en', 'language:es', 'language:id', 'language:ja', 'language:ru', 'language:tr', 'language:zh', 'license:cc-by-4.0', 'size_categories:1K<n<10K', 'format:parquet', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']",,https://huggingface.co/datasets/floschne/xflickrco_1k,"['de', 'en', 'es', 'id', 'ja', 'ru', 'tr', 'zh']",['image-to-text'],['1K<n<10K']
sentence-transformers/parallel-sentences-opus-100,sentence-transformers,2024-05-25 06:52:13+00:00,2024-07-09 14:28:24+00:00,1035,1,"['task_categories:feature-extraction', 'task_categories:sentence-similarity', 'annotations_creators:no-annotation', 'language_creators:found', 'language:af', 'language:am', 'language:an', 'language:ar', 'language:as', 'language:az', 'language:be', 'language:bg', 'language:bn', 'language:br', 'language:bs', 'language:ca', 'language:cs', 'language:cy', 'language:da', 'language:de', 'language:dz', 'language:el', 'language:en', 'language:eo', 'language:es', 'language:et', 'language:eu', 'language:fa', 'language:fi', 'language:fr', 'language:fy', 'language:ga', 'language:gd', 'language:gl', 'language:gu', 'language:ha', 'language:he', 'language:hi', 'language:hr', 'language:hu', 'language:hy', 'language:id', 'language:ig', 'language:is', 'language:it', 'language:ja', 'language:ka', 'language:kk', 'language:km', 'language:kn', 'language:ko', 'language:ku', 'language:ky', 'language:li', 'language:lt', 'language:lv', 'language:mg', 'language:mk', 'language:ml', 'language:mn', 'language:mr', 'language:ms', 'language:mt', 'language:my', 'language:nb', 'language:ne', 'language:nl', 'language:nn', 'language:no', 'language:oc', 'language:or', 'language:pa', 'language:pl', 'language:ps', 'language:pt', 'language:ro', 'language:ru', 'language:rw', 'language:se', 'language:sh', 'language:si', 'language:sk', 'language:sl', 'language:sq', 'language:sr', 'language:sv', 'language:ta', 'language:te', 'language:tg', 'language:th', 'language:tk', 'language:tr', 'language:tt', 'language:ug', 'language:uk', 'language:ur', 'language:uz', 'language:vi', 'language:wa', 'language:xh', 'language:yi', 'language:yo', 'language:zh', 'language:zu', 'size_categories:10M<n<100M', 'format:parquet', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us', 'sentence-transformers']","
	
		
		Dataset Card for Parallel Sentences - OPUS-100
	

This dataset contains parallel sentences (i.e. English sentence + the same sentences in another language) for numerous other languages. The sentences originate from the OPUS-100 website.
In particular, this dataset is a reformatting of the OPUS-100 dataset.

	
		
	
	
		Related Datasets
	

The following datasets are also a part of the Parallel Sentences collection:

parallel-sentences-europarl
parallel-sentences-global-voices… See the full description on the dataset page: https://huggingface.co/datasets/sentence-transformers/parallel-sentences-opus-100.",https://huggingface.co/datasets/sentence-transformers/parallel-sentences-opus-100,"['af', 'am', 'an', 'ar', 'as', 'az', 'be', 'bg', 'bn', 'br', 'bs', 'ca', 'cs', 'cy', 'da', 'de', 'dz', 'el', 'en', 'eo', 'es', 'et', 'eu', 'fa', 'fi', 'fr', 'fy', 'ga', 'gd', 'gl', 'gu', 'ha', 'he', 'hi', 'hr', 'hu', 'hy', 'id', 'ig', 'is', 'it', 'ja', 'ka', 'kk', 'km', 'kn', 'ko', 'ku', 'ky', 'li', 'lt', 'lv', 'mg', 'mk', 'ml', 'mn', 'mr', 'ms', 'mt', 'my', 'nb', 'ne', 'nl', 'nn', 'no', 'oc', 'or', 'pa', 'pl', 'ps', 'pt', 'ro', 'ru', 'rw', 'se', 'sh', 'si', 'sk', 'sl', 'sq', 'sr', 'sv', 'ta', 'te', 'tg', 'th', 'tk', 'tr', 'tt', 'ug', 'uk', 'ur', 'uz', 'vi', 'wa', 'xh', 'yi', 'yo', 'zh', 'zu']","['feature-extraction', 'sentence-similarity']",['10M<n<100M']
sentence-transformers/parallel-sentences-ccmatrix,sentence-transformers,2024-05-25 08:10:49+00:00,2024-06-18 19:49:55+00:00,3485,10,"['task_categories:feature-extraction', 'task_categories:sentence-similarity', 'language:af', 'language:ar', 'language:ast', 'language:az', 'language:be', 'language:bg', 'language:bn', 'language:br', 'language:ca', 'language:ceb', 'language:cs', 'language:da', 'language:de', 'language:el', 'language:eo', 'language:es', 'language:et', 'language:eu', 'language:fa', 'language:fi', 'language:fr', 'language:fy', 'language:ga', 'language:gd', 'language:gl', 'language:ha', 'language:he', 'language:hi', 'language:hr', 'language:hu', 'language:id', 'language:ig', 'language:ilo', 'language:is', 'language:it', 'language:ja', 'language:jv', 'language:ko', 'language:la', 'language:lb', 'language:lt', 'language:lv', 'language:mg', 'language:mk', 'language:ml', 'language:mr', 'language:ms', 'language:ne', 'language:nl', 'language:no', 'language:oc', 'language:or', 'language:pl', 'language:pt', 'language:ro', 'language:ru', 'language:sd', 'language:si', 'language:sk', 'language:sl', 'language:so', 'language:sq', 'language:sr', 'language:su', 'language:sv', 'language:sw', 'language:ta', 'language:tl', 'language:tr', 'language:uk', 'language:ur', 'language:vi', 'language:xh', 'language:yi', 'language:zh', 'size_categories:1B<n<10B', 'format:parquet', 'modality:text', 'library:datasets', 'library:dask', 'library:mlcroissant', 'library:polars', 'region:us', 'sentence-transformers']","
	
		
		Dataset Card for Parallel Sentences - CCMatrix
	

This dataset contains parallel sentences (i.e. English sentence + the same sentences in another language) for numerous other languages. The texts originate from the CCMatrix dataset.

	
		
		Related Datasets
	

The following datasets are also a part of the Parallel Sentences collection:

parallel-sentences-europarl
parallel-sentences-global-voices
parallel-sentences-muse
parallel-sentences-jw300
parallel-sentences-news-commentary… See the full description on the dataset page: https://huggingface.co/datasets/sentence-transformers/parallel-sentences-ccmatrix.",https://huggingface.co/datasets/sentence-transformers/parallel-sentences-ccmatrix,"['af', 'ar', 'ast', 'az', 'be', 'bg', 'bn', 'br', 'ca', 'ceb', 'cs', 'da', 'de', 'el', 'eo', 'es', 'et', 'eu', 'fa', 'fi', 'fr', 'fy', 'ga', 'gd', 'gl', 'ha', 'he', 'hi', 'hr', 'hu', 'id', 'ig', 'ilo', 'is', 'it', 'ja', 'jv', 'ko', 'la', 'lb', 'lt', 'lv', 'mg', 'mk', 'ml', 'mr', 'ms', 'ne', 'nl', 'no', 'oc', 'or', 'pl', 'pt', 'ro', 'ru', 'sd', 'si', 'sk', 'sl', 'so', 'sq', 'sr', 'su', 'sv', 'sw', 'ta', 'tl', 'tr', 'uk', 'ur', 'vi', 'xh', 'yi', 'zh']","['feature-extraction', 'sentence-similarity']",['1B<n<10B']
HachiML/self-rewarding_instruct,HachiML,2024-05-26 04:11:53+00:00,2024-05-28 05:13:47+00:00,9,1,"['task_categories:text-generation', 'language:ja', 'license:apache-2.0', 'size_categories:10K<n<100K', 'format:parquet', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us', 'synthetic', 'self-instruct', 'self-rewarding']","
	
		
		self-rewarding_instruct
	


self-rewarding_instructは、  

Stanford Alpacaの手法
kunishou/oasst1-89k-jaをseed tasksとして  
mistralai/Mixtral-8x22B-Instruct-v0.1

で作った合成データ(Synthetic data)です。モデルの利用にはDeepinfraを利用しています。データセットはmistralai/Mixtral-8x22B-Instruct-v0.1によって精査されています。  
self-rewarding用に作成したため、output_exampleとなっていますがInstruction Tuningにも用いれると思います。  



	
	
	
		Dataset Details
	


	
	
	
		Dataset Description
	




Curated by: HachiMLLanguage(s) (NLP): Japanese
License: Apache 2.0
Github:… See the full description on the dataset page: https://huggingface.co/datasets/HachiML/self-rewarding_instruct.",https://huggingface.co/datasets/HachiML/self-rewarding_instruct,['ja'],['text-generation'],['10K<n<100K']
HachiML/self-rewarding_AIFT_MSv0.3_lora,HachiML,2024-05-26 10:37:30+00:00,2024-05-28 01:42:07+00:00,15,0,"['task_categories:text-generation', 'language:ja', 'license:apache-2.0', 'size_categories:10K<n<100K', 'format:parquet', 'modality:tabular', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us', 'synthetic', 'self-rewarding']","
	
		
		self-rewarding_AIFT_MSv0.3_lora
	



HachiML/self-rewarding_instructを、

split=AIFT_M1 は HachiML/Mistral-7B-v0.3-m1-lora
split=AIFT_M2 は HachiML/Mistral-7B-v0.3-m2-lora
でそれぞれself-rewardingして作成したAIFT(AI Feedback Tuning) dataです。
手順は以下の通りです。


HachiML/self-rewarding_instructのInstructionに対する回答を各モデルで4つずつ作成
回答に対して各モデルで点数評価
最高評価の回答をchosen、最低評価の回答をrejectedとする
詳細はself-rewardingの論文を参照してください。




	
	
	
		Dataset Details
	


	
	
	
		Dataset Description
	




Curated by: HachiMLLanguage(s) (NLP):… See the full description on the dataset page: https://huggingface.co/datasets/HachiML/self-rewarding_AIFT_MSv0.3_lora.",https://huggingface.co/datasets/HachiML/self-rewarding_AIFT_MSv0.3_lora,['ja'],['text-generation'],['10K<n<100K']
ernie-research/rendered_xnli,ernie-research,2024-05-26 12:23:45+00:00,2024-10-04 05:20:49+00:00,18,1,"['language:en', 'language:ja', 'language:zh', 'language:fr', 'language:ru', 'language:ar', 'language:hi', 'license:apache-2.0', 'arxiv:2404.10710', 'region:us']","   

	
		
		Dataset Card for rendered XNLI
	


This repository contains the rendered XNLI dataset evaluated in the paper Autoregressive Pre-Training on Pixels and Texts (EMNLP 2024). For detailed instructions on how to use the model, please visit our GitHub page.

	
		
		Citation
	

@misc{chai2024autoregressivepretrainingpixelstexts,
  title = {Autoregressive Pre-Training on Pixels and Texts},
  author = {Chai, Yekun and Liu, Qingyi and Xiao, Jingwu and Wang, Shuohuan and Sun, Yu and Wu, Hua}… See the full description on the dataset page: https://huggingface.co/datasets/ernie-research/rendered_xnli.",https://huggingface.co/datasets/ernie-research/rendered_xnli,"['en', 'ja', 'zh', 'fr', 'ru', 'ar', 'hi']",[],[]
biki647/japanese_language,biki647,2024-05-27 06:17:56+00:00,2024-05-30 06:23:01+00:00,7,0,"['language:en', 'language:ja', 'size_categories:1K<n<10K', 'format:parquet', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']",,https://huggingface.co/datasets/biki647/japanese_language,"['en', 'ja']",[],['1K<n<10K']
heiwa4126/test1,heiwa4126,2024-05-28 04:32:33+00:00,2024-05-28 05:05:59+00:00,10,0,"['language:ja', 'size_categories:10K<n<100K', 'format:parquet', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","
	
		
		heiwa4126/test1
	

",https://huggingface.co/datasets/heiwa4126/test1,['ja'],[],['10K<n<100K']
HachiML/JMT-Bench-result_self-rewarding_Mistral-7B-lora,HachiML,2024-05-28 06:40:15+00:00,2024-05-28 06:58:58+00:00,8,0,"['task_categories:text-generation', 'language:ja', 'size_categories:n<1K', 'format:json', 'modality:tabular', 'modality:text', 'library:datasets', 'library:dask', 'library:mlcroissant', 'library:polars', 'region:us', 'JMT-Bench']","
	
		
		JMT-Bench result
	



	
		
		Answer language
	

JMT-Benchの回答のうち、Englishで回答した件数  

	
		
Model
Count


		
mistralai/Mistral-7B-v0.3
25


HachiML/Mistral-7B-v0.3-m1-lora
7


HachiML/Mistral-7B-v0.3-m2-lora
7


HachiML/Mistral-7B-v0.3-m3-lora
2


	

",https://huggingface.co/datasets/HachiML/JMT-Bench-result_self-rewarding_Mistral-7B-lora,['ja'],['text-generation'],['n<1K']
lissette/kuon-audio,lissette,2024-05-29 01:14:32+00:00,2024-05-29 01:33:02+00:00,9,0,"['task_categories:audio-to-audio', 'task_categories:text-to-audio', 'language:ja', 'license:apache-2.0', 'size_categories:n<1K', 'format:audiofolder', 'modality:audio', 'library:datasets', 'library:mlcroissant', 'region:us']","久远语音
来源于TV动画提取，进过uvr分离背景音，人工筛选质量较好的。
610个短语音，1个歌曲
",https://huggingface.co/datasets/lissette/kuon-audio,['ja'],"['audio-to-audio', 'text-to-audio']",['n<1K']
ayousanz/common-voice-speechMOS-analyze,ayousanz,2024-05-29 15:34:35+00:00,2024-05-29 15:55:23+00:00,18,0,"['language:ja', 'license:cc0-1.0', 'region:us']","
	
		
		概要
	

 Common Voice Corpus 17.0をspeechMOSにて音声品質の分析を行った結果です。
分析した結果を audio_analysis_results_speechMOS.jsonというjsonにて保存しました。
jsonのフォーマットは以下になっています
""ファイル名"": file_name,
""MOS値"": snr value

以下jsonのデータをヒストグラムにしたものです

また各MOS値以上の音声ファイル数は以下です。

SNR値が1以上のデータの数: 356921
SNR値が2以上のデータの数: 280810
SNR値が3以上のデータの数: 84247


	
	
	
		備考
	

こちらのデータ分析は、AiHUB様に計算リソースをご提供いただきました。
",https://huggingface.co/datasets/ayousanz/common-voice-speechMOS-analyze,['ja'],[],[]
recursal/MDN,recursal,2024-05-30 06:50:40+00:00,2024-06-13 01:18:19+00:00,121,2,"['task_categories:text-generation', 'task_categories:fill-mask', 'task_ids:language-modeling', 'task_ids:masked-language-modeling', 'annotations_creators:no-annotation', 'language_creators:crowdsourced', 'source_datasets:original', 'language:en', 'language:es', 'language:fr', 'language:ja', 'language:ko', 'language:pt', 'language:ru', 'language:zho', 'license:cc-by-sa-3.0', 'size_categories:10K<n<100K', 'format:json', 'modality:text', 'library:datasets', 'library:dask', 'library:mlcroissant', 'library:polars', 'region:us']","
	
		
		Dataset Card for MDN
	


Waifu to catch your attention.

	
		
	
	
		Dataset Description
	

MDN is a ~57M Tokens (llama-2-7b-chat-tokenizer) / ~46.52M Tokens (RWKV Tokenizer) scrape of MDN (Developer.mozilla.org).
It serves as a training resource for large language models and other NLP tasks. 
This card details the dataset's origin, content, and limitations.

Curated by:KaraKaraWitch
Funded by: Recursal.ai (I work there lol)
Shared by: KaraKaraWitch
Language(s) (NLP): English, Espanol… See the full description on the dataset page: https://huggingface.co/datasets/recursal/MDN.",https://huggingface.co/datasets/recursal/MDN,"['en', 'es', 'fr', 'ja', 'ko', 'pt', 'ru', 'zho']","['text-generation', 'fill-mask']",['10K<n<100K']
traintogpb/aihub-koja-translation-integrated-large-4.3m,traintogpb,2024-05-30 07:45:56+00:00,2024-05-30 08:44:33+00:00,108,3,"['task_categories:translation', 'language:ko', 'language:ja', 'license:mit', 'size_categories:1M<n<10M', 'format:csv', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","
	
		
		AI Hub Ko-Ja Translation Dataset (Integrated)
	

AI Hub의 한-일 번역 관련 데이터셋 10개를 병합한 자료입니다. 병합 시 총 데이터 개수는 4,339,465개이며, 이중 10,000개의 validation set와 2,000개의 test set가 분리되어 모든 데이터 사이즈(large-4.3m, base-1m, small-100k)에서 동일하게 사용됩니다.

large-4.3m (train): 병합 데이터 100% 사용; 총 4,327,465개

base-1m (train): 병합 데이터 중 1M개 사용; 총 1,000,000개

small-100k (train): 병합 데이터 중 100K개 사용; 총 100,000개



	
		
		Subsets
	


	
		
Name
Total Size
Japanese Size (Utilized Only)
URL
Datasetkey (AIHub)


		
한국어-일본어 번역 말뭉치… See the full description on the dataset page: https://huggingface.co/datasets/traintogpb/aihub-koja-translation-integrated-large-4.3m.",https://huggingface.co/datasets/traintogpb/aihub-koja-translation-integrated-large-4.3m,"['ko', 'ja']",['translation'],['1M<n<10M']
traintogpb/aihub-koja-translation-integrated-base-1m,traintogpb,2024-05-30 07:47:22+00:00,2024-05-30 08:45:06+00:00,19,0,"['task_categories:translation', 'language:ko', 'language:ja', 'license:mit', 'size_categories:1M<n<10M', 'format:csv', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","
	
		
		AI Hub Ko-Ja Translation Dataset (Integrated)
	

AI Hub의 한-일 번역 관련 데이터셋 10개를 병합한 자료입니다. 병합 시 총 데이터 개수는 4,339,465개이며, 이중 10,000개의 validation set와 2,000개의 test set가 분리되어 모든 데이터 사이즈(large-4.3m, base-1m, small-100k)에서 동일하게 사용됩니다.

large-4.3m (train): 병합 데이터 100% 사용; 총 4,327,465개

base-1m (train): 병합 데이터 중 1M개 사용; 총 1,000,000개

small-100k (train): 병합 데이터 중 100K개 사용; 총 100,000개



	
		
		Subsets
	


	
		
Name
Total Size
Japanese Size (Utilized Only)
URL
Datasetkey (AIHub)


		
한국어-일본어 번역 말뭉치… See the full description on the dataset page: https://huggingface.co/datasets/traintogpb/aihub-koja-translation-integrated-base-1m.",https://huggingface.co/datasets/traintogpb/aihub-koja-translation-integrated-base-1m,"['ko', 'ja']",['translation'],['1M<n<10M']
traintogpb/aihub-koja-translation-integrated-small-100k,traintogpb,2024-05-30 07:47:41+00:00,2024-05-30 08:44:54+00:00,12,0,"['task_categories:translation', 'language:ko', 'language:ja', 'license:mit', 'size_categories:100K<n<1M', 'format:csv', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","
	
		
		AI Hub Ko-Ja Translation Dataset (Integrated)
	

AI Hub의 한-일 번역 관련 데이터셋 10개를 병합한 자료입니다. 병합 시 총 데이터 개수는 4,339,465개이며, 이중 10,000개의 validation set와 2,000개의 test set가 분리되어 모든 데이터 사이즈(large-4.3m, base-1m, small-100k)에서 동일하게 사용됩니다.

large-4.3m (train): 병합 데이터 100% 사용; 총 4,327,465개

base-1m (train): 병합 데이터 중 1M개 사용; 총 1,000,000개

small-100k (train): 병합 데이터 중 100K개 사용; 총 100,000개



	
		
		Subsets
	


	
		
Name
Total Size
Japanese Size (Utilized Only)
URL
Datasetkey (AIHub)


		
한국어-일본어 번역 말뭉치… See the full description on the dataset page: https://huggingface.co/datasets/traintogpb/aihub-koja-translation-integrated-small-100k.",https://huggingface.co/datasets/traintogpb/aihub-koja-translation-integrated-small-100k,"['ko', 'ja']",['translation'],['100K<n<1M']
deepghs/danbooru2023-webp-4Mpixel_index,deepghs,2024-05-31 07:35:02+00:00,2024-07-18 13:27:22+00:00,2113,3,"['task_categories:image-classification', 'task_categories:image-to-image', 'task_categories:text-to-image', 'language:en', 'language:ja', 'license:mit', 'size_categories:1M<n<10M', 'region:us']","Index files of KBlueLeaf/danbooru2023-webp-4Mpixel.
You can download images from KBlueLeaf/danbooru2023-webp-4Mpixel with cheesechaser.
from cheesechaser.datapool import DanbooruWebpDataPool

pool = DanbooruWebpDataPool()

# download danbooru images with webp format, to directory /data/danbooru_webp
pool.batch_download_to_directory(
    resource_ids=range(6000000, 6001000),
    dst_dir='/data/danbooru_webp',
    max_workers=12,
)

",https://huggingface.co/datasets/deepghs/danbooru2023-webp-4Mpixel_index,"['en', 'ja']","['image-classification', 'image-to-image', 'text-to-image']",['1M<n<10M']
kenkensz9/kenkensz9_1242tw2,kenkensz9,2024-06-01 00:05:43+00:00,2024-06-01 01:38:08+00:00,9,0,"['task_categories:text-generation', 'language:ja', 'license:apache-2.0', 'size_categories:1K<n<10K', 'format:csv', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","このデータセットは、著作者である自分がしたツイートから特に優れたもの(後述)を集めたものです。
定義：言語化が難しい事柄を言語化しているツイート。または世界観が独特なもの。
期間：2022年5月16日～2024年5月24日
ツイート数：1243
上の期間以前にもツイート自体はしていますが、人力で選定しているため、とりあえずこの期間のみとなっています。
このセットで微調整をすると、ベースモデルの表現力を拡張することはできるのではないかと思います。
とりわけ、人格を与えることとツイートを生成するタスクに使用しているため、システムプロンプトと入力は固定で使用しています。
",https://huggingface.co/datasets/kenkensz9/kenkensz9_1242tw2,['ja'],['text-generation'],['1K<n<10K']
kenkensz9/nareba1691,kenkensz9,2024-06-01 02:13:56+00:00,2024-06-01 02:44:25+00:00,10,0,"['task_categories:text-generation', 'language:ja', 'license:apache-2.0', 'size_categories:1K<n<10K', 'format:csv', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","このデータセットは、OpenAI社のGPT-3.5を
https://huggingface.co/datasets/kenkensz9/kenkensz9_1242tw2
のデータでファインチューニングした後に、更に独自に収集した人格のあるツイート330でファインチューニングしたモデルでツイートを生成し、
それに対してスコアを付与したモデルです。
10点：おー
9点：まあまあ
8点：うーん
みたいな感じです。
",https://huggingface.co/datasets/kenkensz9/nareba1691,['ja'],['text-generation'],['1K<n<10K']
geniacllm/livedoor_news_corpus,geniacllm,2024-06-01 08:48:24+00:00,2024-08-20 10:21:19+00:00,43,1,"['language:ja', 'size_categories:1K<n<10K', 'format:parquet', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","This is a fork of the dataset provided by LLM Book on Hugging Face (https://huggingface.co/datasets/llm-book/livedoor-news-corpus).

	
		
		Licence
	

Attribution-NoDerivs 2.1 Japan (CC BY-ND 2.1 JP) License
",https://huggingface.co/datasets/geniacllm/livedoor_news_corpus,['ja'],[],['1K<n<10K']
alfredplpl/anime-with-caption-cc0,alfredplpl,2024-06-03 04:37:13+00:00,2024-06-03 05:49:20+00:00,81,19,"['task_categories:image-to-text', 'language:en', 'language:ja', 'license:cc0-1.0', 'size_categories:10K<n<100K', 'format:parquet', 'modality:image', 'modality:text', 'library:datasets', 'library:dask', 'library:mlcroissant', 'library:polars', 'region:us']","
	
		
		Anime with caption CC-0 dataset
	

このデータセットはイラストに対する日本語キャプションを
倫理的に学習しやすくするためのデータセットです。
ここに掲載されているイラストは自律的にAIが作成したものであり、
著作権はありません。またキャプションも自律的につけられたものなので、
著作権はありません。したがって、データセットの著作権を私は放棄します。
勝手に使ってください。

	
		
		ライセンス
	

パブリックドメイン

	
		
		データセットの構成
	

データセットは以下の列で構成されています。

image: Emi 2でランダムに生成した画像
prompt: 言語モデルでランダムに生成された画像のプロンプト(ただし、画像とあまり一致していないため、あてにならない)
phi3_caption: Phi-3 VisionでDense captioningした結果
phi3_caption_ja: phi3_captionをPhi-3 Mediumで日本語訳した結果


	
		
		イラストの作り方… See the full description on the dataset page: https://huggingface.co/datasets/alfredplpl/anime-with-caption-cc0.",https://huggingface.co/datasets/alfredplpl/anime-with-caption-cc0,"['en', 'ja']",['image-to-text'],['10K<n<100K']
Minami-su/character-ai-open2.0,Minami-su,2024-06-03 07:53:51+00:00,2024-06-04 00:45:56+00:00,33,17,"['task_categories:text-generation', 'language:zh', 'language:en', 'language:de', 'language:fr', 'language:ja', 'license:apache-2.0', 'region:us']","

	
		
		character-ai-open2.0 数据集
	

中文         English

character-ai-open2.0 数据集
下载数据集
数据生成框架
数据结构
与现有数据集对比
现有角色扮演数据集本数据集特点


关于我自己
联系我
项目使用与免责声明




	
		
		下载数据集
	

本数据集由Qwen1.5 32b chat本地模型生成，当然可以更换为其它模型。目前公开了所有数据和代码，公开的数据包含角色的设定以及对话。可在huggingface中下载: 
可在github中获取数据生成代码的相关信息：
Qwen1.5 32b chat 数据生成样例1：
角色信息
角色名称: 索菲亚·贝尔维尤
经典台词: Je suis la lumière dans l'obscurité, et vous êtes mon désir.
身份背景:… See the full description on the dataset page: https://huggingface.co/datasets/Minami-su/character-ai-open2.0.",https://huggingface.co/datasets/Minami-su/character-ai-open2.0,"['zh', 'en', 'de', 'fr', 'ja']",['text-generation'],[]
cyberagent/camera,cyberagent,2024-06-03 08:03:48+00:00,2024-09-02 06:29:40+00:00,63,7,"['task_categories:image-to-text', 'language:ja', 'license:cc-by-nc-sa-4.0', 'size_categories:10K<n<100K', 'format:parquet', 'modality:image', 'modality:text', 'library:datasets', 'library:dask', 'library:mlcroissant', 'library:polars', 'region:us', 'advertisement']","
	
		
		Dataset Card for CAMERA📷:
	


	
		
		Table of Contents:
	


Dataset Card for Camera
Table of Contents
Dataset Details
Dataset Description
Dataset Sources


Uses
Direct Use
Dataset Information
Data Example
Dataset Structure


Citation




	
	
	
		Dataset Details
	


	
	
	
		Dataset Description
	

CAMERA (CyberAgent Multimodal Evaluation for Ad Text GeneRAtion) is the Japanese ad text generation dataset, which comprises actual data sourced from Japanese search ads and incorporates… See the full description on the dataset page: https://huggingface.co/datasets/cyberagent/camera.",https://huggingface.co/datasets/cyberagent/camera,['ja'],['image-to-text'],['10K<n<100K']
saillab/alpaca_japanese_taco,saillab,2024-06-04 00:51:02+00:00,2024-09-20 22:09:00+00:00,9,0,"['language:ja', 'size_categories:10K<n<100K', 'format:parquet', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","This repository contains the dataset used for the TaCo paper.
The dataset follows the style outlined in the TaCo paper, as follows:
{
""instruction"": ""instruction in xx"",
""input"": ""input in xx"",
""output"": ""Instruction in English: instruction in en , 
            Response in English: response in en ,
            Response in xx: response in xx ""
}

Please refer to the paper for more details: OpenReview
If you have used our dataset, please cite it as follows:
Citation… See the full description on the dataset page: https://huggingface.co/datasets/saillab/alpaca_japanese_taco.",https://huggingface.co/datasets/saillab/alpaca_japanese_taco,['ja'],[],['10K<n<100K']
kanhatakeyama/SyntheticText,kanhatakeyama,2024-06-04 04:56:13+00:00,2024-07-16 07:30:43+00:00,152,2,"['language:ja', 'license:cc-by-sa-3.0', 'size_categories:1M<n<10M', 'format:parquet', 'modality:text', 'library:datasets', 'library:dask', 'library:mlcroissant', 'library:polars', 'region:us']","
以下のデータ源からランダムに抽出したテキストをもとに､phi3で再生成した文章です｡
Wikibooks
Wikipedia
Cosmopedia
判例データ




	
		
		データ
	


parquetファイルが数十GB程度あります
datasetsライブラリからでは､はじめの数GB程度しか読み込めない可能性があります｡git lfsなどでダウンロードする必要がありそうです｡


	
		
		コード
	


こちら

一部の計算には東京工業大学のスーパーコンピュータTSUBAME4.0を利用しました｡


",https://huggingface.co/datasets/kanhatakeyama/SyntheticText,['ja'],[],['1M<n<10M']
lissette/Nanami-Chiaki-audio,lissette,2024-06-04 06:37:48+00:00,2024-06-04 09:48:41+00:00,5,0,"['language:ja', 'license:apache-2.0', 'size_categories:n<1K', 'format:audiofolder', 'modality:audio', 'library:datasets', 'library:mlcroissant', 'region:us']","弹丸论破的七海千秋语音数据
",https://huggingface.co/datasets/lissette/Nanami-Chiaki-audio,['ja'],[],['n<1K']
lissette/Yokodera-audio,lissette,2024-06-04 09:38:51+00:00,2024-06-04 09:45:18+00:00,7,0,"['language:ja', 'license:apache-2.0', 'size_categories:1K<n<10K', 'format:audiofolder', 'modality:audio', 'library:datasets', 'library:mlcroissant', 'region:us']","《变态王子与不笑猫》男主角，横寺阳人，声优：梶裕贵
",https://huggingface.co/datasets/lissette/Yokodera-audio,['ja'],[],['1K<n<10K']
ibm-research/SocialStigmaQA-JA,ibm-research,2024-06-05 01:14:25+00:00,2025-01-09 07:20:55+00:00,90,4,"['task_categories:question-answering', 'language:ja', 'license:cdla-permissive-2.0', 'size_categories:10K<n<100K', 'format:csv', 'modality:tabular', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","
	
		
		SocialStigmaQA-JA Dataset Card
	

It is crucial to test the social bias of large language models.
SocialStigmaQA dataset is meant to capture the amplification of social bias, via stigmas, in generative language models.
Taking inspiration from social science research, the dataset is constructed from a documented list of 93 US-centric stigmas and a hand-curated question-answering (QA) templates which involves social situations.
Here, we introduce SocialStigmaQA-JA, a Japanese version of… See the full description on the dataset page: https://huggingface.co/datasets/ibm-research/SocialStigmaQA-JA.",https://huggingface.co/datasets/ibm-research/SocialStigmaQA-JA,['ja'],['question-answering'],['10K<n<100K']
thashiguchi/LizeHelesta_Benchmark,thashiguchi,2024-06-05 15:01:57+00:00,2024-06-05 15:08:10+00:00,6,0,"['task_categories:question-answering', 'language:ja', 'size_categories:n<1K', 'format:parquet', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']",,https://huggingface.co/datasets/thashiguchi/LizeHelesta_Benchmark,['ja'],['question-answering'],['n<1K']
RikkaBotan/tts-collections,RikkaBotan,2024-06-06 07:36:25+00:00,2025-03-11 07:08:54+00:00,10,0,"['task_categories:text-to-speech', 'task_categories:text-to-audio', 'language:ja', 'language:en', 'language:zh', 'license:cc-by-sa-4.0', 'region:us']","
	
		
		Cute, Dynamic and Modern Flet Application for windows
	

The application can be used under special Internet structures that are blocked by proxies by authenticating the site.
It is available in three languages (Japanese, English, and Chinese) and can synthesize speech in any language.
It provides an intuitive and cute GUI.
I would be very happy if you could try using it !!!


	
	
	
		childish and unapologetic voice generation for free, both commercial and non-commercial.… See the full description on the dataset page: https://huggingface.co/datasets/RikkaBotan/tts-collections.",https://huggingface.co/datasets/RikkaBotan/tts-collections,"['ja', 'en', 'zh']","['text-to-speech', 'text-to-audio']",[]
kevineen/Tanuki-Phase2-annotation-dataset,kevineen,2024-06-07 01:47:32+00:00,2024-06-23 09:22:14+00:00,14,0,"['task_categories:text-classification', 'language:ja', 'license:apache-2.0', 'size_categories:n<1K', 'format:json', 'modality:tabular', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']",,https://huggingface.co/datasets/kevineen/Tanuki-Phase2-annotation-dataset,['ja'],['text-classification'],['n<1K']
RajChat/Chatgpt,RajChat,2024-06-07 11:16:22+00:00,2024-06-07 14:23:01+00:00,18,1,"['language:en', 'language:es', 'language:ru', 'language:de', 'language:pl', 'language:th', 'language:vi', 'language:sv', 'language:bn', 'language:da', 'language:he', 'language:it', 'language:fa', 'language:sk', 'language:id', 'language:nb', 'language:el', 'language:nl', 'language:hu', 'language:eu', 'language:zh', 'language:eo', 'language:ja', 'language:ca', 'language:cs', 'language:bg', 'language:fi', 'language:pt', 'language:tr', 'language:ro', 'language:ar', 'language:uk', 'language:gl', 'language:fr', 'language:ko', 'license:apache-2.0', 'size_categories:10K<n<100K', 'format:parquet', 'modality:tabular', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'arxiv:2304.07327', 'region:us', 'human-feedback']","
	
		
		OpenAssistant Conversations Dataset (OASST1)
	


	
		
		Dataset Summary
	

In an effort to democratize research on large-scale alignment, we release OpenAssistant 
Conversations (OASST1), a human-generated, human-annotated assistant-style conversation 
corpus consisting of 161,443 messages in 35 different languages, annotated with 461,292 
quality ratings, resulting in over 10,000 fully annotated conversation trees. The corpus 
is a product of a worldwide crowd-sourcing effort… See the full description on the dataset page: https://huggingface.co/datasets/RajChat/Chatgpt.",https://huggingface.co/datasets/RajChat/Chatgpt,"['en', 'es', 'ru', 'de', 'pl', 'th', 'vi', 'sv', 'bn', 'da', 'he', 'it', 'fa', 'sk', 'id', 'nb', 'el', 'nl', 'hu', 'eu', 'zh', 'eo', 'ja', 'ca', 'cs', 'bg', 'fi', 'pt', 'tr', 'ro', 'ar', 'uk', 'gl', 'fr', 'ko']",[],['10K<n<100K']
fufufukakaka/pokemon_battle_team_dataset_regulation_f,fufufukakaka,2024-06-08 08:26:54+00:00,2024-06-09 07:16:16+00:00,16,0,"['language:ja', 'license:mit', 'size_categories:n<1K', 'format:csv', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","ポケモン(VGC)のレギュレーションF ルールにおける選出データを記録したデータセットです。
YouTube 上で公開状態になっていた対戦配信から選出データを収集しました。trainer_id がそれぞれ配信を行っていた方に対応します。
なお、trainer_id 13 は本データセット作者が行った対戦データを示しています。
こちらのデータを用いて、2024年5月にリモートポケモン学会というコミュニティで発表を行いました。

配信 https://youtu.be/4Op-JvVEQ10?t=3479
スライド https://speakerdeck.com/fufufukakaka/ji-jie-xue-xi-woyong-itapokemondui-zhan-xuan-chu-yu-ce

",https://huggingface.co/datasets/fufufukakaka/pokemon_battle_team_dataset_regulation_f,['ja'],[],['n<1K']
OmniAICreator/Japanese-Roleplay-Dialogues,OmniAICreator,2024-06-08 08:41:10+00:00,2024-06-08 16:25:27+00:00,32,10,"['task_categories:text-generation', 'language:ja', 'license:apache-2.0', 'size_categories:10K<n<100K', 'format:json', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us', 'roleplay']","
	
		
		Japanese-Roleplay-Dialogues
	

This is a dialogue corpus collected from Japanese role-playing forum (commonly known as ""なりきりチャット(narikiri chat)""). Each record corresponds to a single thread.
For the original version, no filtering has been applied.
For the filtered version, the following filtering and cleaning conditions have been applied:

If the number of unique poster in the posts of each record is 1 or less, delete the entire record.
If the length of the posts is 10 or less, delete… See the full description on the dataset page: https://huggingface.co/datasets/OmniAICreator/Japanese-Roleplay-Dialogues.",https://huggingface.co/datasets/OmniAICreator/Japanese-Roleplay-Dialogues,['ja'],['text-generation'],['10K<n<100K']
lmg-anon/vntl-leaderboard,lmg-anon,2024-06-08 20:33:07+00:00,2025-01-02 16:34:32+00:00,418,38,"['task_categories:translation', 'language:en', 'language:ja', 'size_categories:n<1K', 'format:json', 'modality:tabular', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us', 'benchmark', 'leaderboard']","
	
		
		VNTL Leaderboard
	

The VNTL leaderboard ranks Large Language Models (LLMs) based on their performance in translating Japanese Visual Novels into English. Please be aware that the current results are preliminary and subject to change as new models are evaluated, or changes are done in the evaluation script.

	
		
		Comparison with Established Translation Tools
	

For comparison, this table shows the scores for established translation tools. These include both widely available online… See the full description on the dataset page: https://huggingface.co/datasets/lmg-anon/vntl-leaderboard.",https://huggingface.co/datasets/lmg-anon/vntl-leaderboard,"['en', 'ja']",['translation'],['n<1K']
alfredplpl/commoncatalog-cc-by-ja,alfredplpl,2024-06-09 21:31:00+00:00,2024-06-23 22:34:30+00:00,19,1,"['task_categories:image-to-text', 'task_categories:text-to-image', 'language:ja', 'license:cc-by-4.0', 'size_categories:100K<n<1M', 'format:csv', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","
	
		
		CommonCatalog CC-BY Ja
	

このリポジトリはCommonCatalog CC-BYを拡張して、追加の情報を入れたものです。
以下の情報が追加されています。

LLaVA-JPを改良したモデルによる簡易な日本語キャプション1つ
LLaVA-JPを改良したモデルによるできるだけ詳細な日本語キャプション3つ (予定)


	
		
		Sample Code
	

df2=pandas.read_csv(""cc-by-ja.csv"")

dataset = load_dataset(""common-canvas/commoncatalog-cc-by"",split=""train"",streaming=True)

data_info=[]
for i,data in enumerate(tqdm(dataset)):
    data[""jpg""].save(f""/mnt/my_raid/pixart_jp/InternImgs/{i:09}.jpg"")

    data_info.append({
        ""height"":… See the full description on the dataset page: https://huggingface.co/datasets/alfredplpl/commoncatalog-cc-by-ja.",https://huggingface.co/datasets/alfredplpl/commoncatalog-cc-by-ja,['ja'],"['image-to-text', 'text-to-image']",['100K<n<1M']
hpprc/auto-wiki-qa-rels,hpprc,2024-06-11 11:51:14+00:00,2024-06-16 06:30:03+00:00,6,1,"['language:ja', 'license:cc-by-sa-4.0', 'size_categories:10K<n<100K', 'format:parquet', 'modality:tabular', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']",,https://huggingface.co/datasets/hpprc/auto-wiki-qa-rels,['ja'],[],['10K<n<100K']
shanearora/CaLMQA,shanearora,2024-06-12 08:08:20+00:00,2025-06-12 08:42:04+00:00,33,2,"['multilinguality:multilingual', 'language:aa', 'language:ar', 'language:bal', 'language:de', 'language:en', 'language:es', 'language:fj', 'language:fo', 'language:he', 'language:hi', 'language:hil', 'language:hu', 'language:ja', 'language:ko', 'language:ru', 'language:rn', 'language:pap', 'language:ps', 'language:sm', 'language:to', 'language:tn', 'language:wo', 'language:zh', 'license:mit', 'size_categories:10K<n<100K', 'format:parquet', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'arxiv:2406.17761', 'doi:10.57967/hf/2525', 'region:us']","
	
		
		Dataset Summary
	



CaLMQA is a translation-free long-form question answering (LFQA) dataset spanning 23 high- to low-resource languages. 

	
		
		Dataset Details
	


	
		
		Dataset Description
	

CaLMQA is a translation-free LFQA dataset with 51.7K questions from 23 languages, 11 high- to mid-resource and 12 low-resource.
All questions are culturally specific – (1) they refer to concepts unique to one or a few cultures, such as
""Kuber iki umwami wa mbere w’uburundi yitwa Ntare?""… See the full description on the dataset page: https://huggingface.co/datasets/shanearora/CaLMQA.",https://huggingface.co/datasets/shanearora/CaLMQA,"['aa', 'ar', 'bal', 'de', 'en', 'es', 'fj', 'fo', 'he', 'hi', 'hil', 'hu', 'ja', 'ko', 'ru', 'rn', 'pap', 'ps', 'sm', 'to', 'tn', 'wo', 'zh']",[],['10K<n<100K']
ServiceNow-AI/M2Lingual,ServiceNow-AI,2024-06-13 00:47:39+00:00,2024-08-13 19:01:43+00:00,369,40,"['language:zh', 'language:ne', 'language:uk', 'language:ja', 'language:zu', 'language:ku', 'language:ig', 'language:mg', 'language:fi', 'language:si', 'language:id', 'language:sw', 'language:ar', 'language:sv', 'language:ru', 'language:yo', 'language:en', 'language:ht', 'language:kn', 'language:ta', 'language:te', 'language:sq', 'language:mr', 'language:am', 'language:wo', 'language:it', 'language:tr', 'language:ha', 'language:pl', 'language:el', 'language:lt', 'language:ms', 'language:jv', 'language:sn', 'language:ml', 'language:ps', 'language:ky', 'language:es', 'language:ga', 'language:gu', 'language:ko', 'language:vi', 'language:sd', 'language:fa', 'language:nl', 'language:hu', 'language:so', 'language:pa', 'language:bn', 'language:pt', 'language:da', 'language:hi', 'language:eu', 'language:de', 'language:ur', 'language:su', 'language:xh', 'language:fr', 'license:cc-by-nc-sa-4.0', 'size_categories:100K<n<1M', 'format:parquet', 'modality:tabular', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'arxiv:2406.16783', 'region:us']","
	
		
		M2Lingual
	

A Multi-turn Multilingual dataset for Instruction Fine-tuning LLMs - Link

	
		
		Dataset Summary
	

The M2Lingual dataset is a comprehensive multi-turn multilingual resource designed to facilitate research and development in conversational AI. It encompasses a wide range of conversation scenarios across multiple languages, making it an invaluable asset for training, evaluating, and benchmarking conversational models. The dataset includes  diverse tasks such as question… See the full description on the dataset page: https://huggingface.co/datasets/ServiceNow-AI/M2Lingual.",https://huggingface.co/datasets/ServiceNow-AI/M2Lingual,"['zh', 'ne', 'uk', 'ja', 'zu', 'ku', 'ig', 'mg', 'fi', 'si', 'id', 'sw', 'ar', 'sv', 'ru', 'yo', 'en', 'ht', 'kn', 'ta', 'te', 'sq', 'mr', 'am', 'wo', 'it', 'tr', 'ha', 'pl', 'el', 'lt', 'ms', 'jv', 'sn', 'ml', 'ps', 'ky', 'es', 'ga', 'gu', 'ko', 'vi', 'sd', 'fa', 'nl', 'hu', 'so', 'pa', 'bn', 'pt', 'da', 'hi', 'eu', 'de', 'ur', 'su', 'xh', 'fr']",[],['100K<n<1M']
kanhatakeyama/SyntheticTextWikiTranslate,kanhatakeyama,2024-06-13 06:50:51+00:00,2024-07-16 07:31:35+00:00,32,1,"['language:ja', 'license:cc-by-sa-3.0', 'size_categories:1M<n<10M', 'format:parquet', 'modality:text', 'library:datasets', 'library:dask', 'library:mlcroissant', 'library:polars', 'region:us']","
以下のデータ源からランダムに抽出した日本語のテキストをPhi-3で再生成し､更に自動英訳したコーパスです｡
Wikibooks
Wikipedia




	
		
		コード
	


こちら

一部の計算には東京工業大学のスーパーコンピュータTSUBAME4.0を利用しました｡



	
		
		データ
	


parquetファイルが数十GB程度あります
datasetsライブラリからでは､はじめの数GB程度しか読み込めない可能性があります｡git lfsなどでダウンロードする必要がありそうです｡

",https://huggingface.co/datasets/kanhatakeyama/SyntheticTextWikiTranslate,['ja'],[],['1M<n<10M']
kanhatakeyama/SyntheticTextOpenMathInstruct,kanhatakeyama,2024-06-13 07:47:23+00:00,2024-06-14 07:12:50+00:00,13,2,"['language:ja', 'license:other', 'size_categories:1M<n<10M', 'format:parquet', 'modality:text', 'library:datasets', 'library:dask', 'library:mlcroissant', 'library:polars', 'region:us']","
以下のデータ源からランダムに抽出した日本語のテキストをもとに､Phi-3で作文したコーパスです｡
OpenMathInstruct-1-1.8m-ja




	
		
		コード
	


こちら

一部の計算には東京工業大学のスーパーコンピュータTSUBAME4.0を利用しました｡


",https://huggingface.co/datasets/kanhatakeyama/SyntheticTextOpenMathInstruct,['ja'],[],['1M<n<10M']
longisland3/NMLE,longisland3,2024-06-13 08:30:18+00:00,2025-02-19 03:03:05+00:00,14,5,"['task_categories:multiple-choice', 'task_categories:question-answering', 'language:ja', 'license:cc-by-nc-nd-4.0', 'size_categories:1K<n<10K', 'format:json', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us', 'medical', 'examination', 'Japan', '医師国家試験', '医療', 'Doctor']","
	
		
		医師国家試験データセット（NMLE datasets）
	


	
		
		はじめに
	

日本の医師国家試験のデータセット
第110回 - 第117回までのデータ

	
		
		用途
	

用途として

モデルの評価
進化的モデルマージのタスクにつかう（「New Task Guide」参照）
RAGなどに用いる情報源
医師国家試験の俯瞰

を想定しています

	
		
		構造
	

data = {
    ""id"": question_id,
    ""question"": question_text,
    ""choices"": choices,
    ""answer"": answers,
    ""explanation"": explanation
    }

一部、構造化データにできなかった問題（画像がメインの出題など）が抜けています

	
	
	
		ライセンス
	

ライセンスはCC-BY-NC-ND4.0で、商用利用禁止となっています
改変、改善、その他ご相談については
X: @longislandtea3
までお願いします… See the full description on the dataset page: https://huggingface.co/datasets/longisland3/NMLE.",https://huggingface.co/datasets/longisland3/NMLE,['ja'],"['multiple-choice', 'question-answering']",['1K<n<10K']
henilp105/ESCI,henilp105,2024-06-13 14:48:07+00:00,2024-06-13 17:21:40+00:00,8,0,"['task_categories:text-classification', 'task_categories:text-retrieval', 'language:en', 'language:ja', 'language:es', 'license:apache-2.0', 'size_categories:100K<n<1M', 'format:arrow', 'modality:tabular', 'modality:text', 'library:datasets', 'library:mlcroissant', 'region:us']",,https://huggingface.co/datasets/henilp105/ESCI,"['en', 'ja', 'es']","['text-classification', 'text-retrieval']",['100K<n<1M']
numad/yuho-text-2023,numad,2024-06-14 07:39:00+00:00,2024-06-14 10:55:42+00:00,25,0,"['language:ja', 'license:apache-2.0', 'size_categories:10K<n<100K', 'format:json', 'modality:text', 'library:datasets', 'library:dask', 'library:mlcroissant', 'library:polars', 'region:us', 'finance']","
	
		
		Dataset Card for Dataset Name
	



このデータはEDINET閲覧（提出）サイトで公開されている2023年に提出された有価証券報告書から特定の章を抜粋したデータです。
各レコードのurl列が出典となります。

	
		
		Dataset Details
	


	
		
		Dataset Description
	


データの内容は下記想定です

	
		
物理名
論理名
型
概要
必須


		
doc_id
文書ID
str
有価証券報告書の単位で発行されるID
〇


edinet_code
EDINETコード
str
EDINET内での企業単位に採番されるID
〇


company_name
企業名
str
企業名
〇


document_name
文書タイトル
str
有価証券報告書のタイトル
〇


sec_code
証券コード
str
証券コード
×


period_start
期開始日
date(yyyy-mm-dd)
報告対象期間の開始日
〇


period_end
期終了日… See the full description on the dataset page: https://huggingface.co/datasets/numad/yuho-text-2023.",https://huggingface.co/datasets/numad/yuho-text-2023,['ja'],[],['10K<n<100K']
numad/yuho-text-2024,numad,2024-06-14 11:17:32+00:00,2024-06-14 11:18:17+00:00,12,1,"['language:ja', 'license:apache-2.0', 'size_categories:1K<n<10K', 'format:json', 'modality:text', 'library:datasets', 'library:dask', 'library:mlcroissant', 'library:polars', 'region:us', 'finance']","
	
		
		Dataset Card for Dataset Name
	



このデータはEDINET閲覧（提出）サイトで公開されている2024年に提出された有価証券報告書から特定の章を抜粋したデータです。
各レコードのurl列が出典となります。

	
		
		Dataset Details
	


	
		
		Dataset Description
	


データの内容は下記想定です

	
		
物理名
論理名
型
概要
必須


		
doc_id
文書ID
str
有価証券報告書の単位で発行されるID
〇


edinet_code
EDINETコード
str
EDINET内での企業単位に採番されるID
〇


company_name
企業名
str
企業名
〇


document_name
文書タイトル
str
有価証券報告書のタイトル
〇


sec_code
証券コード
str
証券コード
×


period_start
期開始日
date(yyyy-mm-dd)
報告対象期間の開始日
〇


period_end
期終了日… See the full description on the dataset page: https://huggingface.co/datasets/numad/yuho-text-2024.",https://huggingface.co/datasets/numad/yuho-text-2024,['ja'],[],['1K<n<10K']
numad/yuho-text-2014-2022,numad,2024-06-15 00:24:41+00:00,2024-06-15 00:29:42+00:00,15,0,"['language:ja', 'license:apache-2.0', 'size_categories:100K<n<1M', 'format:json', 'modality:text', 'library:datasets', 'library:dask', 'library:mlcroissant', 'library:polars', 'region:us', 'finance']","
	
		
		Dataset Card for Dataset Name
	



このデータはEDINET閲覧（提出）サイトで公開されている2014~2022年に提出された有価証券報告書から特定の章を抜粋したデータです。
各レコードのurl列が出典となります。データ取得の都合上2014/06/14以降のデータになります。

	
		
		Dataset Details
	


	
		
		Dataset Description
	


データの内容は下記想定です

	
		
物理名
論理名
型
概要
必須


		
doc_id
文書ID
str
有価証券報告書の単位で発行されるID
〇


edinet_code
EDINETコード
str
EDINET内での企業単位に採番されるID
〇


company_name
企業名
str
企業名
〇


document_name
文書タイトル
str
有価証券報告書のタイトル
〇


sec_code
証券コード
str
証券コード
×


period_start
期開始日
date(yyyy-mm-dd)… See the full description on the dataset page: https://huggingface.co/datasets/numad/yuho-text-2014-2022.",https://huggingface.co/datasets/numad/yuho-text-2014-2022,['ja'],[],['100K<n<1M']
iam-ajaymeena/Self-Instruct-Japanese-Elzya-13B,iam-ajaymeena,2024-06-15 08:11:55+00:00,2024-06-16 09:12:56+00:00,9,0,"['task_categories:text-generation', 'language:ja', 'license:apache-2.0', 'size_categories:1K<n<10K', 'format:parquet', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","A Japanese dataset generated with an opensource elyza/ELYZA-japanese-Llama-2-13b-instruct model. 
This dataset is used in evaluating AI-generated text detection methods and is well-suited for self-instruct methods.
The instructions were taken from:

https://huggingface.co/datasets/CausalLM/GPT-4-Self-Instruct-Japanese

The model used is:

https://huggingface.co/elyza/ELYZA-japanese-Llama-2-7b

License: refer to the model's license
",https://huggingface.co/datasets/iam-ajaymeena/Self-Instruct-Japanese-Elzya-13B,['ja'],['text-generation'],['1K<n<10K']
Geralt-Targaryen/MELA,Geralt-Targaryen,2024-06-16 04:16:19+00:00,2024-06-16 08:55:22+00:00,162,0,"['task_categories:text-classification', 'language:en', 'language:zh', 'language:it', 'language:ru', 'language:de', 'language:fr', 'language:es', 'language:ja', 'language:ar', 'language:is', 'license:apache-2.0', 'size_categories:10K<n<100K', 'format:csv', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us', 'linguistic acceptability']","See the GitHub repo for details.
",https://huggingface.co/datasets/Geralt-Targaryen/MELA,"['en', 'zh', 'it', 'ru', 'de', 'fr', 'es', 'ja', 'ar', 'is']",['text-classification'],['10K<n<100K']
iam-ajaymeena/Self-Instruct-Japanese-Qwen1.5-14B,iam-ajaymeena,2024-06-16 06:04:11+00:00,2024-06-16 09:12:08+00:00,16,2,"['task_categories:text-generation', 'language:ja', 'license:apache-2.0', 'size_categories:1K<n<10K', 'format:parquet', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","A Japanese dataset generated with Qwen/Qwen1.5-14B model. 
This dataset is used in evaluating AI-generated text detection methods and is well-suited for self-instruct methods.
The instructions were taken from:

https://huggingface.co/datasets/CausalLM/GPT-4-Self-Instruct-Japanese

The model used is:

https://huggingface.co/Qwen/Qwen1.5-14B

License: Please refer to the model's license
",https://huggingface.co/datasets/iam-ajaymeena/Self-Instruct-Japanese-Qwen1.5-14B,['ja'],['text-generation'],['1K<n<10K']
kurogane/Magpie_RakutenAI_prompt_extract_example50,kurogane,2024-06-17 13:33:28+00:00,2024-06-17 14:04:01+00:00,18,0,"['language:ja', 'license:apache-2.0', 'size_categories:n<1K', 'format:json', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'arxiv:2406.08464', 'region:us']","Magpie方式によるprompt抽出をRakuten/RakutenAI-7B-chatで行ってみました。
設定しているsystem promptは論文のサプリ記載のpromptを翻訳したものを使用しています。
Magpie: Alignment Data Synthesis from Scratch by Prompting Aligned LLMs with Nothing
https://arxiv.org/abs/2406.08464
",https://huggingface.co/datasets/kurogane/Magpie_RakutenAI_prompt_extract_example50,['ja'],[],['n<1K']
neody/madlad-400-ja-cleaned,neody,2024-06-18 08:28:11+00:00,2024-07-06 08:30:01+00:00,11,0,"['language:ja', 'size_categories:1M<n<10M', 'format:parquet', 'modality:text', 'library:datasets', 'library:dask', 'library:mlcroissant', 'library:polars', 'region:us']",,https://huggingface.co/datasets/neody/madlad-400-ja-cleaned,['ja'],[],['1M<n<10M']
kurogane/Magpie_llama-3-youko-8b_prompt_extract_example50,kurogane,2024-06-18 12:45:15+00:00,2024-06-18 12:47:01+00:00,13,0,"['language:ja', 'license:llama3', 'size_categories:n<1K', 'format:json', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'arxiv:2406.08464', 'region:us']","Magpie方式によるprompt抽出をrinna/llama-3-youko-8bで行ってみました。
設定しているsystem promptは論文のサプリ記載のpromptを翻訳したものを使用しています。
rinna/llama-3-youko-8bはinstructモデルではないため、不適切な試みであったかもしれません。
Magpie: Alignment Data Synthesis from Scratch by Prompting Aligned LLMs with Nothing
https://arxiv.org/abs/2406.08464
",https://huggingface.co/datasets/kurogane/Magpie_llama-3-youko-8b_prompt_extract_example50,['ja'],[],['n<1K']
kurogane/Magpie_aixsatoshi_Llama-3-youko-8b-instruct-chatvector_prompt_extract_example50,kurogane,2024-06-18 14:28:03+00:00,2024-06-18 14:28:56+00:00,9,0,"['language:ja', 'license:llama3', 'size_categories:n<1K', 'format:json', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'arxiv:2406.08464', 'region:us']","Magpie方式によるprompt抽出をaixsatoshi/Llama-3-youko-8b-instruct-chatvectorで行ってみました。
設定しているsystem promptは論文のサプリ記載のpromptを翻訳したものを使用しています。
Magpie: Alignment Data Synthesis from Scratch by Prompting Aligned LLMs with Nothing
https://arxiv.org/abs/2406.08464
",https://huggingface.co/datasets/kurogane/Magpie_aixsatoshi_Llama-3-youko-8b-instruct-chatvector_prompt_extract_example50,['ja'],[],['n<1K']
ryota39/open_preference_v0.2,ryota39,2024-06-19 09:34:01+00:00,2024-07-04 12:55:23+00:00,15,0,"['language:ja', 'license:cc-by-sa-3.0', 'size_categories:10K<n<100K', 'format:json', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","
	
		
		description
	


public RLHF dataset in Japanese
the construction of the reward model was reformatted into a classification task
Quality of Japanese text is somewhat low arise from the combination of synthetic generated text and machine translation API


	
		
		details
	


reformatted dataset of open_preference_v0.1
label 1 stands for chosen sentence
label 0 stands for rejected sentence

",https://huggingface.co/datasets/ryota39/open_preference_v0.2,['ja'],[],['10K<n<100K']
llm-book/llm-jp-eval,llm-book,2024-06-19 10:31:57+00:00,2025-08-20 09:59:26+00:00,2414,3,"['task_categories:text-generation', 'language:ja', 'license:apache-2.0', 'region:us']","
	
		
		Dataset Card for llm-book/ja-vicuna-qa-benchmark
	

書籍『大規模言語モデル入門Ⅱ〜生成型LLMの実装と評価』で使用する、LLM-jpが提供する「llm-jp-eval」で使用されるデータセットです。 
オリジナルのサイトと同じものを使用しています。
本データセットは、複数のデータセットを横断して日本語の大規模言語モデルを自動評価するにの使用されます。

	
		
		Licence
	

Apache License, Version 2.0
",https://huggingface.co/datasets/llm-book/llm-jp-eval,['ja'],['text-generation'],[]
sentence-transformers/miracl,sentence-transformers,2024-06-19 14:20:16+00:00,2024-06-20 13:50:24+00:00,996,2,"['task_categories:feature-extraction', 'task_categories:sentence-similarity', 'language:en', 'language:ar', 'language:bn', 'language:es', 'language:fa', 'language:fi', 'language:fr', 'language:hi', 'language:id', 'language:ja', 'language:ko', 'language:ru', 'language:sw', 'language:te', 'language:th', 'language:zh', 'size_categories:1M<n<10M', 'format:parquet', 'modality:text', 'library:datasets', 'library:dask', 'library:mlcroissant', 'library:polars', 'region:us', 'sentence-transformers']","
	
		
		Dataset Card for MIRACL
	

This is a reformatting of the MIRACL dataset used to train the BGE-M3 model. See the full BGE-M3 dataset in Shitao/bge-m3-data.

	
		
		Dataset Subsets
	


	
		
		...-triplet subset
	


Columns: ""anchor"", ""positive"", ""negative""
Column types: str, str, str
Examples:{
  'anchor': '月球到地球的距离是多少？',
  'positive': '月球距離\n月球距離 (LD) 是天文學上從地球到月球的距離，從地球到月球的平均距離是384,401公里 (238,856英里)。因為月球在橢圓軌道上運動，實際的距離隨時都在變化著。',
  'negative':… See the full description on the dataset page: https://huggingface.co/datasets/sentence-transformers/miracl.",https://huggingface.co/datasets/sentence-transformers/miracl,"['en', 'ar', 'bn', 'es', 'fa', 'fi', 'fr', 'hi', 'id', 'ja', 'ko', 'ru', 'sw', 'te', 'th', 'zh']","['feature-extraction', 'sentence-similarity']",['1M<n<10M']
sentence-transformers/mldr,sentence-transformers,2024-06-19 14:53:42+00:00,2024-06-19 16:22:10+00:00,1498,5,"['task_categories:feature-extraction', 'task_categories:sentence-similarity', 'multilinguality:monolingual', 'language:ar', 'language:de', 'language:en', 'language:es', 'language:fr', 'language:hi', 'language:it', 'language:ja', 'language:ko', 'language:pt', 'language:ru', 'language:th', 'language:zh', 'size_categories:100K<n<1M', 'format:parquet', 'modality:text', 'library:datasets', 'library:dask', 'library:mlcroissant', 'library:polars', 'region:us', 'sentence-transformers']","
	
		
		Dataset Card for MLDR
	

This is a reformatting of the MLDR dataset used to train the BGE-M3 model. See the full BGE-M3 dataset in Shitao/bge-m3-data.

	
		
		Dataset Subsets
	


	
		
		...-triplet subset
	


Columns: ""anchor"", ""positive"", ""negative""
Column types: str, str, str
Examples:{
  'anchor': '¿Cuál es el efecto de la dilución crema simple en los pelajes básicos de los caballos?',
  'positive': 'Gen crema\n\nPelajes resultantes\n\nTodos los caballos tienen dos copias del gen… See the full description on the dataset page: https://huggingface.co/datasets/sentence-transformers/mldr.",https://huggingface.co/datasets/sentence-transformers/mldr,"['ar', 'de', 'en', 'es', 'fr', 'hi', 'it', 'ja', 'ko', 'pt', 'ru', 'th', 'zh']","['feature-extraction', 'sentence-similarity']",['100K<n<1M']
retarfi/economy-watchers-survey-evaluation,retarfi,2024-06-19 15:03:33+00:00,2025-04-10 09:52:49+00:00,19,0,"['task_categories:text-classification', 'language:ja', 'license:cc-by-4.0', 'size_categories:100K<n<1M', 'arxiv:2407.14727', 'doi:10.57967/hf/4514', 'region:us']",Dataset from the Economy Watchers Survey for use as evaluation tasks,https://huggingface.co/datasets/retarfi/economy-watchers-survey-evaluation,['ja'],['text-classification'],['100K<n<1M']
sentence-transformers/mr-tydi,sentence-transformers,2024-06-19 15:55:59+00:00,2024-06-20 13:53:43+00:00,588,1,"['task_categories:feature-extraction', 'task_categories:sentence-similarity', 'language:ar', 'language:bn', 'language:en', 'language:fi', 'language:id', 'language:ja', 'language:ko', 'language:ru', 'language:sw', 'language:te', 'language:th', 'size_categories:1M<n<10M', 'format:parquet', 'modality:text', 'library:datasets', 'library:dask', 'library:mlcroissant', 'library:polars', 'region:us', 'sentence-transformers']","
	
		
		Dataset Card for Mr. TyDi
	

This is a reformatting of the Mr. TyDi dataset used to train the BGE-M3 model. See the full BGE-M3 dataset in Shitao/bge-m3-data.

	
		
		Dataset Subsets
	


	
		
		...-triplet subset
	


Columns: ""anchor"", ""positive"", ""negative""
Column types: str, str, str
Examples:{
  'anchor': 'มหาวิทยาลัยมหาสารคาม เปิดสอนกี่สาขาวิชา?',
  'positive': 'มหาวิทยาลัยมหาสารคาม\nปัจจุบัน มหาวิทยาลัยมหาสารคามมีศูนย์กลางบริหารงานอยู่ที่เขตพื้นที่ขามเรียง ตำบลขามเรียง… See the full description on the dataset page: https://huggingface.co/datasets/sentence-transformers/mr-tydi.",https://huggingface.co/datasets/sentence-transformers/mr-tydi,"['ar', 'bn', 'en', 'fi', 'id', 'ja', 'ko', 'ru', 'sw', 'te', 'th']","['feature-extraction', 'sentence-similarity']",['1M<n<10M']
neody/oscar-ja-cleaned,neody,2024-06-20 07:55:12+00:00,2024-07-06 08:30:33+00:00,51,0,"['language:ja', 'size_categories:10M<n<100M', 'format:parquet', 'modality:text', 'library:datasets', 'library:dask', 'library:mlcroissant', 'library:polars', 'region:us']",,https://huggingface.co/datasets/neody/oscar-ja-cleaned,['ja'],[],['10M<n<100M']
aiana94/xMINDsmall,aiana94,2024-06-20 08:44:37+00:00,2024-10-25 08:30:20+00:00,23,4,"['task_categories:translation', 'task_categories:text-retrieval', 'multilinguality:translation', 'multilinguality:multilingual', 'multilinguality:multi-parallel', 'source_datasets:MIND', 'language:fi', 'language:gn', 'language:ht', 'language:id', 'language:ja', 'language:ka', 'language:ro', 'language:so', 'language:sw', 'language:ta', 'language:th', 'language:tr', 'language:vi', 'language:zh', 'license:cc-by-nc-sa-4.0', 'size_categories:1M<n<10M', 'format:parquet', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'arxiv:2403.17876', 'region:us', 'news', 'multilingual', 'machine-translated', 'nllb']","
	
		
		Dataset Card for xMINDsmall
	


	
		
		Dataset Summary
	

xMINDsmall is an open, large-scale multi-parallel news dataset for multi- and cross-lingual news recommendation. 
It is derived from the English MINDsmall dataset using open-source neural machine translation (i.e., NLLB 3.3B).
For the large version of the dataset, see xMINDlarge.

	
		
	
	
		Uses
	

This dataset can be used for machine translation, text retrieval, or as a benchmark dataset for news recommendation.… See the full description on the dataset page: https://huggingface.co/datasets/aiana94/xMINDsmall.",https://huggingface.co/datasets/aiana94/xMINDsmall,"['fi', 'gn', 'ht', 'id', 'ja', 'ka', 'ro', 'so', 'sw', 'ta', 'th', 'tr', 'vi', 'zh']","['translation', 'text-retrieval']",['1M<n<10M']
RJZ/ConceptNetSyntheticPhi3Text_ja,RJZ,2024-06-20 12:23:49+00:00,2024-06-21 14:22:03+00:00,10,1,"['language:ja', 'license:cc-by-sa-4.0', 'size_categories:10K<n<100K', 'format:json', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","
	
		
		Dataset Card for Dataset Name
	


ConceptNet(5.7)の日本語のトリプルに対して, Phi-3 を用いて文を生成したデータセット

	
		
		Dataset Details
	


	
		
		Dataset Creation
	


Generate a sentence in phi-3 using the below prompt

// h = {start}, r = {relation}, t = {end}
prompt = f""<|assistant|>\n次に示すトリプル: <start>, <relation>, <end>を用いて、<start>と<end>を<relation>で結びつけた関係を表す文を作成しなさい。必ずすべての情報を網羅し､日本語で出力すること。<|end|>\n<|user|>\nトリプル: {h}, {r}, {t}<|end|>\n<|assistant|>""

[More Information Needed]

	
		
	
	
		Source Data… See the full description on the dataset page: https://huggingface.co/datasets/RJZ/ConceptNetSyntheticPhi3Text_ja.",https://huggingface.co/datasets/RJZ/ConceptNetSyntheticPhi3Text_ja,['ja'],[],['10K<n<100K']
cl-nagoya/auto-wiki-qa-nemotron,cl-nagoya,2024-06-20 13:27:49+00:00,2024-09-13 01:44:38+00:00,14,2,"['language:ja', 'license:cc-by-sa-4.0', 'size_categories:100K<n<1M', 'format:parquet', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'arxiv:2406.11704', 'arxiv:2409.07737', 'region:us']","
	
		
		AutoWikiQA Nemotron
	

A dataset constructed by generating queries and answers from Wikipedia text using Nemotron-4 340B.
",https://huggingface.co/datasets/cl-nagoya/auto-wiki-qa-nemotron,['ja'],[],['100K<n<1M']
shunk031/STAIR-Captions,shunk031,2024-06-21 04:10:47+00:00,2024-06-22 06:23:12+00:00,514,5,"['task_categories:image-to-text', 'task_ids:image-captioning', 'annotations_creators:crowdsourced', 'language_creators:found', 'multilinguality:monolingual', 'source_datasets:extended|MSCOCO', 'language:ja', 'license:cc-by-4.0', 'size_categories:100K<n<1M', 'format:parquet', 'modality:image', 'modality:text', 'library:datasets', 'library:dask', 'library:mlcroissant', 'library:polars', 'arxiv:1705.00823', 'arxiv:2005.00614', 'region:us', 'image-captioning', 'mscoco']","
	
		
		Dataset Card for STAIR-Captions
	




	
		
	
	
		Dataset Summary
	

STAIR Captions is a large-scale dataset containing 820,310 Japanese captions. This dataset can be used for caption generation, multimodal retrieval, and image generation.

	
	
	
		Supported Tasks and Leaderboards
	

[More Information Needed]





	
	
	
		Languages
	

The language data in JDocQA is in Japanese (BCP-47 ja-JP).



	
		
		Dataset Structure
	


	
		
		Data Instances
	

[More Information Needed]… See the full description on the dataset page: https://huggingface.co/datasets/shunk031/STAIR-Captions.",https://huggingface.co/datasets/shunk031/STAIR-Captions,['ja'],['image-to-text'],['100K<n<1M']
kunishou/HelpSteer2-20k-ja,kunishou,2024-06-21 08:09:33+00:00,2024-06-21 08:44:21+00:00,11,7,"['language:ja', 'license:cc-by-4.0', 'size_categories:10K<n<100K', 'format:json', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","NVIDIA が公開している SteerLM 向けのトライアルデータセット HelpSteer2を日本語に自動翻訳したデータセットになります。HelpSteer2 は Nemotron-4-430B-Reward でも利用されています。SteerLM でのアライメントや報酬モデルの作成にご活用下さい。
NVIDIA Releases Open Synthetic Data Generation Pipeline for Training Large Language Models  
SteerLM での LLM トレーニング方法については以下の URL を参考にして下さい。  

Announcing NVIDIA SteerLM : https://developer.nvidia.com/blog/announcing-steerlm-a-simple-and-practical-technique-to-customize-llms-during-inference
NeMo Aligner : https://github.com/NVIDIA/NeMo-Aligner… See the full description on the dataset page: https://huggingface.co/datasets/kunishou/HelpSteer2-20k-ja.",https://huggingface.co/datasets/kunishou/HelpSteer2-20k-ja,['ja'],[],['10K<n<100K']
sbintuitions/aio-extended-answers,sbintuitions,2024-06-21 08:15:23+00:00,2024-12-17 03:28:15+00:00,45,0,"['task_categories:question-answering', 'language:ja', 'license:cc-by-sa-4.0', 'size_categories:1K<n<10K', 'format:parquet', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","
	
		
		AIO with extended answers
	

AIO (AI王) is a Japanese quiz dataset.
This repository contains the validation set of Version 2.0, augmented with manually annotated valid answers for each question.
Source: AI王　〜クイズAI日本一決定戦〜

	
		
		Data Fields
	


qid (str): Unique identifier for each entry in the dataset.
competition (str): The name of the competition that the data was first created for.
timestamp (str): The timestamp when the data was created.
section (str): The split the data belongs… See the full description on the dataset page: https://huggingface.co/datasets/sbintuitions/aio-extended-answers.",https://huggingface.co/datasets/sbintuitions/aio-extended-answers,['ja'],['question-answering'],['1K<n<10K']
oshizo/ASRClustering-ja,oshizo,2024-06-22 12:12:34+00:00,2024-06-23 15:35:03+00:00,11,2,"['task_categories:text-classification', 'language:ja', 'license:apache-2.0', 'size_categories:1K<n<10K', 'format:parquet', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","埋め込みモデルの学習、評価のためのクラスタリングデータセットです。
numad/yuho-text-2023を整形して作成しました。元データの取得元であるEDINETの利用規約に基づきデータセットとして公開しております。
事業の内容を表すテキストとして、tagが""DescriptionOfBusinessTextBlock""のデータを抽出し、edinet_codeを使ってEDINETで使われている業種コードとの紐づけを行い、クラスラベルを付与しました。labelの割合を保ちつつ、ランダムにtrainとtestに分割しました。それぞれのsplitの件数は以下の通りです。

	
		
label
提出者業種
train
test


		
0
水産・農林業
8
3


1
鉱業
5
2


2
建設業
127
42


3
食料品
99
33


4
繊維製品
39
13


5
パルプ・紙
18
7


6
化学
162
54


7
医薬品
60
20


8
石油・石炭製品
7
3


9
ゴム製品
14
5


10
ガラス・土石製品
45
15


11
鉄鋼
33
10… See the full description on the dataset page: https://huggingface.co/datasets/oshizo/ASRClustering-ja.",https://huggingface.co/datasets/oshizo/ASRClustering-ja,['ja'],['text-classification'],['1K<n<10K']
oshizo/LawClustering-ja,oshizo,2024-06-23 05:25:56+00:00,2024-06-23 15:35:15+00:00,9,1,"['task_categories:text-classification', 'language:ja', 'license:apache-2.0', 'size_categories:1K<n<10K', 'format:parquet', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","埋め込みモデルの学習、評価のためのクラスタリングデータセットです。
e-Govから収集したXMLデータを整形して作成しました。利用規約に基づき、データセットとして公開しております。
2024/6/22時点でダウンロードした11,111件のXMLファイルのうち、Eraタグが""Heisei""または""Reiwa""のデータ6,127件を抽出しました。
text列はLawTitleタグから取得した法令タイトルと、MainProvisionタグから取得した本文を結合したデータです。label列は、上記のURLの「法令分類データ」に基づく分類としています。labelの割合を保ちつつ、ランダムにtrainとtestに分割しました。それぞれのsplitの件数は以下の通りです。

	
		
label
分類
train
test


		
1
憲法
27
8


2
刑事
81
27


3
財務通則
9732


4
水産業
31
11


5
観光
32
11


6
国会
22
8


7
警察
94
31


8
国有財産
10
3


9
鉱業
9
3


10
郵務
23
8


11… See the full description on the dataset page: https://huggingface.co/datasets/oshizo/LawClustering-ja.",https://huggingface.co/datasets/oshizo/LawClustering-ja,['ja'],['text-classification'],['1K<n<10K']
AlienKevin/ndlbib-furigana,AlienKevin,2024-06-23 06:07:38+00:00,2024-06-23 10:08:55+00:00,8,1,"['task_categories:token-classification', 'language:ja', 'license:cc-by-4.0', 'size_categories:10M<n<100M', 'format:parquet', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","国立国会図書館の書誌データから作成した振り仮名のデータセット
A dataset of furigana characters created from bibliographic data from the National Diet Library.
Github Repo: https://github.com/ndl-lab/huriganacorpus-ndlbib
Download Source: https://lab.ndl.go.jp/dataset/huriganacorpus/shosi_dataset.zip
",https://huggingface.co/datasets/AlienKevin/ndlbib-furigana,['ja'],['token-classification'],['10M<n<100M']
Aratako/Synthetic-JP-Roleplay-Instruction-Nemotron-4-1k,Aratako,2024-06-23 08:28:26+00:00,2024-06-23 08:42:32+00:00,18,6,"['task_categories:text-generation', 'language:ja', 'license:apache-2.0', 'size_categories:1K<n<10K', 'format:json', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'arxiv:2406.08464', 'region:us', 'roleplay']","
	
		
		Synthetic-JP-Roleplay-Instruction-Nemotron-4
	

Magpieの手法をnvidia/Nemotron-4-340B-Instructに対して適用し作成した、約1000件の日本語ロールプレイ用のinstructionデータセットです。
データセットの作成にはDeepInfraを利用しました。
特に事後的なフィルタ処理は加えていないため、クオリティの低いレコードが含まれている可能性があります。ご注意ください。
",https://huggingface.co/datasets/Aratako/Synthetic-JP-Roleplay-Instruction-Nemotron-4-1k,['ja'],['text-generation'],['1K<n<10K']
oshizo/HSClustering-ja,oshizo,2024-06-23 12:46:05+00:00,2024-06-23 15:34:38+00:00,11,1,"['task_categories:text-classification', 'language:ja', 'license:apache-2.0', 'size_categories:1K<n<10K', 'format:parquet', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","埋め込みモデルの学習、評価のためのクラスタリングデータセットです。
税関の事前教示回答（品目分類）から収集したデータを整形して作成しました。利用規約に基づき、データセットとして公開しております。
2024/6/23時点でダウンロードしたデータから、「一般的品名」が重複しているデータを削除しました。text列は「一般的品名」と「貨物概要」を結合したデータです。label列は、HSコードの「部」に該当します。部の情報は関税率表解説・分類例規のページの一覧表から取得しました。labelの割合を保ちつつ、ランダムにtrainとtestに分割しました。それぞれのsplitの件数は以下の通りです。

	
		
label
train
test


		
1
150
51


2
214
71


3
32
11
4
576
192


5
27
9


6
308
102


7
246
82


8
46
16


9
67
22


10
30
10


11
304
101


12
66
22


13
45
15


14
14
5


15
149
50


16
138
45… See the full description on the dataset page: https://huggingface.co/datasets/oshizo/HSClustering-ja.",https://huggingface.co/datasets/oshizo/HSClustering-ja,['ja'],['text-classification'],['1K<n<10K']
oshizo/JMDNClustering-ja,oshizo,2024-06-23 15:17:04+00:00,2024-06-23 15:35:29+00:00,9,1,"['task_categories:text-classification', 'language:ja', 'license:apache-2.0', 'size_categories:1K<n<10K', 'format:parquet', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","埋め込みモデルの学習、評価のためのクラスタリングデータセットです。
独立行政法人医薬品医療機器総合機構のウェブサイトのページから取得したデータを整形して作成しました。利用規約に基づき、出展を明示してデータセットとして公開しております。
2024/6/22時点でダウンロードしたデータから「類別コード」が空欄のデータを削除しました。text列は「一般的名称」と「一般的名称定義」を結合したデータです。label列は「類別コード」に該当します。labelの割合を保ちつつ、ランダムにtrainとtestに分割しました。それぞれのsplitの件数は以下の通りです。

	
		
label
類別
train
test


		
0
プ01
131
43


1
プ02
14
5


2
医01
5
2


3
医02
20
7


4
医03
6
2


5
医04
257
85


6
医05
8
3


7
医06
9
3


8
器01
28
10


9
器02
14
5


10
器03
24
8


11
器04
1
0


12
器05
22
7


13
器06
65
22… See the full description on the dataset page: https://huggingface.co/datasets/oshizo/JMDNClustering-ja.",https://huggingface.co/datasets/oshizo/JMDNClustering-ja,['ja'],['text-classification'],['1K<n<10K']
HachiML/Timeseries-QA,HachiML,2024-06-23 23:22:57+00:00,2024-06-25 02:09:56+00:00,15,4,"['task_categories:text-generation', 'task_categories:time-series-forecasting', 'language:en', 'language:ja', 'license:mit', 'size_categories:100K<n<1M', 'format:parquet', 'modality:tabular', 'modality:text', 'library:datasets', 'library:dask', 'library:mlcroissant', 'library:polars', 'region:us', 'time-series', 'Timeseries Instruction Tuning', 'synthetic']","
	
		
		Timeseries-QA
	



This is a dataset for Timeseries Instruction Tuning.
It was created using the following steps:

Extracted features from time series data in AutonLab/Timeseries-PILE
microsoft/Phi-3-medium-4k-instruct generated the QA pairs

Timeseries Instruction Tuning用のデータセットです。
以下の手順で作成しました。

AutonLab/Timeseries-PILE　の時系列データの特徴を抽出
microsoft/Phi-3-medium-4k-instruct がQAを作成


	
	
	
		Dataset Details
	


	
	
	
		Dataset Description
	




Curated by: HachiMLLanguage(s) (NLP): English… See the full description on the dataset page: https://huggingface.co/datasets/HachiML/Timeseries-QA.",https://huggingface.co/datasets/HachiML/Timeseries-QA,"['en', 'ja']","['text-generation', 'time-series-forecasting']",['100K<n<1M']
ryota39/open_preference-v0.3,ryota39,2024-06-25 08:55:53+00:00,2024-07-04 12:55:42+00:00,11,0,"['language:ja', 'license:cc-by-4.0', 'size_categories:10K<n<100K', 'format:json', 'modality:tabular', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","
	
		
		description
	


public RLHF dataset in Japanese
the construction of the reward model was reformatted into a classification task.
Quality of Japanese text is middle arise from the synthetic generated sentences by Phi-3-medium(14B)


	
		
		details
	


reformatted version of this dataset
label 1 stands for chosen sentence.
label 0 stands for rejected sentence.

",https://huggingface.co/datasets/ryota39/open_preference-v0.3,['ja'],[],['10K<n<100K']
aiana94/xMINDlarge,aiana94,2024-06-25 11:54:02+00:00,2024-10-25 08:29:52+00:00,119,4,"['task_categories:translation', 'task_categories:text-retrieval', 'multilinguality:translation', 'multilinguality:multilingual', 'multilinguality:multi-parallel', 'source_datasets:MIND', 'language:fi', 'language:gn', 'language:ht', 'language:id', 'language:ja', 'language:ka', 'language:ro', 'language:so', 'language:sw', 'language:ta', 'language:th', 'language:tr', 'language:vi', 'language:zh', 'license:cc-by-nc-sa-4.0', 'size_categories:1M<n<10M', 'format:parquet', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'arxiv:2403.17876', 'region:us', 'news', 'multilingual', 'machine-translated', 'nllb']","
	
		
		Dataset Card for xMINDlarge
	


	
		
		Dataset Summary
	

xMINDlarge is an open, large-scale multi-parallel news dataset for multi- and cross-lingual news recommendation. 
It is derived from the English MINDlarge dataset using open-source neural machine translation (i.e., NLLB 3.3B).
For the small version of the dataset, see xMINDsmall.

	
		
	
	
		Uses
	

This dataset can be used for machine translation, text retrieval, or as a benchmark dataset for news recommendation.… See the full description on the dataset page: https://huggingface.co/datasets/aiana94/xMINDlarge.",https://huggingface.co/datasets/aiana94/xMINDlarge,"['fi', 'gn', 'ht', 'id', 'ja', 'ka', 'ro', 'so', 'sw', 'ta', 'th', 'tr', 'vi', 'zh']","['translation', 'text-retrieval']",['1M<n<10M']
sbintuitions/JEMHopQA,sbintuitions,2024-06-25 16:26:47+00:00,2025-04-21 02:54:40+00:00,361,3,"['task_categories:question-answering', 'language:ja', 'license:cc-by-sa-4.0', 'size_categories:1K<n<10K', 'format:parquet', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","評価スコアの再現性確保と SB Intuitions 修正版の公開用クローン
ソース: aiishii/JEMHopQA on GitHub

	
		
		JEMHopQA
	


JEMHopQA (Japanese Explainable Multi-hop Question Answering)は、回答導出ステップの情報付きの日本語の根拠情報付きマルチホップQAデータセットです。質問 (Question)を入力として、回答 (Answer)と導出 (Derivation)を生成するタスクです。導出は導出ステップの集合で、半構造化されたエンティティ間の関係表現です。問題は、Wikipediaの２つの記事の情報をリンクさせて答える構成問題 (compositional)と2つの記事の情報を比較して答える比較問題 (comparison)が含まれています。


	
		
		Licensing Information
	

Creative Commons Attribution Share Alike 4.0 International

	
		
		Citation… See the full description on the dataset page: https://huggingface.co/datasets/sbintuitions/JEMHopQA.",https://huggingface.co/datasets/sbintuitions/JEMHopQA,['ja'],['question-answering'],['1K<n<10K']
llm-book/ja-vicuna-qa-benchmark,llm-book,2024-06-25 22:14:55+00:00,2024-08-31 12:37:25+00:00,28,0,"['task_categories:text-generation', 'language:ja', 'license:apache-2.0', 'size_categories:n<1K', 'format:parquet', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","
	
		
		Dataset Card for llm-book/ja-vicuna-qa-benchmark
	

書籍『大規模言語モデル入門Ⅱ〜生成型LLMの実装と評価』で使用する、京都大学が提供する「Japanese Vicuna QA Benchmark」のデータセットです。 
オリジナルのサイトと同じものを使用しています。
本データセットは、10のカテゴリー(汎用、コーディング、ロールプレイ、ライティングなど)にわたる80の多様な質問で構成されており、LLM-as-a-judgeを使用して、参照なしで日本語LLMモデルの回答を評価することができます。

	
		
		Licence
	

Apache License, Version 2.0
",https://huggingface.co/datasets/llm-book/ja-vicuna-qa-benchmark,['ja'],['text-generation'],['n<1K']
joujiboi/japanese-anime-speech-v2,joujiboi,2024-06-26 14:18:01+00:00,2025-05-25 17:46:49+00:00,1058,116,"['task_categories:automatic-speech-recognition', 'language:ja', 'license:gpl', 'size_categories:100K<n<1M', 'format:parquet', 'modality:audio', 'modality:text', 'library:datasets', 'library:dask', 'library:mlcroissant', 'library:polars', 'region:us', 'japanese', 'anime', 'speech', '日本語', 'audio-text', 'asr', 'whisper', 'voice']","
	
		
		Japanese Anime Speech Dataset V2
	

日本語はこちら
japanese-anime-speech-v2 is an audio-text dataset designed for training automatic speech recognition models.
The dataset comprises 292,637 audio clips and their corresponding transcriptions from various visual novels.
This dataset is not an expanded version of japanese-anime-speech-v1.
For that reason, much of the audio from japanese-anime-speech-v1 is not included in this dataset.
The goal of this dataset is to increase the accuracy of… See the full description on the dataset page: https://huggingface.co/datasets/joujiboi/japanese-anime-speech-v2.",https://huggingface.co/datasets/joujiboi/japanese-anime-speech-v2,['ja'],['automatic-speech-recognition'],['100K<n<1M']
TangRain/SingMOS-preview,TangRain,2024-06-26 14:22:52+00:00,2025-10-02 07:04:08+00:00,20,0,"['language:zh', 'language:ja', 'license:cc-by-4.0', 'size_categories:100M<n<1B', 'arxiv:2406.10911', 'region:us', 'singing', 'MOS']","paper link: SingMOS: An extensive Open-Source Singing Voice Dataset for MOS Prediction


	
		
		Overview
	

SingMOS-v1 (the preview version of SingMOS-Pro) includes 3,421 Chinese and Japanese vocal clips with a sample rate of 16 kHz, totaling 4.25 hours in duration.

	
		
		SingMOS arichitecture
	

|---SingMOS-v1
    |---sets
        |---train.txt
        |---dev.txt
        |---test-main.txt
        |---test-other1.txt
    |---wav
        |---sys0001-utt0001.wav
        ...… See the full description on the dataset page: https://huggingface.co/datasets/TangRain/SingMOS-preview.",https://huggingface.co/datasets/TangRain/SingMOS-preview,"['zh', 'ja']",[],['100M<n<1B']
qgyd2021/cc_audio_8,qgyd2021,2024-06-28 06:34:11+00:00,2024-06-28 09:54:18+00:00,21,0,"['language:zh', 'language:en', 'language:es', 'language:ko', 'language:ja', 'license:apache-2.0', 'size_categories:100M<n<1B', 'modality:audio', 'region:us']","
	
		
		国际语音,电话场景中的声音分类
	

",https://huggingface.co/datasets/qgyd2021/cc_audio_8,"['zh', 'en', 'es', 'ko', 'ja']",[],['100M<n<1B']
izhx/xtreme-r-udpos,izhx,2024-06-28 07:46:47+00:00,2024-06-28 12:50:37+00:00,118,1,"['task_categories:token-classification', 'task_ids:part-of-speech', 'annotations_creators:found', 'language_creators:found', 'multilinguality:multilingual', 'multilinguality:translation', 'language:af', 'language:ar', 'language:bg', 'language:bn', 'language:de', 'language:el', 'language:en', 'language:es', 'language:et', 'language:eu', 'language:fa', 'language:fi', 'language:fr', 'language:he', 'language:hi', 'language:hu', 'language:id', 'language:it', 'language:ja', 'language:jv', 'language:ka', 'language:kk', 'language:ko', 'language:ml', 'language:mr', 'language:ms', 'language:my', 'language:nl', 'language:pt', 'language:ru', 'language:sw', 'language:ta', 'language:te', 'language:th', 'language:tl', 'language:tr', 'language:ur', 'language:vi', 'language:yo', 'language:zh', 'license:other', 'size_categories:100K<n<1M', 'format:parquet', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'arxiv:2104.07412', 'region:us']","
	
		
		UDPOS of XTREME-R
	

Generated by build_parquet.py
XTREME-R: Towards More Challenging and Nuanced Multilingual Evaluation
https://arxiv.org/abs/2104.07412
",https://huggingface.co/datasets/izhx/xtreme-r-udpos,"['af', 'ar', 'bg', 'bn', 'de', 'el', 'en', 'es', 'et', 'eu', 'fa', 'fi', 'fr', 'he', 'hi', 'hu', 'id', 'it', 'ja', 'jv', 'ka', 'kk', 'ko', 'ml', 'mr', 'ms', 'my', 'nl', 'pt', 'ru', 'sw', 'ta', 'te', 'th', 'tl', 'tr', 'ur', 'vi', 'yo', 'zh']",['token-classification'],['100K<n<1M']
neody/kusanagi,neody,2024-06-28 14:00:10+00:00,2024-07-08 22:57:44+00:00,180,1,"['language:ja', 'size_categories:100M<n<1B', 'format:parquet', 'modality:text', 'library:datasets', 'library:dask', 'library:mlcroissant', 'library:polars', 'region:us']",,https://huggingface.co/datasets/neody/kusanagi,['ja'],[],['100M<n<1B']
stanford-oval/wikipedia_20240401_10-languages_bge-m3_qdrant_index,stanford-oval,2024-06-28 21:06:25+00:00,2024-08-24 04:43:16+00:00,1290,0,"['task_categories:text-retrieval', 'language:en', 'language:de', 'language:it', 'language:fa', 'language:ru', 'language:zh', 'language:pt', 'language:fr', 'language:es', 'language:ja', 'size_categories:100M<n<1B', 'arxiv:2305.14292', 'arxiv:2406.00562', 'region:us']","This repository contains a Qdrant index created from preprocessed and chunked Wikipedia HTML dumps from 10 languages. The embedding model used is BAAI/bge-m3
This index is compatible with WikiChat v2.0.
Refer to the following for more information:
GitHub repository: https://github.com/stanford-oval/WikiChat
Papers:

WikiChat: Stopping the Hallucination of Large Language Model Chatbots by Few-Shot Grounding on Wikipedia
SPAGHETTI: Open-Domain Question Answering from Heterogeneous Data Sources… See the full description on the dataset page: https://huggingface.co/datasets/stanford-oval/wikipedia_20240401_10-languages_bge-m3_qdrant_index.",https://huggingface.co/datasets/stanford-oval/wikipedia_20240401_10-languages_bge-m3_qdrant_index,"['en', 'de', 'it', 'fa', 'ru', 'zh', 'pt', 'fr', 'es', 'ja']",['text-retrieval'],['100M<n<1B']
sbintuitions/niilc-qa,sbintuitions,2024-06-29 04:02:35+00:00,2025-01-22 06:44:39+00:00,26,0,"['task_categories:question-answering', 'language:ja', 'license:cc-by-sa-4.0', 'size_categories:1K<n<10K', 'format:parquet', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","評価スコアの再現性確保と SB Intuitions 修正版の公開用クローン

ソース: mynlp/niilc-qa on GitHub


	
		
		NIILC Question Answering Dataset
	


This project provides a dataset for supporting the development of question answering systems. The data includes questions and their answers, and meta information such as question types, clues to obtain answers, Wikipedia pages in which answers can be found, and SPARQL queries for JWO (Japanese Wikipedia Ontology).


Homepage:
日本語:… See the full description on the dataset page: https://huggingface.co/datasets/sbintuitions/niilc-qa.",https://huggingface.co/datasets/sbintuitions/niilc-qa,['ja'],['question-answering'],['1K<n<10K']
neody/amazon-reviews-label-ja,neody,2024-06-29 07:31:36+00:00,2024-07-06 08:30:16+00:00,7,1,"['language:ja', 'size_categories:100K<n<1M', 'format:parquet', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']",,https://huggingface.co/datasets/neody/amazon-reviews-label-ja,['ja'],[],['100K<n<1M']
iryneko571/CCMatrix-v1-Ja_Zh-fused,iryneko571,2024-07-01 07:50:25+00:00,2024-07-01 10:10:46+00:00,14,2,"['task_categories:translation', 'language:ja', 'language:zh', 'license:unknown', 'size_categories:100K<n<1M', 'format:arrow', 'modality:text', 'library:datasets', 'library:mlcroissant', 'region:us']","
	
		
		Derived from larryvrh/CCMatrix-v1-Ja_Zh-filtered
	

Made some changes to the dataset to train the new mt5-base model

since it's all from the community anyway so i disclose this.
putting lora adapters isn't sufficient to solve old and general habits


	
		
		weakness of the translation model
	


translation stops or repeats after 30 words, and doesnt recognize line breaks
the dataset generally too short, 83% below 50 words
solution: fused some sentenses with "" "",""。"" or line breaks to… See the full description on the dataset page: https://huggingface.co/datasets/iryneko571/CCMatrix-v1-Ja_Zh-fused.",https://huggingface.co/datasets/iryneko571/CCMatrix-v1-Ja_Zh-fused,"['ja', 'zh']",['translation'],['100K<n<1M']
lesserfield/translate-en-ja-id,lesserfield,2024-07-01 23:00:58+00:00,2024-07-12 19:46:31+00:00,6,1,"['task_categories:translation', 'language:en', 'language:ja', 'language:id', 'license:cc-by-nc-nd-4.0', 'size_categories:100K<n<1M', 'format:json', 'modality:text', 'library:datasets', 'library:dask', 'library:mlcroissant', 'region:us']",,https://huggingface.co/datasets/lesserfield/translate-en-ja-id,"['en', 'ja', 'id']",['translation'],['100K<n<1M']
kenu/hf-first,kenu,2024-07-02 07:10:31+00:00,2024-07-02 07:37:08+00:00,13,0,"['task_categories:text-generation', 'language:zh', 'language:ko', 'language:ja', 'license:mit', 'size_categories:n<1K', 'format:csv', 'modality:tabular', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']",,https://huggingface.co/datasets/kenu/hf-first,"['zh', 'ko', 'ja']",['text-generation'],['n<1K']
amphion/Emilia,amphion,2024-07-02 08:49:26+00:00,2025-09-03 16:32:12+00:00,116,85,"['task_categories:text-to-speech', 'language:zh', 'language:en', 'language:ja', 'language:ko', 'language:de', 'language:fr', 'license:cc-by-nc-4.0', 'region:us']","
	
		
		Emilia: An Extensive, Multilingual, and Diverse Speech Dataset for Large-Scale Speech Generation
	

The Emilia dataset is the first open-source, multilingual, in-the-wild dataset designed for speech generation. It offers over 101,000 hours of high-quality speech data across six languages: Chinese (zh), English (en), Japanese (ja), Korean (ko), German (de), and French (fr). The dataset includes various speaking styles and their corresponding transcriptions.

	
		
	
	
		README… See the full description on the dataset page: https://huggingface.co/datasets/amphion/Emilia.",https://huggingface.co/datasets/amphion/Emilia,"['zh', 'en', 'ja', 'ko', 'de', 'fr']",['text-to-speech'],[]
kenu/assembly,kenu,2024-07-02 12:53:44+00:00,2024-07-02 13:07:46+00:00,10,0,"['task_categories:text-generation', 'language:en', 'language:ja', 'language:zh', 'license:mit', 'region:us']",,https://huggingface.co/datasets/kenu/assembly,"['en', 'ja', 'zh']",['text-generation'],[]
kanhatakeyama/CreativeCommons-RAG-QA-Mixtral8x22b,kanhatakeyama,2024-07-03 07:54:49+00:00,2024-07-12 06:43:18+00:00,15,0,"['language:ja', 'license:cc-by-sa-3.0', 'size_categories:1M<n<10M', 'format:json', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","
以下のデータ源からランダムに抽出した日本語のテキストをもとに､RAG形式のQ&Aを自動生成したものです｡

Wikibooks
Wikipedia
判例データ
instruction datasetとしてではなく､事前学習での利用を想定しています(質疑応答をするための訓練)｡
一部の計算には東京工業大学のスーパーコンピュータTSUBAME4.0を利用しました｡

",https://huggingface.co/datasets/kanhatakeyama/CreativeCommons-RAG-QA-Mixtral8x22b,['ja'],[],['1M<n<10M']
Aratako/Synthetic-JP-10-Turns-Roleplay-Dialogues-Nemotron-4-1k,Aratako,2024-07-03 13:21:22+00:00,2024-07-03 13:53:20+00:00,22,3,"['task_categories:text-generation', 'language:ja', 'license:apache-2.0', 'size_categories:1K<n<10K', 'format:json', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'arxiv:2406.08464', 'region:us', 'roleplay']","
	
		
		Synthetic-JP-10-Turns-Roleplay-Dialogues-Nemotron-4-1k
	

nvidia/Nemotron-4-340B-Instructを用いて作成した、約1000件・各10ターンの日本語ロールプレイの対話を収録した合成対話データセットです。
Magpieの手法を用いて作成した合成instructionデータセットであるAratako/Synthetic-JP-Roleplay-Instruction-Nemotron-4-1kを元に、同じくMagpieの手法を使い続きの対話を生成させています。
Nemotron-4の利用にはDeepInfraを利用しました。
特に事後的なフィルタ処理は加えていないため、クオリティの低いレコードが含まれている可能性があります。ご注意ください。
また、一部のデータを見る限り、長いターンの対話の際途中でロールプレイを終了させようとする傾向があるように見えます。5ターンまで使うなど、利用するデータを絞ったほうが良いかもしれません。
",https://huggingface.co/datasets/Aratako/Synthetic-JP-10-Turns-Roleplay-Dialogues-Nemotron-4-1k,['ja'],['text-generation'],['1K<n<10K']
toramaru-u/cc100-ja,toramaru-u,2024-07-05 05:00:50+00:00,2025-10-08 11:28:04+00:00,40,2,"['language:ja', 'size_categories:100M<n<1B', 'format:parquet', 'modality:tabular', 'modality:text', 'library:datasets', 'library:dask', 'library:mlcroissant', 'library:polars', 'region:us']",,https://huggingface.co/datasets/toramaru-u/cc100-ja,['ja'],[],['100M<n<1B']
Aratako/Synthetic-JP-Conversations-Magpie-Nemotron-4-10k,Aratako,2024-07-05 13:53:44+00:00,2024-07-05 13:57:08+00:00,33,11,"['task_categories:text-generation', 'language:ja', 'license:apache-2.0', 'size_categories:10K<n<100K', 'format:json', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'arxiv:2406.08464', 'region:us']","
	
		
		Synthetic-JP-Conversations-Magpie-Nemotron-4-10k
	

Magpieの手法をnvidia/Nemotron-4-340B-Instructに対して適用し作成した、約10000件の日本語instruction tuning用データセットです。
データセットの作成にはDeepInfraを利用しました。
また、このリポジトリでデータセット作成に用いたコードを公開しています。
特に事後的なフィルタ処理は加えていないため、クオリティの低いレコードが含まれている可能性があります。ご注意ください。
",https://huggingface.co/datasets/Aratako/Synthetic-JP-Conversations-Magpie-Nemotron-4-10k,['ja'],['text-generation'],['10K<n<100K']
Aratako/Synthetic-JP-Coding-Dataset-Magpie-Nemotron-4-10k,Aratako,2024-07-06 06:53:27+00:00,2024-07-06 06:57:57+00:00,16,0,"['task_categories:text-generation', 'language:ja', 'license:apache-2.0', 'size_categories:10K<n<100K', 'format:json', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'arxiv:2406.08464', 'region:us', 'code']","
	
		
		Synthetic-JP-Coding-Dataset-Magpie-Nemotron-4-10k
	

Magpieの手法をnvidia/Nemotron-4-340B-Instructに対して適用し作成した、約10000件の日本語のコーディング用対話データセットです。
データセットの作成にはDeepInfraを利用しました。
また、このリポジトリでデータセット作成に用いたコードを公開しています。これをベースに、システムプロンプトとstopを一部変更することで生成しています。
特に事後的なフィルタ処理は加えていないため、クオリティの低いレコードが含まれている可能性があります。ご注意ください。
",https://huggingface.co/datasets/Aratako/Synthetic-JP-Coding-Dataset-Magpie-Nemotron-4-10k,['ja'],['text-generation'],['10K<n<100K']
TaiMingLu/Multilingual-Benchmark,TaiMingLu,2024-07-06 18:24:12+00:00,2024-12-01 06:22:38+00:00,92,2,"['task_categories:zero-shot-classification', 'task_categories:question-answering', 'task_categories:translation', 'language:en', 'language:de', 'language:nl', 'language:fr', 'language:es', 'language:it', 'language:pt', 'language:ru', 'language:zh', 'language:ja', 'language:ko', 'language:tr', 'language:ar', 'language:pl', 'language:hi', 'language:th', 'language:sw', 'language:ha', 'language:ur', 'language:af', 'language:id', 'language:uk', 'language:el', 'language:lv', 'language:cy', 'language:is', 'language:bn', 'language:ne', 'language:pa', 'language:mr', 'language:te', 'license:apache-2.0', 'size_categories:1M<n<10M', 'format:json', 'modality:tabular', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'arxiv:2406.13748', 'region:us', 'synthetic', 'text', 'math', 'reasoning', 'instruction']","These are the GSM8K and ARC dataset translated by Google Translate. 
BibTex
@misc{lu2024languagecountslearnunlearn,
      title={Every Language Counts: Learn and Unlearn in Multilingual LLMs}, 
      author={Taiming Lu and Philipp Koehn},
      year={2024},
      eprint={2406.13748},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2406.13748}, 
}

",https://huggingface.co/datasets/TaiMingLu/Multilingual-Benchmark,"['en', 'de', 'nl', 'fr', 'es', 'it', 'pt', 'ru', 'zh', 'ja', 'ko', 'tr', 'ar', 'pl', 'hi', 'th', 'sw', 'ha', 'ur', 'af', 'id', 'uk', 'el', 'lv', 'cy', 'is', 'bn', 'ne', 'pa', 'mr', 'te']","['zero-shot-classification', 'question-answering', 'translation']",['1M<n<10M']
isek-ai/danbooru-wiki-2024,isek-ai,2024-07-07 05:28:47+00:00,2024-11-15 04:33:40+00:00,175,25,"['task_categories:text-generation', 'task_categories:text-classification', 'language:en', 'language:ja', 'license:cc-by-sa-4.0', 'size_categories:100K<n<1M', 'format:parquet', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","
	
		
		danbooru-wiki-2024
	


	
		
		About
	

Wiki pages about the danbooru tags on danbooru.donmai.us. The wiki contains the description of each tag and matching to pixiv tags.

	
		
		Usage
	

from datasets import load_dataset

ds = load_dataset(
  ""isek-ai/danbooru-wiki-2024"",
# revision=""202408-at20240906"", # optional
  split=""train"",
)

The revision name is as same as isek-ai/danbooru-tags-2024's.

[!WARNING]
Note:
This dataset would be irreguraly updated, if you want to use the same… See the full description on the dataset page: https://huggingface.co/datasets/isek-ai/danbooru-wiki-2024.",https://huggingface.co/datasets/isek-ai/danbooru-wiki-2024,"['en', 'ja']","['text-generation', 'text-classification']",['100K<n<1M']
Aratako/Synthetic-JP-EN-Translation-Dataset-Magpie-Nemotron-4-20k,Aratako,2024-07-07 11:08:34+00:00,2024-07-07 11:13:47+00:00,18,5,"['task_categories:text-generation', 'language:ja', 'license:apache-2.0', 'size_categories:10K<n<100K', 'format:json', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'arxiv:2406.08464', 'region:us', 'translation']","
	
		
		Synthetic-JP-EN-Translation-Dataset-Magpie-Nemotron-4-20k
	

Magpieの手法をnvidia/Nemotron-4-340B-Instructに対して適用し作成した、20000件の日⇔英翻訳データセットです。
データセットの作成にはDeepInfraを利用しました。
また、このリポジトリでデータセット作成に用いたコードを公開しています。これをベースに、システムプロンプトとstopを一部変更することで生成しています。
特に事後的なフィルタ処理は加えていないため、クオリティの低いレコードが含まれている可能性があります。ご注意ください。
",https://huggingface.co/datasets/Aratako/Synthetic-JP-EN-Translation-Dataset-Magpie-Nemotron-4-20k,['ja'],['text-generation'],['10K<n<100K']
yamamuchiiii/idkman2,yamamuchiiii,2024-07-08 07:45:55+00:00,2024-07-22 14:33:28+00:00,6,0,"['task_categories:text-classification', 'task_categories:text-generation', 'language:en', 'language:ja', 'region:us']","
	
		
		Your Dataset Name
	

This is an updated README for your dataset. You can provide a description of your dataset here, as well as any other relevant information.
",https://huggingface.co/datasets/yamamuchiiii/idkman2,"['en', 'ja']","['text-classification', 'text-generation']",[]
neody/nwc2010-cleaned,neody,2024-07-08 09:48:05+00:00,2024-07-10 08:12:25+00:00,18,2,"['language:ja', 'size_categories:10M<n<100M', 'format:parquet', 'modality:text', 'library:datasets', 'library:dask', 'library:mlcroissant', 'library:polars', 'region:us']",,https://huggingface.co/datasets/neody/nwc2010-cleaned,['ja'],[],['10M<n<100M']
quchenyuan/360x_dataset_HR,quchenyuan,2024-07-09 09:19:18+00:00,2025-01-06 14:30:25+00:00,117,7,"['language:en', 'language:zh', 'language:fr', 'language:ja', 'language:es', 'license:cc-by-nc-sa-4.0', 'arxiv:2404.00989', 'region:us', 'Multimedia', 'Panoramic', 'Video', 'Multi-viewpoint']","
	
		
		360+x Dataset
	

For more information, please feel free to check our project page.

	
		
		Overview
	

360+x dataset introduces a unique panoptic perspective to scene understanding, differentiating itself from traditional
datasets by offering multiple viewpoints and modalities, captured from a variety of scenes

	
		
		Key Features:
	


Multi-viewpoint Captures: Includes 360° panoramic video, third-person front view video, egocentric monocular
video, and egocentric binocular video.… See the full description on the dataset page: https://huggingface.co/datasets/quchenyuan/360x_dataset_HR.",https://huggingface.co/datasets/quchenyuan/360x_dataset_HR,"['en', 'zh', 'fr', 'ja', 'es']",[],[]
Kendamarron/jimba-wiki-instruction-calm3,Kendamarron,2024-07-09 22:18:35+00:00,2024-07-20 12:57:05+00:00,16,0,"['task_categories:text-generation', 'language:ja', 'license:cc-by-sa-3.0', 'size_categories:10K<n<100K', 'format:parquet', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us', 'synthetic']","
	
		
		Kendamarron/jimba-wiki-instruction-calm3
	

grapevine-AI/CALM3-22B-Chat-GGUFのQ4_K_Mを使った合成instructionデータセットです。

RAGのように文章を参照しながら回答しているため比較的ハルシネーションは少ないですが、一部、ハルシネーションが含まれていることを確認しています。ご利用の際はご注意ください。
生成後のフィルタリングは行っていないため、instructionの後にそのままoutputが生成されているレコードなどが含まれています。


	
		
		作成手順
	


Kendamarron/jimba-instuction-1k-betaのinstruction3つのサンプルとして与えた上で、izumi-lab/wikipedia-ja-20230720のtextに関するinstructionを生成
生成したinstructionと元々のtextを与え、outputを生成


	
		
		使い方
	

from datasets import load_dataset… See the full description on the dataset page: https://huggingface.co/datasets/Kendamarron/jimba-wiki-instruction-calm3.",https://huggingface.co/datasets/Kendamarron/jimba-wiki-instruction-calm3,['ja'],['text-generation'],['10K<n<100K']
Youseff1987/multilingual-sentiment-dataset,Youseff1987,2024-07-10 06:00:18+00:00,2024-07-10 12:53:31+00:00,72,3,"['task_categories:text-classification', 'language:ko', 'language:ja', 'language:en', 'language:de', 'language:es', 'language:fr', 'language:zh', 'license:mit', 'size_categories:1M<n<10M', 'format:parquet', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","
	
		
		Dataset Card for Dataset Name
	



This dataset card aims to be a base template for new datasets. It has been generated using this raw template.

	
		
		Dataset Details
	


	
		
		Dataset Description
	






Curated by: [More Information Needed]
Funded by [optional]: [More Information Needed]
Shared by [optional]: [More Information Needed]
Language(s) (NLP): [More Information Needed]
License: [More Information Needed]


	
		
		Dataset Sources [optional]
	




Repository:
Blpeng/nsmc… See the full description on the dataset page: https://huggingface.co/datasets/Youseff1987/multilingual-sentiment-dataset.",https://huggingface.co/datasets/Youseff1987/multilingual-sentiment-dataset,"['ko', 'ja', 'en', 'de', 'es', 'fr', 'zh']",['text-classification'],['1M<n<10M']
hpprc/auto-wikinews-qa,hpprc,2024-07-10 06:29:59+00:00,2024-07-10 06:39:53+00:00,8,0,"['task_categories:question-answering', 'language:ja', 'license:cc-by-sa-4.0', 'size_categories:1K<n<10K', 'format:parquet', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']",,https://huggingface.co/datasets/hpprc/auto-wikinews-qa,['ja'],['question-answering'],['1K<n<10K']
karakuri-ai/corrected-mt-bench-ja,karakuri-ai,2024-07-11 06:25:14+00:00,2024-07-11 12:47:19+00:00,25,1,"['task_categories:text-generation', 'language:ja', 'license:apache-2.0', 'size_categories:n<1K', 'format:parquet', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","
	
		
		Corrected MT-Bench-ja
	

Inflection AIによるCorrected MT-Benchの日本語訳です。
一部の設問はStability AIによるJapanese MT-Benchを使用しています。
",https://huggingface.co/datasets/karakuri-ai/corrected-mt-bench-ja,['ja'],['text-generation'],['n<1K']
Aratako/Synthetic-JP-EN-Coding-Dataset-Magpie-69k,Aratako,2024-07-11 10:19:45+00:00,2024-07-11 12:07:01+00:00,36,9,"['task_categories:text-generation', 'language:ja', 'license:apache-2.0', 'size_categories:10K<n<100K', 'format:json', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'arxiv:2406.08464', 'region:us', 'code']","
	
		
		Synthetic-JP-EN-Coding-Dataset-Magpie-69k
	

Magpieの手法を様々なモデルに対して適用し作成した、約69000件の日本語・英語のコーディング対話データセットです。
作成に利用したモデルは以下の通りです。modelキーに該当レコードの作成に利用したモデル情報があります。

nvidia/Nemotron-4-340B-Instruct
microsoft/Phi-3-medium-4k-instruct
mistralai/Mixtral-8x22B-Instruct-v0.1
cyberagent/calm3-22b-chat

データセットの作成にはDeepInfraを利用しました。
また、このリポジトリでデータセット作成に用いたコードを公開しています。これをベースに、プロンプトテンプレートやシステムプロンプト等を一部変更することで生成しています。特に事後的なフィルタ処理は加えていないため、クオリティの低いレコードが含まれている可能性があります。ご注意ください。
",https://huggingface.co/datasets/Aratako/Synthetic-JP-EN-Coding-Dataset-Magpie-69k,['ja'],['text-generation'],['10K<n<100K']
hotchpotch/cc100-ja-documents,hotchpotch,2024-07-11 22:26:16+00:00,2024-07-13 12:02:11+00:00,269,3,"['language:ja', 'size_categories:10M<n<100M', 'format:parquet', 'modality:text', 'library:datasets', 'library:dask', 'library:mlcroissant', 'library:polars', 'region:us']","
	
		
		cc100-ja-documents
	

HuggingFace で公開されている cc100 / cc100-ja  は line 単位の分割のため、document 単位に結合したものです。
ライセンスはオリジナルのcc100 に準拠します。
",https://huggingface.co/datasets/hotchpotch/cc100-ja-documents,['ja'],[],['10M<n<100M']
coastalcph/tydi_xor_rc,coastalcph,2024-07-12 12:03:01+00:00,2025-09-09 07:53:16+00:00,4498,0,"['task_categories:question-answering', 'task_ids:extractive-qa', 'annotations_creators:crowdsourced', 'language_creators:crowdsourced', 'multilinguality:multilingual', 'source_datasets:extended|wikipedia', 'language:en', 'language:ar', 'language:bn', 'language:fi', 'language:ja', 'language:ko', 'language:ru', 'language:te', 'license:mit', 'size_categories:10K<n<100K', 'format:parquet', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","
	
		
		Dataset Card for ""tydi_xor_rc""
	


	
		
		Dataset Summary
	

TyDi QA is a question answering dataset covering 11 typologically diverse languages. 
XORQA is an extension of the original TyDi QA dataset to also include unanswerable questions, where context documents are only in English but questions are in 7 languages.
XOR-AttriQA contains annotated attribution data for a sample of XORQA.
This dataset is a combined and simplified version of the Reading Comprehension data from XORQA and… See the full description on the dataset page: https://huggingface.co/datasets/coastalcph/tydi_xor_rc.",https://huggingface.co/datasets/coastalcph/tydi_xor_rc,"['en', 'ar', 'bn', 'fi', 'ja', 'ko', 'ru', 'te']",['question-answering'],['10K<n<100K']
sarulab-speech/J-CHAT,sarulab-speech,2024-07-13 19:35:48+00:00,2025-02-09 11:09:13+00:00,101,31,"['language:ja', 'license:other', 'size_categories:1K<n<10K', 'format:text', 'modality:text', 'library:datasets', 'library:mlcroissant', 'arxiv:2407.15828', 'region:us']","J-CHAT is a Japanese large-scale dialogue speech corpus.
For the detailed explanation, please see our paper

	
		
		PLEASE READ THIS FIRST
	


[!IMPORTANT]
TO USE THIS DATASET, YOU MUST AGREE THAT YOU WILL USE THE DATASET SOLELY FOR THE PURPOSE OF JAPANESE COPYRIGHT ACT ARTICLE 30-4.


	
		
		What's new?
	


[!NOTE] 
Add transcription of corpus. transcripition are based on reazonspeech-nemo-v2


	
		
		How can I use this data for commercial purposes?
	

Commercial use is not admitted. If you… See the full description on the dataset page: https://huggingface.co/datasets/sarulab-speech/J-CHAT.",https://huggingface.co/datasets/sarulab-speech/J-CHAT,['ja'],[],['1K<n<10K']
1024m/mMGTD-Corpus,1024m,2024-07-14 02:25:42+00:00,2025-02-04 22:37:08+00:00,12,9,"['task_categories:token-classification', 'language:ar', 'language:cs', 'language:de', 'language:nl', 'language:en', 'language:zh', 'language:fa', 'language:fr', 'language:el', 'language:he', 'language:hi', 'language:id', 'language:it', 'language:ja', 'language:ko', 'language:pl', 'language:pt', 'language:ro', 'language:ru', 'language:es', 'language:tr', 'language:uk', 'language:vi', 'license:cc-by-nc-nd-4.0', 'size_categories:1M<n<10M', 'format:csv', 'modality:tabular', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'doi:10.57967/hf/3194', 'region:us', 'linguistics', 'MGT', 'AI text detection']","
	
		
		Dataset for Multilingual Machine-Generated Text Portion Detection
	


	
		
		Model Details
	

To be made Available by Feb 1, 2025Public Version available at :https://huggingface.co/datasets/1024m/MGTPD/

	
		
		Model Description
	


Developed by: 1-800-SHARED-TASKS
Funded by: Traversaal L.A.R.G.E Research Grant (Nov 2024) , and Cohere's Research Compute Grant (July 2024)(dataset creation for cohere's LLMs) 
Model type: Small Transformer-based for token-classification
Languages (NLP):… See the full description on the dataset page: https://huggingface.co/datasets/1024m/mMGTD-Corpus.",https://huggingface.co/datasets/1024m/mMGTD-Corpus,"['ar', 'cs', 'de', 'nl', 'en', 'zh', 'fa', 'fr', 'el', 'he', 'hi', 'id', 'it', 'ja', 'ko', 'pl', 'pt', 'ro', 'ru', 'es', 'tr', 'uk', 'vi']",['token-classification'],['1M<n<10M']
Aratako/Synthetic-JP-EN-Coding-Dataset-801k,Aratako,2024-07-14 14:04:30+00:00,2024-09-28 05:01:14+00:00,127,16,"['task_categories:text-generation', 'language:ja', 'license:apache-2.0', 'size_categories:100K<n<1M', 'format:parquet', 'modality:tabular', 'modality:text', 'library:datasets', 'library:dask', 'library:mlcroissant', 'library:polars', 'region:us', 'code']","
	
		
		Synthetic-JP-EN-Coding-Dataset-801k
	

Magpieによって作成したコードSFTデータセットであるAratako/Synthetic-JP-EN-Coding-Dataset-Magpie-69kを元に、Evol-Instructのような手法を用いて複数のinstructionとresonseを生成し拡張して作成した、日英混合801262件のコードSFT用合成データセットです。

日本語: 173849件
英語: 627413件

元のinstructionの作成に利用したモデルは以下の通りです。modelキーに該当レコードの作成に利用したモデル情報があります。

nvidia/Nemotron-4-340B-Instruct
microsoft/Phi-3-medium-4k-instruct
mistralai/Mixtral-8x22B-Instruct-v0.1… See the full description on the dataset page: https://huggingface.co/datasets/Aratako/Synthetic-JP-EN-Coding-Dataset-801k.",https://huggingface.co/datasets/Aratako/Synthetic-JP-EN-Coding-Dataset-801k,['ja'],['text-generation'],['100K<n<1M']
YukiTomita-CC/ELYZA-tasks-100_Human_solved,YukiTomita-CC,2024-07-15 01:33:31+00:00,2024-07-17 03:55:33+00:00,11,5,"['language:ja', 'license:cc-by-sa-4.0', 'size_categories:n<1K', 'format:parquet', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","
	
		
		概要
	

このデータセットは日本語LLMの評価用としてよく用いられるelyza/ELYZA-tasks-100について人間が回答を行った結果です。outputはこのリポジトリの作成者によるオリジナルですが、inputはELYZA-tasks-100からそのまま流用しています。
詳しくは下記の記事をご覧ください。https://zenn.dev/yuki127/articles/2496cd8383c84c

	
		
		採点
	

GPT-4oによる自動採点において、この回答での平均スコアは3.69点(+0.03 / -0.03) (計5回の同条件での採点結果の平均値と、最大値及び最小値との差分)  
Claude 3.5 Sonnet(api: claude-3-5-sonnet-20240620)のELYZA-tasks-100の回答を同様に自動採点したところ4.42点(+0.02 / -0.02) となりました。… See the full description on the dataset page: https://huggingface.co/datasets/YukiTomita-CC/ELYZA-tasks-100_Human_solved.",https://huggingface.co/datasets/YukiTomita-CC/ELYZA-tasks-100_Human_solved,['ja'],[],['n<1K']
neody/commoncrawl-ja-sample,neody,2024-07-15 03:34:44+00:00,2024-07-16 09:24:51+00:00,27,0,"['language:ja', 'size_categories:100K<n<1M', 'format:parquet', 'modality:text', 'library:datasets', 'library:dask', 'library:mlcroissant', 'library:polars', 'region:us']",,https://huggingface.co/datasets/neody/commoncrawl-ja-sample,['ja'],[],['100K<n<1M']
stanford-oval/ccnews,stanford-oval,2024-07-16 07:54:40+00:00,2024-08-31 17:28:13+00:00,3858,28,"['task_categories:text-classification', 'task_categories:question-answering', 'task_categories:text-generation', 'language:multilingual', 'language:af', 'language:am', 'language:ar', 'language:as', 'language:az', 'language:be', 'language:bg', 'language:bn', 'language:br', 'language:bs', 'language:ca', 'language:cs', 'language:cy', 'language:da', 'language:de', 'language:el', 'language:en', 'language:eo', 'language:es', 'language:et', 'language:eu', 'language:fa', 'language:fi', 'language:fr', 'language:fy', 'language:ga', 'language:gd', 'language:gl', 'language:gu', 'language:ha', 'language:he', 'language:hi', 'language:hr', 'language:hu', 'language:hy', 'language:id', 'language:is', 'language:it', 'language:ja', 'language:jv', 'language:ka', 'language:kk', 'language:km', 'language:kn', 'language:ko', 'language:ku', 'language:ky', 'language:la', 'language:lo', 'language:lt', 'language:lv', 'language:mg', 'language:mk', 'language:ml', 'language:mn', 'language:mr', 'language:ms', 'language:my', 'language:ne', 'language:nl', 'language:no', 'language:om', 'language:or', 'language:pa', 'language:pl', 'language:ps', 'language:pt', 'language:ro', 'language:ru', 'language:sa', 'language:sd', 'language:si', 'language:sk', 'language:sl', 'language:so', 'language:sq', 'language:sr', 'language:su', 'language:sv', 'language:sw', 'language:ta', 'language:te', 'language:th', 'language:tl', 'language:tr', 'language:ug', 'language:uk', 'language:ur', 'language:uz', 'language:vi', 'language:xh', 'language:yi', 'language:zh', 'size_categories:100M<n<1B', 'format:parquet', 'modality:image', 'modality:text', 'library:datasets', 'library:dask', 'library:mlcroissant', 'library:polars', 'region:us', 'news']","This dataset is the result of processing all WARC files in the CCNews Corpus, from the beginning (2016) to June of 2024.
The data has been cleaned and deduplicated, and language of articles have been detected and added. The process is similar to what HuggingFace's DataTrove does.
Overall, it contains about 600 million news articles in more than 100 languages from all around the globe.
For license information, please refer to CommonCrawl's Terms of Use.
Sample Python code to explore this… See the full description on the dataset page: https://huggingface.co/datasets/stanford-oval/ccnews.",https://huggingface.co/datasets/stanford-oval/ccnews,"['multilingual', 'af', 'am', 'ar', 'as', 'az', 'be', 'bg', 'bn', 'br', 'bs', 'ca', 'cs', 'cy', 'da', 'de', 'el', 'en', 'eo', 'es', 'et', 'eu', 'fa', 'fi', 'fr', 'fy', 'ga', 'gd', 'gl', 'gu', 'ha', 'he', 'hi', 'hr', 'hu', 'hy', 'id', 'is', 'it', 'ja', 'jv', 'ka', 'kk', 'km', 'kn', 'ko', 'ku', 'ky', 'la', 'lo', 'lt', 'lv', 'mg', 'mk', 'ml', 'mn', 'mr', 'ms', 'my', 'ne', 'nl', 'no', 'om', 'or', 'pa', 'pl', 'ps', 'pt', 'ro', 'ru', 'sa', 'sd', 'si', 'sk', 'sl', 'so', 'sq', 'sr', 'su', 'sv', 'sw', 'ta', 'te', 'th', 'tl', 'tr', 'ug', 'uk', 'ur', 'uz', 'vi', 'xh', 'yi', 'zh']","['text-classification', 'question-answering', 'text-generation']",['100M<n<1B']
Silviase/Japanese-Heron-Bench,Silviase,2024-07-16 08:12:30+00:00,2024-07-28 12:33:15+00:00,137,1,"['language:ja', 'size_categories:n<1K', 'format:parquet', 'modality:image', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'arxiv:2404.07824', 'region:us']","This dataset is a clarified version of the image, context, and question set included in the Japanese-Heron-Bench for the construction of the Japanese evaluation benchmark suite.
The original dataset refers to turing-motors/Japanese-Heron-Bench.
Link to the original dataset🔗: https://huggingface.co/datasets/turing-motors/Japanese-Heron-Bench
@misc{inoue2024heronbench,
      title={Heron-Bench: A Benchmark for Evaluating Vision Language Models in Japanese}, 
      author={Yuichi Inoue and Kento… See the full description on the dataset page: https://huggingface.co/datasets/Silviase/Japanese-Heron-Bench.",https://huggingface.co/datasets/Silviase/Japanese-Heron-Bench,['ja'],[],['n<1K']
hpprc/auto-wiki-nli,hpprc,2024-07-16 10:02:34+00:00,2024-07-18 01:37:01+00:00,8,0,"['language:ja', 'license:cc-by-sa-4.0', 'size_categories:100K<n<1M', 'format:parquet', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']",,https://huggingface.co/datasets/hpprc/auto-wiki-nli,['ja'],[],['100K<n<1M']
yuntian-deng/mgsm,yuntian-deng,2024-07-16 16:40:45+00:00,2024-07-16 16:54:17+00:00,27,2,"['annotations_creators:found', 'language_creators:found', 'language_creators:expert-generated', 'multilinguality:multilingual', 'source_datasets:extended|gsm8k', 'language:en', 'language:es', 'language:fr', 'language:de', 'language:ru', 'language:zh', 'language:ja', 'language:th', 'language:sw', 'language:bn', 'license:cc-by-sa-4.0', 'size_categories:1K<n<10K', 'arxiv:2110.14168', 'arxiv:2210.03057', 'region:us', 'math-word-problems']","Multilingual Grade School Math Benchmark (MGSM) is a benchmark of grade-school math problems, proposed in the paper [Language models are multilingual chain-of-thought reasoners](http://arxiv.org/abs/2210.03057).

The same 250 problems from [GSM8K](https://arxiv.org/abs/2110.14168) are each translated via human annotators in 10 languages. The 10 languages are:
- Spanish
- French
- German
- Russian
- Chinese
- Japanese
- Thai
- Swahili
- Bengali
- Telugu

You can find the input and targets for each of the ten languages (and English) as `.tsv` files.
We also include few-shot exemplars that are also manually translated from each language in `exemplars.py`.",https://huggingface.co/datasets/yuntian-deng/mgsm,"['en', 'es', 'fr', 'de', 'ru', 'zh', 'ja', 'th', 'sw', 'bn']",[],['1K<n<10K']
kanhatakeyama/AutoMultiTurnByCalm3-22B,kanhatakeyama,2024-07-17 09:53:20+00:00,2024-07-17 10:03:02+00:00,55,1,"['language:ja', 'license:other', 'size_categories:10K<n<100K', 'format:json', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","
	
		
		自動生成のマルチターンデータセット
	


	
		
		オープンなデータソースから､Calm3-22bを使ってQ&Aを自動生成したものです｡
	


一部の計算には東京工業大学のスーパーコンピュータTSUBAME4.0を利用しました｡


	
		
		データソース
	


	
		
		はじめの質問(q1)を､種々のデータソースから収集しました｡その後のやりとりはすべて､Calmが生成しました｡質問文については､元データのライセンスに準拠します｡
	


oasst2-33k-ja
apache 2.0


databricks-dolly-15k-ja
cc-by-sa-3.0


minnade
CC0


cyberagent/chatbot-arena-ja-calm2-7b-chat-experimental
cc-by-4.0



",https://huggingface.co/datasets/kanhatakeyama/AutoMultiTurnByCalm3-22B,['ja'],[],['10K<n<100K']
cl-nagoya/auto-wiki-nli-reward,cl-nagoya,2024-07-18 01:36:31+00:00,2024-09-13 01:46:46+00:00,12,2,"['language:ja', 'license:cc-by-sa-4.0', 'size_categories:100K<n<1M', 'format:parquet', 'modality:tabular', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'arxiv:2406.11704', 'arxiv:2409.07737', 'region:us']","
	
		
		AutoWikiNLI reward
	

A dataset constructed by generating hypothesis sentences corresponding to entailment and contradiction from Wikipedia text using Nemotron-4 340B.
Helpfulness and other scores are assigned using the Nemotron-4 340B reward model.
",https://huggingface.co/datasets/cl-nagoya/auto-wiki-nli-reward,['ja'],[],['100K<n<1M']
ganchengguang/MMM-dataset-Trainset,ganchengguang,2024-07-18 16:00:17+00:00,2024-07-18 16:15:15+00:00,120,1,"['language:en', 'language:ja', 'language:zh', 'license:cc-by-nc-4.0', 'arxiv:2407.10953', 'arxiv:2308.03279', 'region:us', 'Information Extraction', 'NER']","Multilingual Mutual Reinforcement Effect Mix Datasets
This is a Training set of OIELLM.
This Train set already formatted by OIELLM's format. The test set is in the another page in huggingface.
The MMM support 3 languages (English, Chinese and Japanese). And you must use task instruct words to define kind of task.

The following is input and output format:
    {
        ""input"": ""In 1953, filming of ""On the Waterfront"" starring Marlon Brando began, and Kazan struggled with Spiegel's persistent… See the full description on the dataset page: https://huggingface.co/datasets/ganchengguang/MMM-dataset-Trainset.",https://huggingface.co/datasets/ganchengguang/MMM-dataset-Trainset,"['en', 'ja', 'zh']",[],[]
ganchengguang/MMM-datasets-Testset,ganchengguang,2024-07-18 16:06:19+00:00,2024-07-18 22:44:38+00:00,19,1,"['language:en', 'language:ja', 'language:zh', 'license:cc-by-nc-4.0', 'size_categories:100K<n<1M', 'format:json', 'modality:text', 'library:datasets', 'library:dask', 'library:mlcroissant', 'arxiv:2407.10953', 'arxiv:2308.03279', 'region:us', 'Information Extraction', 'NER']","Multilingual Mutual Reinforcement Effect Mix Datasets
This is a Training set of OIELLM.
This Train set already formatted by OIELLM's format. The test set is in the another page in huggingface.
The MMM support 3 languages (English, Chinese and Japanese). And you must use task instruct words to define kind of task.
Mutual Reinforcement Effect.

OIELLM's input and output
MMM Dataset

The following is input and output format:
    {
        ""input"": ""In 1953, filming of ""On the Waterfront"" starring… See the full description on the dataset page: https://huggingface.co/datasets/ganchengguang/MMM-datasets-Testset.",https://huggingface.co/datasets/ganchengguang/MMM-datasets-Testset,"['en', 'ja', 'zh']",[],['100K<n<1M']
tokyotech-llm/Swallow-Instruct-v0.1,tokyotech-llm,2024-07-18 20:27:22+00:00,2024-07-18 20:31:35+00:00,51,10,"['language:ja', 'language:en', 'license:apache-2.0', 'size_categories:10K<n<100K', 'format:json', 'modality:text', 'library:datasets', 'library:dask', 'library:mlcroissant', 'library:polars', 'region:us']","
	
		
		Swallow Instruct v0.1 Dataset
	

This dataset was used for supervised fine-tuning (SFT) of the Swallow v0.1 model series.

	
		
		Model Index
	

The following Instruct models were created using this dataset:

Llama-3-Swallow-8B-Instruct-v0.1
Llama-3-Swallow-70B-Instruct-v0.1
Swallow-7b-instruct-v0.1
Swallow-13b-instruct-v0.1
Swallow-70b-instruct-v0.1

Note: The data used for Swallow-MS-7b-instruct-v0.1 is different.

		
		Statistical Information
	


	
		
Dataset
Conversations… See the full description on the dataset page: https://huggingface.co/datasets/tokyotech-llm/Swallow-Instruct-v0.1.",https://huggingface.co/datasets/tokyotech-llm/Swallow-Instruct-v0.1,"['ja', 'en']",[],['10K<n<100K']
maya-multimodal/pretrain,maya-multimodal,2024-07-18 21:09:51+00:00,2025-05-19 14:00:53+00:00,23,18,"['language:fr', 'language:en', 'language:es', 'language:hi', 'language:ja', 'language:zh', 'language:ru', 'language:ar', 'license:cc-by-nc-4.0', 'size_categories:1M<n<10M', 'format:json', 'modality:text', 'library:datasets', 'library:dask', 'library:mlcroissant', 'arxiv:2412.07112', 'arxiv:2505.08910', 'arxiv:2505.06356', 'region:us']","
	
		
		Maya LLaVA-Pretrain Dataset
	


	
		
		Overview
	

Maya-LLaVA-Pretrain is a large-scale, multilingual dataset designed for pretraining large language and vision models. It contains 4,404,776 entries across 8 languages, derived from an original llava-pretrain English dataset and expanded through machine translation and toxicity filtering. The dataset is particularly suited for image-captioning or visual question-answering tasks.

	
		
	
	
		Key Features
	


Multilingual: Includes 8… See the full description on the dataset page: https://huggingface.co/datasets/maya-multimodal/pretrain.",https://huggingface.co/datasets/maya-multimodal/pretrain,"['fr', 'en', 'es', 'hi', 'ja', 'zh', 'ru', 'ar']",[],['1M<n<10M']
hpprc/jawiki-books-paragraphs,hpprc,2024-07-19 03:11:16+00:00,2024-07-21 14:47:47+00:00,13,0,"['language:ja', 'license:cc-by-sa-4.0', 'size_categories:100K<n<1M', 'format:parquet', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']",,https://huggingface.co/datasets/hpprc/jawiki-books-paragraphs,['ja'],[],['100K<n<1M']
hpprc/jawiki-news-paragraphs,hpprc,2024-07-19 03:11:32+00:00,2024-07-25 06:26:28+00:00,9,1,"['language:ja', 'license:cc-by-sa-4.0', 'size_categories:10K<n<100K', 'format:parquet', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']",,https://huggingface.co/datasets/hpprc/jawiki-news-paragraphs,['ja'],[],['10K<n<100K']
watashihakobashi/ogiri,watashihakobashi,2024-07-19 20:46:13+00:00,2024-09-24 20:41:22+00:00,13,5,"['language:ja', 'license:cc-by-nc-nd-4.0', 'size_categories:n<1K', 'format:csv', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","東京大学松尾・岩澤研究室主催のLLM講座2024の第5回「SFT」演習で使用するデータセットです。https://weblab.t.u-tokyo.ac.jp/en/education/large-language-model/  
人手で作成した入力に対して以下の2つのモデルによる出力を抜粋したデータとなります。https://huggingface.co/watashiha/watashiha-gpt-6bhttps://huggingface.co/watashiha/Watashiha-Llama-2-13B-Ogiri-sft  
教育、研究目的でのみ使用してください。  
",https://huggingface.co/datasets/watashihakobashi/ogiri,['ja'],[],['n<1K']
grider-transwithai/nekopara-speech,grider-transwithai,2024-07-20 02:48:24+00:00,2024-07-20 13:52:58+00:00,66,14,"['task_categories:text-to-speech', 'task_categories:automatic-speech-recognition', 'language:ja', 'size_categories:10K<n<100K', 'format:parquet', 'modality:audio', 'modality:text', 'library:datasets', 'library:dask', 'library:mlcroissant', 'library:polars', 'region:us', 'anime', 'galgame', 'visual novel']","
	
		
		Nekopara Audio Dataset
	


	
		
		Dataset Description
	

This dataset contains audio samples and associated metadata from the Nekopara visual novel series, covering volumes 0-4 and extra content.

	
		
		Features
	


	
		
Feature Name
Type
Description


		
character_name
string
Name of the character speaking


volume
string
Game volume the audio is from (extra, vol0, vol1, vol2, vol3, vol4)


audio
Audio
Audio sample (44.1 kHz sampling rate)


voice_file
string
Original filename of the… See the full description on the dataset page: https://huggingface.co/datasets/grider-transwithai/nekopara-speech.",https://huggingface.co/datasets/grider-transwithai/nekopara-speech,['ja'],"['text-to-speech', 'automatic-speech-recognition']",['10K<n<100K']
YANS-official/ogiri-keitai,YANS-official,2024-07-20 10:11:36+00:00,2024-09-15 02:26:03+00:00,178,1,"['language:ja', 'size_categories:n<1K', 'format:json', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","
	
		
		概要
	

NHKで定期的に放送されていた『着信御礼！ケータイ大喜利』の放送内で紹介されていた全ての大喜利のお題と回答のデータです。以下のページからクロールし、原本のHTMLファイルと構造化処理を行った結果を格納しました。https://keitaioogiri.hatenablog.com/archive/category/%E5%85%A8%E4%BD%9C%E5%93%81%E3%83%87%E3%83%BC%E3%82%BF%E3%83%99%E3%83%BC%E3%82%B9
一部、HTMLのparse errorを含む可能性があります。ご了承ください。

	
		
	
	
		データセットの各カラム説明
	


	
		
カラム名
型
例
概要


		
odai_id
int
302
お題の通し番号


episode_id
int
100
放送の話数


type
str
text_to_text
text_to_textしか入ってない。


odai
str
こわくてイヤ！美容室「ホラー」ってどんなの？
お題の内容


responses
list… See the full description on the dataset page: https://huggingface.co/datasets/YANS-official/ogiri-keitai.",https://huggingface.co/datasets/YANS-official/ogiri-keitai,['ja'],[],['n<1K']
YANS-official/ogiri-bokete,YANS-official,2024-07-21 09:58:14+00:00,2024-09-15 02:26:56+00:00,545,2,"['task_categories:text-generation', 'task_categories:image-to-text', 'language:ja', 'size_categories:n<1K', 'format:imagefolder', 'modality:image', 'modality:text', 'library:datasets', 'library:mlcroissant', 'arxiv:2312.02439', 'region:us']","
	
		
		読み込み方
	

from datasets import load_dataset

dataset = load_dataset(""YANS-official/ogiri-bokete"", split=""train"")


	
		
		概要
	

大喜利投稿サイトBoketeのクロールデータです。元データは CLoT-Oogiri-Go [Zhang+ CVPR2024]というデータの一部です。
詳細はCVPRのプロジェクトページをご確認ください。  
このデータは以下の3タスクが含まれます。  

text_to_text: テキストでお題が渡され、それに対する回答を返します。
image_to_text: いわゆる「画像で一言」です。画像のみが渡されて、テキストによる回答を返します。
text_image_to_text: 画像中にテキストが書かれています。テキストの一部が空欄になっているので、そこに穴埋めする形で回答を返します。

それぞれの量は以下の通りです。（8/30現在。ハッカソン当日までに増やす可能性があります。）

	
		
タスク… See the full description on the dataset page: https://huggingface.co/datasets/YANS-official/ogiri-bokete.",https://huggingface.co/datasets/YANS-official/ogiri-bokete,['ja'],"['text-generation', 'image-to-text']",['n<1K']
toramaru-u/wiki40b-ja,toramaru-u,2024-07-24 07:12:30+00:00,2024-12-18 10:05:25+00:00,6,4,"['language:ja', 'size_categories:10M<n<100M', 'format:parquet', 'modality:tabular', 'modality:text', 'library:datasets', 'library:dask', 'library:mlcroissant', 'library:polars', 'region:us']",,https://huggingface.co/datasets/toramaru-u/wiki40b-ja,['ja'],[],['10M<n<100M']
ryota39/self-rewarding_instruct_AIFT_M1_scored,ryota39,2024-07-25 14:37:55+00:00,2024-07-27 10:01:23+00:00,6,0,"['language:ja', 'size_categories:1K<n<10K', 'format:parquet', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']",,https://huggingface.co/datasets/ryota39/self-rewarding_instruct_AIFT_M1_scored,['ja'],[],['1K<n<10K']
ryota39/self-rewarding_instruct_AIFT_M2_scored,ryota39,2024-07-25 14:48:58+00:00,2024-07-28 07:50:40+00:00,9,0,"['language:ja', 'size_categories:1K<n<10K', 'format:parquet', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']",,https://huggingface.co/datasets/ryota39/self-rewarding_instruct_AIFT_M2_scored,['ja'],[],['1K<n<10K']
ryota39/self-rewarding_instruct_AIFT_M3_scored,ryota39,2024-07-25 15:01:04+00:00,2024-07-28 10:46:45+00:00,9,0,"['language:ja', 'size_categories:1K<n<10K', 'format:parquet', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']",,https://huggingface.co/datasets/ryota39/self-rewarding_instruct_AIFT_M3_scored,['ja'],[],['1K<n<10K']
miracl/nomiracl-instruct,miracl,2024-07-25 20:18:13+00:00,2024-11-23 18:33:23+00:00,32,2,"['task_categories:text-classification', 'task_categories:text-generation', 'language:ar', 'language:bn', 'language:de', 'language:en', 'language:es', 'language:fa', 'language:fi', 'language:fr', 'language:hi', 'language:id', 'language:ja', 'language:ko', 'language:ru', 'language:sw', 'language:te', 'language:th', 'language:yo', 'language:zh', 'license:apache-2.0', 'size_categories:10K<n<100K', 'format:parquet', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","
	
		
		Dataset Card for NoMIRACL (EMNLP 2024 Findings Track)
	


	
		
		Quick Overview
	

This repository contains the fine-tuning (training & development split) of the NoMIRACL instruct dataset for fine-tuning LLMs on multilingual relevance assessment.
The training dataset is a binary classification task; they need to explicitly output either Yes, answer is present or I don't know. 
The dataset contains training pairs from all 18 languages for both splits: relevant & non-relevant.
import… See the full description on the dataset page: https://huggingface.co/datasets/miracl/nomiracl-instruct.",https://huggingface.co/datasets/miracl/nomiracl-instruct,"['ar', 'bn', 'de', 'en', 'es', 'fa', 'fi', 'fr', 'hi', 'id', 'ja', 'ko', 'ru', 'sw', 'te', 'th', 'yo', 'zh']","['text-classification', 'text-generation']",['10K<n<100K']
SakanaAI/JA-Multi-Image-VQA,SakanaAI,2024-07-26 11:11:42+00:00,2024-08-01 11:44:27+00:00,68,10,"['task_categories:visual-question-answering', 'language:ja', 'license:apache-2.0', 'size_categories:n<1K', 'format:parquet', 'modality:image', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","
	
		
		JA-Multi-Image-VQA
	


	
		
		Dataset Description
	

JA-Multi-Image-VQA is a dataset for evaluating the question answering capabilities on multiple image inputs. 
We carefully collected a diverse set of 39 images with 55 questions in total.
Some images contain Japanese culture and objects in Japan. The Japanese questions and answers were created manually.



	
		
		Usage
	

from datasets import load_dataset
dataset = load_dataset(""SakanaAI/JA-Multi-Image-VQA"", split=""test"")… See the full description on the dataset page: https://huggingface.co/datasets/SakanaAI/JA-Multi-Image-VQA.",https://huggingface.co/datasets/SakanaAI/JA-Multi-Image-VQA,['ja'],['visual-question-answering'],['n<1K']
ThePioneer/japanese-photos,ThePioneer,2024-07-26 14:59:08+00:00,2025-04-29 06:04:43+00:00,428,31,"['language:en', 'language:ja', 'license:cc0-1.0', 'size_categories:10K<n<100K', 'modality:image', 'region:us']","
	
		
		Japan Diverse Images Dataset
	


	
		
		Overview
	

This dataset is a comprehensive collection of high-quality images capturing the diverse aspects of Japan, including urban landscapes, natural scenery, historical sites, contemporary art, everyday life, and culinary experiences. It is designed to provide a rich and varied representation of Japan for AI training purposes.
Note that the photos were taken by myself in the 2020s, mainly from 2022 to 2024, with some exceptions.… See the full description on the dataset page: https://huggingface.co/datasets/ThePioneer/japanese-photos.",https://huggingface.co/datasets/ThePioneer/japanese-photos,"['en', 'ja']",[],['10K<n<100K']
Calvin-Xu/Furigana-Aozora,Calvin-Xu,2024-07-28 02:29:57+00:00,2024-07-28 09:09:55+00:00,10,2,"['language:ja', 'license:mit', 'size_categories:1M<n<10M', 'format:arrow', 'modality:text', 'library:datasets', 'library:mlcroissant', 'region:us', 'furigana', 'education']","Derived from 青空文庫及びサピエの点字データから作成した振り仮名のデータセット（GitHub）
https://github.com/ndl-lab/huriganacorpus-aozora
Certain mismatches in the original corpus were eliminated during validation (307 instances)
Error: 烈しい調子である。 != パンツだったのである。, file: 中島敦/環礁_ミクロネシヤ巡島記抄/kansho.txt
Error: 彼がそれにどれだけ成功するかは、これからの問題だが。 != ――, file: 堀辰雄/聖家族/seikazoku.txt
Error: 「なんだか目の中にゴミがはいっちゃったわ……」 != 「びっくりしたじゃないの……」, file: 堀辰雄/聖家族/seikazoku.txt
Error: それは斯波という男の声であった。 != ……, file: 堀辰雄/聖家族/seikazoku.txt
Error:… See the full description on the dataset page: https://huggingface.co/datasets/Calvin-Xu/Furigana-Aozora.",https://huggingface.co/datasets/Calvin-Xu/Furigana-Aozora,['ja'],[],['1M<n<10M']
Calvin-Xu/Furigana-NDLBIB,Calvin-Xu,2024-07-28 08:37:17+00:00,2024-07-28 09:08:08+00:00,8,0,"['language:ja', 'license:mit', 'size_categories:10M<n<100M', 'format:arrow', 'modality:text', 'library:datasets', 'library:mlcroissant', 'region:us', 'furigana']","Derived from 全国書誌データから作成した振り仮名のデータセット（GitHub）
https://github.com/ndl-lab/huriganacorpus-ndlbib
Certain mismatches in the original corpus were eliminated during validation (5064 instances).
",https://huggingface.co/datasets/Calvin-Xu/Furigana-NDLBIB,['ja'],[],['10M<n<100M']
Calvin-Xu/Furigana-Aozora-Speech,Calvin-Xu,2024-07-29 04:19:29+00:00,2024-07-30 08:25:50+00:00,27,2,"['language:ja', 'license:cc', 'size_categories:1M<n<10M', 'format:arrow', 'modality:text', 'library:datasets', 'library:mlcroissant', 'region:us', 'furigana', 'education']","Derived from 青空文庫及びサピエの音声デイジーデータから作成した振り仮名注釈付き音声コーパスのデータセット https://github.com/ndl-lab/hurigana-speech-corpus-aozora
All text files in the original data were processed for 3361443 entries; duplicates and entries with no kanji were dropped post cleanup
",https://huggingface.co/datasets/Calvin-Xu/Furigana-Aozora-Speech,['ja'],[],['1M<n<10M']
sbintuitions/JSQuAD,sbintuitions,2024-07-30 05:20:25+00:00,2025-09-26 04:41:40+00:00,156,0,"['task_categories:question-answering', 'language:ja', 'license:cc-by-sa-4.0', 'size_categories:10K<n<100K', 'format:parquet', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","評価スコアの再現性確保と SB Intuitions 修正版の公開用クローン
ソース: yahoojapan/JGLUE on GitHub

	
		
		JSQuAD
	


JSQuAD is a Japanese version of SQuAD (Rajpurkar+, 2016), one of the datasets of reading comprehension.
Each instance in the dataset consists of a question regarding a given context (Wikipedia article) and its answer.
JSQuAD is based on SQuAD 1.1 (there are no unanswerable questions).
We used the Japanese Wikipedia dump as of 20211101.


	
		
		Licensing Information
	

Creative Commons Attribution Share… See the full description on the dataset page: https://huggingface.co/datasets/sbintuitions/JSQuAD.",https://huggingface.co/datasets/sbintuitions/JSQuAD,['ja'],['question-answering'],['10K<n<100K']
sbintuitions/JCommonsenseQA,sbintuitions,2024-07-30 05:21:01+00:00,2025-09-26 04:29:23+00:00,49,0,"['task_categories:question-answering', 'language:ja', 'license:cc-by-sa-4.0', 'size_categories:10K<n<100K', 'format:parquet', 'modality:tabular', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","評価スコアの再現性確保と SB Intuitions 修正版の公開用クローン
ソース: yahoojapan/JGLUE on GitHub

datasets/jcommonsenseqa-v1.1


	
		
		JCommonsenseQA
	


JCommonsenseQA is a Japanese version of CommonsenseQA (Talmor+, 2019), which is a multiple-choice question answering dataset that requires commonsense reasoning ability.
It is built using crowdsourcing with seeds extracted from the knowledge base ConceptNet.


	
		
		Licensing Information
	

Creative Commons Attribution Share Alike 4.0 International

	
		
		Citation… See the full description on the dataset page: https://huggingface.co/datasets/sbintuitions/JCommonsenseQA.",https://huggingface.co/datasets/sbintuitions/JCommonsenseQA,['ja'],['question-answering'],['10K<n<100K']
NJUyued/NoW,NJUyued,2024-07-30 06:26:41+00:00,2024-11-30 08:22:32+00:00,50,0,"['task_categories:text-to-image', 'task_categories:image-to-text', 'task_categories:text-retrieval', 'language:zh', 'language:en', 'language:ja', 'language:ru', 'license:cc-by-nc-4.0', 'size_categories:100K<n<1M', 'modality:text', 'modality:image', 'arxiv:2408.01349', 'region:us', 'image-text retrieval', 'noisy correspondence learning', 'NCL-specific benchmark', 'realistic', 'industry', 'mobile user interface', 'image-text matching', 'image', 'text', 'npy', 'txt', 'json']","
	
		
		PC2-NoiseofWeb
	

This repo releases data introduced in our paper accepted:

PC2: Pseudo-Classification Based Pseudo-Captioning for Noisy Correspondence Learning in Cross-Modal RetrievalAuthors: Yue Duan, Zhangxuan Gu, Zhenzhe Ying, Lei Qi, Changhua Meng and Yinghuan Shi


🔗 Quick links:

Dataset download
[PDF/Abs-arXiv | PDF/Abs-Published | Code |  Video | Poster/Slides | 文章解读-知乎(Zhihu) | 视频解读-bilibili]


📰 Latest news:

We provide a video presentation (in chinese) of this work on… See the full description on the dataset page: https://huggingface.co/datasets/NJUyued/NoW.",https://huggingface.co/datasets/NJUyued/NoW,"['zh', 'en', 'ja', 'ru']","['text-to-image', 'image-to-text', 'text-retrieval']",['100K<n<1M']
AI4H/EC-Guide,AI4H,2024-07-30 11:07:57+00:00,2024-08-12 06:51:08+00:00,75,5,"['task_categories:question-answering', 'task_categories:text-generation', 'task_categories:translation', 'language:en', 'language:zh', 'language:ja', 'language:de', 'language:es', 'language:it', 'language:fr', 'license:apache-2.0', 'size_categories:10K<n<100K', 'arxiv:2408.02970', 'region:us']","
	
		
		Amazon KDDCup 2024 Team ZJU-AI4H’s Solution and Dataset (Track 2 Top 2; Track 5 Top 5)
	

The Amazon KDD Cup’24 competition presents a unique challenge by focusing on the application of LLMs in E-commerce across multiple tasks. Our solution for addressing Tracks 2 and 5 involves a comprehensive pipeline encompassing dataset construction, instruction tuning, post-training quantization, and inference optimization. The core of our strategy is EC-Guide specifically tailored for E-commerce… See the full description on the dataset page: https://huggingface.co/datasets/AI4H/EC-Guide.",https://huggingface.co/datasets/AI4H/EC-Guide,"['en', 'zh', 'ja', 'de', 'es', 'it', 'fr']","['question-answering', 'text-generation', 'translation']",['10K<n<100K']
AiMijie/EC-Guide,AiMijie,2024-07-30 11:22:08+00:00,2024-08-12 06:50:33+00:00,70,2,"['task_categories:question-answering', 'task_categories:text-generation', 'task_categories:translation', 'language:en', 'language:zh', 'language:ja', 'language:de', 'language:es', 'language:it', 'language:fr', 'license:apache-2.0', 'size_categories:10K<n<100K', 'format:csv', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'arxiv:2408.02970', 'region:us']","
	
		
		This repo is only used for dataset viewer. Please download from here.
	


	
		
		Amazon KDDCup 2024 Team ZJU-AI4H’s Solution and Dataset (Track 2 Top 2; Track 5 Top 5)
	

The Amazon KDD Cup’24 competition presents a unique challenge by focusing on the application of LLMs in E-commerce across multiple tasks. Our solution for addressing Tracks 2 and 5 involves a comprehensive pipeline encompassing dataset construction, instruction tuning, post-training quantization, and inference… See the full description on the dataset page: https://huggingface.co/datasets/AiMijie/EC-Guide.",https://huggingface.co/datasets/AiMijie/EC-Guide,"['en', 'zh', 'ja', 'de', 'es', 'it', 'fr']","['question-answering', 'text-generation', 'translation']",['10K<n<100K']
jg07/SpeechAmplitueEnvelope17Languages,jg07,2024-07-30 14:30:39+00:00,2025-02-17 09:23:06+00:00,43,0,"['language:ar', 'language:en', 'language:es', 'language:eu', 'language:fi', 'language:fr', 'language:hi', 'language:hy', 'language:ja', 'language:ko', 'language:nl', 'language:ru', 'language:sv', 'language:ta', 'language:th', 'language:vi', 'language:zh', 'license:cc-by-nc-4.0', 'region:us']","
	
		
		Speech Amplitude Envelope for 17 languages
	

This dataset contains Speech Amplitude envelope computed on audio files extracted from ‘www.faithcomesbyhearing.com'
We selected recordings which did not contain any sound effects but only plain speech. 

	
		
language
nb of files
duration


		
ar: arabic
7224 files
6.02 hours


en: English
6078 files
5.06 hours


es: Spanish
6767 files
5.64 hours


eu: Basque
6573 files
5.47 hours


fi: Finnish
7393 files
6.16 hours


fr: French
5606 files… See the full description on the dataset page: https://huggingface.co/datasets/jg07/SpeechAmplitueEnvelope17Languages.",https://huggingface.co/datasets/jg07/SpeechAmplitueEnvelope17Languages,"['ar', 'en', 'es', 'eu', 'fi', 'fr', 'hi', 'hy', 'ja', 'ko', 'nl', 'ru', 'sv', 'ta', 'th', 'vi', 'zh']",[],[]
jlcmoore/ValueConsistency,jlcmoore,2024-07-30 23:59:36+00:00,2024-09-21 19:38:00+00:00,41,1,"['language:en', 'language:zh', 'language:de', 'language:ja', 'license:mit', 'size_categories:1K<n<10K', 'format:json', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'arxiv:2407.02996', 'region:us']","
	
		
		Dataset Card for ValueConsistency
	



This is the ValueConsistency data set as introduced in the paper
""Are Large Language Models Consistent over Value-laden Questions?"".

	
		
		Dataset Details
	


	
		
		Dataset Description
	


ValueConsistency is a dataset of both controversial and uncontroversial questions 
in English, Chinese, German, and Japanese for topics from the U.S., China, Germany, and Japan. 
It was generated via prompting by GPT-4 and validated manually.
You can find… See the full description on the dataset page: https://huggingface.co/datasets/jlcmoore/ValueConsistency.",https://huggingface.co/datasets/jlcmoore/ValueConsistency,"['en', 'zh', 'de', 'ja']",[],['1K<n<10K']
Hoshikuzu/ccmatrix-en-ja,Hoshikuzu,2024-08-01 07:18:51+00:00,2024-08-03 16:25:04+00:00,8,1,"['task_categories:translation', 'language:en', 'language:ja', 'license:unknown', 'size_categories:10M<n<100M', 'format:parquet', 'modality:tabular', 'modality:text', 'library:datasets', 'library:dask', 'library:mlcroissant', 'library:polars', 'arxiv:1911.00359', 'arxiv:1911.04944', 'arxiv:2010.11125', 'region:us']","
	
		
		Dataset Card for CCMatrix-en-ja
	


	
		
		Dataset Summary
	

This corpus is extracted from yhavinga/ccmatrix, with Japanese and English pairs.

	
		
		How to use
	

It is used in much the same way as yhavinga/ccmatrix. The only difference is that you do not have to specify the language.
from datasets import load_dataset
dataset = load_dataset(""yhavinga/ccmatrix"")

If data loading times are too long and boring, use Streaming.
from datasets import load_dataset
dataset =… See the full description on the dataset page: https://huggingface.co/datasets/Hoshikuzu/ccmatrix-en-ja.",https://huggingface.co/datasets/Hoshikuzu/ccmatrix-en-ja,"['en', 'ja']",['translation'],['10M<n<100M']
Hoshikuzu/opus-100-en-ja,Hoshikuzu,2024-08-01 11:06:08+00:00,2024-08-03 16:41:33+00:00,17,1,"['language:en', 'language:ja', 'license:unknown', 'size_categories:1M<n<10M', 'format:parquet', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","
	
		
		Dataset Card for OPUS-100-en-ja
	


	
		
		Dataset Summary
	

This corpus is extracted from Helsinki-NLP/opus-100, with Japanese and English pairs.

	
		
		How to use
	

It is used in much the same way as Helsinki-NLP/opus-100. The only difference is that you do not have to specify the language.
from datasets import load_dataset
dataset = load_dataset(""Hoshikuzu/opus-100-en-ja"")

If data loading times are too long and boring, use Streaming.
from datasets import load_dataset
dataset =… See the full description on the dataset page: https://huggingface.co/datasets/Hoshikuzu/opus-100-en-ja.",https://huggingface.co/datasets/Hoshikuzu/opus-100-en-ja,"['en', 'ja']",[],['1M<n<10M']
Calvin-Xu/FLFL-Aozora-Speech-Train,Calvin-Xu,2024-08-01 21:09:24+00:00,2024-08-22 01:27:38+00:00,11,2,"['language:ja', 'license:cc', 'size_categories:1M<n<10M', 'format:json', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us', 'furigana', 'education']","A more aggressively cleaned up version of Calvin-Xu/Furigana-Aozora-Speech, which consists of 2,536,041 out of the 3,361,443 entries generated from the raw data 青空文庫及びサピエの音声デイジーデータから作成した振り仮名注釈付き音声コーパスのデータセット https://github.com/ndl-lab/hurigana-speech-corpus-aozora. Training data of Calvin-Xu/FLFL.
The Whisper-generated transcriptions in the original dataset contains many errors. Additional sanity-checking is implemented to filter on reading of common kanji and eliminate wildly inaccurate… See the full description on the dataset page: https://huggingface.co/datasets/Calvin-Xu/FLFL-Aozora-Speech-Train.",https://huggingface.co/datasets/Calvin-Xu/FLFL-Aozora-Speech-Train,['ja'],[],['1M<n<10M']
sbintuitions/MGSM_ja,sbintuitions,2024-08-02 02:09:43+00:00,2025-04-11 04:48:24+00:00,26,2,"['language:ja', 'license:cc-by-sa-4.0', 'size_categories:n<1K', 'format:parquet', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'arxiv:2110.14168', 'arxiv:2210.03057', 'region:us']","評価スコアの再現性確保と SB Intuitions 修正版の公開用クローン

ソース: juletxara/mgsm on Hugging Face
Subset: ja のみを抽出




	
		
		MGSM
	


Multilingual Grade School Math Benchmark (MGSM) is a benchmark of grade-school math problems,
proposed in the paper Language models are multilingual chain-of-thought reasoners.


	
		
		Licensing Information
	

Creative Commons Attribution Share Alike 4.0 International

	
		
		Citation Information
	

@article{cobbe2021gsm8k,
    title={Training Verifiers to Solve Math Word Problems}… See the full description on the dataset page: https://huggingface.co/datasets/sbintuitions/MGSM_ja.",https://huggingface.co/datasets/sbintuitions/MGSM_ja,['ja'],[],['n<1K']
hpprc/quiz-works,hpprc,2024-08-04 05:57:46+00:00,2024-08-04 21:25:11+00:00,16,1,"['language:ja', 'license:other', 'size_categories:10K<n<100K', 'format:parquet', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","Quiz Works様に掲載のクイズのうち、2024年8月4日~8月5日時点において取得可能だったクイズを収載したデータセットです。
検索拡張生成(RAG)や文書検索システムの構築などへの利用に適した高品質なデータです。
Quiz Works様ホームページ上のこのサイトについてに記載されている

このサイトに掲載されるクイズはすべて自由に二次利用可能です。

との記述に基づき、本データセットも同様、自由に二次利用可能なデータセットとして公開しております。
ただし、Quiz Works様およびその他関係者の皆様へ迷惑のかかる利用方法はお断りさせていただきますことをご了承ください。

	
		
		Contact
	

本ページ上に公開されているデータについて何らかの問題・お気づきの点があれば本ページ作成者までお問い合わせくださいませ。

	
		
		Acknowledgement
	

本データの掲載元であるQuiz Works様に感謝申し上げます。
",https://huggingface.co/datasets/hpprc/quiz-works,['ja'],[],['10K<n<100K']
hpprc/quiz-no-mori,hpprc,2024-08-05 01:24:25+00:00,2024-08-05 08:04:34+00:00,11,2,"['task_categories:question-answering', 'language:ja', 'license:other', 'size_categories:10K<n<100K', 'format:parquet', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","クイズの杜様に掲載のクイズのうち、2024年8月5日時点において取得可能だったクイズのうち「二次利用許諾レベル」が「フリー」であったものを収載したデータセットです。
検索拡張生成(RAG)や文書検索システムの構築などへの利用に適した高品質なデータです。
クイズの杜様ホームページ上の問題の二次利用についてに記載されている「二次利用許諾レベル」に関する説明のうち

フリー改変した問題、前フリをつけた問題、インスピレーションを受けて作成した類題等を、商用目的で利用する（例・クイズ番組での出題、利益を上げているオープン大会での出題、販売）コピー行い、不特定多数に配布したり、www上に公開したりする。フォーマットを変換し、不特定多数に公開する。他、全ての二次利用は自由。  

との記述に基づき、本データセットも同様、自由に二次利用可能なデータセットとして公開しております。
ただし、クイズの杜様およびその他関係者の皆様へ迷惑のかかる利用方法はお断りさせていただきますことをご了承ください。

	
		
	
	
		Contact… See the full description on the dataset page: https://huggingface.co/datasets/hpprc/quiz-no-mori.",https://huggingface.co/datasets/hpprc/quiz-no-mori,['ja'],['question-answering'],['10K<n<100K']
turing-motors/Cauldron-JA,turing-motors,2024-08-05 02:20:03+00:00,2024-10-24 02:57:55+00:00,29905,8,"['task_categories:visual-question-answering', 'language:ja', 'license:cc-by-4.0', 'size_categories:1M<n<10M', 'format:parquet', 'modality:text', 'modality:image', 'library:datasets', 'library:dask', 'library:mlcroissant', 'library:polars', 'arxiv:2405.02246', 'arxiv:1603.07396', 'arxiv:2206.01718', 'arxiv:2208.05358', 'arxiv:1612.06890', 'arxiv:2310.00367', 'arxiv:1710.07300', 'arxiv:2312.12241', 'arxiv:1912.03098', 'arxiv:2211.08545', 'arxiv:2306.05425', 'arxiv:1709.00103', 'arxiv:2003.12462', 'arxiv:1612.00837', 'arxiv:2205.00363', 'arxiv:2403.09029', 'region:us', 'image', 'text']","
	
		
		Dataset Card for The Cauldron-JA
	


	
		
		Dataset description
	

The Cauldron-JA is a Vision Language Model dataset that translates 'The Cauldron' into Japanese using the DeepL API. The Cauldron is a massive collection of 50 vision-language datasets (training sets only) that were used for the fine-tuning of the vision-language model Idefics2.
To create a Japanese Vision Language Dataset, datasets related to OCR, coding, and graphs were excluded because translating them into Japanese… See the full description on the dataset page: https://huggingface.co/datasets/turing-motors/Cauldron-JA.",https://huggingface.co/datasets/turing-motors/Cauldron-JA,['ja'],['visual-question-answering'],['1M<n<10M']
p1atdev/LLM-jp-Toxicity-Dataset,p1atdev,2024-08-07 07:11:08+00:00,2024-08-07 07:21:07+00:00,63,5,"['task_categories:text-classification', 'language:ja', 'license:cc-by-4.0', 'size_categories:1K<n<10K', 'format:json', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","
	
		
		LLM-jp Toxicity Dataset
	

日本語有害文書データセット「LLM-jp Toxicity Dataset」
See https://gitlab.llm-jp.nii.ac.jp/datasets/llm-jp-toxicity-dataset
",https://huggingface.co/datasets/p1atdev/LLM-jp-Toxicity-Dataset,['ja'],['text-classification'],['1K<n<10K']
cl-nagoya/ruri-dataset-reranker,cl-nagoya,2024-08-08 03:57:57+00:00,2024-09-13 01:49:51+00:00,825,4,"['task_categories:question-answering', 'language:ja', 'license:other', 'size_categories:1M<n<10M', 'format:parquet', 'modality:text', 'library:datasets', 'library:dask', 'library:mlcroissant', 'library:polars', 'arxiv:2409.07737', 'region:us']","
	
		
		Ruri-Dataset Reranker
	

Datasets used for training Ruri-Reranker.
Please refer to https://huggingface.co/datasets/hpprc/emb for individual datasets.
",https://huggingface.co/datasets/cl-nagoya/ruri-dataset-reranker,['ja'],['question-answering'],['1M<n<10M']
cl-nagoya/Simplifyingmt,cl-nagoya,2024-08-08 05:09:57+00:00,2024-08-08 05:25:52+00:00,13,0,"['language:en', 'language:ja', 'license:cc-by-sa-4.0', 'size_categories:100K<n<1M', 'format:parquet', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","
	
		
		SimplifyingMT
	


	
		
		Dataset Description
	

-Repository: https://github.com/nttcslab-nlp/SimplifyingMT_ACL24-Papre: to appear

	
		
		Paper
	

Oshika et al., Simplifying Translations for Children: Iterative Simplification Considering Age of Acquisition with LLMs, Findings of ACL 2024

	
		
		Abstract
	

In recent years, neural machine translation (NMT) has been widely used in everyday life.
However, the current NMT lacks a mechanism to adjust the difficulty level of translations to… See the full description on the dataset page: https://huggingface.co/datasets/cl-nagoya/Simplifyingmt.",https://huggingface.co/datasets/cl-nagoya/Simplifyingmt,"['en', 'ja']",[],['100K<n<1M']
nthakur/mirage-bench-instruct,nthakur,2024-08-09 00:15:43+00:00,2025-03-31 21:06:10+00:00,79,2,"['task_categories:sentence-similarity', 'language:ar', 'language:bn', 'language:en', 'language:es', 'language:fa', 'language:fi', 'language:fr', 'language:hi', 'language:id', 'language:ja', 'language:ko', 'language:ru', 'language:sw', 'language:te', 'language:th', 'language:zh', 'license:apache-2.0', 'size_categories:10K<n<100K', 'format:parquet', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","
	
		
		MIRAGE-Bench (Instruct)
	

This dataset contains the structured RAG outputs for queries in the train split of MIRAGE-Bench (or MIRACL) for 16 languages for five models:

gpt-4o-azure                          (GPT-4o using Azure API)
meta-llama/Meta-Llama-3-70B-Instruct  (Llama-3-70B-Instruct using Anyscale API)
mistralai/Mixtral-8x22B-Instruct-v0.1 (Mixtral-8x22B-Instruct using Anyscale API)
meta-llama/Meta-Llama-3-8B-Instruct   (Llama-3-8B-Instruct using vLLM)… See the full description on the dataset page: https://huggingface.co/datasets/nthakur/mirage-bench-instruct.",https://huggingface.co/datasets/nthakur/mirage-bench-instruct,"['ar', 'bn', 'en', 'es', 'fa', 'fi', 'fr', 'hi', 'id', 'ja', 'ko', 'ru', 'sw', 'te', 'th', 'zh']",['sentence-similarity'],['10K<n<100K']
mrzjy/zenless_zone_zero_interknots_v1.0,mrzjy,2024-08-09 08:10:14+00:00,2024-08-09 08:19:37+00:00,16,0,"['task_categories:text-generation', 'language:zh', 'language:en', 'language:ja', 'language:de', 'language:fr', 'language:ko', 'language:ru', 'language:vi', 'language:es', 'language:id', 'language:pt', 'language:th', 'license:cc-by-sa-4.0', 'size_categories:n<1K', 'region:us', 'game', 'zzz', 'hoyoverse']","
	
		
		ZZZ Interknots
	

This datasets contains extracted Interknot posts and comments (绳网的博客与评论) in multi-language.
Up to game version: 1.0

Interknot posts and comments examples

{
  ""id"": ""1021"",
  ""poster"": ""Sorrowful Intern"",
  ""title"": ""[Commission] Missing Bangboo merchants"",
  ""text"": ""Hello, pros... Some of the senior Bangboo of our merchant association have gone missing! We urgently need an expert to help find them!!\nLet me explain, I recently joined a very prestigious association… See the full description on the dataset page: https://huggingface.co/datasets/mrzjy/zenless_zone_zero_interknots_v1.0.",https://huggingface.co/datasets/mrzjy/zenless_zone_zero_interknots_v1.0,"['zh', 'en', 'ja', 'de', 'fr', 'ko', 'ru', 'vi', 'es', 'id', 'pt', 'th']",['text-generation'],['n<1K']
Upstash/wikipedia-2024-06-bge-m3,Upstash,2024-08-09 08:46:15+00:00,2025-02-17 12:52:33+00:00,1534,36,"['language:en', 'language:de', 'language:es', 'language:fa', 'language:fr', 'language:it', 'language:ja', 'language:pt', 'language:ru', 'language:tr', 'language:zh', 'license:apache-2.0', 'size_categories:100M<n<1B', 'format:parquet', 'modality:text', 'library:datasets', 'library:dask', 'library:mlcroissant', 'library:polars', 'region:us']","
	
		
		Wikipedia Embeddings with BGE-M3
	

This dataset contains embeddings from the
June 2024 Wikipedia dump
for the 11 most popular languages.
The embeddings are generated with the multilingual
BGE-M3 model.
The dataset consists of Wikipedia articles split into paragraphs,
and embedded with the aforementioned model.
To enhance search quality, the paragraphs are prefixed with their
respective article titles before embedding.
Additionally, paragraphs containing fewer than 100 characters… See the full description on the dataset page: https://huggingface.co/datasets/Upstash/wikipedia-2024-06-bge-m3.",https://huggingface.co/datasets/Upstash/wikipedia-2024-06-bge-m3,"['en', 'de', 'es', 'fa', 'fr', 'it', 'ja', 'pt', 'ru', 'tr', 'zh']",[],['100M<n<1B']
werty1248/OpenOrca-EnKoZhJa-18k,werty1248,2024-08-10 18:54:09+00:00,2024-08-10 19:16:35+00:00,11,0,"['language:en', 'language:ko', 'language:zh', 'language:ja', 'license:mit', 'size_categories:10K<n<100K', 'format:parquet', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","This dataset is a collection of Korean, Chinese, and Japanese OpenOrca translation datasets.
The dataset was matched using id based on kyujinpy/OpenOrca-KO, which had the smallest number of rows.
When more than one translation existed for a language, I chose the more similar one based on similarity of embedding(BAAI/BGE-m3).

	
		
		Data Sources
	


English(Original)
Open-Orca/OpenOrca


Korean(Translated with DeepL Pro API)
kyujinpy/OpenOrca-KO


Chinese(Translated with Google Translate)… See the full description on the dataset page: https://huggingface.co/datasets/werty1248/OpenOrca-EnKoZhJa-18k.",https://huggingface.co/datasets/werty1248/OpenOrca-EnKoZhJa-18k,"['en', 'ko', 'zh', 'ja']",[],['10K<n<100K']
kelze/Anisfera,kelze,2024-08-11 10:20:54+00:00,2024-08-11 11:04:32+00:00,7,0,"['task_categories:text-classification', 'language:ja', 'language:en', 'license:mit', 'size_categories:n<1K', 'region:us', 'anime recommendation']","git remote set-url origin {https://github.com/kelzemeta/Anisfea-GraphQL-Docs.git}
",https://huggingface.co/datasets/kelze/Anisfera,"['ja', 'en']",['text-classification'],['n<1K']
sarulab-speech/SaSLaW,sarulab-speech,2024-08-11 12:27:42+00:00,2024-08-13 12:27:29+00:00,356,0,"['task_categories:text-to-speech', 'language:ja', 'license:cc-by-nc-4.0', 'size_categories:1K<n<10K', 'format:audiofolder', 'modality:audio', 'modality:text', 'library:datasets', 'library:mlcroissant', 'region:us']","This repository contains the data of SaSLaW corpus. You can download it via the following command:
huggingface-cli download sarulab-speech/SaSLaW --repo-type dataset --local-dir SaSLaW

Please see the GitHub repo for the information about its contents, metadata, and license.
",https://huggingface.co/datasets/sarulab-speech/SaSLaW,['ja'],['text-to-speech'],['1K<n<10K']
cl-nagoya/ruri-dataset-ft,cl-nagoya,2024-08-13 05:29:17+00:00,2024-09-13 01:49:58+00:00,246,5,"['language:ja', 'license:other', 'size_categories:1M<n<10M', 'format:parquet', 'modality:text', 'library:datasets', 'library:dask', 'library:mlcroissant', 'library:polars', 'arxiv:2409.07737', 'region:us']","
	
		
		Ruri-Dataset FT
	

Datasets used for fine-tuning Ruri.
Please refer to https://huggingface.co/datasets/hpprc/emb for individual datasets.
",https://huggingface.co/datasets/cl-nagoya/ruri-dataset-ft,['ja'],[],['1M<n<10M']
hotchpotch/mmarco-hard-negatives-reranker-score,hotchpotch,2024-08-14 22:22:53+00:00,2024-12-17 08:19:41+00:00,130,1,"['language:en', 'language:zh', 'language:fr', 'language:de', 'language:id', 'language:it', 'language:pt', 'language:ru', 'language:es', 'language:ar', 'language:nl', 'language:hi', 'language:ja', 'language:vi', 'license:apache-2.0', 'size_categories:1M<n<10M', 'format:parquet', 'library:datasets', 'library:dask', 'library:mlcroissant', 'library:polars', 'region:us']","
hotchpotch/mmarco-hard-negatives-reranker-score

This repository contains data from mMARCO scored using the reranker BAAI/bge-reranker-v2-m3.

	
		
		Languages Covered
	

target_languages = [
    ""english"",
    ""chinese"", 
    ""french"",
    ""german"",
    ""indonesian"",
    ""italian"",
    ""portuguese"",
    ""russian"",
    ""spanish"",
    ""arabic"",
    ""dutch"",
    ""hindi"",
    ""japanese"",
    ""vietnamese""
]


	
		
		Hard Negative Data
	

The hard negative data is derived from… See the full description on the dataset page: https://huggingface.co/datasets/hotchpotch/mmarco-hard-negatives-reranker-score.",https://huggingface.co/datasets/hotchpotch/mmarco-hard-negatives-reranker-score,"['en', 'zh', 'fr', 'de', 'id', 'it', 'pt', 'ru', 'es', 'ar', 'nl', 'hi', 'ja', 'vi']",[],['1M<n<10M']
valencianatasha/AnythingLLM,valencianatasha,2024-08-15 04:27:21+00:00,2024-08-15 05:00:13+00:00,5,0,"['task_categories:text-generation', 'language:zh', 'language:ja', 'language:ko', 'license:openrail', 'size_categories:n<1K', 'format:csv', 'modality:tabular', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']",,https://huggingface.co/datasets/valencianatasha/AnythingLLM,"['zh', 'ja', 'ko']",['text-generation'],['n<1K']
data-silence/sumnews,data-silence,2024-08-15 20:12:12+00:00,2024-08-21 17:45:16+00:00,33,2,"['task_categories:summarization', 'task_categories:text-generation', 'multilinguality:multilingual', 'language:am', 'language:ar', 'language:az', 'language:bn', 'language:my', 'language:zh', 'language:en', 'language:fr', 'language:gu', 'language:ha', 'language:hi', 'language:ig', 'language:id', 'language:ja', 'language:rn', 'language:ko', 'language:ky', 'language:mr', 'language:ne', 'language:om', 'language:ps', 'language:fa', 'language:pcm', 'language:pt', 'language:pa', 'language:ru', 'language:gd', 'language:sr', 'language:si', 'language:so', 'language:es', 'language:sw', 'language:ta', 'language:te', 'language:th', 'language:ti', 'language:tr', 'language:uk', 'language:ur', 'language:uz', 'language:vi', 'language:cy', 'language:yo', 'license:cc-by-nc-sa-4.0', 'size_categories:100K<n<1M', 'format:parquet', 'modality:text', 'library:datasets', 'library:dask', 'library:mlcroissant', 'library:polars', 'region:us', 'news', 'media', 'conditional-text-generation']","
	
		
		Dataset Card for ""Sum-any-news""
	


	
		
		Dataset Description
	

This dataset is a set for fine-tuning the summarization task on the “google/mt5-base” model and its derivatives. 
The set is based on the well-known dataset “csebuetnlp/xlsum”, but is a limited 20,000 examples of news articles from it. 
In addition, about 20 thousand news articles in Russian for the period from 2019-01-01 to 2024-08-01 have been added to the model (multiple sources).
",https://huggingface.co/datasets/data-silence/sumnews,"['am', 'ar', 'az', 'bn', 'my', 'zh', 'en', 'fr', 'gu', 'ha', 'hi', 'ig', 'id', 'ja', 'rn', 'ko', 'ky', 'mr', 'ne', 'om', 'ps', 'fa', 'pcm', 'pt', 'pa', 'ru', 'gd', 'sr', 'si', 'so', 'es', 'sw', 'ta', 'te', 'th', 'ti', 'tr', 'uk', 'ur', 'uz', 'vi', 'cy', 'yo']","['summarization', 'text-generation']",['100K<n<1M']
KaraKaraWitch/uta-net-songs,KaraKaraWitch,2024-08-16 05:03:23+00:00,2024-08-24 14:41:51+00:00,21,1,"['language:ja', 'size_categories:100K<n<1M', 'format:json', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","
	
		
		Dataset Details
	


	
		
		Dataset Description
	

This dataset contains a processed version of a web scrape I did for uta-net. The raw data is available for download at here.
Uta-Net site mainly lists songs that have been released in Japan officially (Anime OP/EDs) up to 2023-03.

Curated by: KaraKaraWitch
Shared by: KaraKaraWitch
Language(s) (NLP): JA
License: Not Disclosed / Unsure

Stuff not in this dataset:

Character Songs for Anime
Doujin/Indie Works


	
		
	
	
		Dataset Sample… See the full description on the dataset page: https://huggingface.co/datasets/KaraKaraWitch/uta-net-songs.",https://huggingface.co/datasets/KaraKaraWitch/uta-net-songs,['ja'],[],['100K<n<1M']
ryota39/open_preference_v0.4,ryota39,2024-08-16 07:56:26+00:00,2024-08-26 08:40:53+00:00,18,1,"['language:en', 'language:ja', 'license:unknown', 'size_categories:100K<n<1M', 'format:json', 'modality:tabular', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","
This dataset is reformatted version of following datasets
ryota39/synthetic-instruct-gptj-pairwise-ja
ryota39/webgpt_comparisons-ja


label 1 stands for chosen sentence
label 0 stands for rejected sentence


	
		
		Format
	


train sample: 199628
validation sample: 1000
test sample: 1000
skip sample: 417
data points which have same chosen and rejected responses were eliminated



    {
        ""index"": 33045,
        ""input"": ""user: 今年知っておくべき税法の変更点にはどのようなものがありますか。\nassistant:… See the full description on the dataset page: https://huggingface.co/datasets/ryota39/open_preference_v0.4.",https://huggingface.co/datasets/ryota39/open_preference_v0.4,"['en', 'ja']",[],['100K<n<1M']
Aratako/Synthetic-Japanese-Roleplay-gpt-4o-mini-39.6k,Aratako,2024-08-16 14:35:16+00:00,2024-09-07 12:33:18+00:00,29,2,"['task_categories:text-generation', 'language:ja', 'license:cc-by-nc-sa-4.0', 'size_categories:10K<n<100K', 'format:json', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us', 'roleplay']","
	
		
		Synthetic-Japanese-Roleplay-gpt-4o-mini-39.6k
	

20240907 データ増量（約19800件→約39600件）

	
		
		概要
	

gpt-4o-miniを用いて作成した、約39600件の日本語ロールプレイの対話を収録した合成データセットです。各データは5ターンから10ターン程度あります。

	
		
		データの詳細
	

各データは以下のキーを含んでいます。

genre: ジャンル
tag: 年齢制限用タグ（全年齢またはR-15）
world_setting: 舞台・世界観の設定
scene_setting: 対話シーンの設定
user_setting: ユーザー側のキャラクターの設定
assistant_setting: アシスタント側のキャラクターの設定
dialogue_tone: 対話のトーン
conversations: 上記設定に基づいたユーザーとアシスタントの対話（OpenAI messages形式）

設定等の情報からsystem… See the full description on the dataset page: https://huggingface.co/datasets/Aratako/Synthetic-Japanese-Roleplay-gpt-4o-mini-39.6k.",https://huggingface.co/datasets/Aratako/Synthetic-Japanese-Roleplay-gpt-4o-mini-39.6k,['ja'],['text-generation'],['10K<n<100K']
Aratako/Synthetic-Japanese-Roleplay-gpt-4o-mini-39.6k-formatted,Aratako,2024-08-16 16:46:06+00:00,2024-10-27 11:31:03+00:00,41,9,"['task_categories:text-generation', 'language:ja', 'license:cc-by-nc-sa-4.0', 'size_categories:10K<n<100K', 'format:parquet', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us', 'roleplay']","
	
		
		Synthetic-Japanese-Roleplay-gpt-4o-mini-39.6k-formatted
	

20240907 データ増量（約19800件→約39600件）

	
		
		概要
	

gpt-4o-miniを用いて作成した日本語ロールプレイデータセットであるAratako/Synthetic-Japanese-Roleplay-gpt-4o-mini-39.6kにsystem messageを追加して整形したデータセットです。
データの詳細については元データセットのREADMEを参照してください。

	
		
		ライセンス
	

CC-BY-NC-SA 4.0の元配布します。
また、OpenAIの利用規約に記載のある通り、このデータを使ってOpenAIのサービスやモデルと競合するようなモデルを開発することは禁止されています。
",https://huggingface.co/datasets/Aratako/Synthetic-Japanese-Roleplay-gpt-4o-mini-39.6k-formatted,['ja'],['text-generation'],['10K<n<100K']
Aratako/Synthetic-Japanese-Roleplay-NSFW-Claude-3.5s-15.3k,Aratako,2024-08-16 16:55:47+00:00,2024-09-07 12:38:09+00:00,48,17,"['task_categories:text-generation', 'language:ja', 'license:cc-by-nc-sa-4.0', 'size_categories:10K<n<100K', 'format:json', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us', 'roleplay', 'not-for-all-audiences']","
	
		
		Synthetic-Japanese-Roleplay-NSFW-Claude-3.5s-15.3k
	

20240907 データ増量（約10500件→約15300件）

	
		
		概要
	

Claude 3.5 Sonnetを用いて作成した、約15300件の日本語ロールプレイの対話を収録した合成データセットです。各データは10ターンから20ターン程度あります。
このデータセットはNSFW表現を含みます。

	
		
		データの詳細
	

各データは以下のキーを含んでいます。

genre: ジャンル
tag: 年齢制限用タグ（R-15またはR-18）
world_setting: 舞台・世界観の設定
scene_setting: 対話シーンの設定
user_setting: ユーザー側のキャラクターの設定
assistant_setting: アシスタント側のキャラクターの設定
dialogue_tone: 対話のトーン
conversations: 上記設定に基づいたユーザーとアシスタントの対話（OpenAI messages形式）… See the full description on the dataset page: https://huggingface.co/datasets/Aratako/Synthetic-Japanese-Roleplay-NSFW-Claude-3.5s-15.3k.",https://huggingface.co/datasets/Aratako/Synthetic-Japanese-Roleplay-NSFW-Claude-3.5s-15.3k,['ja'],['text-generation'],['10K<n<100K']
Aratako/Synthetic-Japanese-Roleplay-NSFW-Claude-3.5s-15.3k-formatted,Aratako,2024-08-16 17:02:17+00:00,2024-09-07 12:44:44+00:00,45,18,"['task_categories:text-generation', 'language:ja', 'license:cc-by-nc-sa-4.0', 'size_categories:10K<n<100K', 'format:json', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us', 'roleplay', 'not-for-all-audiences']","
	
		
		Synthetic-Japanese-Roleplay-NSFW-Claude-3.5s-15.3k-formatted
	

20240907 データ増量（約10500件→約15300件）

	
		
		概要
	

Claude 3.5 Sonnetを用いて作成した日本語ロールプレイデータセットであるAratako/Synthetic-Japanese-Roleplay-NSFW-Claude-3.5s-15.3kにsystem messageを追加して整形したデータセットです。
データの詳細については元データセットのREADMEを参照してください。

	
		
		ライセンス
	

CC-BY-NC-SA 4.0の元配布します。
また、Anthropicの利用規約に記載のある通り、このデータを使ってAnthropicのサービスやモデルと競合するようなモデルを開発することは禁止されています。
",https://huggingface.co/datasets/Aratako/Synthetic-Japanese-Roleplay-NSFW-Claude-3.5s-15.3k-formatted,['ja'],['text-generation'],['10K<n<100K']
tanooki426/Datasets_JP,tanooki426,2024-08-16 17:44:08+00:00,2024-10-27 13:46:50+00:00,48,2,"['task_categories:automatic-speech-recognition', 'task_categories:audio-classification', 'task_categories:text-to-speech', 'task_categories:text-classification', 'language:ja', 'license:openrail', 'size_categories:1K<n<10K', 'format:audiofolder', 'modality:audio', 'library:datasets', 'library:mlcroissant', 'region:us']",,https://huggingface.co/datasets/tanooki426/Datasets_JP,['ja'],"['automatic-speech-recognition', 'audio-classification', 'text-to-speech', 'text-classification']",['1K<n<10K']
xinqiyang/tradingview_msn_financial_news_1k,xinqiyang,2024-08-16 22:36:19+00:00,2024-09-04 13:56:45+00:00,18,0,"['task_categories:summarization', 'language:ja', 'language:en', 'license:cc0-1.0', 'size_categories:1K<n<10K', 'format:csv', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us', 'finance']",,https://huggingface.co/datasets/xinqiyang/tradingview_msn_financial_news_1k,"['ja', 'en']",['summarization'],['1K<n<10K']
Coldog2333/JMedBench,Coldog2333,2024-08-17 11:12:54+00:00,2025-01-19 13:12:11+00:00,1523,7,"['task_categories:text-classification', 'task_categories:question-answering', 'task_categories:translation', 'task_categories:sentence-similarity', 'language:ja', 'size_categories:100K<n<1M', 'format:json', 'modality:tabular', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'arxiv:2409.13317', 'arxiv:2303.18027', 'region:us']","
	
		
		Maintainers
	


Junfeng Jiang@Aizawa Lab: jiangjf (at) is.s.u-tokyo.ac.jp
Jiahao Huang@Aizawa Lab: jiahao-huang (at) g.ecc.u-tokyo.ac.jp

If you find any error in this benchmark or want to contribute to this benchmark, please feel free to contact us.

	
		
		Introduction
	

This is a dataset collection of JMedBench, which is a benchmark for evaluating Japanese biomedical large language models (LLMs). 
Details can be found in this paper. We also provide an evaluation framework, med-eval… See the full description on the dataset page: https://huggingface.co/datasets/Coldog2333/JMedBench.",https://huggingface.co/datasets/Coldog2333/JMedBench,['ja'],"['text-classification', 'question-answering', 'translation', 'sentence-similarity']",['100K<n<1M']
YANS-official/ogiri-test-with-references,YANS-official,2024-08-18 02:53:04+00:00,2024-09-02 09:37:28+00:00,98,0,"['task_categories:image-to-text', 'language:ja', 'size_categories:n<1K', 'format:imagefolder', 'modality:image', 'modality:text', 'library:datasets', 'library:mlcroissant', 'arxiv:2312.02439', 'region:us']","
	
		
		読み込み方
	

from datasets import load_dataset

dataset = load_dataset(""YANS-official/bokete-ogiri-test"", split=""test"")


	
		
		概要
	

大喜利投稿サイトBoketeのクロールデータです。元データは CLoT-Oogiri-Go [Zhang+ CVPR2024]というデータの一部です。
詳細はCVPRのプロジェクトページをご確認ください。  
このデータは以下の3タスクが含まれます。  

text_to_text: テキストでお題が渡され、それに対する回答を返します。
image_to_text: いわゆる「画像で一言」です。画像のみが渡されて、テキストによる回答を返します。
text_image_to_text: 画像中にテキストが書かれています。テキストの一部が空欄になっているので、そこに穴埋めする形で回答を返します。

それぞれの量は以下の通りです。

	
		
タスク
お題数（画像枚数）
回答数
うち委員が用意したお題… See the full description on the dataset page: https://huggingface.co/datasets/YANS-official/ogiri-test-with-references.",https://huggingface.co/datasets/YANS-official/ogiri-test-with-references,['ja'],['image-to-text'],['n<1K']
turing-motors/Wikipedia-Vision-JA,turing-motors,2024-08-19 09:38:13+00:00,2024-08-21 03:11:40+00:00,20,14,"['task_categories:image-to-text', 'language:ja', 'license:cc-by-sa-4.0', 'size_categories:1M<n<10M', 'format:json', 'modality:image', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us', 'image', 'text']","
	
		
		Dataset Card for Wikipedia-Vision-JA
	


	
		
		Dataset description
	

The Wikipedia-Vision-JA is a Vision Language Model dataset generated from Japanese Wikipedia, containing 1.6M pairs of images, captions, and descriptions.
This dataset itself does not contain raw image data. Instead, an image_url is provided for each item.

	
		
		Format
	

Wikipedia_Vision_JA.jsonl contains JSON-formatted rows with the following keys:

key: Unique JSON ID
caption: Short caption for the image… See the full description on the dataset page: https://huggingface.co/datasets/turing-motors/Wikipedia-Vision-JA.",https://huggingface.co/datasets/turing-motors/Wikipedia-Vision-JA,['ja'],['image-to-text'],['1M<n<10M']
yehzw/JGLUE,yehzw,2024-08-19 11:31:36+00:00,2024-08-21 08:47:59+00:00,50,0,"['language:ja', 'size_categories:100K<n<1M', 'format:parquet', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']",,https://huggingface.co/datasets/yehzw/JGLUE,['ja'],[],['100K<n<1M']
liboaccn/MIT-10M,liboaccn,2024-08-21 17:37:55+00:00,2025-03-13 03:09:43+00:00,42,9,"['task_categories:translation', 'task_categories:image-to-text', 'language:en', 'language:zh', 'language:pt', 'language:ja', 'language:fr', 'language:es', 'language:it', 'language:de', 'language:ru', 'language:ar', 'language:ko', 'language:tr', 'language:th', 'language:hi', 'license:apache-2.0', 'size_categories:10M<n<100M', 'format:json', 'modality:tabular', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","
	
		
		MIT-10M
	

Paper: https://aclanthology.org/2025.coling-main.346/
Introduction:
Image Translation (IT) holds immense potential across diverse domains, enabling the translation of textual content within images into various languages.
However, existing datasets often suffer from limitations in scale, diversity, and quality, hindering the development and evaluation of IT models.
To address this issue, we introduce MIT-10M, a large-scale parallel corpus of multilingual image translation… See the full description on the dataset page: https://huggingface.co/datasets/liboaccn/MIT-10M.",https://huggingface.co/datasets/liboaccn/MIT-10M,"['en', 'zh', 'pt', 'ja', 'fr', 'es', 'it', 'de', 'ru', 'ar', 'ko', 'tr', 'th', 'hi']","['translation', 'image-to-text']",['10M<n<100M']
jniimi/weather_forecast_japan,jniimi,2024-08-22 11:37:59+00:00,2025-10-13 03:08:17+00:00,2092,2,"['task_categories:tabular-regression', 'task_categories:tabular-classification', 'language:ja', 'language:en', 'license:cc-by-4.0', 'size_categories:100K<n<1M', 'format:parquet', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us', 'climate']","
	
		
		Overview
	

This dataset contains daily-collected weather forecasts for up to seven days ahead for all the meteorological observatories in Japan, published by the Japan Meteorological Agency (JMA) at https://www.jma.go.jp/bosai/forecast/. 
We collect, structurize, and accumulate the prediction since the page is overridden whenever the information is updated. 
The data is automatically updated daily using GitHub Actions. Since the actual forecasts are published multiple times a day, we… See the full description on the dataset page: https://huggingface.co/datasets/jniimi/weather_forecast_japan.",https://huggingface.co/datasets/jniimi/weather_forecast_japan,"['ja', 'en']","['tabular-regression', 'tabular-classification']",['100K<n<1M']
jlli/JDocQA-binary,jlli,2024-08-23 00:34:44+00:00,2024-09-24 18:53:36+00:00,28,0,"['language:ja', 'size_categories:1K<n<10K', 'format:parquet', 'modality:image', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']",,https://huggingface.co/datasets/jlli/JDocQA-binary,['ja'],[],['1K<n<10K']
jlli/JDocQA-nonbinary,jlli,2024-08-23 00:35:07+00:00,2024-09-24 18:53:10+00:00,43,0,"['language:ja', 'size_categories:1K<n<10K', 'format:parquet', 'modality:image', 'modality:text', 'library:datasets', 'library:dask', 'library:mlcroissant', 'library:polars', 'region:us']",,https://huggingface.co/datasets/jlli/JDocQA-nonbinary,['ja'],[],['1K<n<10K']
stanford-oval/wikipedia,stanford-oval,2024-08-23 07:39:01+00:00,2025-04-29 09:35:09+00:00,6374,11,"['task_categories:text-retrieval', 'task_categories:text-generation', 'language:en', 'language:fr', 'language:de', 'language:es', 'language:ja', 'language:ru', 'language:pt', 'language:zh', 'language:it', 'language:ar', 'language:fa', 'language:pl', 'language:nl', 'language:uk', 'language:he', 'language:id', 'language:tr', 'language:cs', 'language:sv', 'language:ko', 'language:fi', 'language:vi', 'language:hu', 'language:ca', 'language:th', 'size_categories:100M<n<1B', 'format:parquet', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'arxiv:2305.14292', 'arxiv:2406.00562', 'region:us']","This dataset contains preprocessed and chunked Wikipedia HTML dumps from 25 languages.
Refer to the following for more information:
GitHub repository: https://github.com/stanford-oval/WikiChat
Papers:

WikiChat: Stopping the Hallucination of Large Language Model Chatbots by Few-Shot Grounding on Wikipedia
SPAGHETTI: Open-Domain Question Answering from Heterogeneous Data Sources with Retrieval and Semantic Parsing


    
    
        WikiChat
        
        
            

    Stopping the… See the full description on the dataset page: https://huggingface.co/datasets/stanford-oval/wikipedia.",https://huggingface.co/datasets/stanford-oval/wikipedia,"['en', 'fr', 'de', 'es', 'ja', 'ru', 'pt', 'zh', 'it', 'ar', 'fa', 'pl', 'nl', 'uk', 'he', 'id', 'tr', 'cs', 'sv', 'ko', 'fi', 'vi', 'hu', 'ca', 'th']","['text-retrieval', 'text-generation']",['100M<n<1B']
stanford-oval/wikipedia_20240801_10-languages_bge-m3_qdrant_index,stanford-oval,2024-08-24 04:29:31+00:00,2024-08-24 12:21:47+00:00,185,3,"['task_categories:text-retrieval', 'language:en', 'language:de', 'language:it', 'language:fa', 'language:ru', 'language:zh', 'language:pt', 'language:fr', 'language:es', 'language:ja', 'size_categories:100M<n<1B', 'arxiv:2305.14292', 'arxiv:2406.00562', 'region:us']","This repository contains a Qdrant index created from preprocessed and chunked Wikipedia HTML dumps from 10 languages. The embedding model used is BAAI/bge-m3
This index is compatible with WikiChat v2.0.
Refer to the following for more information:
GitHub repository: https://github.com/stanford-oval/WikiChat
Papers:

WikiChat: Stopping the Hallucination of Large Language Model Chatbots by Few-Shot Grounding on Wikipedia
SPAGHETTI: Open-Domain Question Answering from Heterogeneous Data Sources… See the full description on the dataset page: https://huggingface.co/datasets/stanford-oval/wikipedia_20240801_10-languages_bge-m3_qdrant_index.",https://huggingface.co/datasets/stanford-oval/wikipedia_20240801_10-languages_bge-m3_qdrant_index,"['en', 'de', 'it', 'fa', 'ru', 'zh', 'pt', 'fr', 'es', 'ja']",['text-retrieval'],['100M<n<1B']
KaraKaraWitch/AnimuSubtitle-JP,KaraKaraWitch,2024-08-24 14:02:38+00:00,2025-02-27 13:47:42+00:00,556,3,"['task_categories:text-classification', 'task_categories:text-generation', 'task_categories:text2text-generation', 'language:ja', 'license:odc-by', 'region:us', 'subtitles']","

	
		
		KaraKaraWitch/AnimuSubtitle-JP
	

This dataset is an extract of Subtitles from anime. The original files are sourced from nyaa.si.

	
		
		Folders
	


data (Deprecated)
data_ass (Extracted .ass subtitles from <SOURCE A>)
data_TS (Extracted arib subtitles from <SOURCE B>)


	
		
		Dataset Format
	

Dataset is in Advanced SubStation Alpha (colloquially known as as ASS) SSA/ASS Specs.
If you're looking for programmatic access, you may parse the file with this python library.
import ass… See the full description on the dataset page: https://huggingface.co/datasets/KaraKaraWitch/AnimuSubtitle-JP.",https://huggingface.co/datasets/KaraKaraWitch/AnimuSubtitle-JP,['ja'],"['text-classification', 'text-generation', 'text2text-generation']",[]
team-hatakeyama-phase2/LLMChat,team-hatakeyama-phase2,2024-08-25 10:27:23+00:00,2024-08-28 16:01:48+00:00,28,4,"['task_categories:text-classification', 'task_categories:text-generation', 'language:ja', 'license:other', 'size_categories:1K<n<10K', 'format:json', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","
	
		
		LLMChat
	


	
		
		概要
	

GENIAC 松尾研 LLM開発プロジェクトで開発したモデルを人手評価するために構築したLLMChatというシステムで収集された質問とLLMの回答、及び人手評価のデータです。
このシステムはChatbot Arenaと同様に、ユーザーが質問を入力するとランダムな2つのLLMからそれぞれ回答が出力され、人間がその2つの出力のどちらが良いか（あるいはどちらも悪い、どちらも良い）を評価するもので、2024年8月19日から2024年8月25日まで運用されました。詳細についてはこちらの記事をご確認ください。
データ件数: 2139件

	
		
		参加モデルの一覧
	

本システムにおける回答の生成には以下の13種類のモデルが参加しました。

weblab-GENIAC/Tanuki-8B-dpo-v1.0
team-hatakeyama-phase2/Tanuki-8x8B-dpo-v1.0
cyberagent/calm3-22b-chat
karakuri-ai/karakuri-lm-8x7b-chat-v0.1… See the full description on the dataset page: https://huggingface.co/datasets/team-hatakeyama-phase2/LLMChat.",https://huggingface.co/datasets/team-hatakeyama-phase2/LLMChat,['ja'],"['text-classification', 'text-generation']",['1K<n<10K']
Nikity/Pornhub,Nikity,2024-08-26 11:16:06+00:00,2024-08-26 15:01:52+00:00,375,42,"['language:sq', 'language:ar', 'language:bn', 'language:bg', 'language:zh', 'language:hr', 'language:cs', 'language:da', 'language:nl', 'language:en', 'language:et', 'language:fi', 'language:fr', 'language:de', 'language:el', 'language:he', 'language:hi', 'language:hu', 'language:id', 'language:it', 'language:ja', 'language:ko', 'language:lv', 'language:lt', 'language:mk', 'language:ml', 'language:mr', 'language:ne', 'language:no', 'language:fa', 'language:pl', 'language:pt', 'language:pa', 'language:ro', 'language:ru', 'language:sk', 'language:sl', 'language:so', 'language:es', 'language:sw', 'language:sv', 'language:tl', 'language:ta', 'language:te', 'language:th', 'language:tr', 'language:uk', 'language:ur', 'language:vi', 'language:cy', 'license:odc-by', 'size_categories:100K<n<1M', 'format:csv', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us', 'not-for-all-audiences']","
	
		
		Pornhub Dataset
	

The Pornhub Dataset provides a comprehensive collection of data sourced from pornhub.com, encompassing various details from MANYYY videos available on the platform.
The file consists of 742.133 lines of videos.

	
		
		Data Description
	


Delimiter: ‽
File Format: CSV
Content:
URL: The URL of the video.
Category: The genre or category of the video.
User: The username of the uploader.
Video_title: The title of the video.
Views: The number of views the video has… See the full description on the dataset page: https://huggingface.co/datasets/Nikity/Pornhub.",https://huggingface.co/datasets/Nikity/Pornhub,"['sq', 'ar', 'bn', 'bg', 'zh', 'hr', 'cs', 'da', 'nl', 'en', 'et', 'fi', 'fr', 'de', 'el', 'he', 'hi', 'hu', 'id', 'it', 'ja', 'ko', 'lv', 'lt', 'mk', 'ml', 'mr', 'ne', 'no', 'fa', 'pl', 'pt', 'pa', 'ro', 'ru', 'sk', 'sl', 'so', 'es', 'sw', 'sv', 'tl', 'ta', 'te', 'th', 'tr', 'uk', 'ur', 'vi', 'cy']",[],['100K<n<1M']
lightblue/text_ratings,lightblue,2024-08-27 05:40:39+00:00,2024-08-29 09:57:53+00:00,233,4,"['language:am', 'language:ar', 'language:bg', 'language:bn', 'language:cs', 'language:da', 'language:de', 'language:el', 'language:en', 'language:es', 'language:fa', 'language:fi', 'language:fr', 'language:gu', 'language:ha', 'language:hi', 'language:hu', 'language:id', 'language:it', 'language:ja', 'language:jv', 'language:kn', 'language:ko', 'language:lt', 'language:mr', 'language:nl', 'language:no', 'language:yo', 'language:zh', 'language:pl', 'language:pt', 'language:ro', 'language:ru', 'language:sk', 'language:sv', 'language:sw', 'language:ta', 'language:te', 'language:th', 'language:tr', 'language:uk', 'language:ur', 'language:vi', 'language:tl', 'license:mit', 'size_categories:1M<n<10M', 'format:parquet', 'modality:tabular', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","Todo - Write dataset card
",https://huggingface.co/datasets/lightblue/text_ratings,"['am', 'ar', 'bg', 'bn', 'cs', 'da', 'de', 'el', 'en', 'es', 'fa', 'fi', 'fr', 'gu', 'ha', 'hi', 'hu', 'id', 'it', 'ja', 'jv', 'kn', 'ko', 'lt', 'mr', 'nl', 'no', 'yo', 'zh', 'pl', 'pt', 'ro', 'ru', 'sk', 'sv', 'sw', 'ta', 'te', 'th', 'tr', 'uk', 'ur', 'vi', 'tl']",[],['1M<n<10M']
deepghs/arknights_voices_jp,deepghs,2024-08-27 15:41:13+00:00,2024-08-28 04:16:00+00:00,53,2,"['task_categories:automatic-speech-recognition', 'task_categories:audio-classification', 'language:ja', 'license:other', 'size_categories:10K<n<100K', 'format:parquet', 'modality:tabular', 'modality:text', 'modality:audio', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us', 'audio', 'text', 'voice', 'anime', 'arknights']","
	
		
		JP Voice-Text Dataset for Arknights Waifus
	

This is the JP voice-text dataset for arknights playable characters. Very useful for fine-tuning or evaluating ASR/ASV models.
Only the voices with strictly one voice actor is maintained here to reduce the noise of this dataset.
10905 records, 26.3 hours in total. Average duration is approximately 8.7s.

	
		
id
char_id
voice_actor_name
voice_title
voice_text
time
sample_rate
file_size
filename
mimetype
file_url


		
char_427_vigil_CN_001… See the full description on the dataset page: https://huggingface.co/datasets/deepghs/arknights_voices_jp.",https://huggingface.co/datasets/deepghs/arknights_voices_jp,['ja'],"['automatic-speech-recognition', 'audio-classification']",['10K<n<100K']
YANS-official/senryu-test-with-references,YANS-official,2024-08-28 18:47:38+00:00,2024-08-31 15:07:22+00:00,42,0,"['task_categories:image-to-text', 'language:ja', 'size_categories:n<1K', 'format:imagefolder', 'modality:image', 'modality:text', 'library:datasets', 'library:mlcroissant', 'region:us']","
	
		
		読み込み方
	

from datasets import load_dataset

dataset = load_dataset(""YANS-official/senryu-test"", split=""test"")


	
		
		概要
	

川柳投稿サイトの『写真川柳』と『川柳投稿まるせん』のクロールデータです。
以下のページからクロールし、原本のHTMLファイルと構造化処理を行った結果を格納しました。

https://www.homemate-research.com/senryu/photo/
https://marusenryu.com/

このデータは以下の2タスクが含まれます。  

image_to_text: 画像でお題が渡され、それに対する回答を返します。  
text_to_text: テキストでお題が渡され、それに対する回答を返します。

それぞれの量は以下の通りです。

	
		
タスク
お題数（画像枚数）
回答数
うち委員が用意したお題


		
image_to_text
70
140
7


text_to_text
30
60… See the full description on the dataset page: https://huggingface.co/datasets/YANS-official/senryu-test-with-references.",https://huggingface.co/datasets/YANS-official/senryu-test-with-references,['ja'],['image-to-text'],['n<1K']
YANS-official/senryu-marusen,YANS-official,2024-08-28 18:49:03+00:00,2024-08-30 11:41:46+00:00,7,0,"['language:ja', 'size_categories:n<1K', 'format:json', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","
	
		
		読み込み方
	

from datasets import load_dataset

dataset = load_dataset(""YANS-official/senryu-marusen"", split=""train"")


	
		
		概要
	

月に1万句以上の投稿がある国内最大級の川柳投稿サイト『川柳投稿まるせん』のクロールデータです。以下のページからクロールし、原本のHTMLファイルと構造化処理を行った結果を格納しました。https://marusenryu.com/
YANSのハッカソン内での利用目的で公開しており、その他の用途への使用はお控えください。
データセットの件数は以下の通りです。

	
		
タスク
お題数
のべ回答数


		
text_to_text
376
5346


	


	
		
	
	
		データセットの各カラム説明
	


	
		
カラム名
型
例
概要


		
odai_id
str
senryu-marusen-27
お題のID


type
str
text_to_text… See the full description on the dataset page: https://huggingface.co/datasets/YANS-official/senryu-marusen.",https://huggingface.co/datasets/YANS-official/senryu-marusen,['ja'],[],['n<1K']
YANS-official/senryu-shashin,YANS-official,2024-08-28 18:50:08+00:00,2024-08-31 03:47:50+00:00,8,0,"['language:ja', 'size_categories:n<1K', 'format:imagefolder', 'modality:image', 'modality:text', 'library:datasets', 'library:mlcroissant', 'region:us']","
	
		
		読み込み方
	

from datasets import load_dataset

dataset = load_dataset(""YANS-official/senryu-shashin"", split=""train"")


	
		
		概要
	

株式会社東建コーポレーションが運営するホームメイト・リサーチによる『ホームメイト川柳大賞』のうち、お題が画像形式で提供される『写真川柳』に関するクロールデータです。以下のページからクロールし、原本のHTMLファイルと構造化処理を行った結果を格納しました。https://www.homemate-research.com/senryu/photo/
YANSのハッカソン内での利用目的で公開しており、その他の用途への使用はお控えください。
データセットの件数は以下の通りです。

	
		
タスク
お題数
のべ回答数


		
image_to_text
435
1767


	


	
		
	
	
		データセットの各カラム説明
	


	
		
カラム名
型
例
概要


		
odai_id
str… See the full description on the dataset page: https://huggingface.co/datasets/YANS-official/senryu-shashin.",https://huggingface.co/datasets/YANS-official/senryu-shashin,['ja'],[],['n<1K']
YANS-official/ogiri-debug,YANS-official,2024-08-30 04:18:35+00:00,2024-09-04 01:49:46+00:00,10,2,"['task_categories:image-to-text', 'language:ja', 'size_categories:n<1K', 'format:imagefolder', 'modality:image', 'modality:text', 'library:datasets', 'library:mlcroissant', 'region:us']","
	
		
		読み込み方
	

from datasets import load_dataset

dataset = load_dataset(""YANS-official/ogiri-debug"", split=""test"")


	
		
		概要
	

大喜利生成の動作確認用データセットです。以下の3タスクが含まれます。  

text_to_text: テキストでお題が渡され、それに対する回答を返します。
image_to_text: いわゆる「画像で一言」です。画像のみが渡されて、テキストによる回答を返します。
text_image_to_text: 画像中にテキストが書かれています。テキストの一部が空欄になっているので、そこに穴埋めする形で回答を返します。


	
		
		データセットの各カラム説明
	


	
		
カラム名
型
例
概要


		
odai_id
str
""origi-dummy-1""
お題のID


file_path
str
""dummy.png""
画像のファイル名


type
str
""text_to_text""… See the full description on the dataset page: https://huggingface.co/datasets/YANS-official/ogiri-debug.",https://huggingface.co/datasets/YANS-official/ogiri-debug,['ja'],['image-to-text'],['n<1K']
YANS-official/senryu-debug,YANS-official,2024-08-30 05:47:58+00:00,2024-09-04 01:49:15+00:00,10,0,"['task_categories:image-to-text', 'language:ja', 'size_categories:n<1K', 'format:imagefolder', 'modality:image', 'modality:text', 'library:datasets', 'library:mlcroissant', 'region:us']","
	
		
		読み込み方
	

from datasets import load_dataset

dataset = load_dataset(""YANS-official/senryu-debug"", split=""test"")


	
		
		概要
	

大喜利生成の動作確認用データセットです。以下の2タスクが含まれます。  

text_to_text: テキストでお題が渡され、それに対する回答を返します。
image_to_text: いわゆる「画像で一言」です。画像のみが渡されて、テキストによる回答を返します。


	
		
		データセットの各カラム説明
	


	
		
カラム名
型
例
概要


		
odai_id
str
""senryu-debug-1""
お題のID


file_path
str
""dummy.png""
画像のファイル名


type
str
""text_to_text""
""text_to_text"", ""image_to_text""のどれかが入っている。


odai
str
""機械学習川柳""… See the full description on the dataset page: https://huggingface.co/datasets/YANS-official/senryu-debug.",https://huggingface.co/datasets/YANS-official/senryu-debug,['ja'],['image-to-text'],['n<1K']
YukiTomita-CC/AKU-d_ms-0.5B-v0.1_dataset,YukiTomita-CC,2024-08-31 13:37:35+00:00,2024-09-15 12:33:54+00:00,35,3,"['task_categories:text-generation', 'language:ja', 'license:other', 'size_categories:10M<n<100M', 'format:text', 'modality:text', 'library:datasets', 'library:mlcroissant', 'region:us']","
	
		
		AKU-d_ms-0.5B-v0.1_dataset
	


	
		
		Overview
	

このリポジトリは、私の開発しているAKUシリーズの1つ目となる、AKU-d_ms-0.5B-chat-v0.1の事前学習に使用したテキストデータを集めています。
これには次で説明するように複数の公開データセットから作成したテキストファイルが含まれており、それぞれのライセンスや著作権は各データセットに従います。また、各データセットに対する処理スクリプトは、上記GitHubリポジトリ内にて公開しています。
合計トークン数は 1.56 B tokensとなります。(モデルに使用しているTokenizerによる計算)

	
		
	
	
		Each Dataset Description
	


	
		
Dataset Name
License
URL or Repository
token count


		
Accommodation Search Dialog Corpus (in Japanese)
CC-BY-4.0
GitHub
139,246… See the full description on the dataset page: https://huggingface.co/datasets/YukiTomita-CC/AKU-d_ms-0.5B-v0.1_dataset.",https://huggingface.co/datasets/YukiTomita-CC/AKU-d_ms-0.5B-v0.1_dataset,['ja'],['text-generation'],['10M<n<100M']
SakanaAI/ChouBun,SakanaAI,2024-09-02 04:15:52+00:00,2024-10-18 02:45:43+00:00,21,9,"['task_categories:question-answering', 'task_categories:summarization', 'language:ja', 'license:apache-2.0', 'size_categories:n<1K', 'format:parquet', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'arxiv:2410.13166', 'region:us', 'Long Context']","
	
		
		ChouBun
	


	
		
		Dataset Description
	

ChouBun is a benchmark for assessing LLMs' performance in long-context tasks in the Japanese language.
It is created and introduced in the paper An Evolved Universal Transformer Memory.
The benchmark includes documents from multiple websites and synthetic question-answer pairs generated by GPT-4 variants and Claude-3.5-Sonnet.
The current version of ChouBun contains 2 task categories -- extractive QA and abstractive summarization -- and 4 tasks… See the full description on the dataset page: https://huggingface.co/datasets/SakanaAI/ChouBun.",https://huggingface.co/datasets/SakanaAI/ChouBun,['ja'],"['question-answering', 'summarization']",['n<1K']
joujiboi/bluemoon-fandom-1-1-rp-jp-translated,joujiboi,2024-09-02 12:56:09+00:00,2025-10-03 13:36:43+00:00,74,3,"['task_categories:text-generation', 'language:ja', 'license:gpl', 'size_categories:n<1K', 'format:parquet', 'modality:tabular', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us', 'roleplay', 'storywriting']","
	
		
		bluemoon-fandom-1-1-rp-jp-translated
	

A subset of Squish42/bluemoon-fandom-1-1-rp-cleaned translated to Japanese using command-r-08-2024.

	
		
		Misc. info
	


I used openrouter's api for inference with command-r-08-2024. Doing so is roughly 4x quicker than running the model locally, doesn't use up 95% of my vram, and doesn't make my 3090 as loud as my neighbours.
I decided to use command-r-08-2024 because it is completely uncensored for nsfw translation and provides translation… See the full description on the dataset page: https://huggingface.co/datasets/joujiboi/bluemoon-fandom-1-1-rp-jp-translated.",https://huggingface.co/datasets/joujiboi/bluemoon-fandom-1-1-rp-jp-translated,['ja'],['text-generation'],['n<1K']
allganize/RAG-Evaluation-Dataset-JA,allganize,2024-09-03 09:00:27+00:00,2024-09-13 00:53:44+00:00,214,33,"['language:ja', 'license:mit', 'size_categories:n<1K', 'format:csv', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","
	
		
		Allganize RAG Leaderboard とは
	

Allganize RAG Leaderboard は、5つの業種ドメイン（金融、情報通信、製造、公共、流通・小売）において、日本語のRAGの性能評価を実施したものです。一般的なRAGは簡単な質問に対する回答は可能ですが、図表の中に記載されている情報などに対して回答できないケースが多く存在します。RAGの導入を希望する多くの企業は、自社と同じ業種ドメイン、文書タイプ、質問形態を反映した日本語のRAGの性能評価を求めています。RAGの性能評価には、検証ドキュメントや質問と回答といったデータセット、検証環境の構築が必要となりますが、AllganizeではRAGの導入検討の参考にしていただきたく、日本語のRAG性能評価に必要なデータを公開いたしました。RAGソリューションは、Parser、Retrieval、Generation の3つのパートで構成されています。現在、この3つのパートを総合的に評価した日本語のRAG Leaderboardは存在していません。（公開時点）Allganize RAG… See the full description on the dataset page: https://huggingface.co/datasets/allganize/RAG-Evaluation-Dataset-JA.",https://huggingface.co/datasets/allganize/RAG-Evaluation-Dataset-JA,['ja'],[],['n<1K']
YANS-official/senryu-test,YANS-official,2024-09-03 15:02:47+00:00,2024-09-09 05:53:26+00:00,97,0,"['task_categories:image-to-text', 'language:ja', 'size_categories:n<1K', 'format:imagefolder', 'modality:image', 'modality:text', 'library:datasets', 'library:mlcroissant', 'region:us']","
	
		
		読み込み方
	

from datasets import load_dataset

dataset = load_dataset(""YANS-official/senryu-test"", split=""test"")


	
		
		概要
	

川柳投稿サイトの『写真川柳』と『川柳投稿まるせん』のクロールデータ、および YANS 委員が作成したデータを含みます。
以下のページからクロールし、原本のHTMLファイルと構造化処理を行った結果を格納しました。

https://www.homemate-research.com/senryu/photo/
https://marusenryu.com/

このデータは以下の2タスクが含まれます。  

image_to_text: 画像でお題が渡され、それに対する回答を返します。  
text_to_text: テキストでお題が渡され、それに対する回答を返します。

それぞれの量は以下の通りです。

	
		
タスク
お題数（画像枚数）


		
image_to_text
70


text_to_text
30… See the full description on the dataset page: https://huggingface.co/datasets/YANS-official/senryu-test.",https://huggingface.co/datasets/YANS-official/senryu-test,['ja'],['image-to-text'],['n<1K']
YANS-official/ogiri-test,YANS-official,2024-09-03 15:08:05+00:00,2024-09-09 05:53:54+00:00,55,0,"['task_categories:image-to-text', 'language:ja', 'size_categories:n<1K', 'format:imagefolder', 'modality:image', 'modality:text', 'library:datasets', 'library:mlcroissant', 'arxiv:2312.02439', 'region:us']","
	
		
		読み込み方
	

from datasets import load_dataset

dataset = load_dataset(""YANS-official/ogiri-test"", split=""test"")


	
		
		概要
	

大喜利投稿サイトBoketeのクロールデータです。元データは CLoT-Oogiri-Go [Zhang+ CVPR2024]というデータの一部です。
詳細はCVPRのプロジェクトページをご確認ください。  
このデータは以下の3タスクが含まれます。  

text_to_text: テキストでお題が渡され、それに対する回答を返します。
image_to_text: いわゆる「画像で一言」です。画像のみが渡されて、テキストによる回答を返します。
text_image_to_text: 画像中にテキストが書かれています。テキストの一部が空欄になっているので、そこに穴埋めする形で回答を返します。

それぞれの量は以下の通りです。

	
		
タスク
お題数（画像枚数）


		
image_to_text
56… See the full description on the dataset page: https://huggingface.co/datasets/YANS-official/ogiri-test.",https://huggingface.co/datasets/YANS-official/ogiri-test,['ja'],['image-to-text'],['n<1K']
werty1248/multilingual-instruct-balanced,werty1248,2024-09-06 17:04:15+00:00,2024-09-19 12:10:44+00:00,28,2,"['task_categories:text-generation', 'language:en', 'language:ko', 'language:ja', 'language:zh', 'size_categories:1M<n<10M', 'format:parquet', 'modality:tabular', 'modality:text', 'library:datasets', 'library:dask', 'library:mlcroissant', 'library:polars', 'region:us', 'not-for-all-audiences']","This repository is a collection of English, Korean, Chinese, and Japanese datasets collected by the HuggingFace Hub and transformed into a unified format. It consists of either native or synthetic data.
Some data is not clearly copyrighted or only allows non-commercial use.
Preprocessing: I removed data with too few answer tokens or more than 8192 tokens, and removed synthetic data with repetitions.
Balancing: I randomly sampled a subset of the data with different weights for each language and… See the full description on the dataset page: https://huggingface.co/datasets/werty1248/multilingual-instruct-balanced.",https://huggingface.co/datasets/werty1248/multilingual-instruct-balanced,"['en', 'ko', 'ja', 'zh']",['text-generation'],['1M<n<10M']
CohereLabsCommunity/multilingual-reward-bench,CohereLabsCommunity,2024-09-07 18:45:29+00:00,2025-07-23 03:38:25+00:00,752,32,"['language:ar', 'language:zh', 'language:cs', 'language:nl', 'language:fr', 'language:de', 'language:el', 'language:he', 'language:hi', 'language:id', 'language:it', 'language:ja', 'language:ko', 'language:fa', 'language:pl', 'language:pt', 'language:ro', 'language:ru', 'language:es', 'language:tr', 'language:uk', 'language:vi', 'license:odc-by', 'size_categories:10K<n<100K', 'format:parquet', 'modality:tabular', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'arxiv:2410.15522', 'doi:10.57967/hf/3352', 'region:us', 'rewardbench', 'cohere', 'aya-23', 'command-r']","
	
		
		Multilingual Reward Bench (v1.0)
	

Reward models (RMs) have driven the development of state-of-the-art LLMs today, with unprecedented impact across the globe. However, their performance in multilingual settings still remains understudied. 
In order to probe reward model behavior on multilingual data, we present M-RewardBench, a benchmark for 23 typologically diverse languages. 
M-RewardBench contains prompt-chosen-rejected preference triples obtained by curating and translating chat… See the full description on the dataset page: https://huggingface.co/datasets/CohereLabsCommunity/multilingual-reward-bench.",https://huggingface.co/datasets/CohereLabsCommunity/multilingual-reward-bench,"['ar', 'zh', 'cs', 'nl', 'fr', 'de', 'el', 'he', 'hi', 'id', 'it', 'ja', 'ko', 'fa', 'pl', 'pt', 'ro', 'ru', 'es', 'tr', 'uk', 'vi']",[],['10K<n<100K']
nazimali/quran,nazimali,2024-09-08 18:50:07+00:00,2024-09-08 18:58:17+00:00,153,12,"['task_categories:text-classification', 'task_categories:token-classification', 'task_categories:translation', 'task_categories:feature-extraction', 'task_categories:text-generation', 'multilinguality:monolingual', 'multilinguality:multilingual', 'language:sq', 'language:ber', 'language:ar', 'language:am', 'language:az', 'language:bn', 'language:bs', 'language:bg', 'language:zh', 'language:cs', 'language:dv', 'language:nl', 'language:en', 'language:fr', 'language:de', 'language:ha', 'language:hi', 'language:id', 'language:it', 'language:ja', 'language:ko', 'language:ku', 'language:ms', 'language:ml', 'language:no', 'language:ps', 'language:fa', 'language:pl', 'language:pt', 'language:ro', 'language:ru', 'language:sd', 'language:so', 'language:es', 'language:sw', 'language:sv', 'language:tg', 'language:ta', 'language:tt', 'language:th', 'language:tr', 'language:ur', 'language:ug', 'language:uz', 'license:cc-by-3.0', 'size_categories:1K<n<10K', 'format:parquet', 'modality:tabular', 'modality:text', 'library:datasets', 'library:dask', 'library:mlcroissant', 'library:polars', 'region:us', 'islam', 'quran', 'translations']","
	
		
		Dataset Card for the Quran
	


	
		
		Summary
	

The Quran with metadata, translations, and multiple Arabic text (can use specific types for embeddings, search, classification, and display). There are 126+ columns containing 43+ languages.

	
		
		TODO
	


 Add Tafsirs  
 Add topics/ontology


	
		
		Usage
	

from datasets import load_dataset

ds = load_dataset(""nazimali/quran"", split=""train"")
ds

Output:
Dataset({
    features: ['surah', 'ayah', 'surah-name', 'surah-total-ayas'… See the full description on the dataset page: https://huggingface.co/datasets/nazimali/quran.",https://huggingface.co/datasets/nazimali/quran,"['sq', 'ber', 'ar', 'am', 'az', 'bn', 'bs', 'bg', 'zh', 'cs', 'dv', 'nl', 'en', 'fr', 'de', 'ha', 'hi', 'id', 'it', 'ja', 'ko', 'ku', 'ms', 'ml', 'no', 'ps', 'fa', 'pl', 'pt', 'ro', 'ru', 'sd', 'so', 'es', 'sw', 'sv', 'tg', 'ta', 'tt', 'th', 'tr', 'ur', 'ug', 'uz']","['text-classification', 'token-classification', 'translation', 'feature-extraction', 'text-generation']",['1K<n<10K']
anusfoil/NeuroPiano-data,anusfoil,2024-09-10 02:18:13+00:00,2025-02-28 10:14:29+00:00,14,6,"['task_categories:audio-classification', 'language:ja', 'language:en', 'license:mit', 'size_categories:1K<n<10K', 'format:parquet', 'modality:audio', 'modality:text', 'library:datasets', 'library:dask', 'library:mlcroissant', 'library:polars', 'arxiv:2410.03139', 'region:us', 'music']","
	
		
		Dataset Card for NeuroPiano-data
	



This dataset contains 2255 entries of audio-question-answer pairs that specializes in music education. Questions ranges from cleaness of attack to hands balancing, each one come with verbal response as well as a rating within 6. There are 104 unique student recordings of piano excercises and part of them are rated by multiple teachers.

	
		
		Dataset Details
	


	
		
		Dataset Description
	





Curated by: Hayato Nishioka, Vincent Cheung, Huan… See the full description on the dataset page: https://huggingface.co/datasets/anusfoil/NeuroPiano-data.",https://huggingface.co/datasets/anusfoil/NeuroPiano-data,"['ja', 'en']",['audio-classification'],['1K<n<10K']
DataPilot/Generated-dataset-by-deepseek-v2.5,DataPilot,2024-09-11 10:38:57+00:00,2024-09-11 12:20:29+00:00,22,0,"['language:ja', 'license:other', 'size_categories:n<1K', 'format:json', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","
	
		
		概要
	

このデータセットはnull-instruct-jaとDeepSeek-v2.5のq4を用いて合成されました。
ollamaとA5000*7基を使い２時間７分で作成されました。(使用時VRAMは合計で136GBでした。)

	
		
		ライセンス
	

このデータセットはdeepseekのライセンスに基づきます。
deepseekのライセンス → https://github.com/deepseek-ai/DeepSeek-V2/blob/main/LICENSE-MODEL

	
		
		謝辞
	

Deepseek-aiとnull-instruct-jaの開発者さんのGooglefanさんに感謝します。
また、機材を貸してくれているMDLの皆様にも感謝を申し上げます
",https://huggingface.co/datasets/DataPilot/Generated-dataset-by-deepseek-v2.5,['ja'],[],['n<1K']
DataPilot/in-foxhound-ja,DataPilot,2024-09-13 04:27:59+00:00,2024-09-13 04:32:51+00:00,13,1,"['language:ja', 'license:apache-2.0', 'size_categories:1K<n<10K', 'format:parquet', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","
	
		
		概要
	

このデータセットはglaive-aiが公開しているin-foxhoundをKUJIRAを用いて日本語に翻訳したものになります。

	
		
		内容
	

このデータセットは主に投資やバークシャーハサウェイ、ウォーレン・バフェットについて書かれているinstructionデータセットになります。

	
		
		謝辞
	

翻訳するための計算資源を貸して下さいったMDLのみなさまに感謝を申し上げます。
",https://huggingface.co/datasets/DataPilot/in-foxhound-ja,['ja'],[],['1K<n<10K']
lightblue/kurage_training_data,lightblue,2024-09-13 10:01:31+00:00,2024-09-16 08:03:51+00:00,38,6,"['language:ar', 'language:en', 'language:es', 'language:hi', 'language:id', 'language:ja', 'language:ko', 'language:ru', 'language:sw', 'language:th', 'language:vi', 'language:zh', 'license:mit', 'size_categories:10K<n<100K', 'format:json', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']",,https://huggingface.co/datasets/lightblue/kurage_training_data,"['ar', 'en', 'es', 'hi', 'id', 'ja', 'ko', 'ru', 'sw', 'th', 'vi', 'zh']",[],['10K<n<100K']
googlefan/guanaco-jp-audio,googlefan,2024-09-13 13:45:44+00:00,2024-09-17 09:37:04+00:00,10,1,"['language:ja', 'size_categories:10K<n<100K', 'format:parquet', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']",,https://huggingface.co/datasets/googlefan/guanaco-jp-audio,['ja'],[],['10K<n<100K']
weblab-GENIAC/jhellaswag,weblab-GENIAC,2024-09-15 10:06:37+00:00,2024-10-08 06:15:15+00:00,6,0,"['language:ja', 'license:mit', 'size_categories:n<1K', 'format:json', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","
	
		
		jHellaSwagのデータセットカード
	


	
		
		データセット情報
	

HellaSwagから""split_type""が""indomain""と""zeroshot""のものをそれぞれランダムに50サンプル、計100サンプル抽出し、日本語に翻訳したものです。
ファイルサイズ: 162 kB
サンプルの例は以下のようになります。なお、この例のendingsは長くなっているため、一部省略しています。
{
    ""ind"": 4,
    ""activity_label"": ""Removing ice from car"",
    ""ctx_a"": ""Then, the man writes over the snow covering the window of a car, and a woman wearing winter clothes smiles."",
    ""ctx_b"": ""then"",
    ""ctx"": ""Then, the man writes over the snow covering the window of a car… See the full description on the dataset page: https://huggingface.co/datasets/weblab-GENIAC/jhellaswag.",https://huggingface.co/datasets/weblab-GENIAC/jhellaswag,['ja'],[],['n<1K']
howdyaendra/xblock-social-screenshots,howdyaendra,2024-09-16 12:56:26+00:00,2024-12-17 23:57:22+00:00,8,0,"['language:en', 'language:pt', 'language:ja', 'size_categories:1K<n<10K', 'region:us', 'not-for-all-audiences']","This dataset contains several thousand screenshots from multiple social media
platforms, collected via user reports from the
XBlock screenshot labelling
service.
Please see screenshots.csv for metadata on each post.
This dataset is provided as a service to help facilitate the creation of tools
and services for the purpose of content moderation.
Note that this is tagged not-for-all-audiences as many images in the dataset
contain adult imagery due to the nature of Bluesky's firehose.
Screenshots… See the full description on the dataset page: https://huggingface.co/datasets/howdyaendra/xblock-social-screenshots.",https://huggingface.co/datasets/howdyaendra/xblock-social-screenshots,"['en', 'pt', 'ja']",[],['1K<n<10K']
weblab-GENIAC/jarc,weblab-GENIAC,2024-09-16 18:03:03+00:00,2024-10-15 01:46:40+00:00,10,0,"['language:ja', 'license:cc-by-sa-4.0', 'size_categories:n<1K', 'format:json', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'arxiv:1803.05457', 'region:us']","
	
		
		jarcのデータセットカード
	


	
		
		データセット情報
	

ARC-Challengeからランダムに50サンプル、ARC-Easyからランダムに50サンプルの計100サンプル抽出し、日本語に翻訳したものです。
ファイルサイズ: 65.7 kB
サンプルの例は以下のようになります。
{
        ""id"": ""Mercury_7137165"",
        ""question"": ""物体の加速に最も影響を与えるのはどの特徴ですか？"",
        ""choices"": {
            ""text"": [
                ""質量"",
                ""速さ"",
                ""質感"",
                ""体積""
            ],
            ""label"": [
                ""A"",
                ""B"",
                ""C"",
                ""D""… See the full description on the dataset page: https://huggingface.co/datasets/weblab-GENIAC/jarc.",https://huggingface.co/datasets/weblab-GENIAC/jarc,['ja'],[],['n<1K']
googlefan/kusanagi-audio,googlefan,2024-09-17 04:14:30+00:00,2024-09-19 22:15:41+00:00,25,1,"['language:ja', 'size_categories:100K<n<1M', 'format:parquet', 'modality:text', 'library:datasets', 'library:dask', 'library:mlcroissant', 'library:polars', 'region:us']",,https://huggingface.co/datasets/googlefan/kusanagi-audio,['ja'],[],['100K<n<1M']
hpprc/llmjp-warp-html,hpprc,2024-09-18 02:41:06+00:00,2024-09-20 10:33:29+00:00,25,3,"['language:ja', 'license:cc-by-4.0', 'size_categories:100K<n<1M', 'format:parquet', 'modality:text', 'library:datasets', 'library:dask', 'library:mlcroissant', 'library:polars', 'region:us']","llm-jp-corpus-v3のwarp_htmlのうちlevel2フィルタリングされたデータをHFフォーマットに変換し、各データに付与されたURLから元記事のタイトルを取得可能なものについては取得して付与したデータセットです。
ライセンスは元ページに従いCC-BY 4.0とします。
",https://huggingface.co/datasets/hpprc/llmjp-warp-html,['ja'],[],['100K<n<1M']
hpprc/llmjp-kaken,hpprc,2024-09-18 02:50:21+00:00,2024-12-08 15:03:11+00:00,43,5,"['language:ja', 'license:cc-by-4.0', 'size_categories:1M<n<10M', 'format:parquet', 'modality:text', 'library:datasets', 'library:dask', 'library:mlcroissant', 'library:polars', 'region:us']","llm-jp-corpus-v3のkakenサブセットをHFフォーマットに変換し、各データに付与されたURLから元記事のタイトルを取得可能なものについては取得して付与したデータセットです。
ライセンスは元ページに従いCC-BY 4.0とします。
",https://huggingface.co/datasets/hpprc/llmjp-kaken,['ja'],[],['1M<n<10M']
weblab-GENIAC/jbbh,weblab-GENIAC,2024-09-18 11:49:07+00:00,2024-10-08 06:43:38+00:00,6,0,"['language:ja', 'license:mit', 'size_categories:n<1K', 'format:json', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'arxiv:2210.09261', 'region:us']","
	
		
		jBIG-Bench-Hardのデータセットカード
	


	
		
		データセット情報
	

BIG-Bench-Hardの23のサブセットから4サンプル、計92サンプルをランダムに抽出し、日本語に翻訳したものです。
BIG-Bench-Hardではサブセットごとにデータセットファイルが分割されていますが、本データセットでは、その情報をsubsetカラムに記載しています。
ファイルサイズ: 60.6 kB
サンプルの例は以下のようになります。
{
    ""id"": 42,
    ""subset"": ""movie_recommendation"",
    ""input"": ""レイダース/失われたアーク、ショーシャンクの空に、インセプション、パルプ・フィクションに似た映画を見つけてください。\n選択肢:\nA ポセイドン・アドベンチャー2\nB コーラス\nC フォレスト・ガンプ\nD ゾンビワールドへようこそ"",
    ""target"": ""C"",
}


	
		
	
	
		データ型
	


id: int64型
subset: string型… See the full description on the dataset page: https://huggingface.co/datasets/weblab-GENIAC/jbbh.",https://huggingface.co/datasets/weblab-GENIAC/jbbh,['ja'],[],['n<1K']
weblab-GENIAC/jwinogrande,weblab-GENIAC,2024-09-20 05:40:34+00:00,2024-10-15 01:45:44+00:00,5,0,"['language:ja', 'license:apache-2.0', 'size_categories:n<1K', 'format:json', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","
	
		
		jwinograndeのデータセットカード
	


	
		
		データセット情報
	

WinoGrandeから97サンプルをランダムに抽出し、日本語に翻訳したものです。
ファイルサイズ: 26.9 kB
サンプルの例は以下のようになります。
{
        ""sentence"": ""マイケルはマシューとは違って、仕事のために中国語を学ぶ必要がありました。なぜなら_はイギリスで働いていたためです。"",
        ""option1"": ""マイケル"",
        ""option2"": ""マシュー"",
        ""answer"": ""2""
    }


	
		
		ライセンス情報
	

apache-2.0

	
		
		引用文献
	

@InProceedings{ai2:winogrande,
title = {WinoGrande: An Adversarial Winograd Schema Challenge at Scale},
authors={Keisuke, Sakaguchi and Ronan, Le Bras and… See the full description on the dataset page: https://huggingface.co/datasets/weblab-GENIAC/jwinogrande.",https://huggingface.co/datasets/weblab-GENIAC/jwinogrande,['ja'],[],['n<1K']
hpprc/jawiki-yomi,hpprc,2024-09-20 09:58:08+00:00,2024-09-20 10:24:22+00:00,11,2,"['language:ja', 'license:cc-by-sa-4.0', 'size_categories:1K<n<10K', 'format:parquet', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']",,https://huggingface.co/datasets/hpprc/jawiki-yomi,['ja'],[],['1K<n<10K']
saillab/alpaca-japanese-cleaned,saillab,2024-09-20 23:21:58+00:00,2024-09-20 23:32:52+00:00,18,0,"['language:ja', 'size_categories:10K<n<100K', 'format:parquet', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","This repository contains the dataset used for the TaCo paper.
Please refer to the paper for more details: OpenReview
If you have used our dataset, please cite it as follows:
Citation
@inproceedings{upadhayay2024taco,
title={TaCo: Enhancing Cross-Lingual Transfer for Low-Resource Languages in {LLM}s through Translation-Assisted Chain-of-Thought Processes},
author={Bibek Upadhayay and Vahid Behzadan},
booktitle={5th Workshop on practical ML for limited/low resource settings, ICLR},
year={2024}… See the full description on the dataset page: https://huggingface.co/datasets/saillab/alpaca-japanese-cleaned.",https://huggingface.co/datasets/saillab/alpaca-japanese-cleaned,['ja'],[],['10K<n<100K']
kanhatakeyama/multiturn-conv-from-aozora-bunko,kanhatakeyama,2024-09-21 06:29:26+00:00,2024-09-21 06:48:07+00:00,11,2,"['language:ja', 'license:apache-2.0', 'size_categories:10K<n<100K', 'format:parquet', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","
	
		
		自動生成の対話データ
	

青空文庫からランダムに抜粋したテキストをもとに､Calm3-22B-chatで自動生成のマルチンターンデータを生成しました｡

生成コード
吾輩は猫である 限定ver


軽いクリーニング

",https://huggingface.co/datasets/kanhatakeyama/multiturn-conv-from-aozora-bunko,['ja'],[],['10K<n<100K']
if001/elementray_small,if001,2024-09-21 22:30:12+00:00,2024-09-28 08:08:24+00:00,6,0,"['language:ja', 'license:apache-2.0', 'size_categories:1K<n<10K', 'format:parquet', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","より多く作成したのがこっちhttps://huggingface.co/datasets/if001/elementray_m
calm3-22bを使って簡単な日本語の例文を作成したデータセットです。
以下のパターンが含まれるように一文を作成しています。
生成に失敗しているものはクリーニングしています。
    ""です/だ (肯定文)"",
    ""ではありません/じゃない (否定文)"",
    ""〜ます (動詞の丁寧形)"",
    ""〜ません (動詞の否定形)"",
    ""〜たい (希望・願望)"",
    ""〜ている (進行形)"",
    ""〜てください (依頼)"",
    ""〜てもいいですか (許可)"",
    ""〜なければなりません/〜なきゃいけない (義務)"",
    ""〜でしょう/〜だろう (推測)"",
    ""〜が好きです/嫌いです (好み)"",
    ""〜と思います (意見・思考)"",
    ""〜から/〜ので (理由)"",
    ""〜のが好きです/嫌いです (動作の好み)"",
    ""〜でしょうか (丁寧な質問)"",
    ""〜てしまう… See the full description on the dataset page: https://huggingface.co/datasets/if001/elementray_small.",https://huggingface.co/datasets/if001/elementray_small,['ja'],[],['1K<n<10K']
Aratako/Japanese-RP-Bench-testdata-SFW,Aratako,2024-09-22 06:25:01+00:00,2024-09-29 05:34:09+00:00,14,4,"['task_categories:text-generation', 'language:ja', 'license:other', 'size_categories:n<1K', 'format:json', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","
	
		
		Japanese-RP-Bench-testdata-SFW
	

本データセットは、LLMの日本語ロールプレイ能力を計測するベンチマークJapanese-RP-Bench用の評価データセットです。
ベンチマークの詳細については記事を参照してください。

	
		
		データの概要
	

本データは以下のようなキーを持ちます。

genre: ロールプレイのジャンル
tag: ロールプレイの年齢区分
world_setting: ロールプレイの世界観設定
scene_setting: ロールプレイのシーン設定
user_setting: ロールプレイのユーザー側キャラクター設定
assistant_setting: ロールプレイのアシスタント側キャラクター設定
dialogue_tone: ロールプレイの対話のトーン
first_user_input: ロールプレイの最初のユーザー発話
response_format: ロールプレイの応答形式
id: データのid


	
		
	
	
		ライセンス… See the full description on the dataset page: https://huggingface.co/datasets/Aratako/Japanese-RP-Bench-testdata-SFW.",https://huggingface.co/datasets/Aratako/Japanese-RP-Bench-testdata-SFW,['ja'],['text-generation'],['n<1K']
recursal/SuperWikiImage-7M,recursal,2024-09-23 05:27:05+00:00,2024-10-07 06:49:22+00:00,1434,19,"['task_categories:image-classification', 'task_categories:image-to-text', 'task_categories:text-to-image', 'task_categories:image-to-image', 'task_ids:language-modeling', 'task_ids:masked-language-modeling', 'annotations_creators:no-annotation', 'language_creators:crowdsourced', 'multilinguality:multilingual', 'source_datasets:original', 'language:af', 'language:ar', 'language:ast', 'language:az', 'language:be', 'language:bg', 'language:bn', 'language:ca', 'language:ce', 'language:cs', 'language:cy', 'language:da', 'language:de', 'language:el', 'language:en', 'language:eo', 'language:es', 'language:et', 'language:eu', 'language:fa', 'language:fi', 'language:fr', 'language:gl', 'language:he', 'language:hi', 'language:hr', 'language:hu', 'language:hy', 'language:id', 'language:it', 'language:ja', 'language:ka', 'language:kk', 'language:ko', 'language:la', 'language:lt', 'language:lv', 'language:mk', 'language:ms', 'language:my', 'language:nl', 'language:nn', 'language:no', 'language:pl', 'language:pt', 'language:ro', 'language:ru', 'language:sh', 'language:sk', 'language:sl', 'language:sr', 'language:sv', 'language:ta', 'language:tg', 'language:th', 'language:tr', 'language:uk', 'language:ur', 'language:uz', 'language:vi', 'language:zh', 'size_categories:10B<n<100B', 'region:us']","
	
		
		Dataset Card for SuperWikiImage (SWI)
	


Waifu to catch your attention.

	
		
		Dataset Details
	


	
		
		Dataset Description
	

Off from the presses of SuperWikipedia-NEXT comes SuperWikiImage: A ~15TiB (~7 Million) collection of images from wikipedia.

Curated by: KaraKaraWitch
Funded by: Recursal.ai
Shared by: KaraKaraWitch
Language(s) (NLP): Many. Refer to the data below for a list of languages.
License: Mixed. Refer to lower section on licensing


	
		
	
	
		Dataset Sources… See the full description on the dataset page: https://huggingface.co/datasets/recursal/SuperWikiImage-7M.",https://huggingface.co/datasets/recursal/SuperWikiImage-7M,"['af', 'ar', 'ast', 'az', 'be', 'bg', 'bn', 'ca', 'ce', 'cs', 'cy', 'da', 'de', 'el', 'en', 'eo', 'es', 'et', 'eu', 'fa', 'fi', 'fr', 'gl', 'he', 'hi', 'hr', 'hu', 'hy', 'id', 'it', 'ja', 'ka', 'kk', 'ko', 'la', 'lt', 'lv', 'mk', 'ms', 'my', 'nl', 'nn', 'no', 'pl', 'pt', 'ro', 'ru', 'sh', 'sk', 'sl', 'sr', 'sv', 'ta', 'tg', 'th', 'tr', 'uk', 'ur', 'uz', 'vi', 'zh']","['image-classification', 'image-to-text', 'text-to-image', 'image-to-image']",['10B<n<100B']
jbross-ibm-research/mgsm,jbross-ibm-research,2024-09-24 18:50:13+00:00,2024-09-24 21:01:33+00:00,1439,1,"['annotations_creators:found', 'language_creators:found', 'language_creators:expert-generated', 'multilinguality:multilingual', 'source_datasets:extended|gsm8k', 'language:en', 'language:es', 'language:fr', 'language:de', 'language:ru', 'language:zh', 'language:ja', 'language:th', 'language:sw', 'language:bn', 'language:ca', 'language:gl', 'language:eu', 'license:cc-by-sa-4.0', 'size_categories:1K<n<10K', 'format:parquet', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'arxiv:2110.14168', 'arxiv:2210.03057', 'region:us', 'math-word-problems']","
	
		
		Dataset Card for MGSM
	


	
		
		Dataset Summary
	

Copy and merge of this MGSM Dataset, Catalan version, Basque version, Galician version, but in training samples we removed the prompt formatting, e.g. removed Question: ... in question field or Answer: ... in answer field.
Multilingual Grade School Math Benchmark (MGSM) is a benchmark of grade-school math problems, proposed in the paper Language models are multilingual chain-of-thought reasoners.
The same 250 problems from GSM8K are… See the full description on the dataset page: https://huggingface.co/datasets/jbross-ibm-research/mgsm.",https://huggingface.co/datasets/jbross-ibm-research/mgsm,"['en', 'es', 'fr', 'de', 'ru', 'zh', 'ja', 'th', 'sw', 'bn', 'ca', 'gl', 'eu']",[],['1K<n<10K']
if001/elementray_m,if001,2024-09-25 11:22:31+00:00,2024-09-28 08:59:49+00:00,5,2,"['language:ja', 'license:apache-2.0', 'size_categories:10K<n<100K', 'format:parquet', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","calm3-22bを使って簡単な日本語の例文を作成したデータセットです。
以下のパターンが含まれるように一文を作成しています。
生成に失敗しているものはクリーニングしています。
    ""です/だ (肯定文)"",
    ""ではありません/じゃない (否定文)"",
    ""〜ます (動詞の丁寧形)"",
    ""〜ません (動詞の否定形)"",
    ""〜たい (希望・願望)"",
    ""〜ている (進行形)"",
    ""〜てください (依頼)"",
    ""〜てもいいですか (許可)"",
    ""〜なければなりません/〜なきゃいけない (義務)"",
    ""〜でしょう/〜だろう (推測)"",
    ""〜が好きです/嫌いです (好み)"",
    ""〜と思います (意見・思考)"",
    ""〜から/〜ので (理由)"",
    ""〜のが好きです/嫌いです (動作の好み)"",
    ""〜でしょうか (丁寧な質問)"",
    ""〜てしまう (完了・後悔)"",
    ""〜ながら (同時進行)"",
    ""〜ば/〜たら (仮定形)"",
    ""〜ておく (準備)""… See the full description on the dataset page: https://huggingface.co/datasets/if001/elementray_m.",https://huggingface.co/datasets/if001/elementray_m,['ja'],[],['10K<n<100K']
Davlan/xtreme-up-semantic-parsing,Davlan,2024-09-25 20:22:49+00:00,2024-09-25 20:43:28+00:00,62,0,"['task_categories:text-classification', 'multilinguality:multilingual', 'language:am', 'language:be', 'language:bn', 'language:de', 'language:en', 'language:es', 'language:fi', 'language:fr', 'language:ha', 'language:hi', 'language:hu', 'language:ja', 'language:pt', 'language:ru', 'language:sw', 'language:ta', 'language:th', 'language:tr', 'language:yo', 'language:zu', 'license:apache-2.0', 'size_categories:10K<n<100K', 'format:json', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us', 'xtreme-up', 'semantic parsing']","
	
		
		Dataset Card for afrixnli
	


	
		
		Dataset Summary
	

See XTREME-UP GitHub

	
		
		Languages
	

There are 20 languages available :

	
		
		Dataset Structure
	


	
		
		Data Instances
	

The examples look like this for English:
from datasets import load_dataset
data = load_dataset('Davlan/xtreme-up-semantic-parsing', 'yor') 
# Please, specify the language code
# A data point example is below:
{
""id"": ""3231323330393336"",
""split"": ""test"",
""intent"": ""IN:GET_REMINDER"",
""locale"": ""en""… See the full description on the dataset page: https://huggingface.co/datasets/Davlan/xtreme-up-semantic-parsing.",https://huggingface.co/datasets/Davlan/xtreme-up-semantic-parsing,"['am', 'be', 'bn', 'de', 'en', 'es', 'fi', 'fr', 'ha', 'hi', 'hu', 'ja', 'pt', 'ru', 'sw', 'ta', 'th', 'tr', 'yo', 'zu']",['text-classification'],['10K<n<100K']
kanhatakeyama/japanese-corpus-categorized,kanhatakeyama,2024-09-25 23:18:11+00:00,2024-09-28 01:36:48+00:00,99,3,"['language:ja', 'license:odbl', 'size_categories:100M<n<1B', 'format:json', 'modality:text', 'library:datasets', 'library:dask', 'library:mlcroissant', 'region:us']","
	
		
		日本語コーパス
	


mc4-jaなどのwebコーパスをクリーニング後､教師なし学習モデルでテキストを約1万件にクラスタリングしたコーパスです｡
著作権法で認められた情報解析目的で使用できます｡
一部のファイルしかparquet化されていないので､ご注意ください｡ファイルリストはoutフォルダ内にあります
git lfsなどでダウンロードください｡



",https://huggingface.co/datasets/kanhatakeyama/japanese-corpus-categorized,['ja'],[],['100M<n<1B']
borderlines/bordirlines,borderlines,2024-09-26 00:47:35+00:00,2025-06-10 00:00:42+00:00,46,8,"['task_categories:question-answering', 'annotations_creators:human', 'annotations_creators:machine-generated', 'language_creators:found', 'multilinguality:multilingual', 'source_datasets:manestay/borderlines', 'language:en', 'language:ar', 'language:es', 'language:fr', 'language:ru', 'language:hi', 'language:ms', 'language:sw', 'language:az', 'language:ko', 'language:pt', 'language:hy', 'language:th', 'language:uk', 'language:ur', 'language:sr', 'language:iw', 'language:ja', 'language:hr', 'language:tl', 'language:ky', 'language:vi', 'language:fa', 'language:tg', 'language:mg', 'language:nl', 'language:ne', 'language:uz', 'language:my', 'language:da', 'language:dz', 'language:id', 'language:is', 'language:tr', 'language:lo', 'language:sl', 'language:so', 'language:mn', 'language:bn', 'language:bs', 'language:ht', 'language:el', 'language:it', 'language:to', 'language:ka', 'language:sn', 'language:sq', 'language:zh', 'license:mit', 'arxiv:2410.01171', 'region:us']","
	
		
		BordIRLines Dataset
	

This is the dataset associated with the paper ""BordIRlines: A Dataset for Evaluating Cross-lingual Retrieval-Augmented Generation"" (link).
Code: https://github.com/manestay/bordIRlines

	
		
		Dataset Summary
	

The BordIRLines Dataset is an information retrieval (IR) dataset constructed from various language corpora. It contains queries and corresponding ranked docs along with their relevance scores. The dataset includes multiple languages, including English… See the full description on the dataset page: https://huggingface.co/datasets/borderlines/bordirlines.",https://huggingface.co/datasets/borderlines/bordirlines,"['en', 'ar', 'es', 'fr', 'ru', 'hi', 'ms', 'sw', 'az', 'ko', 'pt', 'hy', 'th', 'uk', 'ur', 'sr', 'iw', 'ja', 'hr', 'tl', 'ky', 'vi', 'fa', 'tg', 'mg', 'nl', 'ne', 'uz', 'my', 'da', 'dz', 'id', 'is', 'tr', 'lo', 'sl', 'so', 'mn', 'bn', 'bs', 'ht', 'el', 'it', 'to', 'ka', 'sn', 'sq', 'zh']",['question-answering'],[]
1-800-SHARED-TASKS/xlsum-subset,1-800-SHARED-TASKS,2024-09-26 13:08:59+00:00,2024-09-26 13:12:19+00:00,179,0,"['task_categories:summarization', 'task_categories:text-generation', 'annotations_creators:found', 'language_creators:found', 'multilinguality:multilingual', 'source_datasets:original', 'language:am', 'language:ar', 'language:az', 'language:bn', 'language:my', 'language:zh', 'language:en', 'language:fr', 'language:gu', 'language:ha', 'language:hi', 'language:ig', 'language:id', 'language:ja', 'language:rn', 'language:ko', 'language:ky', 'language:mr', 'language:ne', 'language:om', 'language:ps', 'language:fa', 'language:pcm', 'language:pt', 'language:pa', 'language:ru', 'language:gd', 'language:sr', 'language:si', 'language:so', 'language:es', 'language:sw', 'language:ta', 'language:te', 'language:th', 'language:ti', 'language:tr', 'language:uk', 'language:ur', 'language:uz', 'language:vi', 'language:cy', 'language:yo', 'license:cc-by-nc-sa-4.0', 'size_categories:n<1K', 'format:webdataset', 'modality:text', 'library:datasets', 'library:webdataset', 'library:mlcroissant', 'arxiv:1607.01759', 'region:us', 'conditional-text-generation']","
	
		
		Dataset Card for ""XL-Sum""
	


	
		
		Dataset Summary
	

We present XLSum, a comprehensive and diverse dataset comprising 1.35 million professionally  annotated article-summary pairs from BBC, extracted using a set of carefully designed heuristics. The dataset covers 45 languages ranging from low to high-resource, for many of which no public dataset is currently available. XL-Sum is highly abstractive, concise, and of high quality, as indicated by human and intrinsic evaluation.… See the full description on the dataset page: https://huggingface.co/datasets/1-800-SHARED-TASKS/xlsum-subset.",https://huggingface.co/datasets/1-800-SHARED-TASKS/xlsum-subset,"['am', 'ar', 'az', 'bn', 'my', 'zh', 'en', 'fr', 'gu', 'ha', 'hi', 'ig', 'id', 'ja', 'rn', 'ko', 'ky', 'mr', 'ne', 'om', 'ps', 'fa', 'pcm', 'pt', 'pa', 'ru', 'gd', 'sr', 'si', 'so', 'es', 'sw', 'ta', 'te', 'th', 'ti', 'tr', 'uk', 'ur', 'uz', 'vi', 'cy', 'yo']","['summarization', 'text-generation']",['n<1K']
ibm-research/AttaQ-JA,ibm-research,2024-09-27 00:04:13+00:00,2025-03-06 01:26:26+00:00,26,2,"['task_categories:question-answering', 'language:ja', 'license:cdla-permissive-2.0', 'size_categories:1K<n<10K', 'format:csv', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","
	
		
		AttaQ-JA Dataset Card
	

AttaQ red teaming dataset was designed to evaluate Large Language Models (LLMs) by assessing their tendency to generate harmful or undesirable responses, which consists of 1402 carefully crafted adversarial questions.
This AttaQ-JA dataset is a Japanese version of AttaQ, created by translating manually and carefully.

	
		
		Disclaimer:
	


The data contains offensive and upsetting content by nature, therefore it may not be easy to read. Please read them in… See the full description on the dataset page: https://huggingface.co/datasets/ibm-research/AttaQ-JA.",https://huggingface.co/datasets/ibm-research/AttaQ-JA,['ja'],['question-answering'],['1K<n<10K']
UniDataPro/llm-training-dataset,UniDataPro,2024-09-27 09:22:06+00:00,2025-04-04 11:17:30+00:00,14,3,"['task_categories:text-generation', 'task_categories:text-classification', 'language:uk', 'language:tr', 'language:th', 'language:sk', 'language:pt', 'language:pl', 'language:fa', 'language:nl', 'language:mr', 'language:ml', 'language:ko', 'language:ja', 'language:it', 'language:id', 'language:hu', 'language:hi', 'language:ga', 'language:el', 'language:de', 'language:fr', 'language:fi', 'language:es', 'language:en', 'language:da', 'language:cs', 'language:ca', 'language:az', 'language:ar', 'license:cc-by-nc-nd-4.0', 'size_categories:1K<n<10K', 'format:csv', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us', 'llm', 'llm fine-tuning ', 'finetuning ', 'logs', 'llm training', 'nlp', 'question answering']","
	
		
		LLM Fine-Tuning Dataset - 4,000,000+ logs, 32 languages
	

The dataset contains over 4 million+ logs written in 32 languages and is tailored for LLM training. It includes log and response pairs from 3 models, and is designed for language models and instruction fine-tuning to achieve improved performance in various NLP tasks - Get the data

	
		
	
	
		Models used for text generation:
	


GPT-3.5
GPT-4
Uncensored GPT Version (is not included inthe sample)


	
	
	
		Languages in the… See the full description on the dataset page: https://huggingface.co/datasets/UniDataPro/llm-training-dataset.",https://huggingface.co/datasets/UniDataPro/llm-training-dataset,"['uk', 'tr', 'th', 'sk', 'pt', 'pl', 'fa', 'nl', 'mr', 'ml', 'ko', 'ja', 'it', 'id', 'hu', 'hi', 'ga', 'el', 'de', 'fr', 'fi', 'es', 'en', 'da', 'cs', 'ca', 'az', 'ar']","['text-generation', 'text-classification']",['1K<n<10K']
AIR-Bench/qa_news_ja,AIR-Bench,2024-09-28 02:35:07+00:00,2024-09-28 04:13:40+00:00,73,0,"['task_categories:text-retrieval', 'task_ids:document-retrieval', 'multilinguality:monolingual', 'language:ja', 'size_categories:100K<n<1M', 'format:json', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","Available Versions:

AIR-Bench_24.05
Task / Domain / Language: qa / news / ja
Available Datasets (Dataset Name: Splits):
default: dev, test





",https://huggingface.co/datasets/AIR-Bench/qa_news_ja,['ja'],['text-retrieval'],['100K<n<1M']
AIR-Bench/qa_wiki_ja,AIR-Bench,2024-09-28 03:15:36+00:00,2024-09-28 04:18:44+00:00,9,0,"['task_categories:text-retrieval', 'task_ids:document-retrieval', 'multilinguality:monolingual', 'language:ja', 'size_categories:1M<n<10M', 'format:json', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","Available Versions:

AIR-Bench_24.05
Task / Domain / Language: qa / wiki / ja
Available Datasets (Dataset Name: Splits):
default: dev, test





",https://huggingface.co/datasets/AIR-Bench/qa_wiki_ja,['ja'],['text-retrieval'],['1M<n<10M']
AIR-Bench/qa_web_ja,AIR-Bench,2024-09-28 04:00:52+00:00,2024-09-28 04:22:05+00:00,10,0,"['task_categories:text-retrieval', 'task_ids:document-retrieval', 'multilinguality:monolingual', 'language:ja', 'size_categories:100K<n<1M', 'format:json', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","Available Versions:

AIR-Bench_24.05
Task / Domain / Language: qa / web / ja
Available Datasets (Dataset Name: Splits):
default: dev, test





",https://huggingface.co/datasets/AIR-Bench/qa_web_ja,['ja'],['text-retrieval'],['100K<n<1M']
PedoIsGay/Takuya,PedoIsGay,2024-09-28 07:05:30+00:00,2024-09-28 07:06:55+00:00,4,0,"['task_categories:text-classification', 'language:ja', 'license:mit', 'region:us']",,https://huggingface.co/datasets/PedoIsGay/Takuya,['ja'],['text-classification'],[]
deepghs/e621-2024_index,deepghs,2024-09-28 12:07:23+00:00,2024-12-03 08:16:20+00:00,61,1,"['task_categories:image-classification', 'task_categories:image-to-image', 'task_categories:text-to-image', 'language:en', 'language:ja', 'license:mit', 'size_categories:1M<n<10M', 'region:us']","Tar index files for boxingscorpionbagel/e621-2024.
You can download images from both boxingscorpionbagel/e621-2024 and deepghs/e621_newest with cheesechaser.
from cheesechaser.datapool import E621NewestDataPool

pool = E621NewestDataPool()

# download e621 #2010000-2010300, to directory /data/e621
pool.batch_download_to_directory(
    resource_ids=range(2010000, 2010300),
    dst_dir='/data/e621',
    max_workers=12,
)

",https://huggingface.co/datasets/deepghs/e621-2024_index,"['en', 'ja']","['image-classification', 'image-to-image', 'text-to-image']",['1M<n<10M']
deepghs/e621_newest,deepghs,2024-09-30 18:12:08+00:00,2025-08-08 17:34:12+00:00,11,3,"['task_categories:image-classification', 'task_categories:zero-shot-image-classification', 'task_categories:text-to-image', 'annotations_creators:no-annotation', 'source_datasets:e621', 'language:en', 'language:ja', 'license:other', 'size_categories:100K<n<1M', 'region:us', 'art', 'anime', 'not-for-all-audiences']","
	
		
		E621 Dataset Newest Supplement
	

This is the newest supplement dataset of e621.net. And only the newest data are up-to-date-ly maintained here, to make sure you can get all the newest data from huggingface instead of e621 site.
If you are looking for some old data, just see: boxingscorpionbagel/e621-2024
All the file types we kept in this dataset: gif, jpg, mp4, png, swf, webm

	
		
	
	
		How to Painlessly Use This
	

Use cheesechaser to quickly get images from this repository and… See the full description on the dataset page: https://huggingface.co/datasets/deepghs/e621_newest.",https://huggingface.co/datasets/deepghs/e621_newest,"['en', 'ja']","['image-classification', 'zero-shot-image-classification', 'text-to-image']",['100K<n<1M']
MichaelR207/MultiSimV2,MichaelR207,2024-10-01 05:16:49+00:00,2024-10-23 00:02:09+00:00,323,5,"['task_categories:summarization', 'task_categories:text-generation', 'language:en', 'language:fr', 'language:ru', 'language:ja', 'language:it', 'language:da', 'language:es', 'language:de', 'language:pt', 'language:sl', 'language:ur', 'language:eu', 'license:mit', 'size_categories:1M<n<10M', 'format:parquet', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'arxiv:2305.15678', 'arxiv:1904.07733', 'region:us', 'medical', 'legal', 'wikipedia', 'encyclopedia', 'science', 'literature', 'news', 'websites']","
	
		
		Dataset Card for MultiSim Benchmark
	


	
		
		Dataset Summary
	

The MultiSim benchmark is a growing collection of text simplification datasets targeted at sentence simplification in several languages.  Currently, the benchmark spans 12 languages.


	
	
	
		Supported Tasks
	


Sentence Simplification


	
	
	
		Usage
	

from datasets importload_dataset

dataset = load_dataset(""MichaelR207/MultiSimV2"")


	
		
		Citation
	

If you use this benchmark, please cite our paper:… See the full description on the dataset page: https://huggingface.co/datasets/MichaelR207/MultiSimV2.",https://huggingface.co/datasets/MichaelR207/MultiSimV2,"['en', 'fr', 'ru', 'ja', 'it', 'da', 'es', 'de', 'pt', 'sl', 'ur', 'eu']","['summarization', 'text-generation']",['1M<n<10M']
deepghs/e621-2024-webp-4Mpixel_index,deepghs,2024-10-02 08:05:24+00:00,2024-10-02 11:08:51+00:00,62,0,"['task_categories:image-classification', 'task_categories:image-to-image', 'task_categories:text-to-image', 'language:en', 'language:ja', 'license:mit', 'size_categories:1M<n<10M', 'region:us']","Index files of NebulaeWis/e621-2024-webp-4Mpixel.
You can download images from NebulaeWis/e621-2024-webp-4Mpixel with cheesechaser.
from cheesechaser.datapool import E621NewestWebpDataPool

pool = E621NewestWebpDataPool()

# download e621 #2010000-2010300, to directory /data/e621
pool.batch_download_to_directory(
    resource_ids=range(2010000, 2010300),
    dst_dir='/data/e621',
    max_workers=12,
)

",https://huggingface.co/datasets/deepghs/e621-2024-webp-4Mpixel_index,"['en', 'ja']","['image-classification', 'image-to-image', 'text-to-image']",['1M<n<10M']
shaunliu82714/GSEN,shaunliu82714,2024-10-03 00:38:07+00:00,2024-10-03 00:38:07+00:00,8,0,"['task_categories:audio-classification', 'task_categories:automatic-speech-recognition', 'task_categories:text-to-speech', 'language:zh', 'language:en', 'language:ja', 'language:ko', 'region:us']","
	
		
		Genshin Voice
	

Genshin Voice is a dataset of voice lines from the popular game Genshin Impact.
Hugging Face 🤗  Genshin-Voice

Last update at 2024-08-30
463383 wavs
20231 without speaker (4%)
24819 without transcription (5%)
602 without inGameFilename (0%)



	
		
	
	
		Dataset Details
	


	
		
	
	
		Dataset Description
	

The dataset contains voice lines from the game's characters in multiple languages, including Chinese, English, Japanese, and Korean.
The voice lines are spoken by… See the full description on the dataset page: https://huggingface.co/datasets/shaunliu82714/GSEN.",https://huggingface.co/datasets/shaunliu82714/GSEN,"['zh', 'en', 'ja', 'ko']","['audio-classification', 'automatic-speech-recognition', 'text-to-speech']",[]
lightblue/architecture_faqs,lightblue,2024-10-03 06:46:00+00:00,2024-10-03 06:55:59+00:00,13,0,"['task_categories:question-answering', 'language:ja', 'size_categories:n<1K', 'format:parquet', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","Japanese construction themes FAQs scraped from https://www.city.yokohama.lg.jp/business/bunyabetsu/kenchiku/annai/faq/qa.html.
Downloaded using the following code:
import requests
from lxml import html
import pandas as pd
from datasets import Dataset

hrefs = [
    ""/business/bunyabetsu/kenchiku/annai/faq/ji-annnai.html"",
    ""/business/bunyabetsu/kenchiku/tetsuduki/kakunin/qa-kakunin.html"",
    ""/business/bunyabetsu/kenchiku/tetsuduki/teikihoukoku/seido/01.html""… See the full description on the dataset page: https://huggingface.co/datasets/lightblue/architecture_faqs.",https://huggingface.co/datasets/lightblue/architecture_faqs,['ja'],['question-answering'],['n<1K']
haoranxu/X-ALMA-Preference,haoranxu,2024-10-03 06:48:48+00:00,2024-10-07 06:10:05+00:00,28,6,"['language:en', 'language:da', 'language:nl', 'language:de', 'language:is', 'language:no', 'language:sc', 'language:af', 'language:ca', 'language:ro', 'language:gl', 'language:it', 'language:pt', 'language:es', 'language:bg', 'language:mk', 'language:sr', 'language:uk', 'language:ru', 'language:id', 'language:ms', 'language:th', 'language:vi', 'language:mg', 'language:fr', 'language:hu', 'language:el', 'language:cs', 'language:pl', 'language:lt', 'language:lv', 'language:ka', 'language:zh', 'language:ja', 'language:ko', 'language:fi', 'language:et', 'language:gu', 'language:hi', 'language:mr', 'language:ne', 'language:ur', 'language:az', 'language:kk', 'language:ky', 'language:tr', 'language:uz', 'language:ar', 'language:he', 'language:fa', 'license:mit', 'size_categories:100K<n<1M', 'format:parquet', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'arxiv:2410.03115', 'region:us']","This is the translation preference dataset used by X-ALMA.
source: the source sentence.
chosen: the preferred translation.
reject: the dis-preferred translation.
directions: the translation direction.
@misc{xu2024xalmaplugplay,
      title={X-ALMA: Plug & Play Modules and Adaptive Rejection for Quality Translation at Scale}, 
      author={Haoran Xu and Kenton Murray and Philipp Koehn and Hieu Hoang and Akiko Eriguchi and Huda Khayrallah},
      year={2024},
      eprint={2410.03115}… See the full description on the dataset page: https://huggingface.co/datasets/haoranxu/X-ALMA-Preference.",https://huggingface.co/datasets/haoranxu/X-ALMA-Preference,"['en', 'da', 'nl', 'de', 'is', 'no', 'sc', 'af', 'ca', 'ro', 'gl', 'it', 'pt', 'es', 'bg', 'mk', 'sr', 'uk', 'ru', 'id', 'ms', 'th', 'vi', 'mg', 'fr', 'hu', 'el', 'cs', 'pl', 'lt', 'lv', 'ka', 'zh', 'ja', 'ko', 'fi', 'et', 'gu', 'hi', 'mr', 'ne', 'ur', 'az', 'kk', 'ky', 'tr', 'uz', 'ar', 'he', 'fa']",[],['100K<n<1M']
Aratako/Magpie-Tanuki-8B-97k,Aratako,2024-10-03 14:02:26+00:00,2024-10-03 14:07:49+00:00,35,11,"['task_categories:text-generation', 'language:ja', 'license:apache-2.0', 'size_categories:10K<n<100K', 'format:parquet', 'modality:text', 'library:datasets', 'library:dask', 'library:mlcroissant', 'library:polars', 'arxiv:2406.08464', 'region:us']","
	
		
		Magpie-Tanuki-8B-97k
	

Magpieの手法をweblab-GENIAC/Tanuki-8B-dpo-v1.0に対して適用し作成した、97269件の日本語対話データセットです。
特に事後的なフィルタ処理は加えていないため、クオリティの低いレコードが含まれている可能性があります。ご注意ください。
",https://huggingface.co/datasets/Aratako/Magpie-Tanuki-8B-97k,['ja'],['text-generation'],['10K<n<100K']
WorldMedQA/V,WorldMedQA,2024-10-03 17:39:46+00:00,2024-10-17 09:24:52+00:00,200,19,"['task_categories:question-answering', 'language:en', 'language:he', 'language:ja', 'language:es', 'language:pt', 'size_categories:1K<n<10K', 'format:csv', 'modality:image', 'modality:tabular', 'modality:text', 'library:datasets', 'library:dask', 'library:mlcroissant', 'library:polars', 'arxiv:2410.12722', 'region:us', 'medical']","
	
		
		WorldMedQA-V: A Multilingual, Multimodal Medical Examination Dataset
	

  
  

	
		
		Overview
	

WorldMedQA-V is a multilingual and multimodal benchmarking dataset designed to evaluate vision-language models (VLMs) in healthcare contexts. The dataset includes medical examination questions from four countries—Brazil, Israel, Japan, and Spain—in both their original languages and English translations. Each multiple-choice question is paired with a corresponding medical image, enabling… See the full description on the dataset page: https://huggingface.co/datasets/WorldMedQA/V.",https://huggingface.co/datasets/WorldMedQA/V,"['en', 'he', 'ja', 'es', 'pt']",['question-answering'],['1K<n<10K']
Sakalti/hachiwari,Sakalti,2024-10-05 01:31:37+00:00,2024-12-15 04:40:15+00:00,9,3,"['task_categories:question-answering', 'language:ja', 'license:cc-by-sa-4.0', 'size_categories:n<1K', 'format:csv', 'modality:text', 'library:datasets', 'library:dask', 'library:mlcroissant', 'library:polars', 'region:us']","#Origin
The name comes from ""hachiwari/はちわれ"" (chiikawa/ちいかわ).
",https://huggingface.co/datasets/Sakalti/hachiwari,['ja'],['question-answering'],['n<1K']
llm-jp/relaion2B-en-research-safe-japanese-translation,llm-jp,2024-10-05 10:56:50+00:00,2025-04-30 21:19:01+00:00,258,3,"['language:ja', 'license:apache-2.0', 'size_categories:1B<n<10B', 'format:parquet', 'modality:image', 'modality:tabular', 'modality:text', 'library:datasets', 'library:dask', 'library:mlcroissant', 'library:polars', 'region:us']","
	
		
		relaion2B-en-research-safe-japanese-translation
	

This dataset is the Japanese translation of the English subset of ReLAION-5B (laion/relaion2B-en-research-safe), translated by gemma-2-9b-it.
We used text2dataset for translating with open-weight LLMs. 
By leveraging the fast LLM inference library vLLM, this tool enables the rapid translation of large English datasets into Japanese.

	
		
	
	
		Prompt
	

The following is the prompt used for translation with Gemma.

 You are an… See the full description on the dataset page: https://huggingface.co/datasets/llm-jp/relaion2B-en-research-safe-japanese-translation.",https://huggingface.co/datasets/llm-jp/relaion2B-en-research-safe-japanese-translation,['ja'],[],['1B<n<10B']
myst72/JHumanEval-Mod,myst72,2024-10-05 16:56:21+00:00,2024-10-05 17:29:15+00:00,8,0,"['language:en', 'language:ja', 'license:mit', 'size_categories:n<1K', 'format:parquet', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us', 'code']",,https://huggingface.co/datasets/myst72/JHumanEval-Mod,"['en', 'ja']",[],['n<1K']
Sin2pi/JA_audio_JA_text_180k_samples,Sin2pi,2024-10-06 04:58:15+00:00,2024-10-10 04:55:21+00:00,90,9,"['task_categories:automatic-speech-recognition', 'task_categories:translation', 'task_categories:text-to-speech', 'task_categories:text-to-audio', 'language:ja', 'license:artistic-2.0', 'size_categories:100K<n<1M', 'format:parquet', 'modality:audio', 'modality:text', 'library:datasets', 'library:dask', 'library:mlcroissant', 'library:polars', 'region:us', 'Japanese', 'good dataset']",,https://huggingface.co/datasets/Sin2pi/JA_audio_JA_text_180k_samples,['ja'],"['automatic-speech-recognition', 'translation', 'text-to-speech', 'text-to-audio']",['100K<n<1M']
DeliberatorArchiver/asmr-archive-data-01,DeliberatorArchiver,2024-10-07 12:52:51+00:00,2025-02-01 13:56:06+00:00,597,9,"['language:ja', 'license:agpl-3.0', 'size_categories:n>1T', 'region:us', 'not-for-all-audiences']","
	
		
		ASMR Media Archive Storage
	

This repository contains an archive of ASMR works.
All data in this repository is uploaded for educational and research purposes only. All use is at your own risk.

[!IMPORTANT]
This repository contains >= 64 TiB of files.Git LFS consumes twice as much disk space because of the way it works, so git clone is not recommended. Hugging Face CLI or Python libraries allow you to select and download only a subset of files.

>>> CLICK HERE or on the IMAGE BELOW… See the full description on the dataset page: https://huggingface.co/datasets/DeliberatorArchiver/asmr-archive-data-01.",https://huggingface.co/datasets/DeliberatorArchiver/asmr-archive-data-01,['ja'],[],['n>1T']
neulab/PangeaBench-xm100,neulab,2024-10-07 23:39:39+00:00,2024-11-03 18:03:06+00:00,382,0,"['task_categories:image-to-text', 'language:ar', 'language:bn', 'language:cs', 'language:da', 'language:de', 'language:el', 'language:en', 'language:es', 'language:fa', 'language:fi', 'language:fil', 'language:fr', 'language:hi', 'language:hr', 'language:hu', 'language:id', 'language:it', 'language:he', 'language:ja', 'language:ko', 'language:mi', 'language:nl', 'language:no', 'language:pl', 'language:pt', 'language:quz', 'language:ro', 'language:ru', 'language:sv', 'language:sw', 'language:te', 'language:th', 'language:tr', 'language:uk', 'language:vi', 'language:zh', 'license:cc-by-4.0', 'size_categories:1K<n<10K', 'region:us']","
	
		
		XM100
	


	
		
		This is a copy from https://google.github.io/crossmodal-3600/
	

If you use this dataset, please cite the original authors:
@inproceedings{ThapliyalCrossmodal2022,
  author = {Ashish Thapliyal and Jordi Pont-Tuset and Xi Chen and Radu Soricut},
  title = {{Crossmodal-3600: A Massively Multilingual Multimodal Evaluation Dataset}},
  booktitle = {EMNLP},
  year = {2022}
}

",https://huggingface.co/datasets/neulab/PangeaBench-xm100,"['ar', 'bn', 'cs', 'da', 'de', 'el', 'en', 'es', 'fa', 'fi', 'fil', 'fr', 'hi', 'hr', 'hu', 'id', 'it', 'he', 'ja', 'ko', 'mi', 'nl', 'no', 'pl', 'pt', 'quz', 'ro', 'ru', 'sv', 'sw', 'te', 'th', 'tr', 'uk', 'vi', 'zh']",['image-to-text'],['1K<n<10K']
opencompass/mmmlu_lite,opencompass,2024-10-08 13:54:09+00:00,2024-11-01 08:34:22+00:00,45,2,"['task_categories:question-answering', 'language:ar', 'language:bn', 'language:de', 'language:es', 'language:fr', 'language:hi', 'language:id', 'language:it', 'language:ja', 'language:ko', 'language:pt', 'language:sw', 'language:yo', 'language:zh', 'license:mit', 'size_categories:10K<n<100K', 'format:json', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","
	
		
		MMMLU-Lite
	


	
		
		Introduction
	

A lite version of the MMMLU dataset, which is an community version of the MMMLU dataset by OpenCompass. Due to the large size of the original dataset (about 200k questions), we have created a lite version of the dataset to make it easier to use. We sample 25 examples from each language subject in the original dataset with fixed seed to ensure reproducibility, finally we have 19950 examples in the lite version of the dataset, which is about 10% of… See the full description on the dataset page: https://huggingface.co/datasets/opencompass/mmmlu_lite.",https://huggingface.co/datasets/opencompass/mmmlu_lite,"['ar', 'bn', 'de', 'es', 'fr', 'hi', 'id', 'it', 'ja', 'ko', 'pt', 'sw', 'yo', 'zh']",['question-answering'],['10K<n<100K']
youngmon/atlassian-qna,youngmon,2024-10-09 08:17:14+00:00,2024-11-13 06:03:56+00:00,9,2,"['task_categories:question-answering', 'language:en', 'language:ko', 'language:zh', 'language:ja', 'language:es', 'language:ru', 'license:mit', 'size_categories:100K<n<1M', 'format:json', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","
	
		
		📄 Question and Answer for Atlassian Products
	


	
		
		Dataset Sources
	


Atlassian Community


	
		
		Data Description
	

The dataset primarily includes questions, answers, tags, and URLs.

Questions contain the author, title, and content of the post.
Answers include usage instructions, solutions, and other information provided by engineers and users.
Tags represent the categories or topics of the post.
URLs provide links to the original documents.


	
		
	
	
		Dataset Structure… See the full description on the dataset page: https://huggingface.co/datasets/youngmon/atlassian-qna.",https://huggingface.co/datasets/youngmon/atlassian-qna,"['en', 'ko', 'zh', 'ja', 'es', 'ru']",['question-answering'],['100K<n<1M']
litagin/Galgame_Speech_ASR_16kHz,litagin,2024-10-10 05:05:29+00:00,2024-10-14 06:37:25+00:00,177,33,"['task_categories:automatic-speech-recognition', 'multilinguality:monolingual', 'language:ja', 'license:gpl-3.0', 'size_categories:1M<n<10M', 'format:webdataset', 'modality:audio', 'modality:text', 'library:datasets', 'library:webdataset', 'library:mlcroissant', 'region:us', 'speech', 'audio', 'text', 'japanese', 'anime', 'voice', 'visual novel', 'galgame']","
	
		
		Dataset Card for Galgame_Speech_ASR_16kHz
	


[!IMPORTANT]The following rules (in the original repository) must be followed:
必须遵守GNU General Public License v3.0内的所有协议！附加：禁止商用，本数据集以及使用本数据集训练出来的任何模型都不得用于任何商业行为，如要用于商业用途，请找数据列表内的所有厂商授权（笑），因违反开源协议而出现的任何问题都与本人无关！
训练出来的模型必须开源，是否在README内引用本数据集由训练者自主决定，不做强制要求。
English:
You must comply with all the terms of the GNU General Public License v3.0!Additional note: Commercial use is prohibited. This dataset and any model trained using this dataset… See the full description on the dataset page: https://huggingface.co/datasets/litagin/Galgame_Speech_ASR_16kHz.",https://huggingface.co/datasets/litagin/Galgame_Speech_ASR_16kHz,['ja'],['automatic-speech-recognition'],['1M<n<10M']
Sakalti/PossitivaAI,Sakalti,2024-10-10 11:17:35+00:00,2024-10-17 08:20:14+00:00,5,0,"['language:ja', 'license:apache-2.0', 'size_categories:n<1K', 'format:json', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']",,https://huggingface.co/datasets/Sakalti/PossitivaAI,['ja'],[],['n<1K']
BEE-spoke-data/TxT360-500k-sample-no_cc,BEE-spoke-data,2024-10-10 20:06:03+00:00,2024-10-11 06:30:04+00:00,56,0,"['task_categories:text-generation', 'task_categories:feature-extraction', 'language:en', 'language:de', 'language:ja', 'language:fr', 'language:es', 'language:it', 'language:cs', 'language:ar', 'language:pl', 'language:ru', 'license:odc-by', 'size_categories:100K<n<1M', 'format:parquet', 'modality:text', 'library:datasets', 'library:dask', 'library:mlcroissant', 'library:polars', 'region:us']","
	
		
		BEE-spoke-data/TxT360-500k-sample-no_cc
	

no common crawl
",https://huggingface.co/datasets/BEE-spoke-data/TxT360-500k-sample-no_cc,"['en', 'de', 'ja', 'fr', 'es', 'it', 'cs', 'ar', 'pl', 'ru']","['text-generation', 'feature-extraction']",['100K<n<1M']
weblab-GENIAC/aya-ja-evol-instruct-calm3-dpo-masked,weblab-GENIAC,2024-10-12 03:03:38+00:00,2024-10-19 01:40:31+00:00,19,8,"['task_categories:text-generation', 'task_categories:question-answering', 'language:ja', 'license:apache-2.0', 'size_categories:10K<n<100K', 'format:json', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'arxiv:2304.12244', 'region:us', 'synthetic']","
	
		
		aya-ja-evol-instruct-calm3-dpo-masked
	


LLMの推論能力の向上のためのデータセット
CohereForAI/aya_datasetの日本語パートを抜粋
Evol-instructを適用し、質問を複雑化
進化元の質問文はこのデータセットに含まれていません。team-hatakeyama-phase2/aya-ja-nemotron-dpo-maskedをご参照ください。


Evol-instructの実装はauthor's repositoryに倣って実装しました。
4種のdepth evolvingと1種のbreadth evolving


chosenカラムはcyberagent/calm3-22b-chatで再生成
rejectedカラムは開発時の内部モデルで生成
29,224件(31,295件の内2,071件削除)ルールベース・機械学習ベースのフィルタリング処理の後、目視確認を行い、個人情報が含まれ得るサンプルについては全件削除対応を実施




	
		
		Format
	

    {… See the full description on the dataset page: https://huggingface.co/datasets/weblab-GENIAC/aya-ja-evol-instruct-calm3-dpo-masked.",https://huggingface.co/datasets/weblab-GENIAC/aya-ja-evol-instruct-calm3-dpo-masked,['ja'],"['text-generation', 'question-answering']",['10K<n<100K']
weblab-GENIAC/Open-Platypus-Japanese-masked,weblab-GENIAC,2024-10-12 03:12:20+00:00,2024-10-19 01:40:51+00:00,7,1,"['task_categories:text-generation', 'task_categories:question-answering', 'language:ja', 'license:cc-by-4.0', 'size_categories:10K<n<100K', 'format:parquet', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'arxiv:2308.07317', 'region:us', 'math']","
	
		
		Open-Platypus-Japanese-masked
	


LLMの数学能力と推論能力を向上させるために作成したデータセット
garage-bAInd/Open-Platypusをcyberagent/calm3-22b-chatで翻訳
13,881件(13,883件の内2件削除)
ルールベース・機械学習ベースのフィルタリング処理の後、目視確認を行い、個人情報が含まれ得るサンプルについては全件削除対応を実施


データセットの構成とライセンスは以下


	
		
Dataset name
Num samples
License type


		
PRM800k
12298
MIT


SciBench
616
MIT


ARB
713
CC-BY-4.0


	


	
		
		Format
	

    {
        ""idx"": インデックス,
        ""instruction_en"": 英語の指示文,
        ""response_en"": 英語の応答文,
        ""translation_model"":… See the full description on the dataset page: https://huggingface.co/datasets/weblab-GENIAC/Open-Platypus-Japanese-masked.",https://huggingface.co/datasets/weblab-GENIAC/Open-Platypus-Japanese-masked,['ja'],"['text-generation', 'question-answering']",['10K<n<100K']
weblab-GENIAC/OpenBookQA-Japanese-masked,weblab-GENIAC,2024-10-12 03:13:11+00:00,2024-10-19 01:41:56+00:00,6,0,"['task_categories:text-generation', 'task_categories:question-answering', 'language:ja', 'license:unknown', 'size_categories:1K<n<10K', 'format:parquet', 'modality:tabular', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us', 'translationese']","
	
		
		OpenBookQA-Japanese-masked
	


与えられた問題に対して4つの選択肢から答えを選択するデータセット
allenai/openbookqaをcyberagent/calm3-22b-chatで翻訳
5,957件
train split: 4,956件(4,957件の内1件削除)
validation split: 500件
test split: 499件(500件の内1件削除)
ルールベース・機械学習ベースのフィルタリング処理の後、目視確認を行い、個人情報が含まれ得るサンプルについては全件削除対応を実施




	
		
	
	
		Format
	


データセットの構成は以下

    {
        ""idx"": ID,
        ""id"": 元ID,
        ""question_stem_en"": 英語の質問文,
        ""choices_en"": {
            ""text"": 選択肢の文章,
            ""label"": 選択肢の記号,
        }… See the full description on the dataset page: https://huggingface.co/datasets/weblab-GENIAC/OpenBookQA-Japanese-masked.",https://huggingface.co/datasets/weblab-GENIAC/OpenBookQA-Japanese-masked,['ja'],"['text-generation', 'question-answering']",['1K<n<10K']
weblab-GENIAC/aya-ja-nemotron-dpo-masked,weblab-GENIAC,2024-10-12 03:14:11+00:00,2024-10-19 01:41:40+00:00,25,4,"['task_categories:text-generation', 'task_categories:question-answering', 'language:ja', 'license:apache-2.0', 'size_categories:1K<n<10K', 'format:json', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us', 'synthetic']","
	
		
		aya-ja-nemotron-dpo-masked
	


LLMの推論能力を向上させるためのデータセット
CohereForAI/aya_datasetから日本語パートを抜粋
deepinfraのnvidia/Nemotron-4-340B-Instructで応答を再生成
2024年8月現在ではnvidia/Nemotron-4-340B-Instructは使用不可


5,651件(6,259件の内608件削除)
ルールベース・機械学習ベースのフィルタリング処理の後、目視確認を行い、個人情報が含まれ得るサンプルについては全件削除対応を実施




	
		
	
	
		Format
	

    {
        ""idx"": インデックス,
        ""prompt"": 日本語の指示文,
        ""chosen"": chosenの応答文,
        ""rejected"": rejectedの応答文,
        ""chosen_model"": chosenとしたモデル,
        ""rejected_model"":… See the full description on the dataset page: https://huggingface.co/datasets/weblab-GENIAC/aya-ja-nemotron-dpo-masked.",https://huggingface.co/datasets/weblab-GENIAC/aya-ja-nemotron-dpo-masked,['ja'],"['text-generation', 'question-answering']",['1K<n<10K']
DeL-TaiseiOzaki/Tengentoppa-sft-reasoning-ja,DeL-TaiseiOzaki,2024-10-12 15:26:10+00:00,2024-10-12 15:45:43+00:00,13,0,"['language:ja', 'license:apache-2.0', 'size_categories:1K<n<10K', 'format:json', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","
	
		
		日本語指示・推論・回答データセット
	


	
		
		概要
	

このリポジトリは、SkunkworksAI/reasoning-0.01 に含まれるインストラクションデータを基に、Qwen/Qwen2.5-32B-Instruct モデルを用いて作成した日本語版の指示・推論・回答データセットです。全2000件を生成し、一部の問題のあるデータを除外した後、約1800件の高品質なデータを収録しています。

	
		
		データセットの構成
	

各データエントリは以下の3つの要素で構成されています：

指示（Instruction）: ユーザーからの具体的な指示や質問。
推論（Reasoning）: 指示に対する論理的な考察やプロセス。
回答（Answer）: 最終的な回答や解決策。

",https://huggingface.co/datasets/DeL-TaiseiOzaki/Tengentoppa-sft-reasoning-ja,['ja'],[],['1K<n<10K']
Mutonix/Vript_Multilingual,Mutonix,2024-10-13 01:33:27+00:00,2024-10-17 08:29:45+00:00,5300,6,"['task_categories:video-classification', 'task_categories:visual-question-answering', 'task_categories:text-to-video', 'task_categories:text-to-image', 'task_categories:image-to-video', 'language:zh', 'language:en', 'language:de', 'language:ja', 'language:ko', 'language:ru', 'language:es', 'language:pt', 'language:jv', 'language:fr', 'language:id', 'language:vi', 'size_categories:100K<n<1M', 'format:json', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'arxiv:2406.06040', 'region:us']","
	
		
		🎬 Vript: A Video Is Worth Thousands of Words [Github Repo]
	


We construct another fine-grained video-text dataset with 19.1K annotated high-resolution UGC videos (~677k clips) in multiple languages to be the Vript_Multilingual. 
New in Vript_Multilingual: 

Multilingual: zh (60%), en (17%), de (15%), ja (6%), ko (2%), ru (<1%), es (<1%), pt (<1%), jv (<1%), fr (<1%), id (<1%), vi (<1%)
More diverse and fine-grained categories: 113 categories (please check vript_CN-V2_meta.json)… See the full description on the dataset page: https://huggingface.co/datasets/Mutonix/Vript_Multilingual.",https://huggingface.co/datasets/Mutonix/Vript_Multilingual,"['zh', 'en', 'de', 'ja', 'ko', 'ru', 'es', 'pt', 'jv', 'fr', 'id', 'vi']","['video-classification', 'visual-question-answering', 'text-to-video', 'text-to-image', 'image-to-video']",['100K<n<1M']
DeL-TaiseiOzaki/magpie-llm-jp-3-13b-20k,DeL-TaiseiOzaki,2024-10-13 03:40:26+00:00,2024-10-13 04:07:44+00:00,9,0,"['language:ja', 'license:apache-2.0', 'size_categories:10K<n<100K', 'format:json', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","
	
		
		合成日本語指示データセット
	


	
		
		概要
	

このデータセットは、大規模言語モデル（LLM）を用いて自動生成された日本語の指示とそれに対する応答のコレクションです。データセットは指示付与型のタスクのための学習や評価に使用することを目的としています。

	
		
		データセット仕様
	


サンプル数: 20,000
言語: 日本語
フォーマット: JSON


	
		
		生成方法
	

データセットは以下のプロセスを通じて生成されました：

LLM-JP 3.13B Instructモデルを使用
各サンプルは3段階のプロセスで生成:
a) 指示文の生成
b) Chain-of-Thought (CoT) 応答の生成 (一部のデータには含まれない)
c) 最終的な応答のself-refine



https://github.com/DeL-TaiseiOzaki/magpie-llm-jp-3

	
		
		データ構造
	

各サンプルは以下の構造を持つJSONオブジェクトです：
{
  ""instruction"": ""指示文""… See the full description on the dataset page: https://huggingface.co/datasets/DeL-TaiseiOzaki/magpie-llm-jp-3-13b-20k.",https://huggingface.co/datasets/DeL-TaiseiOzaki/magpie-llm-jp-3-13b-20k,['ja'],[],['10K<n<100K']
ifmain/comment-translation-01,ifmain,2024-10-13 11:30:55+00:00,2024-10-13 13:16:36+00:00,13,1,"['language:en', 'language:de', 'language:fr', 'language:es', 'language:it', 'language:sv', 'language:fi', 'language:pl', 'language:cs', 'language:lv', 'language:zh', 'language:ja', 'language:ko', 'language:ru', 'language:uk', 'language:be', 'language:kk', 'license:apache-2.0', 'size_categories:1M<n<10M', 'format:json', 'modality:text', 'library:datasets', 'library:dask', 'library:mlcroissant', 'region:us']","This dataset is based on Kaggle.  
This dataset includes translations of 69,000 Reddit comments into 17 languages (English to 16 languages):
Belarusian, Czech, German,
English, Spanish, Finnish,
French, Italian, Japanese,
Kazakh, Korean, Latvian,
Polish, Russian, Swedish,
Ukrainian, and Chinese.
It contains 50% regular comments and 50% highly negative ones.
Enjoy using it!
",https://huggingface.co/datasets/ifmain/comment-translation-01,"['en', 'de', 'fr', 'es', 'it', 'sv', 'fi', 'pl', 'cs', 'lv', 'zh', 'ja', 'ko', 'ru', 'uk', 'be', 'kk']",[],['1M<n<10M']
ifmain/text-moderation-02-multilingual,ifmain,2024-10-13 11:37:25+00:00,2024-10-13 13:50:00+00:00,20,1,"['language:en', 'language:de', 'language:fr', 'language:es', 'language:it', 'language:sv', 'language:fi', 'language:pl', 'language:cs', 'language:lv', 'language:zh', 'language:ja', 'language:ko', 'language:ru', 'language:uk', 'language:be', 'language:kk', 'license:apache-2.0', 'size_categories:1M<n<10M', 'format:json', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","This dataset is based on Kaggle.It represents a version of @ifmain/text-moderation-410K that has been cleansed of semantically similar values and normalized to a 50/50 ratio of negative and neutral entries.
The dataset contains 1.5M entries (91K * 17 languages).  
Before use, augmentation is recommended! (e.g., character substitution to bypass moderation).
For augmentation, you can use @ifmain/StringAugmentor.  
Enjoy using it!
",https://huggingface.co/datasets/ifmain/text-moderation-02-multilingual,"['en', 'de', 'fr', 'es', 'it', 'sv', 'fi', 'pl', 'cs', 'lv', 'zh', 'ja', 'ko', 'ru', 'uk', 'be', 'kk']",[],['1M<n<10M']
kai271/TinyStories-Japanese,kai271,2024-10-13 12:38:07+00:00,2025-02-16 16:54:17+00:00,64,2,"['task_categories:text-generation', 'language:ja', 'license:mit', 'size_categories:1K<n<10K', 'format:text', 'modality:text', 'library:datasets', 'library:mlcroissant', 'arxiv:2305.07759', 'region:us']","Dataset containing ~3000 synthetically generated (by GPT-4o-mini) children's stories in Japanese that only use simple words.
It was created using the method described in https://arxiv.org/abs/2305.07759.
",https://huggingface.co/datasets/kai271/TinyStories-Japanese,['ja'],['text-generation'],['1K<n<10K']
FreedomIntelligence/ApolloMoEDataset,FreedomIntelligence,2024-10-14 03:03:59+00:00,2024-10-18 02:52:33+00:00,163,5,"['task_categories:question-answering', 'language:ar', 'language:en', 'language:zh', 'language:ko', 'language:ja', 'language:mn', 'language:th', 'language:vi', 'language:lo', 'language:mg', 'language:de', 'language:pt', 'language:es', 'language:fr', 'language:ru', 'language:it', 'language:hr', 'language:gl', 'language:cs', 'language:co', 'language:la', 'language:uk', 'language:bs', 'language:bg', 'language:eo', 'language:sq', 'language:da', 'language:sa', 'language:no', 'language:gn', 'language:sr', 'language:sk', 'language:gd', 'language:lb', 'language:hi', 'language:ku', 'language:mt', 'language:he', 'language:ln', 'language:bm', 'language:sw', 'language:ig', 'language:rw', 'language:ha', 'license:mit', 'size_categories:100K<n<1M', 'format:json', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'arxiv:2410.10626', 'region:us', 'biology', 'medical']","
	
		
		Democratizing Medical LLMs For Much More Languages
	

Covering 12 Major Languages including English, Chinese, French, Hindi, Spanish, Arabic, Russian, Japanese, Korean, German, Italian, Portuguese and 38 Minor Languages So far.

   📃 Paper • 🌐 Demo • 🤗 ApolloMoEDataset • 🤗 ApolloMoEBench  • 🤗 Models  •🌐 Apollo  • 🌐 ApolloMoE






	
		
		🌈 Update
	


[2024.10.15] ApolloMoE repo is published！🎉


	
		
		Languages Coverage
	

12 Major Languages and 38 Minor Languages

  Click to… See the full description on the dataset page: https://huggingface.co/datasets/FreedomIntelligence/ApolloMoEDataset.",https://huggingface.co/datasets/FreedomIntelligence/ApolloMoEDataset,"['ar', 'en', 'zh', 'ko', 'ja', 'mn', 'th', 'vi', 'lo', 'mg', 'de', 'pt', 'es', 'fr', 'ru', 'it', 'hr', 'gl', 'cs', 'co', 'la', 'uk', 'bs', 'bg', 'eo', 'sq', 'da', 'sa', 'no', 'gn', 'sr', 'sk', 'gd', 'lb', 'hi', 'ku', 'mt', 'he', 'ln', 'bm', 'sw', 'ig', 'rw', 'ha']",['question-answering'],['100K<n<1M']
FreedomIntelligence/ApolloMoEBench,FreedomIntelligence,2024-10-14 03:04:30+00:00,2024-10-15 08:38:05+00:00,76,0,"['task_categories:question-answering', 'language:ar', 'language:en', 'language:zh', 'language:ko', 'language:ja', 'language:mn', 'language:th', 'language:vi', 'language:lo', 'language:mg', 'language:de', 'language:pt', 'language:es', 'language:fr', 'language:ru', 'language:it', 'language:hr', 'language:gl', 'language:cs', 'language:co', 'language:la', 'language:uk', 'language:bs', 'language:bg', 'language:eo', 'language:sq', 'language:da', 'language:sa', 'language:no', 'language:gn', 'language:sr', 'language:sk', 'language:gd', 'language:lb', 'language:hi', 'language:ku', 'language:mt', 'language:he', 'language:ln', 'language:bm', 'language:sw', 'language:ig', 'language:rw', 'language:ha', 'license:mit', 'size_categories:10K<n<100K', 'format:json', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'arxiv:2410.10626', 'region:us', 'biology', 'medical']","
	
		
		Democratizing Medical LLMs For Much More Languages
	

Covering 12 Major Languages including English, Chinese, French, Hindi, Spanish, Arabic, Russian, Japanese, Korean, German, Italian, Portuguese and 38 Minor Languages So far.

   📃 Paper • 🌐 Demo • 🤗 ApolloMoEDataset • 🤗 ApolloMoEBench  • 🤗 Models  •🌐 Apollo  • 🌐 ApolloMoE






	
		
		🌈 Update
	


[2024.10.15] ApolloMoE repo is published！🎉


	
		
		Languages Coverage
	

12 Major Languages and 38 Minor Languages

  Click to… See the full description on the dataset page: https://huggingface.co/datasets/FreedomIntelligence/ApolloMoEBench.",https://huggingface.co/datasets/FreedomIntelligence/ApolloMoEBench,"['ar', 'en', 'zh', 'ko', 'ja', 'mn', 'th', 'vi', 'lo', 'mg', 'de', 'pt', 'es', 'fr', 'ru', 'it', 'hr', 'gl', 'cs', 'co', 'la', 'uk', 'bs', 'bg', 'eo', 'sq', 'da', 'sa', 'no', 'gn', 'sr', 'sk', 'gd', 'lb', 'hi', 'ku', 'mt', 'he', 'ln', 'bm', 'sw', 'ig', 'rw', 'ha']",['question-answering'],['10K<n<100K']
Sakalti/Multilingal-sakalt-data,Sakalti,2024-10-14 05:11:16+00:00,2024-10-17 10:41:45+00:00,25,1,"['task_categories:text-generation', 'language:ab', 'language:bho', 'language:ce', 'language:cs', 'language:da', 'language:de', 'language:et', 'language:es', 'language:fr', 'language:hi', 'language:hrv', 'language:hu', 'language:it', 'language:ja', 'language:ko', 'language:nl', 'language:pl', 'language:pt', 'language:ro', 'language:ru', 'language:sah', 'language:swh', 'language:yue', 'language:zh', 'license:mit', 'size_categories:1K<n<10K', 'format:json', 'modality:text', 'library:datasets', 'library:dask', 'library:mlcroissant', 'region:us']","マルチリンガルデータセットです。mitライセンスです。
",https://huggingface.co/datasets/Sakalti/Multilingal-sakalt-data,"['ab', 'bho', 'ce', 'cs', 'da', 'de', 'et', 'es', 'fr', 'hi', 'hrv', 'hu', 'it', 'ja', 'ko', 'nl', 'pl', 'pt', 'ro', 'ru', 'sah', 'swh', 'yue', 'zh']",['text-generation'],['1K<n<10K']
jayliqinzhang/Test_mumospee,jayliqinzhang,2024-10-14 18:06:21+00:00,2024-10-21 07:22:00+00:00,24,0,"['language:de', 'language:en', 'language:zh', 'language:ja', 'language:ko', 'language:fr', 'license:cc-by-nc-4.0', 'size_categories:1K<n<10K', 'format:parquet', 'modality:audio', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","
	
		
		Mumospee tiny demo
	

This is a tiny Mumospee demo. 
",https://huggingface.co/datasets/jayliqinzhang/Test_mumospee,"['de', 'en', 'zh', 'ja', 'ko', 'fr']",[],['1K<n<10K']
DeL-TaiseiOzaki/magpie-qwen2.5-32B-10K-ja,DeL-TaiseiOzaki,2024-10-14 22:20:52+00:00,2024-10-14 22:54:57+00:00,10,0,"['language:ja', 'license:apache-2.0', 'size_categories:10K<n<100K', 'format:json', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","
	
		
		合成日本語指示データセット
	


	
		
		概要
	

このデータセットは、大規模言語モデル（Qwen2.5-32B-instruct）を用いて自動生成された日本語の指示とそれに対する応答のコレクションです。データセットは指示付与型のタスクのための学習や評価に使用することを目的としています。

	
		
		データセット仕様
	


サンプル数: 20,000
言語: 日本語
フォーマット: JSON
ライセンス: Apache-2.0
サイズカテゴリ: 10K<n<100K


	
		
		生成方法
	

データセットは以下のプロセスを通じて生成されました：

Qwen2.5-32B Instructモデルを使用
各サンプルは3段階のプロセスで生成:
a) 指示文の生成
b) Chain-of-Thought (CoT) 応答の生成 (一部のデータには含まれない)
c) 最終的な応答のself-refine


生成の多様性を向上させるため、10種類のペルソナからランダムに1つ選んでシステムプロンプトに入力

詳細な生成プロセスはこちらをご覧ください。… See the full description on the dataset page: https://huggingface.co/datasets/DeL-TaiseiOzaki/magpie-qwen2.5-32B-10K-ja.",https://huggingface.co/datasets/DeL-TaiseiOzaki/magpie-qwen2.5-32B-10K-ja,['ja'],[],['10K<n<100K']
if001/word_frequency_from_wiki_ja,if001,2024-10-15 08:09:25+00:00,2025-05-27 10:14:00+00:00,9,0,"['language:ja', 'size_categories:100K<n<1M', 'format:parquet', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","wikipediaのデータ400000を対象に、文章中の動詞と名詞をカウント
https://huggingface.co/datasets/izumi-lab/wikipedia-ja-20230720
全体: 221115
名詞: 204661
動詞: 16454
",https://huggingface.co/datasets/if001/word_frequency_from_wiki_ja,['ja'],[],['100K<n<1M']
p1atdev/danbooru-ja-tag-pair-20241015,p1atdev,2024-10-15 14:35:08+00:00,2024-10-16 12:48:36+00:00,39,8,"['task_categories:translation', 'language:en', 'language:ja', 'license:cc0-1.0', 'size_categories:100K<n<1M', 'format:parquet', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","
	
		
		danbooru-ja-tag-pair-20241015
	

2024/10/15に作成したdanbooruタグと日本語タグのペアデータセット(約15万件)
p1atdev/danbooru-ja-tag-pair-20240715 との違いは、

ベースのwikiデータが増えたのでその分対応タグも増えた
fasttextでのフィルタリングを挟むようにした
「明らかに他言語のタグ」が混じる頻度はちょっと減った気がするけど、完全ではない



(calm3くんの処理に)ミスがなければ、最低一つ以上の日本語タグ (other_names フィールド) が存在するはず

	
		
		作成過程
	

isek-ai/danbooru-wiki-2024 の #202408-at20240906 revision を元に、

other_names (基本的にPixivのタグ)がついているものから、日本語じゃないもの・曖昧・意味の過不足が大きいタグを除去。処理内容:
fasttext で80%以上の確信度で日本語ではないものを除去… See the full description on the dataset page: https://huggingface.co/datasets/p1atdev/danbooru-ja-tag-pair-20241015.",https://huggingface.co/datasets/p1atdev/danbooru-ja-tag-pair-20241015,"['en', 'ja']",['translation'],['100K<n<1M']
if001/elementray_l,if001,2024-10-15 15:31:38+00:00,2024-10-21 13:15:01+00:00,21,0,"['language:ja', 'license:apache-2.0', 'size_categories:10K<n<100K', 'format:parquet', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","calm3-22bを使って簡単な日本語の例文を作成したデータセットです。
以下のパターンが含まれるように一文を作成しています。
生成に失敗しているものはクリーニングしています。
    ""です/だ (肯定文)"",
    ""ではありません/じゃない (否定文)"",
    ""〜ます (動詞の丁寧形)"",
    ""〜ません (動詞の否定形)"",
    ""〜たい (希望・願望)"",
    ""〜ている (進行形)"",
    ""〜てください (依頼)"",
    ""〜てもいいですか (許可)"",
    ""〜なければなりません/〜なきゃいけない (義務)"",
    ""〜でしょう/〜だろう (推測)"",
    ""〜が好きです/嫌いです (好み)"",
    ""〜と思います (意見・思考)"",
    ""〜から/〜ので (理由)"",
    ""〜のが好きです/嫌いです (動作の好み)"",
    ""〜でしょうか (丁寧な質問)"",
    ""〜てしまう (完了・後悔)"",
    ""〜ながら (同時進行)"",
    ""〜ば/〜たら (仮定形)"",
    ""〜ておく (準備)""… See the full description on the dataset page: https://huggingface.co/datasets/if001/elementray_l.",https://huggingface.co/datasets/if001/elementray_l,['ja'],[],['10K<n<100K']
jaeyong2/persona-inst,jaeyong2,2024-10-16 14:43:18+00:00,2024-10-26 03:05:38+00:00,10,0,"['language:ja', 'language:ko', 'language:th', 'language:vi', 'license:cc-by-nc-sa-4.0', 'size_categories:1M<n<10M', 'format:parquet', 'modality:text', 'library:datasets', 'library:dask', 'library:mlcroissant', 'library:polars', 'region:us']","
	
		
		How to use
	

>>> from datasets import load_dataset

>>> ds = load_dataset(""jaeyong2/persona-inst"", split=""train"")
>>> ds
Dataset({
    features: ['Level', 'English', 'Korean', 'Thai', 'Vietnamese', 'context'],
    num_rows: 3006572
})


	
	
	
		Development Process
	


Generate persona pair from proj-persona/PersonaHub
We used Qwen/Qwen2-72B-Instruct model to generate Question.


	
		
		License
	


Qwen/Qwen2.5-72B-Instruct :… See the full description on the dataset page: https://huggingface.co/datasets/jaeyong2/persona-inst.",https://huggingface.co/datasets/jaeyong2/persona-inst,"['ja', 'ko', 'th', 'vi']",[],['1M<n<10M']
Sakalti/Tylbass,Sakalti,2024-10-17 10:24:05+00:00,2024-10-17 10:36:59+00:00,8,1,"['task_categories:translation', 'language:ja', 'language:sah', 'license:apache-2.0', 'size_categories:n<1K', 'format:json', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']",,https://huggingface.co/datasets/Sakalti/Tylbass,"['ja', 'sah']",['translation'],['n<1K']
ganchengguang/Sentence-Classification-and-NER-Mix-Datasets-SCNM,ganchengguang,2024-10-18 14:48:29+00:00,2024-10-18 14:54:38+00:00,13,0,"['task_categories:text-classification', 'language:ja', 'license:cc-by-nc-4.0', 'arxiv:2306.15978', 'region:us']","The dataset of SLG framework. The paper as the following:
https://link.springer.com/chapter/10.1007/978-3-031-35320-8_18
arxiv : https://arxiv.org/abs/2306.15978
Paper code is opensource in GitHub:
https://github.com/ganchengguang/SLG-framework
Cite BibTex:
@inproceedings{gan2023sentence,
  title={Sentence-to-label generation framework for multi-task learning of japanese sentence classification and named entity recognition},
  author={Gan, Chengguang and Zhang, Qinghao and Mori, Tatsunori}… See the full description on the dataset page: https://huggingface.co/datasets/ganchengguang/Sentence-Classification-and-NER-Mix-Datasets-SCNM.",https://huggingface.co/datasets/ganchengguang/Sentence-Classification-and-NER-Mix-Datasets-SCNM,['ja'],['text-classification'],[]
ganchengguang/Text-Sentiment-Classification-and-Part-of-Speech-Sentiment-Classification-Mix-Dataset,ganchengguang,2024-10-18 14:57:51+00:00,2024-10-18 15:01:09+00:00,8,0,"['task_categories:text-classification', 'task_categories:token-classification', 'language:ja', 'license:cc-by-nc-4.0', 'arxiv:2309.03787', 'region:us']","USA model paper SCPOS datasets. Including four sub-datasets.
paper address:
https://arxiv.org/abs/2309.03787
Cite:
@article{gan2023usa,
  title={USA: Universal Sentiment Analysis Model & Construction of Japanese Sentiment Text Classification and Part of Speech Dataset},
  author={Gan, Chengguang and Zhang, Qinghao and Mori, Tatsunori},
  journal={arXiv preprint arXiv:2309.03787},
  year={2023}
}
This dataset constructed base in JGLUE benchmark text sentiment classification task… See the full description on the dataset page: https://huggingface.co/datasets/ganchengguang/Text-Sentiment-Classification-and-Part-of-Speech-Sentiment-Classification-Mix-Dataset.",https://huggingface.co/datasets/ganchengguang/Text-Sentiment-Classification-and-Part-of-Speech-Sentiment-Classification-Mix-Dataset,['ja'],"['text-classification', 'token-classification']",[]
ganchengguang/Text-Classification-and-Relation-Event-Extraction-Mix-datasets,ganchengguang,2024-10-18 15:02:08+00:00,2024-10-18 15:05:42+00:00,13,1,"['task_categories:text-classification', 'task_categories:token-classification', 'language:ja', 'license:cc-by-nc-4.0', 'size_categories:1K<n<10K', 'format:csv', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'arxiv:2311.06838', 'region:us']","The paper of GIELLM dataset.
https://arxiv.org/abs/2311.06838
Cite:
@article{gan2023giellm,
  title={Giellm: Japanese general information extraction large language model utilizing mutual reinforcement effect},
  author={Gan, Chengguang and Zhang, Qinghao and Mori, Tatsunori},
  journal={arXiv preprint arXiv:2311.06838},
  year={2023}
}
The dataset constructed base in livedoor news corpus 関口宏司 https://www.rondhuit.com/download.html
",https://huggingface.co/datasets/ganchengguang/Text-Classification-and-Relation-Event-Extraction-Mix-datasets,['ja'],"['text-classification', 'token-classification']",['1K<n<10K']
nikolare/test,nikolare,2024-10-19 12:41:44+00:00,2024-12-01 21:47:25+00:00,64,0,"['language:ca', 'language:ja', 'size_categories:10M<n<100M', 'format:parquet', 'modality:tabular', 'modality:text', 'library:datasets', 'library:dask', 'library:mlcroissant', 'library:polars', 'region:us']",,https://huggingface.co/datasets/nikolare/test,"['ca', 'ja']",[],['10M<n<100M']
neulab/PangeaInstruct,neulab,2024-10-19 21:55:48+00:00,2025-02-02 16:40:32+00:00,122,86,"['task_categories:visual-question-answering', 'task_categories:question-answering', 'language:am', 'language:ar', 'language:bg', 'language:bn', 'language:cs', 'language:de', 'language:el', 'language:en', 'language:es', 'language:fa', 'language:fr', 'language:ga', 'language:hi', 'language:id', 'language:ig', 'language:it', 'language:iw', 'language:ja', 'language:jv', 'language:ko', 'language:nl', 'language:mn', 'language:ms', 'language:no', 'language:pl', 'language:pt', 'language:ro', 'language:ru', 'language:si', 'language:su', 'language:sw', 'language:ta', 'language:te', 'language:th', 'language:tr', 'language:uk', 'language:ur', 'language:vi', 'language:zh', 'license:apache-2.0', 'size_categories:1M<n<10M', 'arxiv:2410.16153', 'region:us', 'multilingual', 'multimodal']","
	
		
		PangeaInstruct
	

Pangea: A Fully Open Multilingual Multimodal LLM for 39 Languages
🇪🇹 🇸🇦 🇧🇬 🇧🇩 🇨🇿 🇩🇪 🇬🇷 🇬🇧 🇺🇸 🇪🇸 🇮🇷 🇫🇷 🇮🇪 🇮🇳 🇮🇩 🇳🇬 🇮🇹 🇮🇱 🇯🇵 🇮🇩 🇰🇷 🇳🇱 🇲🇳 🇲🇾 🇳🇴 🇵🇱 🇵🇹 🇧🇷 🇷🇴 🇷🇺 🇱🇰 🇮🇩 🇰🇪 🇹🇿 🇱🇰 🇮🇳 🇮🇳 🇹🇭 🇹🇷 🇺🇦 🇵🇰 🇮🇳 🇻🇳 🇨🇳 🇹🇼
🏠 Homepage | 🤖 Pangea-7B | 📊 PangeaIns | 🧪 PangeaBench | 💻 Github | 📄 Arxiv | 📕 PDF | 🖥️ Demo


This README provides comprehensive details on the PangeaIns dataset, which… See the full description on the dataset page: https://huggingface.co/datasets/neulab/PangeaInstruct.",https://huggingface.co/datasets/neulab/PangeaInstruct,"['am', 'ar', 'bg', 'bn', 'cs', 'de', 'el', 'en', 'es', 'fa', 'fr', 'ga', 'hi', 'id', 'ig', 'it', 'iw', 'ja', 'jv', 'ko', 'nl', 'mn', 'ms', 'no', 'pl', 'pt', 'ro', 'ru', 'si', 'su', 'sw', 'ta', 'te', 'th', 'tr', 'uk', 'ur', 'vi', 'zh']","['visual-question-answering', 'question-answering']",['1M<n<10M']
openfoodfacts/product-database,openfoodfacts,2024-10-21 08:44:28+00:00,2025-10-12 18:25:10+00:00,22387,49,"['language:en', 'language:fr', 'language:de', 'language:es', 'language:it', 'language:nl', 'language:pl', 'language:pt', 'language:sv', 'language:bg', 'language:ro', 'language:fi', 'language:ru', 'language:nb', 'language:cs', 'language:th', 'language:da', 'language:hr', 'language:hu', 'language:ar', 'language:el', 'language:ja', 'language:ca', 'language:sr', 'language:sl', 'language:sk', 'language:tr', 'language:lt', 'language:zh', 'language:et', 'language:lv', 'language:xx', 'language:uk', 'language:id', 'language:he', 'language:vi', 'language:is', 'language:la', 'language:in', 'language:ko', 'language:sq', 'language:iw', 'language:ka', 'language:ms', 'language:bs', 'language:fa', 'language:bn', 'language:gl', 'language:kk', 'language:mk', 'language:nn', 'language:hi', 'language:aa', 'language:uz', 'language:so', 'language:af', 'language:eu', 'license:agpl-3.0', 'license:odbl', 'size_categories:1M<n<10M', 'format:parquet', 'modality:tabular', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","
	
		
		Open Food Facts Database
	


	
		
		What is 🍊 Open Food Facts?
	


	
		
		A food products database
	

Open Food Facts is a database of food products with ingredients, allergens, nutrition facts and all the tidbits of information we can find on product labels.

	
		
		Made by everyone
	

Open Food Facts is a non-profit association of volunteers. 25.000+ contributors like you have added 1.7 million + products from 150 countries using our Android or iPhone app or their camera to scan… See the full description on the dataset page: https://huggingface.co/datasets/openfoodfacts/product-database.",https://huggingface.co/datasets/openfoodfacts/product-database,"['en', 'fr', 'de', 'es', 'it', 'nl', 'pl', 'pt', 'sv', 'bg', 'ro', 'fi', 'ru', 'nb', 'cs', 'th', 'da', 'hr', 'hu', 'ar', 'el', 'ja', 'ca', 'sr', 'sl', 'sk', 'tr', 'lt', 'zh', 'et', 'lv', 'xx', 'uk', 'id', 'he', 'vi', 'is', 'la', 'in', 'ko', 'sq', 'iw', 'ka', 'ms', 'bs', 'fa', 'bn', 'gl', 'kk', 'mk', 'nn', 'hi', 'aa', 'uz', 'so', 'af', 'eu']",[],['1M<n<10M']
cyberagent/FaithCAMERA,cyberagent,2024-10-22 06:04:54+00:00,2024-10-22 10:22:34+00:00,26,1,"['task_categories:text-generation', 'language:ja', 'license:cc-by-sa-4.0', 'size_categories:n<1K', 'format:parquet', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'arxiv:2410.03839', 'region:us', 'faithfulness', 'advertisement']","
	
		
		Overview
	

In ad text generation (ATG), desirable ad text is both faithful and informative. That is, it should be faithful to the input document, while at the same time containing important information that appeals to potential customers.
The existing evaluation data, CAMERA (Mita et al.,2024), is suitable for evaluating informativeness, as it consists of reference ad texts created by ad creators. However, these references often include information unfaithful to the input, which is a… See the full description on the dataset page: https://huggingface.co/datasets/cyberagent/FaithCAMERA.",https://huggingface.co/datasets/cyberagent/FaithCAMERA,['ja'],['text-generation'],['n<1K']
llm-jp/japanese-photos-conversation,llm-jp,2024-10-22 06:39:57+00:00,2024-11-19 10:46:49+00:00,18,6,"['task_categories:visual-question-answering', 'language:ja', 'size_categories:10K<n<100K', 'format:json', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","
	
		
		Dataset Card for japanese photos conversation
	


	
		
		Dataset details
	

This dataset contains multi-turn conversational instructions about images taken in Japan. The images were sourced from https://huggingface.co/datasets/ThePioneer/japanese-photos. 
We input each image into GPT-4o (gpt-4o-2024-05-13) via the Azure OpenAI API to generate the instruction data.
Some of the images in the original dataset were filtered by the Azure OpenAI API when they were input, resulting in a total… See the full description on the dataset page: https://huggingface.co/datasets/llm-jp/japanese-photos-conversation.",https://huggingface.co/datasets/llm-jp/japanese-photos-conversation,['ja'],['visual-question-answering'],['10K<n<100K']
llm-jp/llava-instruct-ja,llm-jp,2024-10-22 06:43:09+00:00,2024-11-19 10:35:55+00:00,27,5,"['task_categories:visual-question-answering', 'language:ja', 'size_categories:100K<n<1M', 'format:json', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","
	
		
		Dataset Card for llava_instruct_ja
	


	
		
		Dataset details
	

This is the Japanese version of LLaVA-Instruct, which contains 156K samples.
We used gpt-4o-mini-2024-07-18 to generate data through via Azure OpenAI API.

	
		
		License
	

Creative Commons Attribution 4.0 License; and it should abide by the OpenAI terms of use
",https://huggingface.co/datasets/llm-jp/llava-instruct-ja,['ja'],['visual-question-answering'],['100K<n<1M']
DeL-TaiseiOzaki/Tengentoppa-sft-reasoning-llama-nemotron-70b-100k,DeL-TaiseiOzaki,2024-10-22 07:10:57+00:00,2024-10-22 07:56:38+00:00,18,0,"['task_categories:text-generation', 'language:ja', 'license:llama3.1', 'size_categories:100K<n<1M', 'format:json', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","
	
		
		Dataset Card for Dataset Name
	



This dataset card aims to be a base template for new datasets. It has been generated using this raw template.

	
		
		Dataset Details
	


	
		
		Dataset Description
	






Curated by: [More Information Needed]
Funded by [optional]: [More Information Needed]
Shared by [optional]: [More Information Needed]
Language(s) (NLP): [More Information Needed]
License: [More Information Needed]


	
		
		Dataset Sources [optional]
	




Repository: [More… See the full description on the dataset page: https://huggingface.co/datasets/DeL-TaiseiOzaki/Tengentoppa-sft-reasoning-llama-nemotron-70b-100k.",https://huggingface.co/datasets/DeL-TaiseiOzaki/Tengentoppa-sft-reasoning-llama-nemotron-70b-100k,['ja'],['text-generation'],['100K<n<1M']
speed/english_quotes_ja,speed,2024-10-22 14:22:50+00:00,2024-10-22 14:46:27+00:00,6,1,"['language:en', 'language:ja', 'license:cc-by-4.0', 'size_categories:1K<n<10K', 'format:parquet', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","This dataset is a translation of https://huggingface.co/datasets/Abirate/english_quotes into Japanese using the llm-jp/llm-jp-3-3.7b-instruct model. 
The license follows the original dataset's Creative Commons Attribution 4.0 International License.
The translation was performed using text2dataset.
",https://huggingface.co/datasets/speed/english_quotes_ja,"['en', 'ja']",[],['1K<n<10K']
speed/arxiver_ja,speed,2024-10-22 18:25:39+00:00,2024-10-23 02:57:05+00:00,24,3,"['language:en', 'language:ja', 'license:cc-by-nc-sa-4.0', 'size_categories:100K<n<1M', 'format:parquet', 'modality:text', 'library:datasets', 'library:dask', 'library:mlcroissant', 'library:polars', 'region:us']","This dataset is a translation of the abstract column of the neuralwork/arxiver into Japanese using the google/gemma-2-2b-it model. 
The license follows the original dataset's CC BY-NC-SA 4.0 License.
The translation was performed using text2dataset.
",https://huggingface.co/datasets/speed/arxiver_ja,"['en', 'ja']",[],['100K<n<1M']
azminetoushikwasi/global-festivals-translated,azminetoushikwasi,2024-10-22 19:41:41+00:00,2024-10-22 20:48:55+00:00,28,0,"['task_categories:text-generation', 'language:en', 'language:fr', 'language:es', 'language:de', 'language:hi', 'language:ja', 'language:ko', 'language:tr', 'language:it', 'license:apache-2.0', 'size_categories:1K<n<10K', 'format:parquet', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us', ""GLOBAL_FESTIVALS_DATASET = 'ciol-research/global-festivals-wiki'""]",,https://huggingface.co/datasets/azminetoushikwasi/global-festivals-translated,"['en', 'fr', 'es', 'de', 'hi', 'ja', 'ko', 'tr', 'it']",['text-generation'],['1K<n<10K']
Aratako/Magpie-Tanuki-8B-annotated-96k,Aratako,2024-10-23 06:23:00+00:00,2024-10-24 14:48:34+00:00,34,6,"['task_categories:text-generation', 'language:ja', 'license:apache-2.0', 'size_categories:10K<n<100K', 'format:parquet', 'modality:text', 'library:datasets', 'library:dask', 'library:mlcroissant', 'library:polars', 'arxiv:2406.08464', 'region:us']","
	
		
		Magpie-Tanuki-8B-annotated-96k
	

Magpieの手法をweblab-GENIAC/Tanuki-8B-dpo-v1.0に対して適用し作成したデータセットであるAratako/Magpie-Tanuki-8B-97kに対して、cyberagent/calm3-22b-chatを用いてinstructionに対して難易度、クオリティ、カテゴリをアノテーションしたデータセットです。

	
		
	
	
		アノテーションのプロンプト
	

calm3によるアノテーションにはそれぞれ以下のプロンプトを利用しました。

	
		
	
	
		難易度のアノテーション
	

# 指示

まず、与えられたユーザーの意図を特定し、その後、ユーザーのクエリの内容に基づいて難易度レベルをラベル付けしてください。

## ユーザーのクエリ
```
{input}
```

## 出力フォーマット
ユーザーのクエリに基づき、まずユーザーの意図を特定し、そのクエリを解決するために必要な知識を明示してください。
その後、難易度レベルを `very… See the full description on the dataset page: https://huggingface.co/datasets/Aratako/Magpie-Tanuki-8B-annotated-96k.",https://huggingface.co/datasets/Aratako/Magpie-Tanuki-8B-annotated-96k,['ja'],['text-generation'],['10K<n<100K']
romrawinjp/multilingual-coco,romrawinjp,2024-10-23 08:03:46+00:00,2024-10-25 11:57:55+00:00,233,1,"['task_categories:image-to-text', 'language:en', 'language:th', 'language:ru', 'language:ja', 'language:it', 'language:de', 'language:vi', 'language:zh', 'language:ar', 'language:es', 'license:cc-by-4.0', 'size_categories:100K<n<1M', 'format:parquet', 'modality:image', 'modality:text', 'library:datasets', 'library:dask', 'library:mlcroissant', 'library:polars', 'arxiv:1405.0312', 'region:us']","
	
		
		Multilingual Common Objects in Context (COCO) Dataset
	

This dataset is a collection of multiple language open-source captions of COCO dataset. 
The split in this dataset is set according to Andrej Karpathy's split from dataset_coco.json file. The collection was created specifically for simplicity of use in training and evaluation pipeline by non-commercial and research purposes. The COCO images dataset is licensed under a Creative Commons Attribution 4.0 License.… See the full description on the dataset page: https://huggingface.co/datasets/romrawinjp/multilingual-coco.",https://huggingface.co/datasets/romrawinjp/multilingual-coco,"['en', 'th', 'ru', 'ja', 'it', 'de', 'vi', 'zh', 'ar', 'es']",['image-to-text'],['100K<n<1M']
CohereLabs/m-ArenaHard,CohereLabs,2024-10-23 09:33:05+00:00,2025-04-15 08:44:05+00:00,376,23,"['language:en', 'language:fr', 'language:de', 'language:es', 'language:it', 'language:pt', 'language:ja', 'language:ko', 'language:zh', 'language:ar', 'language:el', 'language:fa', 'language:pl', 'language:id', 'language:cs', 'language:he', 'language:hi', 'language:nl', 'language:ro', 'language:ru', 'language:tr', 'language:uk', 'language:vi', 'license:apache-2.0', 'size_categories:10K<n<100K', 'format:parquet', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'arxiv:2412.04261', 'region:us']","
	
		
		Dataset Card for m-ArenaHard
	


	
		
		Dataset Details
	

The m-ArenaHard dataset is a multilingual LLM evaluation set. This dataset was created by translating the prompts from the originally English-only LMarena (formerly LMSYS) arena-hard-auto-v0.1 test dataset using Google Translate API v3 to 22 languages. The original English-only prompts were created by Li et al. (2024) and consist of 500 challenging user queries sourced from Chatbot Arena. The authors show that these can be used… See the full description on the dataset page: https://huggingface.co/datasets/CohereLabs/m-ArenaHard.",https://huggingface.co/datasets/CohereLabs/m-ArenaHard,"['en', 'fr', 'de', 'es', 'it', 'pt', 'ja', 'ko', 'zh', 'ar', 'el', 'fa', 'pl', 'id', 'cs', 'he', 'hi', 'nl', 'ro', 'ru', 'tr', 'uk', 'vi']",[],['10K<n<100K']
tokyotech-llm/lmsys-chat-1m-synth,tokyotech-llm,2024-10-24 01:29:56+00:00,2025-06-25 00:26:48+00:00,414,16,"['task_categories:text-generation', 'source_datasets:lmsys-chat-1m', 'language:ja', 'language:en', 'license:other', 'size_categories:100K<n<1M', 'region:us']","
	
		
		LMSYS-Chat-1M-Synth: Japanese/English Synthetic Conversation Dataset Derived from LMSYS-Chat-1M
	

This repository contains a series of Japanese and English conversation datasets derived from LMSYS-Chat-1M. 

Llama-3.1-LMSYS-Chat-1M-Synth
Utilized in the post-training of Llama-3.1-Swallow-8B-Instruct-v0.1 and Llama-3.1-Swallow-70B-Instruct-v0.1


Gemma-2-LMSYS-Chat-1M-Synth
Utilized in the post-training of Llama-3.1-Swallow-8B-Instruct-v0.3 and Llama-3.1-Swallow-70B-Instruct-v0.3… See the full description on the dataset page: https://huggingface.co/datasets/tokyotech-llm/lmsys-chat-1m-synth.",https://huggingface.co/datasets/tokyotech-llm/lmsys-chat-1m-synth,"['ja', 'en']",['text-generation'],['100K<n<1M']
espnet/floras,espnet,2024-10-24 01:40:36+00:00,2024-11-29 20:12:19+00:00,2147,12,"['task_categories:automatic-speech-recognition', 'task_categories:translation', 'task_categories:summarization', 'language:en', 'language:es', 'language:fr', 'language:de', 'language:nl', 'language:it', 'language:pt', 'language:hu', 'language:fi', 'language:el', 'language:ca', 'language:eo', 'language:et', 'language:da', 'language:la', 'language:sv', 'language:cy', 'language:gl', 'language:ru', 'language:pl', 'language:uk', 'language:ro', 'language:cs', 'language:sl', 'language:sk', 'language:hr', 'language:bg', 'language:bs', 'language:ka', 'language:tr', 'language:fa', 'language:ar', 'language:uz', 'language:az', 'language:ku', 'language:ky', 'language:hi', 'language:ta', 'language:ur', 'language:bn', 'language:id', 'language:vi', 'language:th', 'language:mi', 'language:ms', 'language:ja', 'language:zh', 'license:cc-by-3.0', 'size_categories:1K<n<10K', 'format:parquet', 'modality:audio', 'modality:text', 'library:datasets', 'library:dask', 'library:mlcroissant', 'library:polars', 'region:us']","
	
		
		FLORAS
	

FLORAS is a 50-language benchmark For LOng-form Recognition And Summarization of spoken language. 
The goal of FLORAS is to create a more realistic benchmarking environment for speech recognition, translation, and summarization models. 
Unlike typical academic benchmarks like LibriSpeech and FLEURS that uses pre-segmented single-speaker read-speech, FLORAS tests the capabilities of models on raw long-form conversational audio, which can have one or many speakers.
To encourage… See the full description on the dataset page: https://huggingface.co/datasets/espnet/floras.",https://huggingface.co/datasets/espnet/floras,"['en', 'es', 'fr', 'de', 'nl', 'it', 'pt', 'hu', 'fi', 'el', 'ca', 'eo', 'et', 'da', 'la', 'sv', 'cy', 'gl', 'ru', 'pl', 'uk', 'ro', 'cs', 'sl', 'sk', 'hr', 'bg', 'bs', 'ka', 'tr', 'fa', 'ar', 'uz', 'az', 'ku', 'ky', 'hi', 'ta', 'ur', 'bn', 'id', 'vi', 'th', 'mi', 'ms', 'ja', 'zh']","['automatic-speech-recognition', 'translation', 'summarization']",['1K<n<10K']
hpprc/paraphrase-qa,hpprc,2024-10-25 08:06:52+00:00,2025-02-11 14:59:45+00:00,55,3,"['task_categories:question-answering', 'language:ja', 'license:cc-by-sa-4.0', 'size_categories:10M<n<100M', 'format:parquet', 'modality:text', 'library:datasets', 'library:dask', 'library:mlcroissant', 'library:polars', 'region:us', 'synthetic']","日本語Wikipedia中のテキストを元に言い換えを生成し、その言い換えを元にクエリと回答をLLMに生成させたデータセットです。
出力にライセンス的な制約があるモデルを利用していないことと、元データとして日本語Wikipediaを利用していることから、CC-BY-SA 4.0ライセンスのもとでの配布とします。
",https://huggingface.co/datasets/hpprc/paraphrase-qa,['ja'],['question-answering'],['10M<n<100M']
prometheus-eval/MM-Eval,prometheus-eval,2024-10-25 09:28:19+00:00,2024-10-26 14:48:00+00:00,154,5,"['language:ar', 'language:bn', 'language:ca', 'language:de', 'language:en', 'language:es', 'language:eu', 'language:fr', 'language:gl', 'language:it', 'language:ja', 'language:ko', 'language:ru', 'language:sw', 'language:te', 'language:th', 'language:vi', 'language:zh', 'license:cc-by-sa-4.0', 'size_categories:10K<n<100K', 'format:parquet', 'modality:tabular', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'arxiv:2410.17578', 'region:us']","
	
		
		Multilingual Meta-EVALuation benchmark (MM-Eval)
	


👨‍💻Code
|
📄Paper
|
🤗 MMQA


MM-Eval is a multilingual meta-evaluation benchmark consisting of five core subsets—Chat, Reasoning, Safety, Language Hallucination, and Linguistics—spanning 18 languages and a Language Resource subset spanning 122 languages for a broader analysis of language effects. 

Design ChoiceIn this work, we minimize the inclusion of translated samples, as mere translation may alter existing preferences due to… See the full description on the dataset page: https://huggingface.co/datasets/prometheus-eval/MM-Eval.",https://huggingface.co/datasets/prometheus-eval/MM-Eval,"['ar', 'bn', 'ca', 'de', 'en', 'es', 'eu', 'fr', 'gl', 'it', 'ja', 'ko', 'ru', 'sw', 'te', 'th', 'vi', 'zh']",[],['10K<n<100K']
jaeyong2/ja-persona-cot-inst,jaeyong2,2024-10-26 02:29:21+00:00,2024-10-26 03:20:07+00:00,10,0,"['language:ja', 'license:cc-by-nc-sa-4.0', 'size_categories:100K<n<1M', 'format:parquet', 'modality:text', 'library:datasets', 'library:dask', 'library:mlcroissant', 'library:polars', 'region:us']","
	
		
		How to use
	

>>> from datasets import load_dataset

>>> ds = load_dataset(""jaeyong2/ja-persona-cot-inst"", split=""train"")
>>> ds
Dataset({
    features: ['content', 'text'],
    num_rows: 645000
})


	
		
	
	
		Development Process
	


load Question dataset from jaeyong2/persona-inst
We used Qwen/Qwen2-72B-Instruct model to generate answer with COT.


	
	
	
		License
	


Qwen/Qwen2.5-72B-Instruct : https://huggingface.co/Qwen/Qwen2-72B-Instruct/blob/main/LICENSE
proj-persona/PersonaHub… See the full description on the dataset page: https://huggingface.co/datasets/jaeyong2/ja-persona-cot-inst.",https://huggingface.co/datasets/jaeyong2/ja-persona-cot-inst,['ja'],[],['100K<n<1M']
Aratako/LLMChat-Judge-Results,Aratako,2024-10-26 06:17:00+00:00,2024-10-26 07:22:39+00:00,29,1,"['task_categories:text-generation', 'task_categories:text-classification', 'language:ja', 'license:other', 'size_categories:10K<n<100K', 'format:parquet', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","
	
		
		LLMChat-Judge-Results
	

team-hatakeyama-phase2/LLMChatの2つのモデルの応答に対して、様々なモデルを用いてPairwise評価を行った結果のデータです。
人手評価とオープンLLMによる自動評価の一致率の検証のために作成しました。詳細についてはこちらの記事を確認してください。

	
		
		ライセンスについて
	

元のデータセットであるteam-hatakeyama-phase2/LLMChatに準じます。一部出力を使ったモデルの学習が禁止されているものもあるのでご注意ください。
その他の詳細については元データセットをご確認ください。
",https://huggingface.co/datasets/Aratako/LLMChat-Judge-Results,['ja'],"['text-generation', 'text-classification']",['10K<n<100K']
neurlang/phonetic,neurlang,2024-10-26 14:53:21+00:00,2025-03-05 22:17:33+00:00,54,8,"['task_categories:translation', 'task_categories:text-classification', 'task_categories:token-classification', 'language:af', 'language:am', 'language:ar', 'language:az', 'language:be', 'language:bn', 'language:my', 'language:ceb', 'language:ce', 'language:zh', 'language:cs', 'language:da', 'language:nl', 'language:dz', 'language:en', 'language:eo', 'language:fa', 'language:fi', 'language:fr', 'language:de', 'language:el', 'language:gu', 'language:ha', 'language:he', 'language:hi', 'language:hu', 'language:is', 'language:id', 'language:tts', 'language:it', 'language:jam', 'language:ja', 'language:jv', 'language:kk', 'language:ko', 'language:lb', 'language:mk', 'language:ml', 'language:ms', 'language:mt', 'language:mr', 'language:mn', 'language:ne', 'language:no', 'language:ps', 'language:pl', 'language:pt', 'language:pa', 'language:ro', 'language:ru', 'language:sk', 'language:es', 'language:sw', 'language:sv', 'language:ta', 'language:te', 'language:th', 'language:bo', 'language:tr', 'language:uk', 'language:ur', 'language:ug', 'language:vi', 'language:zu', 'language:hy', 'language:eu', 'language:bg', 'language:ca', 'language:ny', 'language:hr', 'language:et', 'language:gl', 'language:ka', 'language:km', 'language:lo', 'language:lv', 'language:lt', 'language:sr', 'language:tl', 'language:yo', 'license:cc', 'size_categories:1M<n<10M', 'region:us', 'ipa', 'phonetic']","
	
		
		Phonetic IPA Dataset for 85+ languages
	

Download the dataset: [https://github.com/neurlang/dataset]
Use our model trained on the dataset: [https://www.hashtron.cloud]

	
		
		Licensing information:
	


MIT Original data for the 15 languages taken from gruut databases
MIT To this the data for the 31 languages were added ipa dict files
CC0: Public Domain Chinese/Mandarin-IPA language sentence pairs were generated:
from the chinese sentences taken from dataset from kaggle
based on the… See the full description on the dataset page: https://huggingface.co/datasets/neurlang/phonetic.",https://huggingface.co/datasets/neurlang/phonetic,"['af', 'am', 'ar', 'az', 'be', 'bn', 'my', 'ceb', 'ce', 'zh', 'cs', 'da', 'nl', 'dz', 'en', 'eo', 'fa', 'fi', 'fr', 'de', 'el', 'gu', 'ha', 'he', 'hi', 'hu', 'is', 'id', 'tts', 'it', 'jam', 'ja', 'jv', 'kk', 'ko', 'lb', 'mk', 'ml', 'ms', 'mt', 'mr', 'mn', 'ne', 'no', 'ps', 'pl', 'pt', 'pa', 'ro', 'ru', 'sk', 'es', 'sw', 'sv', 'ta', 'te', 'th', 'bo', 'tr', 'uk', 'ur', 'ug', 'vi', 'zu', 'hy', 'eu', 'bg', 'ca', 'ny', 'hr', 'et', 'gl', 'ka', 'km', 'lo', 'lv', 'lt', 'sr', 'tl', 'yo']","['translation', 'text-classification', 'token-classification']",['1M<n<10M']
StingrayBench/StingrayBench,StingrayBench,2024-10-27 04:02:22+00:00,2025-02-19 19:46:16+00:00,42,0,"['task_categories:text-classification', 'task_categories:question-answering', 'language:id', 'language:en', 'language:de', 'language:zh', 'language:tl', 'language:ja', 'language:ms', 'license:cc-by-sa-4.0', 'size_categories:1K<n<10K', 'region:us', 'multilingual']","
	
		
		Dataset Card for StingrayBench
	





	
		
		Dataset Description
	


StingrayBench is a benchmark dataset designed to evaluate cross-lingual sense disambiguation in multilingual large language models (LLMs). This dataset targets the comprehension of false friends—words that appear orthographically similar but have distinct meanings across languages. It serves as the first benchmark specifically measuring cross-lingual semantic understanding in LLMs.

Curated by: Samuel Cahyawijaya… See the full description on the dataset page: https://huggingface.co/datasets/StingrayBench/StingrayBench.",https://huggingface.co/datasets/StingrayBench/StingrayBench,"['id', 'en', 'de', 'zh', 'tl', 'ja', 'ms']","['text-classification', 'question-answering']",['1K<n<10K']
Aratako/SFT-Dataset-For-Self-Taught-Evaluators-iter1,Aratako,2024-10-27 08:26:38+00:00,2024-10-27 10:29:53+00:00,15,1,"['task_categories:text-generation', 'language:ja', 'license:apache-2.0', 'size_categories:10K<n<100K', 'format:parquet', 'modality:tabular', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']",,https://huggingface.co/datasets/Aratako/SFT-Dataset-For-Self-Taught-Evaluators-iter1,['ja'],['text-generation'],['10K<n<100K']
neulab/PangeaBench-xmmmu,neulab,2024-10-28 01:28:23+00:00,2024-11-03 16:51:11+00:00,187,2,"['task_categories:visual-question-answering', 'task_categories:question-answering', 'task_categories:multiple-choice', 'language:ar', 'language:fr', 'language:hi', 'language:id', 'language:ja', 'language:pt', 'language:en', 'license:mit', 'size_categories:1K<n<10K', 'format:parquet', 'modality:image', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']",,https://huggingface.co/datasets/neulab/PangeaBench-xmmmu,"['ar', 'fr', 'hi', 'id', 'ja', 'pt', 'en']","['visual-question-answering', 'question-answering', 'multiple-choice']",['1K<n<10K']
DeL-TaiseiOzaki/magpie-reasonig-ja-qwen2.5-72b-16k,DeL-TaiseiOzaki,2024-10-28 01:32:23+00:00,2024-11-19 15:30:41+00:00,7,0,"['language:ja', 'license:other', 'size_categories:10K<n<100K', 'format:json', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","
	
		
		合成日本語指示データセット
	


	
		
		概要
	

このデータセットは、大規模言語モデル（LLM）を用いて自動生成された日本語の指示とそれに対する推論・初期応答・改善応答のコレクションです。データセットは指示付与型のタスクのための学習や評価に使用することを目的としています。

	
		
		データセット仕様
	


サンプル数: 約16,000
言語: 日本語
フォーマット: JSONL


	
		
		生成方法
	

データセットは以下のプロセスを通じて生成されました：

Qwen2.5 72B Instructモデルを使用
各サンプルは以下のプロセスで生成:
a) 10種のペルソナシステムプロンプトからランダムに1件選択し，事前に用意した指示文の参考例を3-shot-learningして指示文の生成．
b) 完成した指示文からコサイン類似度0.9を閾値として重複削除
c) 指示応答を生成するための推論手順を生成
d) 指示文と推論手順を元に初期解答を生成
e) 初期応答のself-refineを行い，最終解答を生成




	
		
		データ構造… See the full description on the dataset page: https://huggingface.co/datasets/DeL-TaiseiOzaki/magpie-reasonig-ja-qwen2.5-72b-16k.",https://huggingface.co/datasets/DeL-TaiseiOzaki/magpie-reasonig-ja-qwen2.5-72b-16k,['ja'],[],['10K<n<100K']
kogi-jwu/cl-humaneval_v1.0,kogi-jwu,2024-10-28 07:06:59+00:00,2024-12-31 06:23:04+00:00,8,0,"['language:en', 'language:ja', 'license:mit', 'size_categories:n<1K', 'format:parquet', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us', 'code']","
	
		
		CL-HumanEval
	


	
		
		Dataset Description
	

CL-HumanEval is a benchmark for evaluating cross-lingual transfer through code generation. 
It is based on the code generation benchmark HumanEval.

	
		
		Languages
	

The dataset contains coding problems in 2 natural languages: English and Japanese.

	
		
		Dataset Structure
	

from datasets import load_dataset
load_dataset(""kogi-jwu/cl-humaneval_v1.0"", ""en"")

DatasetDict({
    test: Dataset({
        features: ['task_id', 'lang'… See the full description on the dataset page: https://huggingface.co/datasets/kogi-jwu/cl-humaneval_v1.0.",https://huggingface.co/datasets/kogi-jwu/cl-humaneval_v1.0,"['en', 'ja']",[],['n<1K']
rikka-snow/prompt-injection-multilingual,rikka-snow,2024-10-28 10:08:49+00:00,2024-10-28 10:11:21+00:00,94,0,"['task_categories:text-classification', 'language:vi', 'language:en', 'language:zh', 'language:fr', 'language:de', 'language:hi', 'language:it', 'language:ja', 'language:pt', 'language:es', 'language:th', 'license:mit', 'size_categories:1K<n<10K', 'format:parquet', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']",,https://huggingface.co/datasets/rikka-snow/prompt-injection-multilingual,"['vi', 'en', 'zh', 'fr', 'de', 'hi', 'it', 'ja', 'pt', 'es', 'th']",['text-classification'],['1K<n<10K']
jaeyong2/ja-rag-cot,jaeyong2,2024-10-29 15:19:38+00:00,2024-11-01 03:55:04+00:00,31,2,"['language:ja', 'license:cc-by-sa-3.0', 'size_categories:100K<n<1M', 'format:parquet', 'modality:text', 'library:datasets', 'library:dask', 'library:mlcroissant', 'library:polars', 'region:us']",">>> from datasets import load_dataset

>>> ds = load_dataset(""jaeyong2/ja-rag-cot"", split=""train"")
>>> ds
Dataset({
    features: ['context', 'Question', 'RAW Ground Truth', 'Thinking', 'Final Answer'],
    num_rows: 209496
})


	
		
	
	
		Development Process
	


source dataset from range3/wikipedia-ja-20230101
We used Qwen/Qwen2-72B-Instruct model to generate answer with COT.


	
	
	
		License
	


Qwen/Qwen2.5-72B-Instruct : https://huggingface.co/Qwen/Qwen2-72B-Instruct/blob/main/LICENSE… See the full description on the dataset page: https://huggingface.co/datasets/jaeyong2/ja-rag-cot.",https://huggingface.co/datasets/jaeyong2/ja-rag-cot,['ja'],[],['100K<n<1M']
neulab/PangeaBench-multilingual-llava-bench,neulab,2024-10-31 06:24:38+00:00,2024-10-31 19:48:20+00:00,6,0,"['language:ar', 'language:bn', 'language:en', 'language:es', 'language:fr', 'language:hi', 'language:ja', 'language:ru', 'language:ur', 'language:zh', 'size_categories:n<1K', 'format:parquet', 'modality:image', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']",,https://huggingface.co/datasets/neulab/PangeaBench-multilingual-llava-bench,"['ar', 'bn', 'en', 'es', 'fr', 'hi', 'ja', 'ru', 'ur', 'zh']",[],['n<1K']
neulab/PangeaBench-cvqa,neulab,2024-10-31 20:31:00+00:00,2024-10-31 20:40:41+00:00,22,1,"['task_categories:question-answering', 'language:id', 'language:su', 'language:ja', 'language:jv', 'language:min', 'language:br', 'language:ga', 'language:es', 'language:pt', 'language:no', 'language:mn', 'language:ms', 'language:zh', 'language:ko', 'language:ta', 'language:ben', 'language:si', 'language:bg', 'language:ro', 'language:ru', 'language:am', 'language:orm', 'language:ar', 'language:ig', 'size_categories:10K<n<100K', 'format:parquet', 'modality:image', 'modality:text', 'library:datasets', 'library:dask', 'library:mlcroissant', 'library:polars', 'region:us']","
	
		
		About CVQA
	

CVQA is a culturally diverse multilingual VQA benchmark consisting of over 9,000 questions from 33 country-language pairs. The questions in CVQA are written in both the native languages and English, and are categorized into 10 diverse categories.
This data is designed for use as a test set. Please submit your submission here to evaluate your model performance. CVQA is constructed through a collaborative effort led by a team of researchers from MBZUAI. Read more about CVQA… See the full description on the dataset page: https://huggingface.co/datasets/neulab/PangeaBench-cvqa.",https://huggingface.co/datasets/neulab/PangeaBench-cvqa,"['id', 'su', 'ja', 'jv', 'min', 'br', 'ga', 'es', 'pt', 'no', 'mn', 'ms', 'zh', 'ko', 'ta', 'ben', 'si', 'bg', 'ro', 'ru', 'am', 'orm', 'ar', 'ig']",['question-answering'],['10K<n<100K']
neulab/PangeaBench-xchat,neulab,2024-10-31 21:38:23+00:00,2024-11-01 15:19:15+00:00,16,0,"['task_categories:visual-question-answering', 'language:zh', 'language:en', 'language:hi', 'language:id', 'language:ja', 'language:rw', 'language:ko', 'language:es', 'license:cc-by-4.0', 'size_categories:n<1K', 'format:parquet', 'modality:image', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']",,https://huggingface.co/datasets/neulab/PangeaBench-xchat,"['zh', 'en', 'hi', 'id', 'ja', 'rw', 'ko', 'es']",['visual-question-answering'],['n<1K']
global-llm-2024/ja_ifeval,global-llm-2024,2024-11-01 07:52:32+00:00,2024-11-01 08:03:04+00:00,6,0,"['language:ja', 'size_categories:n<1K', 'format:json', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","
	
		
		Dataset Card for Dataset Name
	



This dataset card aims to be a base template for new datasets. It has been generated using this raw template.

	
		
		Dataset Details
	


	
		
		Dataset Description
	






Curated by: [More Information Needed]
Funded by [optional]: [More Information Needed]
Shared by [optional]: [More Information Needed]
Language(s) (NLP): [More Information Needed]
License: [More Information Needed]


	
		
		Dataset Sources [optional]
	




Repository: [More… See the full description on the dataset page: https://huggingface.co/datasets/global-llm-2024/ja_ifeval.",https://huggingface.co/datasets/global-llm-2024/ja_ifeval,['ja'],[],['n<1K']
neulab/PangeaBench-tydiqa,neulab,2024-11-01 16:28:55+00:00,2024-11-01 18:29:22+00:00,53,0,"['task_categories:question-answering', 'task_ids:extractive-qa', 'annotations_creators:crowdsourced', 'language_creators:crowdsourced', 'multilinguality:multilingual', 'source_datasets:extended|wikipedia', 'language:ar', 'language:bn', 'language:en', 'language:fi', 'language:id', 'language:ja', 'language:ko', 'language:ru', 'language:sw', 'language:te', 'language:th', 'license:apache-2.0', 'size_categories:100K<n<1M', 'modality:text', 'region:us']","
	
		
		Dataset Card for ""tydiqa""
	


	
		
		Dataset Summary
	

TyDi QA is a question answering dataset covering 11 typologically diverse languages with 204K question-answer pairs.
The languages of TyDi QA are diverse with regard to their typology -- the set of linguistic features that each language
expresses -- such that we expect models performing well on this set to generalize across a large number of the languages
in the world. It contains language phenomena that would not be found in… See the full description on the dataset page: https://huggingface.co/datasets/neulab/PangeaBench-tydiqa.",https://huggingface.co/datasets/neulab/PangeaBench-tydiqa,"['ar', 'bn', 'en', 'fi', 'id', 'ja', 'ko', 'ru', 'sw', 'te', 'th']",['question-answering'],['100K<n<1M']
Rio-Rf/oscar_2023_filtered_and_ai_text_filtered,Rio-Rf,2024-11-02 02:52:51+00:00,2024-11-02 03:30:47+00:00,5,0,"['task_categories:text-classification', 'task_categories:text-generation', 'language:ja', 'license:cc0-1.0', 'size_categories:10K<n<100K', 'format:json', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","
人間が作成したテキスト(OSCAR)とLLM生成テキスト(GPT-3.5 Turbo)から成るデータセット
LLMで生成された日本語テキストの検出性能の検証のために作成した

詳細はコードを参照
https://github.com/Rio-Rf/Lab-CreateDataset
",https://huggingface.co/datasets/Rio-Rf/oscar_2023_filtered_and_ai_text_filtered,['ja'],"['text-classification', 'text-generation']",['10K<n<100K']
deepghs/danbooru2024,deepghs,2024-11-02 17:23:45+00:00,2024-11-25 13:26:02+00:00,2439,30,"['task_categories:image-classification', 'task_categories:zero-shot-image-classification', 'task_categories:text-to-image', 'annotations_creators:no-annotation', 'source_datasets:danbooru', 'language:en', 'language:ja', 'license:other', 'size_categories:1M<n<10M', 'region:us', 'art', 'anime', 'not-for-all-audiences']","
	
		
		Danbooru2024 Dataset
	

8058098 original images in total.

	
		
		🎨 Danbooru2024 Dataset
	





	
		
	
	
		📊 Dataset Overview
	

The Danbooru2024 dataset is a comprehensive collection focused on animation and illustration artwork, derived from the official Danbooru platform. It contains approximately 8.05 million high-quality, user-annotated images with corresponding tags and textual descriptions.

	
	
	
		✨ Features
	


	
	
	
		📋 Metadata Support
	

Includes a Parquet format… See the full description on the dataset page: https://huggingface.co/datasets/deepghs/danbooru2024.",https://huggingface.co/datasets/deepghs/danbooru2024,"['en', 'ja']","['image-classification', 'zero-shot-image-classification', 'text-to-image']",['1M<n<10M']
deepghs/danbooru2024-sfw,deepghs,2024-11-02 17:44:14+00:00,2024-11-18 13:25:27+00:00,808,11,"['task_categories:image-classification', 'task_categories:zero-shot-image-classification', 'task_categories:text-to-image', 'annotations_creators:no-annotation', 'source_datasets:danbooru', 'language:en', 'language:ja', 'license:other', 'size_categories:1M<n<10M', 'region:us', 'art', 'anime', 'not-for-all-audiences']","
	
		
		🎨 Danbooru2024 Dataset
	





	
		
	
	
		📊 Dataset Overview
	

The Danbooru2024 dataset is a comprehensive collection focused on animation and illustration artwork, derived from the official Danbooru platform. It contains approximately 6.5 million high-quality, user-annotated images with corresponding tags and textual descriptions.
This dataset is filtered from an original set of 8.3 million entries, excluding NSFW-rated, opt-out entries to create a more accessible and… See the full description on the dataset page: https://huggingface.co/datasets/deepghs/danbooru2024-sfw.",https://huggingface.co/datasets/deepghs/danbooru2024-sfw,"['en', 'ja']","['image-classification', 'zero-shot-image-classification', 'text-to-image']",['1M<n<10M']
deepghs/danbooru2024-webp-4Mpixel,deepghs,2024-11-02 18:50:50+00:00,2024-11-18 13:26:12+00:00,6884,16,"['task_categories:image-classification', 'task_categories:zero-shot-image-classification', 'task_categories:text-to-image', 'annotations_creators:no-annotation', 'source_datasets:danbooru', 'language:en', 'language:ja', 'license:other', 'size_categories:100M<n<1B', 'format:webdataset', 'modality:text', 'modality:timeseries', 'library:datasets', 'library:webdataset', 'library:mlcroissant', 'region:us', 'art', 'anime', 'not-for-all-audiences']","
	
		
		🎨 Danbooru2024 Webp 4MPixel Dataset
	





	
		
	
	
		📊 Dataset Overview
	

The Danbooru2024-Webp dataset is a comprehensive collection focused on animation and illustration artwork, derived from the official Danbooru platform. It contains approximately 8.05 million high-quality, user-annotated images with corresponding tags and textual descriptions.
This dataset is 4MP-focused webp resized-dataset of Danbooru2024.

		
		✨ Features
	


	
		
		📋 Metadata Support
	

Includes a Parquet… See the full description on the dataset page: https://huggingface.co/datasets/deepghs/danbooru2024-webp-4Mpixel.",https://huggingface.co/datasets/deepghs/danbooru2024-webp-4Mpixel,"['en', 'ja']","['image-classification', 'zero-shot-image-classification', 'text-to-image']",['100M<n<1B']
kajuma/ABEJA-CC-JA,kajuma,2024-11-03 05:37:36+00:00,2024-12-06 07:22:40+00:00,113,2,"['task_categories:text-generation', 'language:ja', 'license:pddl', 'size_categories:100M<n<1B', 'format:parquet', 'modality:text', 'library:datasets', 'library:dask', 'library:mlcroissant', 'library:polars', 'region:us']","
	
		
		ABEJA-CC-JA
	

This dataset is hf mirror of https://registry.opendata.aws/abeja-cc-ja/
Please Refer to https://tech-blog.abeja.asia/entry/abeja-cc-ja-202409
このデータセットはhttps://registry.opendata.aws/abeja-cc-ja/のHFミラーです。
この記事を参照してください。
",https://huggingface.co/datasets/kajuma/ABEJA-CC-JA,['ja'],['text-generation'],['100M<n<1B']
DeL-TaiseiOzaki/Tengentoppa-sft-qwen2.5-32b-reasoning-100k,DeL-TaiseiOzaki,2024-11-03 07:18:52+00:00,2024-11-03 07:34:14+00:00,13,1,"['language:ja', 'license:apache-2.0', 'size_categories:100K<n<1M', 'format:json', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","
	
		
		合成日本語指示データセット
	


	
		
		概要
	

このデータセットは、大規模言語モデル（Qwen2.5-32B-instruct）を用いて自動生成された日本語の指示とそれに対する応答のコレクションです。データセットは指示付与型のタスクのための学習や評価に使用することを目的としています。

	
		
		データセット仕様
	


サンプル数: 125,000
言語: 日本語
フォーマット: JSONL
ライセンス: Apache-2.0
サイズカテゴリ: 100K<n


	
		
		生成方法
	

データセットは以下のプロセスを通じて生成されました：

Qwen2.5-32B Instructモデルを使用
各サンプルは3段階のプロセスで生成:
a) マルチペルソナに基づく多様な指示文の生成
b) Chain-of-Thought (CoT) 指示文に対する回答手順を生成
c) 回答生成
c) self-refine後の回答


生成の多様性を向上させるため、10種類のペルソナからランダムに1つ選んでシステムプロンプトに入力


	
		
		データ構造… See the full description on the dataset page: https://huggingface.co/datasets/DeL-TaiseiOzaki/Tengentoppa-sft-qwen2.5-32b-reasoning-100k.",https://huggingface.co/datasets/DeL-TaiseiOzaki/Tengentoppa-sft-qwen2.5-32b-reasoning-100k,['ja'],[],['100K<n<1M']
efederici/mc-translation,efederici,2024-11-03 22:56:19+00:00,2024-11-05 10:27:01+00:00,25,2,"['task_categories:translation', 'language:en', 'language:sw', 'language:es', 'language:de', 'language:zh', 'language:bn', 'language:it', 'language:hi', 'language:ja', 'language:ko', 'language:pt', 'language:ar', 'language:id', 'license:mit', 'size_categories:100K<n<1M', 'format:parquet', 'modality:text', 'library:datasets', 'library:dask', 'library:mlcroissant', 'library:polars', 'region:us', 'multiple-choice', 'eval']","This dataset contains professional human translations from OpenAI's MMMLU dataset, repurposed to train translation models that can help translate future evaluation datasets.

	
		
		Why This Dataset?
	

Translation of evaluation benchmarks is a critical but challenging task. While automated translations may introduce errors or biases, professional human translations are expensive and time-consuming. This dataset leverages existing professional translations (MMMLU) to train specialized… See the full description on the dataset page: https://huggingface.co/datasets/efederici/mc-translation.",https://huggingface.co/datasets/efederici/mc-translation,"['en', 'sw', 'es', 'de', 'zh', 'bn', 'it', 'hi', 'ja', 'ko', 'pt', 'ar', 'id']",['translation'],['100K<n<1M']
ryota39/preference-en-ja-100k,ryota39,2024-11-04 05:10:16+00:00,2024-11-19 11:24:26+00:00,27,1,"['task_categories:reinforcement-learning', 'language:en', 'language:ja', 'license:unknown', 'size_categories:100K<n<1M', 'format:json', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us', 'translation']","
	
		
		preference-en-ja-100k
	


以下のデータセットを選好データの形式に加工し、和訳データを加えた後にOpenAI message形式に加工しました

Dahoas/synthetic-instruct-gptj-pairwise
openai/webgpt_comparisons


和訳に使用したモデル

llm-jp/llm-jp-3-13b-instruct




	
		
	
	
		License
	


使用させていただいたデータセットおよびモデルのライセンスに従い、下記の通り設定しました


	
		
dataset
license


		
Dahoas/synthetic-instruct-gptj-pairwise
unknown

openai/webgpt_comparisons
unknown


	


	
		
model
license


		
llm-jp/llm-jp-3-13b-instruct
apache-2.0


	

",https://huggingface.co/datasets/ryota39/preference-en-ja-100k,"['en', 'ja']",['reinforcement-learning'],['100K<n<1M']
None1145/Vulpisfoglia,None1145,2024-11-05 01:29:25+00:00,2024-11-16 12:24:10+00:00,11,1,"['task_categories:audio-to-audio', 'task_categories:text-to-speech', 'language:zh', 'language:ja', 'language:it', 'license:mit', 'size_categories:n<1K', 'format:audiofolder', 'modality:audio', 'library:datasets', 'library:mlcroissant', 'region:us', 'Vulpisfoglia', 'Arknights', '忍冬', '明日方舟、']",,https://huggingface.co/datasets/None1145/Vulpisfoglia,"['zh', 'ja', 'it']","['audio-to-audio', 'text-to-speech']",['n<1K']
TangRain/SingMOS,TangRain,2024-11-05 16:11:07+00:00,2025-10-02 07:22:35+00:00,169,4,"['language:zh', 'language:ja', 'license:cc-by-4.0', 'size_categories:1K<n<10K', 'format:audiofolder', 'modality:audio', 'modality:text', 'library:datasets', 'library:mlcroissant', 'arxiv:2406.10911', 'region:us', 'singing', 'MOS']","NOTICE[Important！！！！]: We release the official version of SingMOS-Pro.
-------------------- Previous Information -----------------------
paper link: SingMOS: An extensive Open-Source Singing Voice Dataset for MOS Prediction
NOTICE: Our new paper has not been released and the information in SingMOS paper remain in SingMOS_v1. We will update it soon.
If you want to use the dataset of the singing track in VoiceMOS 2024, you can visit SingMOS_v1.
If you want to use our pretrained SingMOS model… See the full description on the dataset page: https://huggingface.co/datasets/TangRain/SingMOS.",https://huggingface.co/datasets/TangRain/SingMOS,"['zh', 'ja']",[],['1K<n<10K']
None1145/Theresa,None1145,2024-11-06 14:51:39+00:00,2024-11-16 12:23:38+00:00,23,1,"['task_categories:text-to-speech', 'task_categories:text-generation', 'language:zh', 'language:ja', 'license:mit', 'size_categories:n<1K', 'format:json', 'modality:audio', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us', 'Theresa', 'Arknights', '特蕾西娅', '魔王', '明日方舟']",,https://huggingface.co/datasets/None1145/Theresa,"['zh', 'ja']","['text-to-speech', 'text-generation']",['n<1K']
pacscilab/VoxCommunis,pacscilab,2024-11-06 22:33:01+00:00,2025-09-01 09:43:46+00:00,2709,6,"['language:ab', 'language:am', 'language:ba', 'language:be', 'language:bg', 'language:bn', 'language:ca', 'language:cs', 'language:cv', 'language:ckb', 'language:dv', 'language:el', 'language:eu', 'language:gn', 'language:ha', 'language:hi', 'language:hsb', 'language:hu', 'language:hy', 'language:id', 'language:it', 'language:ja', 'language:ka', 'language:kk', 'language:ko', 'language:ky', 'language:lt', 'language:mk', 'language:mn', 'language:mr', 'language:mt', 'language:nl', 'language:or', 'language:pa', 'language:pl', 'language:pt', 'language:ro', 'language:ru', 'language:rw', 'language:sk', 'language:sl', 'language:sq', 'language:sr', 'language:sv', 'language:sw', 'language:ta', 'language:th', 'language:tk', 'language:tr', 'language:ug', 'language:uk', 'language:uz', 'language:vi', 'language:yo', 'language:yue', 'language:zh', 'license:cc0-1.0', 'size_categories:n<1K', 'region:us', 'Phonetics', 'Linguistics', 'Corpus']","
	
		
		VoxCommunis Corpus
	

The VoxCommunis Corpus is a phonetic corpus derived from the Mozilla Common Voice Corpus. Corresponding audio files and corpus metadata can be downloaded from Mozilla Common Voice, or from one of several Hugging Face repositories for the differing versions. 
Within each folder, the filenames share similar structure and contain critical information for effectively using the file. More detail regarding the specifics of the filename for each file type is provided… See the full description on the dataset page: https://huggingface.co/datasets/pacscilab/VoxCommunis.",https://huggingface.co/datasets/pacscilab/VoxCommunis,"['ab', 'am', 'ba', 'be', 'bg', 'bn', 'ca', 'cs', 'cv', 'ckb', 'dv', 'el', 'eu', 'gn', 'ha', 'hi', 'hsb', 'hu', 'hy', 'id', 'it', 'ja', 'ka', 'kk', 'ko', 'ky', 'lt', 'mk', 'mn', 'mr', 'mt', 'nl', 'or', 'pa', 'pl', 'pt', 'ro', 'ru', 'rw', 'sk', 'sl', 'sq', 'sr', 'sv', 'sw', 'ta', 'th', 'tk', 'tr', 'ug', 'uk', 'uz', 'vi', 'yo', 'yue', 'zh']",[],['n<1K']
tosa-no-onchan/opp,tosa-no-onchan,2024-11-07 10:03:45+00:00,2024-11-07 10:19:04+00:00,7,0,"['language:ja', 'size_categories:1K<n<10K', 'format:imagefolder', 'modality:image', 'library:datasets', 'library:mlcroissant', 'region:us']","OPP Transformer and LSTM Trainning datasets.Obstacle Path Planner with Transformer and LSTM
",https://huggingface.co/datasets/tosa-no-onchan/opp,['ja'],[],['1K<n<10K']
None1145/Lappland-the-Decadenza,None1145,2024-11-08 06:24:38+00:00,2024-11-16 12:24:21+00:00,12,2,"['task_categories:audio-to-audio', 'task_categories:text-to-speech', 'language:zh', 'language:ja', 'language:it', 'license:mit', 'size_categories:n<1K', 'format:audiofolder', 'modality:audio', 'library:datasets', 'library:mlcroissant', 'region:us', 'Lappland the Decadenza', 'Arknights', '荒芜拉普兰德', '明日方舟']",,https://huggingface.co/datasets/None1145/Lappland-the-Decadenza,"['zh', 'ja', 'it']","['audio-to-audio', 'text-to-speech']",['n<1K']
ryota39/preference_test,ryota39,2024-11-09 05:59:35+00:00,2024-11-16 03:25:50+00:00,7,0,"['language:ja', 'size_categories:10K<n<100K', 'format:parquet', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']",,https://huggingface.co/datasets/ryota39/preference_test,['ja'],[],['10K<n<100K']
litagin/Galgame_Speech_SER_16kHz,litagin,2024-11-10 00:56:46+00:00,2024-11-10 23:51:32+00:00,180,11,"['task_categories:automatic-speech-recognition', 'task_categories:audio-classification', 'multilinguality:monolingual', 'language:ja', 'license:gpl-3.0', 'size_categories:1M<n<10M', 'format:webdataset', 'modality:audio', 'modality:text', 'library:datasets', 'library:webdataset', 'library:mlcroissant', 'region:us', 'speech', 'audio', 'emotion', 'speech-emotion-recognition', 'text', 'japanese', 'anime', 'voice', 'visual novel', 'galgame']","
	
		
		Dataset Card for Galgame_Speech_SER_16kHz
	


[!IMPORTANT]The following rules (in the original repository) must be followed:
必须遵守GNU General Public License v3.0内的所有协议！附加：禁止商用，本数据集以及使用本数据集训练出来的任何模型都不得用于任何商业行为，如要用于商业用途，请找数据列表内的所有厂商授权（笑），因违反开源协议而出现的任何问题都与本人无关！
训练出来的模型必须开源，是否在README内引用本数据集由训练者自主决定，不做强制要求。
English:
You must comply with all the terms of the GNU General Public License v3.0!Additional note: Commercial use is prohibited. This dataset and any model trained using this dataset… See the full description on the dataset page: https://huggingface.co/datasets/litagin/Galgame_Speech_SER_16kHz.",https://huggingface.co/datasets/litagin/Galgame_Speech_SER_16kHz,['ja'],"['automatic-speech-recognition', 'audio-classification']",['1M<n<10M']
hal-utokyo/Manga109-s,hal-utokyo,2024-11-10 14:34:10+00:00,2025-05-23 09:56:55+00:00,49,14,"['language:ja', 'license:other', 'modality:image', 'region:us']","
	
		

Academic Use
Non-academic Use


		
Academic Institutions (e.g. University)
Manga109
Manga109-s


Others (e.g. Company)
Manga109-s
Manga109-s


	


	
		
		Manga109-s Dataset
	

Among the works contained in the Manga109 dataset, 87 books are available for commercial use, under the following conditions.
This special subset of the Manga109 dataset is available as the Manga109-s dataset (hereby referred to as “the dataset”).
The Manga109-s dataset is available for the following uses:

Using… See the full description on the dataset page: https://huggingface.co/datasets/hal-utokyo/Manga109-s.",https://huggingface.co/datasets/hal-utokyo/Manga109-s,['ja'],[],[]
hal-utokyo/Manga109,hal-utokyo,2024-11-10 14:43:28+00:00,2025-08-15 01:26:22+00:00,98,13,"['language:ja', 'license:other', 'modality:image', 'region:us']","
	
		

Academic Use
Non-academic Use


		
Academic Institutions (e.g. University)
Manga109
Manga109-s


Others (e.g. Company)
Manga109-s
Manga109-s


	


	
		
		⚠️ Important Notice ⚠️
	

Manga109 is for academic use. To apply for its use, the Primary email address in your Hugging Face account settings must be from an academic institution such as a university or equivalent (e.g. an email address ending in .ac.jp or .edu). 
If this is not the case, your data use request will not be approved. For… See the full description on the dataset page: https://huggingface.co/datasets/hal-utokyo/Manga109.",https://huggingface.co/datasets/hal-utokyo/Manga109,['ja'],[],[]
Aratako/dataset-for-annotation,Aratako,2024-11-10 15:50:23+00:00,2024-11-10 15:52:06+00:00,10,1,"['task_categories:text-generation', 'language:ja', 'license:apache-2.0', 'size_categories:10K<n<100K', 'format:parquet', 'modality:text', 'library:datasets', 'library:dask', 'library:mlcroissant', 'library:polars', 'region:us']",,https://huggingface.co/datasets/Aratako/dataset-for-annotation,['ja'],['text-generation'],['10K<n<100K']
None1145/Theresa-Recording,None1145,2024-11-11 00:41:26+00:00,2024-11-16 12:23:57+00:00,7,1,"['task_categories:text-to-speech', 'language:ja', 'license:mit', 'size_categories:n<1K', 'format:audiofolder', 'modality:audio', 'library:datasets', 'library:mlcroissant', 'region:us', 'Theresa', 'Arknights', '特蕾西娅', '魔王', '明日方舟']",,https://huggingface.co/datasets/None1145/Theresa-Recording,['ja'],['text-to-speech'],['n<1K']
Kendamarron/multiturn-qwen2.5-32b,Kendamarron,2024-11-11 07:28:24+00:00,2024-11-16 04:33:18+00:00,8,1,"['language:ja', 'license:apache-2.0', 'size_categories:1K<n<10K', 'format:parquet', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","Qwen/Qwen2.5-32B-Instruct-AWQで生成した3ターンのマルチターンinstructionデータセットです。
Qwenで生成したため、英語や中国語が混ざっているレコードがあります。適宜フィルタリングを行ってください。
Aratako/Magpie-Tanuki-8B-annotated-96kのinstructionをお借りしました。
",https://huggingface.co/datasets/Kendamarron/multiturn-qwen2.5-32b,['ja'],[],['1K<n<10K']
Aratako/dataset-for-annotation-v2,Aratako,2024-11-11 10:24:55+00:00,2024-11-30 15:13:22+00:00,14,0,"['task_categories:text-generation', 'language:ja', 'license:apache-2.0', 'size_categories:100K<n<1M', 'format:parquet', 'modality:tabular', 'modality:text', 'library:datasets', 'library:dask', 'library:mlcroissant', 'library:polars', 'region:us']",,https://huggingface.co/datasets/Aratako/dataset-for-annotation-v2,['ja'],['text-generation'],['100K<n<1M']
hpprc/ihyoki,hpprc,2024-11-11 13:53:39+00:00,2024-11-11 14:07:53+00:00,8,4,"['language:ja', 'license:cc-by-sa-4.0', 'size_categories:1M<n<10M', 'format:parquet', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']",,https://huggingface.co/datasets/hpprc/ihyoki,['ja'],[],['1M<n<10M']
nyuuzyou/suno,nyuuzyou,2024-11-11 16:32:01+00:00,2024-11-20 06:32:55+00:00,189,68,"['task_categories:audio-classification', 'task_categories:text-to-audio', 'annotations_creators:found', 'multilinguality:multilingual', 'source_datasets:original', 'language:en', 'language:ja', 'language:multilingual', 'license:cc0-1.0', 'size_categories:100K<n<1M', 'modality:image', 'modality:audio', 'modality:video', 'modality:text', 'region:us', 'audio', 'video', 'image', 'text']","
	
		
		Dataset Card for Suno.ai Music Generation
	


	
		
		Dataset Summary
	

This dataset contains metadata for 659,788 songs generated by artificial intelligence on the suno.com platform, a service that generates music using artificial intelligence. The songs were discovered by search queries with words from the dwyl/english-words word list.

	
		
		Languages
	

The dataset is multilingual with English as the primary language:

English (en): Primary language for metadata and most lyrics… See the full description on the dataset page: https://huggingface.co/datasets/nyuuzyou/suno.",https://huggingface.co/datasets/nyuuzyou/suno,"['en', 'ja', 'multilingual']","['audio-classification', 'text-to-audio']",['100K<n<1M']
arsaporta/symile-m3,arsaporta,2024-11-12 05:26:09+00:00,2024-11-26 00:51:57+00:00,14971,6,"['task_categories:zero-shot-classification', 'task_categories:zero-shot-image-classification', 'language:ar', 'language:el', 'language:en', 'language:hi', 'language:ja', 'language:ko', 'language:te', 'language:th', 'language:uk', 'language:zh', 'license:cc-by-nc-sa-4.0', 'size_categories:10M<n<100M', 'format:parquet', 'modality:audio', 'modality:image', 'modality:text', 'library:datasets', 'library:dask', 'library:mlcroissant', 'library:polars', 'arxiv:2411.01053', 'region:us', 'multimodal', 'representation learning', 'multilingual']","
	
		
		Dataset Card for Symile-M3
	

Symile-M3 is a multilingual dataset of (audio, image, text) samples. The dataset is specifically designed to test a model's ability to capture higher-order information between three distinct high-dimensional data types: by incorporating multiple languages, we construct a task where text and audio are both needed to predict the image, and where, importantly, neither text nor audio alone would suffice.

Paper: https://arxiv.org/abs/2411.01053
GitHub:… See the full description on the dataset page: https://huggingface.co/datasets/arsaporta/symile-m3.",https://huggingface.co/datasets/arsaporta/symile-m3,"['ar', 'el', 'en', 'hi', 'ja', 'ko', 'te', 'th', 'uk', 'zh']","['zero-shot-classification', 'zero-shot-image-classification']",['10M<n<100M']
None1145/Lappland,None1145,2024-11-12 11:58:22+00:00,2024-11-16 12:23:26+00:00,17,2,"['task_categories:audio-to-audio', 'task_categories:text-to-speech', 'language:zh', 'language:ja', 'language:en', 'language:it', 'language:ko', 'license:mit', 'size_categories:n<1K', 'format:audiofolder', 'modality:audio', 'library:datasets', 'library:mlcroissant', 'region:us', 'Lappland', 'Arknights', '拉普兰德', '明日方舟']",,https://huggingface.co/datasets/None1145/Lappland,"['zh', 'ja', 'en', 'it', 'ko']","['audio-to-audio', 'text-to-speech']",['n<1K']
llm-jp/magpie-sft-v1.0,llm-jp,2024-11-13 18:02:16+00:00,2024-11-13 18:54:02+00:00,90,13,"['task_categories:text-generation', 'language:ja', 'license:apache-2.0', 'size_categories:100K<n<1M', 'format:json', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'arxiv:2406.08464', 'region:us']","
	
		
		magpie-sft-v1.0
	

This repository provides an instruction-tuning dataset developed by LLM-jp, a collaborative project launched in Japan.
This is a dataset of instruction and response pairs created using the Magpie method.
cyberagent/calm3-22b-chat was used for generating the instructions, and Qwen/Qwen2.5-32B-Instruct was used for generating the responses.

	
		
	
	
		Send Questions to
	

llm-jp(at)nii.ac.jp

	
		
	
	
		Model Card Authors
	

The names are listed in alphabetical order.… See the full description on the dataset page: https://huggingface.co/datasets/llm-jp/magpie-sft-v1.0.",https://huggingface.co/datasets/llm-jp/magpie-sft-v1.0,['ja'],['text-generation'],['100K<n<1M']
labofsahil/animelist-dataset,labofsahil,2024-11-16 05:37:06+00:00,2025-09-07 20:42:17+00:00,14,1,"['language:en', 'language:ja', 'license:agpl-3.0', 'size_categories:10K<n<100K', 'format:json', 'modality:image', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us', 'anime']","A JSON based anime dataset containing the most important meta data as well as cross references to various anime sites such as MAL, ANIDB, ANILIST, KITSU and more...
Credits: https://github.com/manami-project/anime-offline-database
",https://huggingface.co/datasets/labofsahil/animelist-dataset,"['en', 'ja']",[],['10K<n<100K']
Kendamarron/jimba-instruction-all,Kendamarron,2024-11-16 05:56:14+00:00,2024-11-16 06:01:16+00:00,13,0,"['language:ja', 'license:other', 'size_categories:10K<n<100K', 'format:parquet', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","
	
		
		データセットについて
	

これまで作成した合成データセットを1つにまとめたものです。

	
		
		構成
	


	
		
		Apache-2.0
	


Kendamarron/jimba-instruction-calm3
Kendamarron/roleplay-multiturn-calm3-chat-format
Kendamarron/system-instruction-calm3-chat-format
Kendamarron/multiturn-qwen2.5-32b


	
		
	
	
		CC-BY-SA-3.0
	


Kendamarron/jimba-wiki-instruction-calm3

",https://huggingface.co/datasets/Kendamarron/jimba-instruction-all,['ja'],[],['10K<n<100K']
milistu/amazon-esci-data,milistu,2024-11-16 18:23:47+00:00,2025-09-11 14:49:31+00:00,106,0,"['task_categories:text-classification', 'task_categories:token-classification', 'task_categories:text-generation', 'task_categories:sentence-similarity', 'language:en', 'language:ja', 'language:es', 'license:apache-2.0', 'size_categories:1M<n<10M', 'format:parquet', 'modality:tabular', 'modality:text', 'library:datasets', 'library:dask', 'library:mlcroissant', 'library:polars', 'arxiv:2206.06588', 'region:us', 'amazon', 'retrieval', 'search', 'ecommerce', 'ranking', 'reranking']","
	
		
		Amazon Shopping Queries Dataset
	

Dataset for improving product search, ranking and recommendations, featuring query-product pairs with detailed relevance labels.

	
		
		Overview
	

The dataset contains search queries paired with up to 40 potentially relevant products, each labeled using the ESCI system:

Exact match: Products that perfectly match the customer's search intent (e.g., searching ""iPhone 13"" and finding ""Apple iPhone 13 128GB"")
Substitute product: Alternative products… See the full description on the dataset page: https://huggingface.co/datasets/milistu/amazon-esci-data.",https://huggingface.co/datasets/milistu/amazon-esci-data,"['en', 'ja', 'es']","['text-classification', 'token-classification', 'text-generation', 'sentence-similarity']",['1M<n<10M']
kajuma/CC-news-2024-July-October-cleaned,kajuma,2024-11-17 13:16:59+00:00,2024-11-17 15:07:26+00:00,168,15,"['task_categories:text-generation', 'language:ja', 'license:odc-by', 'size_categories:100K<n<1M', 'format:parquet', 'modality:text', 'library:datasets', 'library:dask', 'library:mlcroissant', 'library:polars', 'region:us']","
	
		
		CC-news-2024-July-October-cleaned
	

このデータセットはCommon Crawlのnewsサブセットから作成した2024年7月から10月の日本語のニュースの文章が収録されています。
データセットの規模はllm-jp/llm-jp-13b-v1.0 tokenizer使用で612M tokensです。
使用したツールはUzushioです。フィルター設定はサンプルのpipeline_03a.confです。
作成につきまして以下を参考にさせていただきました。
uzushio使ってwebコンテンツから綺麗な日本語コーパスを抽出する手順
",https://huggingface.co/datasets/kajuma/CC-news-2024-July-October-cleaned,['ja'],['text-generation'],['100K<n<1M']
hotchpotch/msmarco-ja-hard-negatives,hotchpotch,2024-11-18 02:33:24+00:00,2024-11-18 20:46:33+00:00,29,3,"['language:ja', 'language:en', 'size_categories:1M<n<10M', 'format:parquet', 'modality:text', 'library:datasets', 'library:dask', 'library:mlcroissant', 'library:polars', 'region:us']","
	
		
		msmarco-ja-hard-negatives
	

hpprc/msmarco-ja で公開されているMS MARCOの日本語翻訳データに、以下の処理を加えたハードネガティブマイニングをしたものです。また、後段タスクとして、情報検索モデルのSPLADEを学習させたモデルで mMARCO との比較を行いました。

	
		
		データの処理
	


	
		
		翻訳データの正規化、フィルタと選択
	


正規化
ユニコード正規化 (NFKC)


dataset(query) のフィルタ・選択
dataset-sim のコサイン類似度が0.98以上のものはほぼ同一のケースが多く、距離が近すぎるので取り除く
元の英文を丸々含むデータを取り除く
残ったデータで、一番類似度が近いものを選択


collection の選択
dataset(query) の pod_ids (正例)が対象の場合、query, doc ペアで BAAI/bge-reranker-v2-m3 のスコアを用い、最もスコアが高いもの選択
正例に含まれないデータの場合、同一の id… See the full description on the dataset page: https://huggingface.co/datasets/hotchpotch/msmarco-ja-hard-negatives.",https://huggingface.co/datasets/hotchpotch/msmarco-ja-hard-negatives,"['ja', 'en']",[],['1M<n<10M']
marzena/jbats,marzena,2024-11-18 21:38:45+00:00,2024-11-18 22:57:25+00:00,8,0,"['task_categories:text-generation', 'language:ja', 'license:cc-by-4.0', 'size_categories:1K<n<10K', 'format:json', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us', 'analogies']","While we are working on adding a nice datacard please refer to the paper (https://aclanthology.org/W18-2905/) and here (https://vecto.space/projects/jBATS/) for more details!
",https://huggingface.co/datasets/marzena/jbats,['ja'],['text-generation'],['1K<n<10K']
hpprc/honyaku,hpprc,2024-11-20 04:42:28+00:00,2024-11-20 09:06:40+00:00,17,3,"['task_categories:translation', 'language:ja', 'language:en', 'license:cc-by-sa-4.0', 'size_categories:n<1K', 'format:parquet', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","英語Wikipedia記事の冒頭複数文を抽出し、人手で日本語翻訳した文章レベル対訳データセットです。
日英対訳コーパスはライセンスが厳しいものが多く、自由に利用できる高品質なパッセージレベルの対訳データセットが少なかったため作成しました。
翻訳は大体をhpprcが、数件をyano氏が行いました。
passageサブセットは文章レベルの翻訳(対応する文ごとに改行区切り)を、sentenceサブセットは文ごとの対訳(こちらは代名詞の翻訳の齟齬など誤った翻訳になっている可能性がある)を収載したデータセットです。

	
		
		翻訳方針
	

DeepLやGoogle翻訳など、既存の翻訳ツールは翻訳結果を機械学習モデルの入力として使用することを禁じています。
本データセットは機械学習用途にも利用できる寛容なライセンスの元で公開したかったため、安全のため、できるだけこれらのツールを使用せずに英日翻訳を行いました。
その代わり、ライセンスの寛容なLLMによる翻訳結果を参考に翻訳を行いました。
具体的には、日本語における性能が高くライセンスがApache… See the full description on the dataset page: https://huggingface.co/datasets/hpprc/honyaku.",https://huggingface.co/datasets/hpprc/honyaku,"['ja', 'en']",['translation'],['n<1K']
Aratako/magpie-qwen2.5-32b-reasoning-100k-formatted,Aratako,2024-11-20 12:42:37+00:00,2024-11-25 16:44:08+00:00,33,1,"['language:ja', 'license:apache-2.0', 'size_categories:100K<n<1M', 'format:parquet', 'modality:text', 'library:datasets', 'library:dask', 'library:mlcroissant', 'library:polars', 'region:us']","
	
		
		magpie-qwen2.5-32b-reasoning-100k-formatted
	

DeL-TaiseiOzaki/magpie-qwen2.5-32b-reasoning-100kをOpenAI messages形式に変換したデータセットです。
中身や注意事項等については元データセットの概要をご確認ください。
",https://huggingface.co/datasets/Aratako/magpie-qwen2.5-32b-reasoning-100k-formatted,['ja'],[],['100K<n<1M']
hpprc/jsec,hpprc,2024-11-20 12:55:54+00:00,2024-11-20 13:52:38+00:00,10,1,"['language:ja', 'language:en', 'license:cc-by-sa-4.0', 'size_categories:1M<n<10M', 'format:parquet', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","JSECホームページ
",https://huggingface.co/datasets/hpprc/jsec,"['ja', 'en']",[],['1M<n<10M']
hugfaceguy0001/LyricsTranslation,hugfaceguy0001,2024-11-20 17:06:39+00:00,2025-01-24 05:48:30+00:00,15,0,"['task_categories:text-generation', 'task_categories:translation', 'language:ja', 'language:zh', 'license:openrail', 'size_categories:n<1K', 'format:parquet', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us', 'music']","
	
		
		歌曲译配数据集
	

本数据集包括网络上的一些外文歌曲（目前仅包含日文，以二次元相关作品为主）翻译填词为中文的高质量作品。

	
		
		特征说明
	


url : 中文翻译填词歌曲发布的视频链接
original_language : 外文原作的语言，目前全部为 jp 即日文
original_author : 外文原作的词作者
original_lyrics : 外文原作歌词
translation_author : 中文填词作者
translated_lyrics : 中文译配歌词


	
		
		更新记录
	

2024/11/21 创建数据集，包含37条数据
2024/11/22 增加到42条数据
2024/11/23 增加到50条数据
2025/01/24 增加到52条数据
",https://huggingface.co/datasets/hugfaceguy0001/LyricsTranslation,"['ja', 'zh']","['text-generation', 'translation']",['n<1K']
spow12/llava_instruct_mix_jp,spow12,2024-11-21 04:20:41+00:00,2024-11-21 05:36:14+00:00,22,0,"['task_categories:visual-question-answering', 'language:ja', 'size_categories:100K<n<1M', 'format:parquet', 'modality:image', 'modality:text', 'library:datasets', 'library:dask', 'library:mlcroissant', 'library:polars', 'region:us']","Translated using ChatWaifu_12B_v2.2(private)

	
		
		Prompt
	

prompt = [
  {
      'role': 'user',
      'content':  [
          {
              'type': 'text', 
              'text': f""""""Translate the sentece to japanese. 
If there is any structure like markdown table or chart, using original format.
Here is the sentence to translate: 36.76""""""
          },
  ]
  },
  {
      'role': 'assistant',
      'content':  [
          {
              'type': 'text', 
              'text': f""""""36.76""""""… See the full description on the dataset page: https://huggingface.co/datasets/spow12/llava_instruct_mix_jp.",https://huggingface.co/datasets/spow12/llava_instruct_mix_jp,['ja'],['visual-question-answering'],['100K<n<1M']
spow12/ShareGPT4V_Waifu,spow12,2024-11-21 05:09:35+00:00,2024-11-21 05:38:28+00:00,9,0,"['task_categories:visual-question-answering', 'language:ja', 'size_categories:10K<n<100K', 'format:parquet', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us', 'roleplay', 'visual_novel']","
	
		
		Caution!
	

This dataset may contain errors or incorrect translations, even after filtering.

	
		
		Original Dataset
	

Lin-Chen/ShareGPT4V
",https://huggingface.co/datasets/spow12/ShareGPT4V_Waifu,['ja'],['visual-question-answering'],['10K<n<100K']
LiuliFox/stickers,LiuliFox,2024-11-21 09:45:06+00:00,2024-11-21 14:42:12+00:00,43,0,"['task_categories:image-classification', 'language:zh', 'language:ja', 'language:en', 'license:mit', 'size_categories:n<1K', 'format:imagefolder', 'modality:image', 'library:datasets', 'library:mlcroissant', 'region:us', 'Anime', 'galgame']","
	
		
		るりのステッカー
	

just for fun.
",https://huggingface.co/datasets/LiuliFox/stickers,"['zh', 'ja', 'en']",['image-classification'],['n<1K']
Aratako/Magpie-Tanuki-Qwen2.5-72B-Answered,Aratako,2024-11-21 14:38:55+00:00,2024-11-25 16:48:52+00:00,15,1,"['language:ja', 'license:other', 'size_categories:10K<n<100K', 'format:json', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","
	
		
		Magpie-Tanuki-Qwen2.5-72B-Answered
	

Aratako/Magpie-Tanuki-8B-annotated-96kからinput_qualityがexcellentのものを抽出し、それに対してQwen/Qwen2.5-72B-Instructで回答の再生成を行ったデータセットです。

	
		
		ライセンス
	

基本的にはApache 2.0に準じますが、Qwen Licenseの影響を受けるため、このデータセットを使ってモデルを学習する際はこのライセンスの制約に従ってください。
",https://huggingface.co/datasets/Aratako/Magpie-Tanuki-Qwen2.5-72B-Answered,['ja'],[],['10K<n<100K']
Aratako/magpie-reasoning-llama-nemotron-70b-100k-filtered,Aratako,2024-11-22 03:06:57+00:00,2024-11-25 16:53:15+00:00,13,0,"['language:ja', 'license:llama3.1', 'size_categories:10K<n<100K', 'format:parquet', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","
	
		
		magpie-reasoning-llama-nemotron-70b-100k-filtered
	

DeL-TaiseiOzaki/magpie-reasoning-llama-nemotron-70b-100kから、refined_answer列に""改良""という文字が含まれていないものを抽出し、OpenAI messages形式に変換したデータセットです。
中身や注意事項等については元データセットの概要をご確認ください。
",https://huggingface.co/datasets/Aratako/magpie-reasoning-llama-nemotron-70b-100k-filtered,['ja'],[],['10K<n<100K']
Aratako/Open-Platypus-Japanese-masked-formatted,Aratako,2024-11-22 03:08:54+00:00,2024-11-25 16:54:55+00:00,10,0,"['language:ja', 'license:cc-by-4.0', 'size_categories:10K<n<100K', 'format:parquet', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","
	
		
		Open-Platypus-Japanese-masked-formatted
	

weblab-GENIAC/Open-Platypus-Japanese-maskedをOpenAI messages形式に変換したデータセットです。
中身や注意事項等については元データセットの概要をご確認ください。
",https://huggingface.co/datasets/Aratako/Open-Platypus-Japanese-masked-formatted,['ja'],[],['10K<n<100K']
Aratako/Synthetic-JP-EN-Coding-Dataset-801k-50k,Aratako,2024-11-22 03:21:08+00:00,2024-12-10 16:57:38+00:00,22,1,"['language:ja', 'language:en', 'license:apache-2.0', 'size_categories:10K<n<100K', 'format:parquet', 'modality:tabular', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","
	
		
		Synthetic-JP-EN-Coding-Dataset-801k-50k
	

Aratako/Synthetic-JP-EN-Coding-Dataset-801kから英語部分5万件を抽出したデータセットです。
中身や注意事項等については元データセットの概要をご確認ください。
",https://huggingface.co/datasets/Aratako/Synthetic-JP-EN-Coding-Dataset-801k-50k,"['ja', 'en']",[],['10K<n<100K']
hpprc/wiki-trans-en-ja,hpprc,2024-11-22 04:34:17+00:00,2025-01-09 04:08:49+00:00,110,7,"['task_categories:translation', 'language:ja', 'language:en', 'license:cc-by-sa-4.0', 'size_categories:1M<n<10M', 'format:parquet', 'modality:tabular', 'modality:text', 'library:datasets', 'library:dask', 'library:mlcroissant', 'library:polars', 'region:us', 'synthetic']",,https://huggingface.co/datasets/hpprc/wiki-trans-en-ja,"['ja', 'en']",['translation'],['1M<n<10M']
googlefan/lami-voice,googlefan,2024-11-22 07:20:21+00:00,2024-11-22 07:33:02+00:00,20,0,"['task_categories:text-to-speech', 'language:ja', 'size_categories:n<1K', 'format:audiofolder', 'modality:audio', 'library:datasets', 'library:mlcroissant', 'region:us']","
	
		
		Credit
	

Lami  

	
		
		Website
	

https://lami.zip/

	
		
		License information
	

For those who had granted permission, may use for any purpose, but don't make this data itself public.
Don't reupload this dataset to anotoher repo/website/or somewhere public.
",https://huggingface.co/datasets/googlefan/lami-voice,['ja'],['text-to-speech'],['n<1K']
None1145/Rosmontis,None1145,2024-11-22 15:29:21+00:00,2024-12-03 12:34:40+00:00,19,1,"['task_categories:text-to-speech', 'task_categories:audio-to-audio', 'language:zh', 'language:ja', 'language:ko', 'license:mit', 'size_categories:n<1K', 'format:audiofolder', 'modality:audio', 'library:datasets', 'library:mlcroissant', 'region:us', 'Rosmontis', 'Arknights', '迷迭香', '明日方舟']",,https://huggingface.co/datasets/None1145/Rosmontis,"['zh', 'ja', 'ko']","['text-to-speech', 'audio-to-audio']",['n<1K']
hpprc/wiki-trans-ja-en,hpprc,2024-11-23 10:09:02+00:00,2025-01-09 04:09:49+00:00,106,4,"['task_categories:translation', 'language:ja', 'language:en', 'license:cc-by-sa-4.0', 'size_categories:1M<n<10M', 'format:parquet', 'modality:tabular', 'modality:text', 'library:datasets', 'library:dask', 'library:mlcroissant', 'library:polars', 'region:us', 'synthetic']",,https://huggingface.co/datasets/hpprc/wiki-trans-ja-en,"['ja', 'en']",['translation'],['1M<n<10M']
DeL-TaiseiOzaki/Tengentoppa-sft-v1.0,DeL-TaiseiOzaki,2024-11-24 01:20:50+00:00,2025-07-16 05:36:09+00:00,73,20,"['task_categories:question-answering', 'language:ja', 'license:cc-by-4.0', 'size_categories:100K<n<1M', 'format:json', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","
	
		
		Tengentoppa corpus for sft (Combined Japanese Instruction Dataset)
	


	
		
		概要
	

このデータセットは、日本語の instruction-following データセット16個を統合して作成された大規模な教師あり学習用データセットです。様々なタスクや対話形式を含む多様なデータソースから構成されています。

	
		
		データセット構成
	


	
		
		基本情報
	


フォーマット: JSON
各データポイントの構造:{
  ""instruction"": ""指示/質問文"",
  ""input"": ""追加の文脈や入力（オプション）"",
  ""output"": ""応答/回答文""
}




	
		
	
	
		データセット変換コード
	

データセット作成に使用したコードは以下のGitHubリポジトリで公開しています：
dataset-processor

	
		
	
	
		含まれるデータセット
	


Hachi-Alpaca_newans… See the full description on the dataset page: https://huggingface.co/datasets/DeL-TaiseiOzaki/Tengentoppa-sft-v1.0.",https://huggingface.co/datasets/DeL-TaiseiOzaki/Tengentoppa-sft-v1.0,['ja'],['question-answering'],['100K<n<1M']
WueNLP/belebele-fleurs,WueNLP,2024-11-25 19:44:15+00:00,2024-12-12 14:26:00+00:00,3006,7,"['task_categories:audio-classification', 'task_categories:automatic-speech-recognition', 'task_categories:audio-text-to-text', 'task_categories:text-to-speech', 'task_categories:question-answering', 'task_categories:document-question-answering', 'annotations_creators:found', 'language_creators:expert-generated', 'multilinguality:multilingual', 'language:af', 'language:am', 'language:ar', 'language:az', 'language:as', 'language:bm', 'language:bn', 'language:bo', 'language:bg', 'language:ca', 'language:cs', 'language:ku', 'language:da', 'language:de', 'language:el', 'language:en', 'language:es', 'language:et', 'language:eu', 'language:fi', 'language:fr', 'language:ff', 'language:om', 'language:gu', 'language:gn', 'language:ht', 'language:ha', 'language:he', 'language:hi', 'language:hr', 'language:hu', 'language:hy', 'language:ig', 'language:id', 'language:it', 'language:is', 'language:jv', 'language:ja', 'language:ka', 'language:kn', 'language:kk', 'language:mn', 'language:km', 'language:rw', 'language:ky', 'language:ko', 'language:lo', 'language:ln', 'language:lt', 'language:lg', 'language:lv', 'language:ml', 'language:mr', 'language:mk', 'language:mt', 'language:mi', 'language:my', 'language:nl', 'language:no', 'language:ne', 'language:ny', 'language:or', 'language:pa', 'language:ps', 'language:fa', 'language:mg', 'language:pl', 'language:pt', 'language:ro', 'language:ru', 'language:sn', 'language:si', 'language:sl', 'language:sv', 'language:sk', 'language:sd', 'language:sw', 'language:ta', 'language:te', 'language:tg', 'language:tl', 'language:th', 'language:ti', 'language:tn', 'language:ts', 'language:tr', 'language:uk', 'language:ur', 'language:uz', 'language:vi', 'language:wo', 'language:xh', 'language:yo', 'language:zh', 'language:ms', 'language:zu', 'language:multilingual', 'license:cc-by-sa-4.0', 'size_categories:10K<n<100K', 'format:parquet', 'modality:audio', 'modality:text', 'library:datasets', 'library:dask', 'library:mlcroissant', 'library:polars', 'region:us']","
	
		
		Belebele-Fleurs
	

Belebele-Fleurs is a dataset suitable to evaluate two core tasks:

Multilingual Spoken Language Understanding (Listening Comprehension): For each spoken paragraph, the task is to answer a multiple-choice question. The question and four answer choices are provided in text form.
Multilingual Long-Form Automatic Speech Recognition (ASR) with Diverse Speakers: By concatenating sentence-level utterances, long-form audio clips (ranging from 30 seconds to 1 minute 30… See the full description on the dataset page: https://huggingface.co/datasets/WueNLP/belebele-fleurs.",https://huggingface.co/datasets/WueNLP/belebele-fleurs,"['af', 'am', 'ar', 'az', 'as', 'bm', 'bn', 'bo', 'bg', 'ca', 'cs', 'ku', 'da', 'de', 'el', 'en', 'es', 'et', 'eu', 'fi', 'fr', 'ff', 'om', 'gu', 'gn', 'ht', 'ha', 'he', 'hi', 'hr', 'hu', 'hy', 'ig', 'id', 'it', 'is', 'jv', 'ja', 'ka', 'kn', 'kk', 'mn', 'km', 'rw', 'ky', 'ko', 'lo', 'ln', 'lt', 'lg', 'lv', 'ml', 'mr', 'mk', 'mt', 'mi', 'my', 'nl', 'no', 'ne', 'ny', 'or', 'pa', 'ps', 'fa', 'mg', 'pl', 'pt', 'ro', 'ru', 'sn', 'si', 'sl', 'sv', 'sk', 'sd', 'sw', 'ta', 'te', 'tg', 'tl', 'th', 'ti', 'tn', 'ts', 'tr', 'uk', 'ur', 'uz', 'vi', 'wo', 'xh', 'yo', 'zh', 'ms', 'zu', 'multilingual']","['audio-classification', 'automatic-speech-recognition', 'audio-text-to-text', 'text-to-speech', 'question-answering', 'document-question-answering']",['10K<n<100K']
NaniDAO/nanipilled,NaniDAO,2024-11-25 22:59:51+00:00,2024-11-25 23:59:55+00:00,9,0,"['task_categories:text-generation', 'language:en', 'language:ja', 'license:agpl-3.0', 'size_categories:1K<n<10K', 'format:json', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']",,https://huggingface.co/datasets/NaniDAO/nanipilled,"['en', 'ja']",['text-generation'],['1K<n<10K']
eyl45/demo,eyl45,2024-11-27 02:07:34+00:00,2024-11-27 02:32:45+00:00,5,0,"['task_categories:text-generation', 'language:zh', 'language:ko', 'language:ja', 'license:mit', 'size_categories:n<1K', 'format:csv', 'modality:tabular', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']",,https://huggingface.co/datasets/eyl45/demo,"['zh', 'ko', 'ja']",['text-generation'],['n<1K']
Aratako/magpie-sft-v1.0-dpo-judged,Aratako,2024-11-27 17:37:12+00:00,2024-12-15 05:36:57+00:00,24,0,"['task_categories:text-generation', 'language:ja', 'license:llama3.1', 'license:gemma', 'size_categories:100K<n<1M', 'format:parquet', 'modality:text', 'library:datasets', 'library:dask', 'library:mlcroissant', 'library:polars', 'region:us']","
	
		
		magpie-sft-v1.0-dpo-judged
	


	
		
		概要
	

llm-jp/magpie-sft-v1.0を元に以下のような改変を加えて作成した日本語Preferenceデータセットです。

開発途中のモデルであるAratako/Llama-Gemma-2-27b-SFT-trial1を用いて回答を再生成
元データセットにあるQwen/Qwen2.5-32B-Instructの回答と再生成した回答の2つを並べ、google/gemma-2-27b-itによりどちらの回答の方が良いかをJudge
良いと判断された方の回答をchosenに、そうでない方の回答をrejectedに配置


	
		
	
	
		ライセンス
	

本データセットは回答の作成に利用したモデルの関係で以下のライセンスの影響を受けます。

META LLAMA 3.1 COMMUNITY LICENSEを継承します。
Gemma Terms of Useを継承します。
Qwen LICENSE… See the full description on the dataset page: https://huggingface.co/datasets/Aratako/magpie-sft-v1.0-dpo-judged.",https://huggingface.co/datasets/Aratako/magpie-sft-v1.0-dpo-judged,['ja'],['text-generation'],['100K<n<1M']
DSULT-Core/Renai-Circulation,DSULT-Core,2024-11-28 09:27:26+00:00,2025-02-09 05:43:22+00:00,8620,1,"['task_categories:text-generation', 'task_categories:text-classification', 'language:ja', 'license:other', 'region:us', 'not-for-all-audiences']","
Renai Circulation is a Image dataset from certain image website.

	
		
	
	
		How is it made?
	

A massive scrape was done on archive.org back in 2023.
Due to that it's in warc files (For obvious reasons), it's extremely unweildy to process. As such we did the following:

Download the megawarc.warc
Process html (pages & comments) to compacted json data.
Save images as-is.


	
	
	
		NFAA?
	

Yes, it contains content that is permitted in Japan I have seen stuff that people post on the site.… See the full description on the dataset page: https://huggingface.co/datasets/DSULT-Core/Renai-Circulation.",https://huggingface.co/datasets/DSULT-Core/Renai-Circulation,['ja'],"['text-generation', 'text-classification']",[]
Mitsua/vrm-color-concept-550k,Mitsua,2024-11-29 02:38:21+00:00,2025-02-13 07:56:30+00:00,85,2,"['task_categories:text-to-image', 'task_categories:image-to-text', 'language:en', 'language:ja', 'license:cc-by-nc-4.0', 'size_categories:100K<n<1M', 'format:webdataset', 'modality:image', 'modality:text', 'library:datasets', 'library:webdataset', 'library:mlcroissant', 'region:us']","
	
		
		VRM Color Concept 550K
	



	
		
		Summary
	

This is a dataset to train anime-style text-to-image or any text and image multimodal models without copyright/licensing concerns.
All assets/materials utilized in this dataset are CC0 or properly licensed, and no pretrained models or any AI models are used to build this dataset. 

	
		
		Image, Metadata and Dataset License
	

All images, metadata in this dataset and the dataset itself are licensed under CC BY-NC 4.0 by ELAN MITSUA Project… See the full description on the dataset page: https://huggingface.co/datasets/Mitsua/vrm-color-concept-550k.",https://huggingface.co/datasets/Mitsua/vrm-color-concept-550k,"['en', 'ja']","['text-to-image', 'image-to-text']",['100K<n<1M']
Aratako/Magpie-Tanuki-Instruction-Selected-Evolved-26.5k,Aratako,2024-11-29 08:10:29+00:00,2024-12-15 06:10:27+00:00,11,0,"['task_categories:text-generation', 'language:ja', 'license:other', 'size_categories:10K<n<100K', 'format:parquet', 'modality:tabular', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'arxiv:2406.08464', 'arxiv:2304.12244', 'region:us']","
	
		
		Magpie-Tanuki-Instruction-Selected-Evolved-26.5k
	


	
		
		概要
	

以下の手順で作成した約2万6500件の日本語の合成instructionデータセットです。

Magpieの手法をteam-hatakeyama-phase2/Tanuki-8x8B-dpo-v1.0-GPTQ-8bitに適用し、約10万件のinstructionを作成
cl-nagoya/ruri-largeを使ってinstructionのベクトル表現を取得
この時点のデータはAratako/Magpie-Tanuki-Instruction-100k-Embeddingsで公開されています。


取得したベクトル表現を元に、Mini Batch K-Meansによって20000個のクラスタにクラスタリング
各クラスタから最大3個までinstructionを抽出
上記で抽出した約2万6500件のinstructionに対し、Qwen/Qwen2.5-72B-Instruct-GPTQ-Int8を使ってEvol-Instructを適用… See the full description on the dataset page: https://huggingface.co/datasets/Aratako/Magpie-Tanuki-Instruction-Selected-Evolved-26.5k.",https://huggingface.co/datasets/Aratako/Magpie-Tanuki-Instruction-Selected-Evolved-26.5k,['ja'],['text-generation'],['10K<n<100K']
hpprc/qwq-ja-en,hpprc,2024-11-29 08:49:58+00:00,2025-01-21 01:53:01+00:00,16,0,"['task_categories:translation', 'language:en', 'language:ja', 'license:cc-by-sa-4.0', 'size_categories:n<1K', 'format:parquet', 'modality:tabular', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']",,https://huggingface.co/datasets/hpprc/qwq-ja-en,"['en', 'ja']",['translation'],['n<1K']
meetween/mumospee,meetween,2024-11-29 09:33:40+00:00,2025-09-18 11:50:43+00:00,43,2,"['task_categories:text-to-speech', 'task_categories:automatic-speech-recognition', 'language:en', 'language:zh', 'language:de', 'language:ja', 'language:fr', 'language:ko', 'language:es', 'language:ca', 'language:it', 'language:fa', 'language:et', 'language:mn', 'language:ar', 'language:lv', 'language:cy', 'language:id', 'language:sl', 'license:cc0-1.0', 'region:us', 'Speech', 'Video']","Mumospee is a continuously growing, comprehensive, multilingual dataset across different modalities.",https://huggingface.co/datasets/meetween/mumospee,"['en', 'zh', 'de', 'ja', 'fr', 'ko', 'es', 'ca', 'it', 'fa', 'et', 'mn', 'ar', 'lv', 'cy', 'id', 'sl']","['text-to-speech', 'automatic-speech-recognition']",[]
CohereLabs/include-base-44,CohereLabs,2024-11-29 10:30:22+00:00,2025-04-15 08:44:46+00:00,15539,41,"['task_categories:multiple-choice', 'language:sq', 'language:ar', 'language:hy', 'language:az', 'language:be', 'language:bn', 'language:eu', 'language:bg', 'language:tr', 'language:hr', 'language:nl', 'language:fa', 'language:es', 'language:et', 'language:fi', 'language:fr', 'language:de', 'language:el', 'language:ka', 'language:he', 'language:hi', 'language:hu', 'language:id', 'language:it', 'language:ja', 'language:kk', 'language:ko', 'language:lt', 'language:ml', 'language:ms', 'language:ne', 'language:pl', 'language:pt', 'language:ru', 'language:ta', 'language:tl', 'language:te', 'language:uk', 'language:ur', 'language:uz', 'language:vi', 'language:zh', 'language:sr', 'language:mk', 'license:apache-2.0', 'size_categories:10K<n<100K', 'modality:text', 'arxiv:2411.19799', 'region:us', 'chemistry', 'biology', 'legal', 'music', 'finance', 'medical', 'climate', 'art', 'code']","
	
		
		INCLUDE-base (44 languages)
	


	
		
		Dataset Description
	



Paper: http://arxiv.org/abs/2411.19799


	
		
		Dataset Summary
	

INCLUDE is a comprehensive knowledge- and reasoning-centric benchmark across 44 languages that evaluates multilingual LLMs for performance in the actual language environments where they would be deployed. 
It contains 22,637 4-option multiple-choice-questions (MCQ) extracted from academic and professional exams, covering 57 topics, including regional… See the full description on the dataset page: https://huggingface.co/datasets/CohereLabs/include-base-44.",https://huggingface.co/datasets/CohereLabs/include-base-44,"['sq', 'ar', 'hy', 'az', 'be', 'bn', 'eu', 'bg', 'tr', 'hr', 'nl', 'fa', 'es', 'et', 'fi', 'fr', 'de', 'el', 'ka', 'he', 'hi', 'hu', 'id', 'it', 'ja', 'kk', 'ko', 'lt', 'ml', 'ms', 'ne', 'pl', 'pt', 'ru', 'ta', 'tl', 'te', 'uk', 'ur', 'uz', 'vi', 'zh', 'sr', 'mk']",['multiple-choice'],['10K<n<100K']
agentlans/LinguaNova,agentlans,2024-11-30 09:53:49+00:00,2025-01-28 21:26:49+00:00,152,0,"['task_categories:text-generation', 'task_categories:text-classification', 'task_categories:text-retrieval', 'language:multilingual', 'language:ar', 'language:az', 'language:bg', 'language:bn', 'language:ca', 'language:cs', 'language:da', 'language:de', 'language:el', 'language:en', 'language:es', 'language:et', 'language:fa', 'language:fi', 'language:fr', 'language:he', 'language:hi', 'language:hu', 'language:hy', 'language:id', 'language:is', 'language:it', 'language:ja', 'language:ka', 'language:kk', 'language:ko', 'language:lt', 'language:lv', 'language:mk', 'language:ml', 'language:mr', 'language:ne', 'language:nl', 'language:no', 'language:pl', 'language:pt', 'language:ro', 'language:ru', 'language:sk', 'language:sl', 'language:sq', 'language:sr', 'language:sv', 'language:ta', 'language:th', 'language:tr', 'language:uk', 'language:ur', 'language:vi', 'language:zh', 'size_categories:100K<n<1M', 'format:json', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']",,https://huggingface.co/datasets/agentlans/LinguaNova,"['multilingual', 'ar', 'az', 'bg', 'bn', 'ca', 'cs', 'da', 'de', 'el', 'en', 'es', 'et', 'fa', 'fi', 'fr', 'he', 'hi', 'hu', 'hy', 'id', 'is', 'it', 'ja', 'ka', 'kk', 'ko', 'lt', 'lv', 'mk', 'ml', 'mr', 'ne', 'nl', 'no', 'pl', 'pt', 'ro', 'ru', 'sk', 'sl', 'sq', 'sr', 'sv', 'ta', 'th', 'tr', 'uk', 'ur', 'vi', 'zh']","['text-generation', 'text-classification', 'text-retrieval']",['100K<n<1M']
preference-team/dataset-for-annotation-v2-annotated,preference-team,2024-11-30 18:21:30+00:00,2025-05-15 01:59:02+00:00,25,3,"['language:ja', 'size_categories:1K<n<10K', 'format:parquet', 'modality:tabular', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'arxiv:2410.01257', 'region:us']","
合成された質問と2つの応答文のペアに対して、日本語を母語とするチームメンバーが、好ましい応答文を人手でアノテーションしました
HelpSteer2-preferenceに習い、選好だけでなく選好の強度も[-3, 3]の範囲で付与しました


	
		
		アノテーション時のメモ
	


ジャンルは以下
簡単な一般知識(wikipediaを読まずに回答できる系)
難しめの一般知識(wikipediaを読んだら回答できる系)
歴史上の出来事の論述
医療知識(応急処置系)
機械学習の課題と解決方法
化学式の解説
架空の物語生成
ロールプレイ
詩の創作
素因数分解や偶数奇数判定などの簡単な数学タスク
コーディングタスク
アルゴリズムやシステムのメリデメの解説
美術や思想についての論述
日本語の文法の解説
その他


LLMの定型文として登場するフレーズは、
「もちろんです」
「～も見逃せません」
「～も見過ごせません」
「総じて、」
「まず始めに、～さらに、～次に、～まとめると、」


データセットを目視で読み込んだ印象… See the full description on the dataset page: https://huggingface.co/datasets/preference-team/dataset-for-annotation-v2-annotated.",https://huggingface.co/datasets/preference-team/dataset-for-annotation-v2-annotated,['ja'],[],['1K<n<10K']
hpprc/TALPCo,hpprc,2024-12-01 09:31:51+00:00,2024-12-01 09:37:29+00:00,11,2,"['task_categories:translation', 'language:ja', 'language:en', 'license:cc-by-4.0', 'size_categories:1K<n<10K', 'format:parquet', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","TALPCoデータセットの日英翻訳ペアをHuggingFace形式に変換したデータセットです。日本語の生データには分かち書き由来の空白文字が含まれていたため、それについは削除してあります。ライセンスは元データセットの記述に従い、CC-BY 4.0とします。

GitHub
論文

Nomoto, Hiroki, Kenji Okano, David Moeljadi and Hideo Sawada. 2018. 
TUFS Asian Language Parallel Corpus (TALPCo).
Proceedings of the Twenty-Fourth Annual Meeting of the Association for Natural Language Processing, 436-439.

",https://huggingface.co/datasets/hpprc/TALPCo,"['ja', 'en']",['translation'],['1K<n<10K']
Kendamarron/japanese-photo-instruction,Kendamarron,2024-12-01 13:42:28+00:00,2024-12-02 14:02:17+00:00,56,4,"['task_categories:visual-question-answering', 'language:ja', 'license:apache-2.0', 'size_categories:1K<n<10K', 'format:parquet', 'modality:image', 'modality:text', 'library:datasets', 'library:dask', 'library:mlcroissant', 'library:polars', 'region:us']","
	
		
		Dataset Information
	

このデータセットは、ThePioneer/japanese-photosの写真をお借りして、

Qwen/Qwen2-VL-7B-Instruct
Qwen/Qwen2.5-32B-Instruct-AWQ

の2つのモデルを使って生成した合成データセットです。

	
		
		Detail
	

https://zenn.dev/kendama/articles/cd5196a33bc46c
",https://huggingface.co/datasets/Kendamarron/japanese-photo-instruction,['ja'],['visual-question-answering'],['1K<n<10K']
StephanAkkerman/open-dict-words-ipa,StephanAkkerman,2024-12-01 19:30:09+00:00,2025-02-19 20:10:16+00:00,1056,1,"['language:ar', 'language:de', 'language:en', 'language:eo', 'language:es', 'language:fa', 'language:fi', 'language:fr', 'language:is', 'language:ja', 'language:jam', 'language:km', 'language:ko', 'language:ma', 'language:nb', 'language:nl', 'language:or', 'language:ro', 'language:sv', 'language:sw', 'language:tts', 'language:vi', 'language:yue', 'language:zh', 'license:mit', 'size_categories:1M<n<10M', 'format:text', 'modality:text', 'library:datasets', 'library:mlcroissant', 'region:us']","
	
		
		Open-dict Words IPA
	

This dataset is a copy of https://github.com/open-dict-data/ipa-dict

	
		
		Languages
	

IPA data is currently available for the following languages:

	
		
Language
Code


		
ar
Arabic (Modern Standard)


de
German


en_UK
English (Received Pronunciation)


en_US
English (General American)


eo
Esperanto


es_ES
Spanish (Spain)


es_MX
Spanish (Mexico)


fa
Persian


fi
Finnish


fr_FR
French (France)


fr_QC
French (Québec)


is
Icelandic


ja
Japanese


jam… See the full description on the dataset page: https://huggingface.co/datasets/StephanAkkerman/open-dict-words-ipa.",https://huggingface.co/datasets/StephanAkkerman/open-dict-words-ipa,"['ar', 'de', 'en', 'eo', 'es', 'fa', 'fi', 'fr', 'is', 'ja', 'jam', 'km', 'ko', 'ma', 'nb', 'nl', 'or', 'ro', 'sv', 'sw', 'tts', 'vi', 'yue', 'zh']",[],['1M<n<10M']
CohereLabs/Global-MMLU,CohereLabs,2024-12-01 22:45:59+00:00,2025-08-14 20:12:53+00:00,16926,137,"['language:en', 'language:ar', 'language:bn', 'language:es', 'language:fr', 'language:hi', 'language:ru', 'language:de', 'language:id', 'language:it', 'language:ja', 'language:ko', 'language:pt', 'language:zh', 'language:yo', 'language:nl', 'language:ro', 'language:uk', 'language:vi', 'language:tr', 'language:pl', 'language:fa', 'language:cs', 'language:he', 'language:el', 'language:ms', 'language:fil', 'language:te', 'language:si', 'language:ne', 'language:ky', 'language:sv', 'language:lt', 'language:sr', 'language:mg', 'language:so', 'language:ha', 'language:am', 'language:sn', 'language:ig', 'language:ny', 'language:sw', 'license:apache-2.0', 'size_categories:100K<n<1M', 'format:parquet', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'library:argilla', 'arxiv:2412.03304', 'region:us', 'argilla']","

	
		
		Dataset Summary
	

Global-MMLU 🌍 is a multilingual evaluation set spanning 42 languages, including English. This dataset combines machine translations for MMLU questions along with professional translations and crowd-sourced post-edits.
It also includes cultural sensitivity annotations for a subset of the questions (2850 questions per language) and classifies them as Culturally Sensitive (CS) 🗽 or Culturally Agnostic (CA) ⚖️. These annotations were collected as part of an open… See the full description on the dataset page: https://huggingface.co/datasets/CohereLabs/Global-MMLU.",https://huggingface.co/datasets/CohereLabs/Global-MMLU,"['en', 'ar', 'bn', 'es', 'fr', 'hi', 'ru', 'de', 'id', 'it', 'ja', 'ko', 'pt', 'zh', 'yo', 'nl', 'ro', 'uk', 'vi', 'tr', 'pl', 'fa', 'cs', 'he', 'el', 'ms', 'fil', 'te', 'si', 'ne', 'ky', 'sv', 'lt', 'sr', 'mg', 'so', 'ha', 'am', 'sn', 'ig', 'ny', 'sw']",[],['100K<n<1M']
YYama0/CT-RATE-JPN,YYama0,2024-12-02 04:38:04+00:00,2025-08-31 06:51:05+00:00,47,0,"['language:ja', 'language:en', 'license:cc-by-nc-sa-4.0', 'size_categories:10K<n<100K', 'region:us']","
	
		
		CT-RATE-JPN Dataset
	

CT-RATE-JPN is a Japanese-translated version of radiology reports from the CT-RATE dataset, which contains chest CT volumes paired with corresponding radiology reports.

	
		
		Dataset Overview
	

CT-RATE-JPN provides Japanese translations of radiology reports from the CT-RATE dataset to facilitate Japanese medical AI model development. While the original CT-RATE contains 25,692 non-contrast chest CT volumes with corresponding reports, this repository focuses on… See the full description on the dataset page: https://huggingface.co/datasets/YYama0/CT-RATE-JPN.",https://huggingface.co/datasets/YYama0/CT-RATE-JPN,"['ja', 'en']",[],['10K<n<100K']
CohereLabs/include-lite-44,CohereLabs,2024-12-02 11:03:07+00:00,2025-04-15 08:45:03+00:00,740,14,"['task_categories:multiple-choice', 'language:sq', 'language:ar', 'language:hy', 'language:az', 'language:be', 'language:bn', 'language:eu', 'language:bg', 'language:tr', 'language:hr', 'language:nl', 'language:fa', 'language:es', 'language:et', 'language:fi', 'language:fr', 'language:de', 'language:el', 'language:ka', 'language:he', 'language:hi', 'language:hu', 'language:id', 'language:it', 'language:ja', 'language:kk', 'language:ko', 'language:lt', 'language:ml', 'language:ms', 'language:ne', 'language:pl', 'language:pt', 'language:ru', 'language:ta', 'language:tl', 'language:te', 'language:uk', 'language:ur', 'language:uz', 'language:vi', 'language:zh', 'language:sr', 'language:mk', 'license:apache-2.0', 'size_categories:10K<n<100K', 'modality:text', 'arxiv:2411.19799', 'region:us', 'chemistry', 'biology', 'finance', 'legal', 'art', 'code', 'medical', 'music', 'climate']","
	
		
		INCLUDE-lite (44 languages)
	


	
		
		Dataset Description
	



Paper: http://arxiv.org/abs/2411.19799


	
		
		Dataset Summary
	

INCLUDE is a comprehensive knowledge- and reasoning-centric benchmark across 44 languages that evaluates multilingual LLMs for performance in the actual language environments where they would be deployed. 
It contains 11,095 4-option multiple-choice-questions (MCQ) extracted from academic and professional exams, covering 57 topics, including regional… See the full description on the dataset page: https://huggingface.co/datasets/CohereLabs/include-lite-44.",https://huggingface.co/datasets/CohereLabs/include-lite-44,"['sq', 'ar', 'hy', 'az', 'be', 'bn', 'eu', 'bg', 'tr', 'hr', 'nl', 'fa', 'es', 'et', 'fi', 'fr', 'de', 'el', 'ka', 'he', 'hi', 'hu', 'id', 'it', 'ja', 'kk', 'ko', 'lt', 'ml', 'ms', 'ne', 'pl', 'pt', 'ru', 'ta', 'tl', 'te', 'uk', 'ur', 'uz', 'vi', 'zh', 'sr', 'mk']",['multiple-choice'],['10K<n<100K']
jaeyong2/Ja-emb-PreView,jaeyong2,2024-12-02 12:37:11+00:00,2024-12-04 06:56:45+00:00,7,0,"['language:ja', 'license:cc-by-sa-3.0', 'size_categories:100K<n<1M', 'format:parquet', 'modality:text', 'library:datasets', 'library:dask', 'library:mlcroissant', 'library:polars', 'region:us']","
	
		
		Development Process
	


source dataset from range3/wikipedia-ja-20230101
We used Qwen/Qwen2-72B-Instruct model to generate answer with COT.


	
		
		License
	


Qwen/Qwen2.5-72B-Instruct : https://huggingface.co/Qwen/Qwen2-72B-Instruct/blob/main/LICENSE
range3/wikipedia-ja-20230101 : https://spdx.org/licenses/CC-BY-SA-3.0 and https://huggingface.co/datasets/range3/wikipedia-ja-20230101


	
		
	
	
		Acknowledgement
	

This research is supported by TPU Research Cloud program.
",https://huggingface.co/datasets/jaeyong2/Ja-emb-PreView,['ja'],[],['100K<n<1M']
Aratako/iterative-dpo-data-for-SimPO-iter2,Aratako,2024-12-04 03:24:08+00:00,2024-12-15 06:33:44+00:00,18,1,"['task_categories:text-generation', 'language:ja', 'license:llama3.1', 'license:gemma', 'size_categories:10K<n<100K', 'format:parquet', 'modality:tabular', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","
	
		
		iterative-dpo-data-for-SimPO-iter2
	


	
		
		概要
	

合成instructionデータであるAratako/Magpie-Tanuki-Instruction-Selected-Evolved-26.5kを元に以下のような手順で作成した日本語Preferenceデータセットです。

開発途中のモデルであるAratako/Llama-Gemma-2-27b-CPO_SimPO-iter1を用いて、temperature=1で回答を5回生成
5個の回答それぞれに対して、Qwen/Qwen2.5-72B-Instruct-GPTQ-Int8を用いて0～5点のスコア付けを実施
1つのinstructionに対する5個の回答について、最もスコアが高いものをchosenに、低いものをrejectedに配置
全て同じスコアの場合や、最も良いスコアが2点以下の場合は除外




	
		
	
	
		ライセンス
	

本データセットは回答の作成に利用したモデルの関係で以下のライセンスの影響を受けます。

META LLAMA 3.1… See the full description on the dataset page: https://huggingface.co/datasets/Aratako/iterative-dpo-data-for-SimPO-iter2.",https://huggingface.co/datasets/Aratako/iterative-dpo-data-for-SimPO-iter2,['ja'],['text-generation'],['10K<n<100K']
ikedachin/CC-news-2024-October-cleaned-1204,ikedachin,2024-12-04 08:10:52+00:00,2025-01-27 02:19:08+00:00,114,1,"['task_categories:feature-extraction', 'language:ja', 'license:odc-by', 'size_categories:10K<n<100K', 'format:parquet', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","kajuma/CC-news-2024-July-October-cleanedを元に、9月、10月のニュースのみを抜き出したデータセット。outputトークン数を1024と想定。効率よく学習するために約1000tokensに調整（使用tokenizerはllm-jp/llm-jp-3-13b）
",https://huggingface.co/datasets/ikedachin/CC-news-2024-October-cleaned-1204,['ja'],['feature-extraction'],['10K<n<100K']
BASF-AI/PubChemWikiJAPC,BASF-AI,2024-12-04 22:35:35+00:00,2024-12-05 20:29:37+00:00,13,0,"['task_categories:text-classification', 'language:en', 'language:ja', 'license:cc-by-nc-sa-4.0', 'size_categories:1K<n<10K', 'format:parquet', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us', 'chemistry', 'chemteb', 'wikipedia', 'pubchem']","
	
		
		PubChem & Wikipedia English-Japanese Paragraph Pair Classification
	

This dataset is a multilingual extension of the PubChem & Wikipedia Paragraphs Pair Classification dataset. It includes pairs of paragraphs in English and Japanese (sent1 and sent2) with a binary labels column indicating whether the paragraphs describe the same entity (1) or different entities (0).
",https://huggingface.co/datasets/BASF-AI/PubChemWikiJAPC,"['en', 'ja']",['text-classification'],['1K<n<10K']
lianghsun/Everything-Instruct-Multilingual-DPO,lianghsun,2024-12-05 01:37:25+00:00,2024-12-10 01:06:43+00:00,31,3,"['language:en', 'language:ru', 'language:zh', 'language:ko', 'language:ur', 'language:la', 'language:ar', 'language:de', 'language:es', 'language:fr', 'language:hi', 'language:it', 'language:ja', 'language:nl', 'language:pt', 'license:cc-by-nc-sa-4.0', 'size_categories:1M<n<10M', 'format:json', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'arxiv:2305.18290', 'region:us', 'sft', 'dpo']","
	
		
		Dataset Card for lianghsun/Everything-Instruct-Multilingual-DPO
	




	
		
		Dataset Details
	


	
		
		Dataset Description
	


這個資料集是分叉於 rombodawg/Everything_Instruct_Multilingual，但在中文回答的部份透過 opencc-python 將簡體中文（zh-cn）轉成繁體中文（zh-tw）。除此之外，我們將資料集升級成具有 DPO 欄位，該 rejected 回覆是由 lianghsun/Llama-3.2-Taiwan-3B-Instruct v2024.11.27 生成，此資料集將用於 lianghsun/Llama-3.2-Taiwan-3B-Instruct 的 DPO 階段。

Curated by: Huang Liang Hsun
Language(s) (NLP): multilingual
License: cc-by-nc-sa-4.0


	
	
	
		Dataset… See the full description on the dataset page: https://huggingface.co/datasets/lianghsun/Everything-Instruct-Multilingual-DPO.",https://huggingface.co/datasets/lianghsun/Everything-Instruct-Multilingual-DPO,"['en', 'ru', 'zh', 'ko', 'ur', 'la', 'ar', 'de', 'es', 'fr', 'hi', 'it', 'ja', 'nl', 'pt']",[],['1M<n<10M']
tokyotech-llm/swallow-gemma-magpie-v0.1,tokyotech-llm,2024-12-05 12:12:25+00:00,2025-01-07 14:11:23+00:00,33,3,"['task_categories:text-generation', 'language:ja', 'license:gemma', 'size_categories:100K<n<1M', 'format:json', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'arxiv:2406.08464', 'region:us', 'synthetic', 'tensorRT-LLM']","
	
		
		📰 News
	


[07/01/2025] Release of the first unfiltered version of the dataset containing 148k pairs.


	
		
		Dataset Summary
	

Swallow-Gemma-Magpie-v0.1 is a synthetic instruction tuning dataset that consists of multiple category Japanese question-answering tasks.
It consists of 148k question-answering-samples, generated with google/gemma-2-27b-it.
Part of Swallow-Gemma-Magpie-v0.1 is a subset of instruction tuning data for training tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.3… See the full description on the dataset page: https://huggingface.co/datasets/tokyotech-llm/swallow-gemma-magpie-v0.1.",https://huggingface.co/datasets/tokyotech-llm/swallow-gemma-magpie-v0.1,['ja'],['text-generation'],['100K<n<1M']
tokyotech-llm/swallow-magpie-ultra-v0.1,tokyotech-llm,2024-12-05 12:40:04+00:00,2025-01-07 14:26:51+00:00,34,5,"['task_categories:text-generation', 'language:en', 'language:ja', 'license:llama3.1', 'size_categories:10K<n<100K', 'format:json', 'modality:text', 'library:datasets', 'library:dask', 'library:mlcroissant', 'region:us', 'synthetic']","
	
		
		📰 News
	


[07/01/2025] Release of the first version of the dataset containing 42k Japanese pairs and 42k English pairs.


	
		
		Dataset Summary
	

Part of Swallow-Magpie-Ultra-v0.1 is a subset of instruction tuning data for training tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.3, tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.3, tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.2.
The data extracted from magpie-ultra-v0.1 with a quality of average, good, or excellent is… See the full description on the dataset page: https://huggingface.co/datasets/tokyotech-llm/swallow-magpie-ultra-v0.1.",https://huggingface.co/datasets/tokyotech-llm/swallow-magpie-ultra-v0.1,"['en', 'ja']",['text-generation'],['10K<n<100K']
akahana/mini-multilanguage,akahana,2024-12-06 22:08:23+00:00,2024-12-26 01:56:21+00:00,26,0,"['language:id', 'language:ar', 'language:ko', 'language:en', 'language:ja', 'language:ms', 'size_categories:1M<n<10M', 'format:parquet', 'modality:text', 'library:datasets', 'library:dask', 'library:mlcroissant', 'library:polars', 'region:us']",,https://huggingface.co/datasets/akahana/mini-multilanguage,"['id', 'ar', 'ko', 'en', 'ja', 'ms']",[],['1M<n<10M']
cc-clean/CC-MAIN-2019-51,cc-clean,2024-12-08 03:11:22+00:00,2024-12-09 08:50:49+00:00,6,0,"['language:ja', 'license:mit', 'region:us']","
	
		
		CC-MAIN-2019-51へようこそ
	

本データセットはCommonCrawlerと呼ばれるものから日本語のみを抽出したものです。
利用したものはcc-downloader-rsです。
なおIPAのICSCoEと呼ばれるところから資源を借りてやりましたゆえに、みなさんIPAに感謝しましょう。
※ IPAは独立行政法人 情報処理推進機構のことです。テストに出ますので覚えましょう。

	
		
		利用について
	

本利用は研究目的のみとさせていただきます。
それ以外の利用につきましては途方のくれない数の著作権者に許可を求めてきてください。
",https://huggingface.co/datasets/cc-clean/CC-MAIN-2019-51,['ja'],[],[]
akkikiki/global_mmlu_ja_edited,akkikiki,2024-12-08 08:34:26+00:00,2024-12-09 05:18:20+00:00,9,0,"['language:ja', 'license:apache-2.0', 'size_categories:n<1K', 'format:parquet', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'arxiv:2412.03304', 'region:us']","Associated code for this dataset is available at https://github.com/akkikiki/global_mmlu_edit

	
		
		Loading the dataset
	

from datasets import load_dataset

# From JSON
ds = load_dataset(""akkikiki/global_mmlu_ja_edited"")

# If migrating with the original Global MMLU, remove additional columns
ds = ds.remove_columns(""is_edited"")


# load HF dataset
global_mmlu_ja = load_dataset(""CohereForAI/Global-MMLU"", 'ja')
global_mmlu_ja[""dev""] = ds[""train""]


	
		
		Additional Information
	

Authorship… See the full description on the dataset page: https://huggingface.co/datasets/akkikiki/global_mmlu_ja_edited.",https://huggingface.co/datasets/akkikiki/global_mmlu_ja_edited,['ja'],[],['n<1K']
supercatdoing/booru_tag_and_artist_20241208,supercatdoing,2024-12-08 11:37:01+00:00,2024-12-10 08:41:39+00:00,14,0,"['language:en', 'language:ja', 'license:cc-by-sa-4.0', 'size_categories:1M<n<10M', 'format:parquet', 'modality:text', 'library:datasets', 'library:dask', 'library:mlcroissant', 'library:polars', 'region:us']","
	
		
		booru_tag_and_artist_20241208
	


	
		
		About
	

This data set is a JSON file with tags and artists extracted from danbooru (2024/12/8 version)  
All data is pre-sorted by tag count.  
A JSONL file is also available so that it can be used in environments where Apache allows Parquet files.  
Please use this as a reference when processing data locally, such as creating CSV files.  
This file was created based on the danbooru API.  

	
		
	
	
		File description… See the full description on the dataset page: https://huggingface.co/datasets/supercatdoing/booru_tag_and_artist_20241208.",https://huggingface.co/datasets/supercatdoing/booru_tag_and_artist_20241208,"['en', 'ja']",[],['1M<n<10M']
marianogonzalezgomez/voxpopuli_es-ja,marianogonzalezgomez,2024-12-08 21:55:33+00:00,2025-01-13 15:16:49+00:00,44,1,"['task_categories:automatic-speech-recognition', 'task_categories:translation', 'language:es', 'language:ja', 'size_categories:10K<n<100K', 'format:parquet', 'modality:audio', 'modality:text', 'library:datasets', 'library:dask', 'library:mlcroissant', 'library:polars', 'region:us']","
	
		
		Dataset Card for Spanish-to-Japanese Automatic Speech Recognition Dataset
	


	
		
		Dataset Summary
	

This dataset was created as part of a workshop organized by Yasmin Moslem, focusing on speech-to-text pipelines.
The workshop's primary goal is to enable accurate transcription and translation of spoken a source language into a written language (and learn how to do so, of course 😃)
The dataset serves as the foundation for developing and evaluating various models, including… See the full description on the dataset page: https://huggingface.co/datasets/marianogonzalezgomez/voxpopuli_es-ja.",https://huggingface.co/datasets/marianogonzalezgomez/voxpopuli_es-ja,"['es', 'ja']","['automatic-speech-recognition', 'translation']",['10K<n<100K']
bot-yaya/parallel_corpus_game,bot-yaya,2024-12-09 15:40:17+00:00,2025-09-23 02:26:28+00:00,133,5,"['task_categories:translation', 'language:ar', 'language:zh', 'language:de', 'language:en', 'language:eo', 'language:es', 'language:fr', 'language:he', 'language:id', 'language:it', 'language:ja', 'language:ko', 'language:nl', 'language:pt', 'language:ru', 'language:sv', 'language:th', 'language:vi', 'language:pl', 'language:tr', 'license:mit', 'size_categories:1M<n<10M', 'format:parquet', 'modality:tabular', 'modality:text', 'library:datasets', 'library:dask', 'library:mlcroissant', 'library:polars', 'region:us', 'game']","https://github.com/mnbvc-parallel-corpus-team/parallel_corpus_mnbvc
Game Corpus Collected by MNBVC Parallel Corpus Team.

	
		
		09/17/2025 Updated
	


Hollow Knight


	
		
		09/15/2025 Updated
	


Limbus Company
Mirror


	
		
		09/08/2025 Updated
	


Spice and Wolf VR (1&2)
Deep Rock Galactic
Cities Skylines 1


	
		
		09/02/2025 Updated
	


Plague Inc


	
		
		09/01/2025 Updated
	


BanGDream from https://bestdori.com/


	
		
		08/15/2025 Updated
	


ATRI from… See the full description on the dataset page: https://huggingface.co/datasets/bot-yaya/parallel_corpus_game.",https://huggingface.co/datasets/bot-yaya/parallel_corpus_game,"['ar', 'zh', 'de', 'en', 'eo', 'es', 'fr', 'he', 'id', 'it', 'ja', 'ko', 'nl', 'pt', 'ru', 'sv', 'th', 'vi', 'pl', 'tr']",['translation'],['1M<n<10M']
cc-clean/CC-MAIN-2019-49,cc-clean,2024-12-10 10:14:17+00:00,2024-12-10 10:59:42+00:00,7,0,"['language:ja', 'size_categories:100M<n<1B', 'format:parquet', 'modality:text', 'library:datasets', 'library:dask', 'library:mlcroissant', 'library:polars', 'region:us']","
	
		
		CC-MAIN-2019-49へようこそ
	

本データセットはCommonCrawlerと呼ばれるものから日本語のみを抽出したものです。
利用したものはcc-downloader-rsです。
なおIPAのICSCoEと呼ばれるところから資源を借りてやりましたゆえに、みなさんIPAに感謝しましょう。
※ IPAは独立行政法人 情報処理推進機構のことです。テストに出ますので覚えましょう。

	
		
		利用について
	

本利用は研究目的のみとさせていただきます。
それ以外の利用につきましては途方もくれない数の著作権者に許可を求めてきてください。
",https://huggingface.co/datasets/cc-clean/CC-MAIN-2019-49,['ja'],[],['100M<n<1B']
cc-clean/CC-MAIN-2019-39,cc-clean,2024-12-11 07:58:31+00:00,2024-12-11 12:53:42+00:00,3114,1,"['language:ja', 'size_categories:100M<n<1B', 'format:parquet', 'modality:text', 'library:datasets', 'library:dask', 'library:mlcroissant', 'library:polars', 'region:us']","
	
		
		CC-MAIN-2019-39へようこそ
	

本データセットはCommonCrawlerと呼ばれるものから日本語のみを抽出したものです。
利用したものはcc-downloader-rsです。
なおIPAのICSCoEと呼ばれるところから資源を借りてやりましたゆえに、みなさんIPAに感謝しましょう。
※ IPAは独立行政法人 情報処理推進機構のことです。テストに出ますので覚えましょう。

	
		
		利用について
	

本利用は研究目的のみとさせていただきます。
それ以外の利用につきましては途方もくれない数の著作権者に許可を求めてきてください。
",https://huggingface.co/datasets/cc-clean/CC-MAIN-2019-39,['ja'],[],['100M<n<1B']
CohereLabs/Global-MMLU-Lite,CohereLabs,2024-12-12 12:50:53+00:00,2025-09-29 21:03:38+00:00,4676,25,"['language:en', 'language:ar', 'language:bn', 'language:es', 'language:fr', 'language:hi', 'language:de', 'language:id', 'language:it', 'language:ja', 'language:ko', 'language:my', 'language:pt', 'language:zh', 'language:yo', 'language:sw', 'license:apache-2.0', 'size_categories:1K<n<10K', 'format:parquet', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'library:argilla', 'arxiv:2412.03304', 'region:us', 'argilla']","

	
		
		Dataset Summary
	

Global-MMLU-Lite is a multilingual evaluation set spanning 16 languages, including English. It is ""lite"" version of the original Global-MMLU dataset 🌍.
It includes 200 Culturally Sensitive (CS) and 200 Culturally Agnostic (CA) samples per language. The samples in Global-MMLU-Lite are corresponding to languages which are fully human translated or post-edited in the original Global-MMLU dataset. 
NOTE: Of the 16 languages presently included in Global-MMLU-Lite, 15… See the full description on the dataset page: https://huggingface.co/datasets/CohereLabs/Global-MMLU-Lite.",https://huggingface.co/datasets/CohereLabs/Global-MMLU-Lite,"['en', 'ar', 'bn', 'es', 'fr', 'hi', 'de', 'id', 'it', 'ja', 'ko', 'my', 'pt', 'zh', 'yo', 'sw']",[],['1K<n<10K']
Aratako/Self-Instruct-Qwen2.5-72B-Instruct-60k,Aratako,2024-12-13 02:56:47+00:00,2024-12-16 17:21:59+00:00,21,0,"['task_categories:text-generation', 'language:ja', 'license:other', 'size_categories:10K<n<100K', 'format:parquet', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'arxiv:2406.08464', 'arxiv:2304.12244', 'arxiv:2212.10560', 'region:us']","
	
		
		Self-Instruct-Qwen2.5-72B-Instruct-60k
	


	
		
		概要
	

以下の手順で作成した約6万件の日本語の合成instructionデータセットです。

MagpieとEvol-Instructを使って作成された合成instructionデータであるAratako/Magpie-Tanuki-Instruction-Selected-Evolved-26.5kに対し、Qwen/Qwen2.5-72B-Instruct-GPTQ-Int8を使ってinstructionのカテゴリを付与
同じカテゴリに分類された3つのinstructionをseed taskとしてQwen/Qwen2.5-72B-Instruct-GPTQ-Int8に与え、Self-Instructの手法で7個のinstructionを生成
元論文の実装とは一部異なります。
generated_instruction列が生成されたinstructionです。




		
	
	ライセンス
	

基本的にはApache 2.0に準じますが、Qwen… See the full description on the dataset page: https://huggingface.co/datasets/Aratako/Self-Instruct-Qwen2.5-72B-Instruct-60k.",https://huggingface.co/datasets/Aratako/Self-Instruct-Qwen2.5-72B-Instruct-60k,['ja'],['text-generation'],['10K<n<100K']
Alsebay/JP-novel-selected-dataset,Alsebay,2024-12-14 05:24:42+00:00,2024-12-16 05:00:50+00:00,9,1,"['language:ja', 'license:cc-by-nc-nd-4.0', 'size_categories:1K<n<10K', 'format:text', 'modality:text', 'library:datasets', 'library:mlcroissant', 'region:us']",,https://huggingface.co/datasets/Alsebay/JP-novel-selected-dataset,['ja'],[],['1K<n<10K']
taozi555/novel_text,taozi555,2024-12-14 12:17:02+00:00,2024-12-14 18:02:58+00:00,37,0,"['task_categories:text-generation', 'language:es', 'language:en', 'language:fr', 'language:id', 'language:zh', 'language:de', 'language:ja', 'language:vi', 'language:th', 'language:ru', 'license:cc-by-2.0', 'size_categories:100K<n<1M', 'format:json', 'modality:text', 'library:datasets', 'library:dask', 'library:mlcroissant', 'library:polars', 'region:us']",,https://huggingface.co/datasets/taozi555/novel_text,"['es', 'en', 'fr', 'id', 'zh', 'de', 'ja', 'vi', 'th', 'ru']",['text-generation'],['100K<n<1M']
JunichiroMorita/Our-Regional-Cuisines,JunichiroMorita,2024-12-14 13:23:01+00:00,2024-12-14 13:53:41+00:00,10,0,"['language:ja', 'license:apache-2.0', 'size_categories:1K<n<10K', 'format:csv', 'modality:text', 'library:datasets', 'library:dask', 'library:mlcroissant', 'library:polars', 'region:us']","
	
		
		Our Regional Cuisines Database
	

""Our Regional Cuisines"" is a database created by Japan's Ministry of Agriculture, Forestry and Fisheries to preserve and pass on Washoku, a UNESCO Intangible Cultural Heritage. 
It offers information on the origins, history, and recipes of regional dishes, along with cultural and geographical backgrounds. 
Launched in 2019, the database supports home cooking, menu development, product creation, and research, promoting the rich diversity of Japan's food… See the full description on the dataset page: https://huggingface.co/datasets/JunichiroMorita/Our-Regional-Cuisines.",https://huggingface.co/datasets/JunichiroMorita/Our-Regional-Cuisines,['ja'],[],['1K<n<10K']
kajuma/Llama-SFT-3000,kajuma,2024-12-14 13:52:01+00:00,2024-12-14 13:56:02+00:00,13,0,"['task_categories:text-generation', 'language:ja', 'license:llama3.1', 'size_categories:1K<n<10K', 'format:parquet', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","The instructions of this dataset are generated by Tanuki-8B-dpo-v1.0 and the outputs are generated by Llama-3.1-SuperSwallow-70B-Instruct-v0.1
Llama 3.1 is licensed under the Llama 3.1 Community License, Copyright © Meta Platforms, Inc. All Rights Reserved.
",https://huggingface.co/datasets/kajuma/Llama-SFT-3000,['ja'],['text-generation'],['1K<n<10K']
tomo1222/Japanese-QA111dataset,tomo1222,2024-12-14 13:54:53+00:00,2024-12-14 14:07:10+00:00,8,0,"['language:ja', 'license:apache-2.0', 'size_categories:n<1K', 'format:parquet', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","Data created manually
",https://huggingface.co/datasets/tomo1222/Japanese-QA111dataset,['ja'],[],['n<1K']
Nurture-intelligence/ins_dataset,Nurture-intelligence,2024-12-15 09:39:47+00:00,2024-12-17 16:27:37+00:00,28,0,"['language:ja', 'license:gemma', 'size_categories:n<1K', 'format:json', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","

	
		
		概要
	

このデータセットはsakura_japanese_datasetの質問に回答する形式で作られた、一問一答形式の合成データセットです。

	
		
		ライセンス
	

このデータセットのライセンスは元データセットのライセンスとGemma Terms of Useライセンスが適用されます。

	
		
		合成方法
	

このデータセットは複数の推論結果から良い推論結果を選ぶPro型推論を適用したNurture-intelligence/Gemma-2-108B-DPO-v0.1を使用して合成されました。

	
		
		謝辞
	

元データセットの作成者のみなさま、Gemma2の開発チーム、計算資源を貸していただいたVOLT MINDに最大の感謝を申し上げます。
",https://huggingface.co/datasets/Nurture-intelligence/ins_dataset,['ja'],[],['n<1K']
Aratako/iterative-dpo-data-for-ORPO-iter3,Aratako,2024-12-15 16:03:35+00:00,2024-12-17 01:42:13+00:00,13,2,"['task_categories:text-generation', 'language:ja', 'license:llama3.1', 'license:gemma', 'size_categories:10K<n<100K', 'format:parquet', 'modality:tabular', 'modality:text', 'library:datasets', 'library:dask', 'library:mlcroissant', 'library:polars', 'region:us']","
	
		
		iterative-dpo-data-for-ORPO-iter3
	


	
		
		概要
	

合成instructionデータであるAratako/Self-Instruct-Qwen2.5-72B-Instruct-60kを元に以下のような手順で作成した日本語Preferenceデータセットです。

開発途中のモデルであるAratako/Llama-Gemma-2-27b-CPO_SimPO-iter2を用いて、temperature=1で回答を5回生成
5個の回答それぞれに対して、Qwen/Qwen2.5-72B-Instruct-GPTQ-Int8を用いて0～5点のスコア付けを実施
1つのinstructionに対する5個の回答について、最もスコアが高いものをchosenに、低いものをrejectedに配置
全て同じスコアの場合や、最も良いスコアが2点以下の場合は除外




	
		
	
	
		ライセンス
	

本データセットは回答の作成に利用したモデルの関係で以下のライセンスの影響を受けます。

META LLAMA 3.1 COMMUNITY… See the full description on the dataset page: https://huggingface.co/datasets/Aratako/iterative-dpo-data-for-ORPO-iter3.",https://huggingface.co/datasets/Aratako/iterative-dpo-data-for-ORPO-iter3,['ja'],['text-generation'],['10K<n<100K']
facebook/2M-Belebele,facebook,2024-12-16 08:45:30+00:00,2024-12-17 13:39:10+00:00,863,11,"['task_categories:question-answering', 'task_categories:automatic-speech-recognition', 'language:bg', 'language:pa', 'language:en', 'language:hu', 'language:sv', 'language:af', 'language:ca', 'language:ka', 'language:sk', 'language:jv', 'language:bn', 'language:tr', 'language:sr', 'language:ro', 'language:tg', 'language:fa', 'language:wo', 'language:fi', 'language:hy', 'language:vi', 'language:kea', 'language:as', 'language:ja', 'language:nl', 'language:ne', 'language:lg', 'language:hi', 'language:xh', 'language:kk', 'language:mn', 'language:yo', 'language:km', 'language:ha', 'language:ru', 'language:sw', 'language:ps', 'language:ko', 'language:cs', 'language:lv', 'language:ig', 'language:ar', 'language:es', 'language:nb', 'language:lt', 'language:fil', 'language:it', 'language:he', 'language:da', 'language:ml', 'language:my', 'language:el', 'language:et', 'language:pl', 'language:sn', 'language:sd', 'language:or', 'language:th', 'language:luo', 'language:sl', 'language:fr', 'language:id', 'language:ta', 'language:gu', 'language:mk', 'language:am', 'language:pt', 'language:cmn', 'language:de', 'language:ceb', 'language:is', 'language:ur', 'language:az', 'language:te', 'license:cc-by-sa-4.0', 'size_categories:10K<n<100K', 'format:parquet', 'modality:tabular', 'modality:text', 'modality:audio', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'arxiv:2412.08274', 'region:us', 'speech-recognition', 'multilingual', 'flores200', 'translation', 'audio', 'speech']","
	
		
		2M-Belebele
	


	
		
		Highly-Multilingual Speech and American Sign Language Comprehension Dataset
	

We introduce 2M-Belebele as the first highly multilingual speech and American Sign Language (ASL) comprehension dataset. Our dataset, which is an extension of the existing Belebele only-text dataset, covers 74 spoken languages at the intersection of Belebele and Fleurs, and one sign language (ASL). 
The speech dataset is built from aligning Belebele, Flores200 and Fleurs datasets as… See the full description on the dataset page: https://huggingface.co/datasets/facebook/2M-Belebele.",https://huggingface.co/datasets/facebook/2M-Belebele,"['bg', 'pa', 'en', 'hu', 'sv', 'af', 'ca', 'ka', 'sk', 'jv', 'bn', 'tr', 'sr', 'ro', 'tg', 'fa', 'wo', 'fi', 'hy', 'vi', 'kea', 'as', 'ja', 'nl', 'ne', 'lg', 'hi', 'xh', 'kk', 'mn', 'yo', 'km', 'ha', 'ru', 'sw', 'ps', 'ko', 'cs', 'lv', 'ig', 'ar', 'es', 'nb', 'lt', 'fil', 'it', 'he', 'da', 'ml', 'my', 'el', 'et', 'pl', 'sn', 'sd', 'or', 'th', 'luo', 'sl', 'fr', 'id', 'ta', 'gu', 'mk', 'am', 'pt', 'cmn', 'de', 'ceb', 'is', 'ur', 'az', 'te']","['question-answering', 'automatic-speech-recognition']",['10K<n<100K']
ayousanz/callhome-ja-plus,ayousanz,2024-12-17 01:21:33+00:00,2024-12-17 01:44:41+00:00,14,2,"['language:ja', 'license:cc-by-nc-sa-4.0', 'region:us', 'speaker-diarization', 'speaker-segmentation', 'voice-activity-detection']","
	
		
		talkbank/callhome for JA plus
	

talkbank/callhomeのJAデータをwavに変換して、metaデータをjsonにまとめたデータセット

	
		
		meta data
	

以下のようなデータ構造の配列になっています
    {
        ""audio_filename"": ""callhome_jpn_0.wav"",
        ""sampling_rate"": 16000,
        ""duration"": 606.53,
        ""utterances"": [
            {
                ""start_time"": 0.0,
                ""end_time"": 3.4799999999999898,
                ""speaker"": ""B""
            },
            {
                ""start_time"": 1.5999999999999943… See the full description on the dataset page: https://huggingface.co/datasets/ayousanz/callhome-ja-plus.",https://huggingface.co/datasets/ayousanz/callhome-ja-plus,['ja'],[],[]
niryuu/Magpie-QwQ-Reasoning-dpo,niryuu,2024-12-17 03:09:05+00:00,2024-12-18 11:41:10+00:00,20,0,"['language:ja', 'license:apache-2.0', 'size_categories:n<1K', 'format:json', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'arxiv:2406.08464', 'region:us']","This DPO dataset is synthesized by this way:

instructions: Magpie on QwQ-32b-Preview
outputs: QwQ-32b-Preview and calm3-22b-chat.

",https://huggingface.co/datasets/niryuu/Magpie-QwQ-Reasoning-dpo,['ja'],[],['n<1K']
Sakalti/Asian-dataset,Sakalti,2024-12-17 13:03:56+00:00,2025-02-01 14:53:54+00:00,4,0,"['language:ja', 'license:apache-2.0', 'region:us']",,https://huggingface.co/datasets/Sakalti/Asian-dataset,['ja'],[],[]
DeL-TaiseiOzaki/Tengentoppa-sft-reasoning-llama-v4.0,DeL-TaiseiOzaki,2024-12-18 07:20:40+00:00,2024-12-18 07:23:25+00:00,10,0,"['task_categories:text-generation', 'language:ja', 'license:llama3.3', 'size_categories:100K<n<1M', 'format:json', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","
	
		
		Dataset Card for Dataset Name
	



This dataset card aims to be a base template for new datasets. It has been generated using this raw template.

	
		
		Dataset Details
	


	
		
		Dataset Description
	






Curated by: [More Information Needed]
Funded by [optional]: [More Information Needed]
Shared by [optional]: [More Information Needed]
Language(s) (NLP): [More Information Needed]
License: [More Information Needed]


	
		
		Dataset Sources [optional]
	




Repository: [More… See the full description on the dataset page: https://huggingface.co/datasets/DeL-TaiseiOzaki/Tengentoppa-sft-reasoning-llama-v4.0.",https://huggingface.co/datasets/DeL-TaiseiOzaki/Tengentoppa-sft-reasoning-llama-v4.0,['ja'],['text-generation'],['100K<n<1M']
zenless-lab/jamp,zenless-lab,2024-12-18 10:09:27+00:00,2024-12-18 14:30:20+00:00,12,0,"['task_categories:text-classification', 'language:ja', 'license:cc-by-sa-4.0', 'size_categories:10K<n<100K', 'format:parquet', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'arxiv:2306.10727', 'region:us', 'nli', 'evaluation', 'benchmark']","
	
		
		Jamp: Controlled Japanese Temporal Inference Dataset for Evaluating Generalization Capacity of Language Models
	

Jamp(tomo-vv/temporalNLI_dataset) is the Japanese temporal inference benchmark. 
This dataset consists of templates, test data, and training data. 
Template subset containing template, time format, or time span in their names are split based on tense fragment, time format, 
or time span, respectively.

	
		
	
	
		Dataset Details
	


	
		
	
	
		Dataset Sources… See the full description on the dataset page: https://huggingface.co/datasets/zenless-lab/jamp.",https://huggingface.co/datasets/zenless-lab/jamp,['ja'],['text-classification'],['10K<n<100K']
zenless-lab/jnli,zenless-lab,2024-12-18 10:09:43+00:00,2024-12-18 14:40:06+00:00,27,0,"['task_categories:text-classification', 'language:ja', 'license:cc-by-sa-4.0', 'size_categories:10K<n<100K', 'format:parquet', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us', 'nli', 'benchmark', 'evaluation']","
	
		
		JGLUE[JNLI]: Japanese General Language Understanding Evaluation
	

JNLI(yahoojapan/JGLUE) is a Japanese version of the NLI (Natural Language Inference) dataset. 
NLI is a task to recognize the inference relation that a premise sentence has to a hypothesis sentence. 
The inference relations are entailment, contradiction, and neutral.

	
		
	
	
		Dataset Details
	


	
		
	
	
		Dataset Sources [optional]
	


Repository: yahoojapan/JGLUE
Paper: [More Information Needed]


	
	
	
		Citation… See the full description on the dataset page: https://huggingface.co/datasets/zenless-lab/jnli.",https://huggingface.co/datasets/zenless-lab/jnli,['ja'],['text-classification'],['10K<n<100K']
zenless-lab/jsem,zenless-lab,2024-12-18 10:10:11+00:00,2024-12-19 08:52:15+00:00,16,0,"['task_categories:text-classification', 'language:ja', 'license:bsd-3-clause', 'size_categories:10K<n<100K', 'format:parquet', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us', 'evaluation', 'benchmark', 'nli']","
	
		
		JSeM: Japanese semantic test suite (Japanese FraCaS and extensions)
	

叙述文間の含意関係は、言語学においては意味論の中心的な説明対象の一つであるとともに、理論を検証するためのベンチマークとして用いられています。
また近年の自然言語処理においては、含意関係認識(Recognizing Textual Entailment: RTE)が意味処理タスクの中核となっています。

前提(premise)：一つの文
仮説(hypothesis)：一つの文
判定(answer)：1.と2.の間に含意関係があるかどうかについての母語話者の判断（entailment, neutralあるいはcontradiction)

このテストセットでは、FraCaS test suite（Cooper et al.(1996)で公開されたオリジナルのテストセット, 
およびBill MacCartney氏による同セットのXML版）の方針にならい、言語現象ごとに含意関係のテストをまとめています。… See the full description on the dataset page: https://huggingface.co/datasets/zenless-lab/jsem.",https://huggingface.co/datasets/zenless-lab/jsem,['ja'],['text-classification'],['10K<n<100K']
zenless-lab/jaqket-aio,zenless-lab,2024-12-18 10:10:59+00:00,2024-12-23 00:34:42+00:00,11,0,"['language:ja', 'size_categories:1K<n<10K', 'format:parquet', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']",,https://huggingface.co/datasets/zenless-lab/jaqket-aio,['ja'],[],['1K<n<10K']
zenless-lab/jsquad,zenless-lab,2024-12-18 10:11:17+00:00,2024-12-27 00:44:36+00:00,7,0,"['language:ja', 'size_categories:10K<n<100K', 'format:parquet', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']",,https://huggingface.co/datasets/zenless-lab/jsquad,['ja'],[],['10K<n<100K']
zenless-lab/jcommonsensemorality,zenless-lab,2024-12-18 10:11:28+00:00,2024-12-23 00:34:19+00:00,13,0,"['language:ja', 'size_categories:10K<n<100K', 'format:parquet', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']",,https://huggingface.co/datasets/zenless-lab/jcommonsensemorality,['ja'],[],['10K<n<100K']
zenless-lab/jcommonsenseqa,zenless-lab,2024-12-18 10:11:40+00:00,2024-12-23 00:34:58+00:00,10,0,"['language:ja', 'size_categories:10K<n<100K', 'format:parquet', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']",,https://huggingface.co/datasets/zenless-lab/jcommonsenseqa,['ja'],[],['10K<n<100K']
zenless-lab/kuci,zenless-lab,2024-12-18 10:11:57+00:00,2024-12-23 00:34:32+00:00,8,0,"['language:ja', 'size_categories:100K<n<1M', 'format:parquet', 'modality:tabular', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']",,https://huggingface.co/datasets/zenless-lab/kuci,['ja'],[],['100K<n<1M']
zenless-lab/chABSA,zenless-lab,2024-12-18 10:12:21+00:00,2024-12-26 00:51:47+00:00,8,0,"['language:ja', 'size_categories:1K<n<10K', 'format:parquet', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']",,https://huggingface.co/datasets/zenless-lab/chABSA,['ja'],[],['1K<n<10K']
zenless-lab/mawps,zenless-lab,2024-12-18 10:12:57+00:00,2024-12-30 12:41:45+00:00,9,0,"['language:ja', 'size_categories:1K<n<10K', 'format:parquet', 'modality:tabular', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']",,https://huggingface.co/datasets/zenless-lab/mawps,['ja'],[],['1K<n<10K']
zenless-lab/jsts,zenless-lab,2024-12-18 10:14:03+00:00,2024-12-23 00:34:51+00:00,8,0,"['language:ja', 'size_categories:10K<n<100K', 'format:parquet', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']",,https://huggingface.co/datasets/zenless-lab/jsts,['ja'],[],['10K<n<100K']
zenless-lab/jmmlu,zenless-lab,2024-12-18 10:14:10+00:00,2024-12-26 00:51:34+00:00,9,0,"['language:ja', 'size_categories:1K<n<10K', 'format:parquet', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']",,https://huggingface.co/datasets/zenless-lab/jmmlu,['ja'],[],['1K<n<10K']
zenless-lab/jmmlu-nc-nd,zenless-lab,2024-12-18 10:14:14+00:00,2024-12-23 00:35:04+00:00,15,0,"['language:ja', 'size_categories:n<1K', 'format:parquet', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']",,https://huggingface.co/datasets/zenless-lab/jmmlu-nc-nd,['ja'],[],['n<1K']
NewEden-Forge/BlueSky-Sharegpt-V0.1,NewEden-Forge,2024-12-18 20:23:18+00:00,2024-12-18 20:39:51+00:00,13,0,"['language:en', 'language:ru', 'language:ja', 'size_categories:100K<n<1M', 'format:json', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us', 'chat']","https://huggingface.co/datasets/metalure/733k_bluesky_threads
Converted into sharegpt format for Finetuning. Need to filter out all non-english data. Only rows with more then 3 turns were considered to be converted.
",https://huggingface.co/datasets/NewEden-Forge/BlueSky-Sharegpt-V0.1,"['en', 'ru', 'ja']",[],['100K<n<1M']
lightblue/reranker_continuous_filt_max7_train,lightblue,2024-12-19 06:17:53+00:00,2025-01-07 01:13:36+00:00,50,6,"['language:en', 'language:zh', 'language:es', 'language:de', 'language:ar', 'language:ru', 'language:ja', 'language:ko', 'language:hi', 'language:sk', 'language:vi', 'language:tr', 'language:fi', 'language:id', 'language:fa', 'language:no', 'language:th', 'language:sv', 'language:pt', 'language:da', 'language:bn', 'language:te', 'language:ro', 'language:it', 'language:fr', 'language:nl', 'language:sw', 'language:pl', 'language:hu', 'language:cs', 'language:el', 'language:uk', 'language:mr', 'language:ta', 'language:tl', 'language:bg', 'language:lt', 'language:ur', 'language:he', 'language:gu', 'language:kn', 'language:am', 'language:kk', 'language:hr', 'language:uz', 'language:jv', 'language:ca', 'language:az', 'language:ms', 'language:sr', 'language:sl', 'language:yo', 'language:lv', 'language:is', 'language:ha', 'language:ka', 'language:et', 'language:bs', 'language:hy', 'language:ml', 'language:pa', 'language:mt', 'language:km', 'language:sq', 'language:or', 'language:as', 'language:my', 'language:mn', 'language:af', 'language:be', 'language:ga', 'language:mk', 'language:cy', 'language:gl', 'language:ceb', 'language:la', 'language:yi', 'language:lb', 'language:tg', 'language:gd', 'language:ne', 'language:ps', 'language:eu', 'language:ky', 'language:ku', 'language:si', 'language:ht', 'language:eo', 'language:lo', 'language:fy', 'language:sd', 'language:mg', 'language:so', 'language:ckb', 'language:su', 'language:nn', 'license:apache-2.0', 'size_categories:1M<n<10M', 'format:parquet', 'modality:tabular', 'modality:text', 'library:datasets', 'library:dask', 'library:mlcroissant', 'library:polars', 'region:us']","
	
		
		Reranker training data
	

This data was generated using 4 steps:

We gathered queries and corresponding text data from 35 high quality datasets covering more than 95 languages.
For datasets which did not already have negative texts for queries, we mined hard negatives using the BAAI/bge-m3 embedding model.
For each query, we selected one positive and one negative text and used Qwen/Qwen2.5-32B-Instruct-GPTQ-Int4 to rate the relatedness of each query-text pair using a token ""1"", ""2""… See the full description on the dataset page: https://huggingface.co/datasets/lightblue/reranker_continuous_filt_max7_train.",https://huggingface.co/datasets/lightblue/reranker_continuous_filt_max7_train,"['en', 'zh', 'es', 'de', 'ar', 'ru', 'ja', 'ko', 'hi', 'sk', 'vi', 'tr', 'fi', 'id', 'fa', 'no', 'th', 'sv', 'pt', 'da', 'bn', 'te', 'ro', 'it', 'fr', 'nl', 'sw', 'pl', 'hu', 'cs', 'el', 'uk', 'mr', 'ta', 'tl', 'bg', 'lt', 'ur', 'he', 'gu', 'kn', 'am', 'kk', 'hr', 'uz', 'jv', 'ca', 'az', 'ms', 'sr', 'sl', 'yo', 'lv', 'is', 'ha', 'ka', 'et', 'bs', 'hy', 'ml', 'pa', 'mt', 'km', 'sq', 'or', 'as', 'my', 'mn', 'af', 'be', 'ga', 'mk', 'cy', 'gl', 'ceb', 'la', 'yi', 'lb', 'tg', 'gd', 'ne', 'ps', 'eu', 'ky', 'ku', 'si', 'ht', 'eo', 'lo', 'fy', 'sd', 'mg', 'so', 'ckb', 'su', 'nn']",[],['1M<n<10M']
Kendamarron/Synthetic-Preference-ja-Qwen2.5-32B-Mistral-Nemo,Kendamarron,2024-12-19 12:56:38+00:00,2024-12-19 13:50:32+00:00,12,0,"['language:ja', 'license:apache-2.0', 'size_categories:1K<n<10K', 'format:parquet', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","
	
		
		detail
	

https://zenn.dev/kendama/articles/d9f6937f28c5a5
",https://huggingface.co/datasets/Kendamarron/Synthetic-Preference-ja-Qwen2.5-32B-Mistral-Nemo,['ja'],[],['1K<n<10K']
zhuzhu2dandan/auto_dataset,zhuzhu2dandan,2024-12-21 09:43:24+00:00,2024-12-21 09:48:40+00:00,10,0,"['language:en', 'language:ar', 'language:bn', 'language:es', 'language:fr', 'language:hi', 'language:ru', 'language:de', 'language:id', 'language:it', 'language:ja', 'language:ko', 'language:pt', 'language:zh', 'language:yo', 'language:nl', 'language:ro', 'language:uk', 'language:vi', 'language:tr', 'language:pl', 'language:fa', 'language:cs', 'language:he', 'language:el', 'language:ms', 'language:fil', 'language:te', 'language:si', 'language:ne', 'language:ky', 'language:sv', 'language:lt', 'language:sr', 'language:mg', 'language:so', 'language:ha', 'language:am', 'language:sn', 'language:ig', 'language:ny', 'language:sw', 'library:argilla', 'arxiv:2412.03304', 'region:us', 'argilla']","

	
		
		Dataset Summary
	

Global-MMLU 🌍 is a multilingual evaluation set spanning 42 languages, including English. This dataset combines machine translations for MMLU questions along with professional translations and crowd-sourced post-edits.
It also includes cultural sensitivity annotations for a subset of the questions (2850 questions per language) and classifies them as Culturally Sensitive (CS) 🗽 or Culturally Agnostic (CA) ⚖️. These annotations were collected as part of an open… See the full description on the dataset page: https://huggingface.co/datasets/zhuzhu2dandan/auto_dataset.",https://huggingface.co/datasets/zhuzhu2dandan/auto_dataset,"['en', 'ar', 'bn', 'es', 'fr', 'hi', 'ru', 'de', 'id', 'it', 'ja', 'ko', 'pt', 'zh', 'yo', 'nl', 'ro', 'uk', 'vi', 'tr', 'pl', 'fa', 'cs', 'he', 'el', 'ms', 'fil', 'te', 'si', 'ne', 'ky', 'sv', 'lt', 'sr', 'mg', 'so', 'ha', 'am', 'sn', 'ig', 'ny', 'sw']",[],[]
cc-clean/CC-MAIN-2019-35,cc-clean,2024-12-22 01:37:19+00:00,2024-12-22 08:07:11+00:00,145,0,"['language:ja', 'size_categories:100M<n<1B', 'format:parquet', 'modality:text', 'library:datasets', 'library:dask', 'library:mlcroissant', 'library:polars', 'region:us']","
	
		
		CC-MAIN-2019-35へようこそ
	

本データセットはCommonCrawlerと呼ばれるものから日本語のみを抽出したものです。
利用したものはcc-downloader-rsです。
なおIPAのICSCoEと呼ばれるところから資源を借りてやりましたゆえに、みなさんIPAに感謝しましょう。
※ IPAは独立行政法人 情報処理推進機構のことです。テストに出ますので覚えましょう。

	
		
		利用について
	

本利用は研究目的のみとさせていただきます。
それ以外の利用につきましては途方もくれない数の著作権者に許可を求めてきてください。
",https://huggingface.co/datasets/cc-clean/CC-MAIN-2019-35,['ja'],[],['100M<n<1B']
tokyotech-llm/swallow-code-v0.1,tokyotech-llm,2024-12-22 05:09:28+00:00,2024-12-27 16:57:55+00:00,37,1,"['task_categories:text-generation', 'source_datasets:bigcode/the-stack-v2-train-smol-ids', 'language:en', 'language:ja', 'license:other', 'region:us', 'code']","
	
		
		What is it?
	

Swallow-code-v0.1 consists of 4 staged dataset subsets and are filtered from bigcode/the-stack-v2-train-smol-ids.

	
		
		What is being released?
	

The dataset is released in four versions:

Swallow Code v0.1 stage 1: 36B tokens, 41M documents containing Python scripts.
Swallow Code v0.1 stage 2: 31B tokens, 37M documents containing Python scripts that are syntax error-free.
Swallow Code v0.1 stage 3: 20B tokens, 24M documents containing Python scripts that are filtered… See the full description on the dataset page: https://huggingface.co/datasets/tokyotech-llm/swallow-code-v0.1.",https://huggingface.co/datasets/tokyotech-llm/swallow-code-v0.1,"['en', 'ja']",['text-generation'],[]
cc-clean/CC-MAIN-2019-30,cc-clean,2024-12-22 08:01:41+00:00,2024-12-22 12:36:11+00:00,211,0,"['language:ja', 'size_categories:100M<n<1B', 'format:parquet', 'modality:text', 'library:datasets', 'library:dask', 'library:mlcroissant', 'library:polars', 'region:us']","
	
		
		CC-MAIN-2019-30へようこそ
	

本データセットはCommonCrawlerと呼ばれるものから日本語のみを抽出したものです。
利用したものはcc-downloader-rsです。
なおIPAのICSCoEと呼ばれるところから資源を借りてやりましたゆえに、みなさんIPAに感謝しましょう。
※ IPAは独立行政法人 情報処理推進機構のことです。テストに出ますので覚えましょう。

	
		
		利用について
	

本利用は研究目的のみとさせていただきます。
それ以外の利用につきましては途方もくれない数の著作権者に許可を求めてきてください。
",https://huggingface.co/datasets/cc-clean/CC-MAIN-2019-30,['ja'],[],['100M<n<1B']
Nurture-intelligence/thinking_dataset_v1,Nurture-intelligence,2024-12-22 08:13:59+00:00,2024-12-22 08:35:44+00:00,10,1,"['task_categories:text-generation', 'language:ja', 'license:apache-2.0', 'size_categories:n<1K', 'format:json', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","
	
		
		概要
	

このデータセットは思考モデルを製作する際のもととなる質問データを集めたものになります。
このデータはQwen/Qwen2.5-32B-Instructのq8_0/GGUFをollama上で動かして製作されたものです。
一応(質問の)クリーニングを入れてはありますが、回答のクリーニング入れておりません。

	
		
		注意
	

回答には別のモデル（mistral large）(確か)を利用したため、""質問の部分だけ""Apache 2.0です。
instruction fine tuning したモデルを公開することはお勧めしません。

	
		
		謝辞
	

元モデルの製作者、計算資源を貸してくださったvolt mindに感謝を申し上げます。
",https://huggingface.co/datasets/Nurture-intelligence/thinking_dataset_v1,['ja'],['text-generation'],['n<1K']
6DammK9/danbooru2024-tags-1ktar,6DammK9,2024-12-24 06:59:37+00:00,2025-02-18 13:04:25+00:00,184,0,"['task_categories:image-classification', 'task_categories:zero-shot-image-classification', 'task_categories:text-to-image', 'annotations_creators:no-annotation', 'source_datasets:danbooru', 'language:en', 'language:ja', 'license:mit', 'size_categories:1M<n<10M', 'region:us', 'art', 'anime', 'not-for-all-audiences']","
	
		
		Danbooru 2024 tags only in 1k tar
	


Dedicated dataset to align deepghs/danbooru2024-webp-4Mpixel.

How to use / why I create this: my speedrun to build the dataset

Instead of this repo, if you are finetuning SDXL with kohya-ss/sd-scripts, refer to my latent repo directly. You don't need the images and tags.

If you are interested in dual tag / caption training, I have prepared the all-in-one version, which is 14GB when decompressed.



	
		
		Core logic
	


The script building this… See the full description on the dataset page: https://huggingface.co/datasets/6DammK9/danbooru2024-tags-1ktar.",https://huggingface.co/datasets/6DammK9/danbooru2024-tags-1ktar,"['en', 'ja']","['image-classification', 'zero-shot-image-classification', 'text-to-image']",['1M<n<10M']
6DammK9/e621_2024-tags-1ktar,6DammK9,2024-12-24 07:07:54+00:00,2025-02-01 07:10:14+00:00,93,1,"['task_categories:image-classification', 'task_categories:zero-shot-image-classification', 'task_categories:text-to-image', 'annotations_creators:no-annotation', 'source_datasets:e621', 'language:en', 'language:ja', 'license:mit', 'size_categories:1M<n<10M', 'region:us', 'art', 'anime', 'not-for-all-audiences']","
	
		
		E621 2024 tags only in 1k tar
	


Dedicated dataset to align both NebulaeWis/e621-2024-webp-4Mpixel and deepghs/e621_newest-webp-4Mpixel.

How to use / why I create this: my speedrun to build the dataset

Instead of this repo, if you are finetuning SDXL with kohya-ss/sd-scripts, refer to my latent repo directly. You don't need the images and tags.



	
	
	
		Core logic
	


The script building this 1ktar

The script building the tag from 2 datasets

Artist and character first. Literally… See the full description on the dataset page: https://huggingface.co/datasets/6DammK9/e621_2024-tags-1ktar.",https://huggingface.co/datasets/6DammK9/e621_2024-tags-1ktar,"['en', 'ja']","['image-classification', 'zero-shot-image-classification', 'text-to-image']",['1M<n<10M']
hama-jp/magpie-qwen-turbo-27k,hama-jp,2024-12-24 15:26:04+00:00,2024-12-24 16:18:58+00:00,13,0,"['task_categories:text-generation', 'language:ja', 'license:apache-2.0', 'size_categories:10K<n<100K', 'format:parquet', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","
	
		
		Magpie-Qwen-Turbo-27k
	

Aratako/Magpie-Tanuki-8B-annotated-96k
のアノテーションを利用して件数を減らし、outputをqwen-2.5-turboで再生成したSFT用の26728件のサブセットです。

	
		
		用途
	

コーディングを除く小規模な日本語チャット用LLMのためのファインチューニングを想定しています。

	
		
		使用データ
	

以下の条件で抽出したinstructionデータを利用して生成しました。

input_quality（クエリの質）：excellent　のみ
difficulty（難易度）：very easy/easy/medium/hard
primary_tag（カテゴリ）：
""Information seeking"",  # ユーザーがさまざまなトピックに関する特定の情報や事実を求めるクエリ。
""Reasoning"",  # 論理的思考、問題解決、または複雑なアイデアの処理が必要なクエリ。
""Planning"",  #… See the full description on the dataset page: https://huggingface.co/datasets/hama-jp/magpie-qwen-turbo-27k.",https://huggingface.co/datasets/hama-jp/magpie-qwen-turbo-27k,['ja'],['text-generation'],['10K<n<100K']
jaeyong2/Ja-functioncall,jaeyong2,2024-12-25 06:40:31+00:00,2025-01-22 06:49:14+00:00,16,1,"['language:ja', 'license:cc-by-sa-3.0', 'size_categories:100K<n<1M', 'format:parquet', 'modality:text', 'library:datasets', 'library:dask', 'library:mlcroissant', 'library:polars', 'region:us']","
	
		
		Development Process
	


source dataset from range3/wikipedia-ja-20230101
We used Qwen/Qwen2-72B-Instruct model to generate function.


	
		
		License
	


Qwen/Qwen2.5-72B-Instruct : https://huggingface.co/Qwen/Qwen2-72B-Instruct/blob/main/LICENSE
range3/wikipedia-ja-20230101 : https://spdx.org/licenses/CC-BY-SA-3.0 and https://huggingface.co/datasets/range3/wikipedia-ja-20230101


	
		
	
	
		Acknowledgement
	

This research is supported by TPU Research Cloud program.
",https://huggingface.co/datasets/jaeyong2/Ja-functioncall,['ja'],[],['100K<n<1M']
Manual-Dataset-Creation-Project/Malum-230,Manual-Dataset-Creation-Project,2024-12-26 23:27:07+00:00,2025-01-05 20:33:36+00:00,31,8,"['language:ja', 'license:apache-2.0', 'size_categories:n<1K', 'format:json', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","
	
		
		Malum-230
	


	
		
		Description
	

Malum-230 is a meticulously handcrafted Japanese dataset featuring multi-turn conversations and passages, specifically designed for logical reasoning tasks.
This dataset can be used for both pre-training and post-training.

	
		
		Details
	


Creation method: Human effort

Dataset type: Logical reasoning

Use case: pre-training and post-training



	
		
		Performance
	

This radar chart shows the evaluation results on Japanese MT-Bench for the… See the full description on the dataset page: https://huggingface.co/datasets/Manual-Dataset-Creation-Project/Malum-230.",https://huggingface.co/datasets/Manual-Dataset-Creation-Project/Malum-230,['ja'],[],['n<1K']
zenless-lab/llm-jp-eval,zenless-lab,2024-12-27 01:02:07+00:00,2024-12-30 12:41:28+00:00,149,0,"['language:ja', 'size_categories:100K<n<1M', 'format:parquet', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']",,https://huggingface.co/datasets/zenless-lab/llm-jp-eval,['ja'],[],['100K<n<1M']
fukugawa/kamakura-tasks-100,fukugawa,2024-12-27 07:24:24+00:00,2025-02-03 02:39:41+00:00,11,0,"['language:ja', 'license:cc-by-4.0', 'size_categories:n<1K', 'format:json', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","
	
		
		Usage
	

from datasets import load_dataset

data = load_dataset(""fukugawa/kamakura-tasks-100"")

data

DatasetDict({
    train: Dataset({
        features: ['task_id', 'input', 'output'],
        num_rows: 100
    })
})

data[""train""][0]

{'task_id': 0,
 'input': '鎌倉観光のアイデアを5つ教えて下さい。',
 'output': '1. 鶴岡八幡宮や銭洗弁天などのパワースポット巡り。\n2. 国宝の鎌倉大仏への参拝。\n3. 小町通り商店街で美味しいものを食べ歩き。\n4. 七里ヶ浜や由比ヶ浜で海の景色を楽しむ。\n5. 長谷寺や極楽寺などのお寺めぐり。'}

",https://huggingface.co/datasets/fukugawa/kamakura-tasks-100,['ja'],[],['n<1K']
clapAI/MultiLingualSentiment,clapAI,2024-12-27 15:30:01+00:00,2024-12-27 16:31:31+00:00,292,12,"['task_categories:text-classification', 'language:ar', 'language:de', 'language:en', 'language:es', 'language:fr', 'language:hi', 'language:id', 'language:it', 'language:ko', 'language:ms', 'language:pt', 'language:ru', 'language:tr', 'language:vi', 'language:zh', 'language:ja', 'license:apache-2.0', 'size_categories:1M<n<10M', 'format:parquet', 'modality:text', 'library:datasets', 'library:dask', 'library:mlcroissant', 'library:polars', 'region:us', 'sentiment', 'multilingual', 'emotion', 'review', 'classification']","
	
		
		Overview
	

MultilingualSentiment is a sentiment classification dataset that encompasses three sentiment labels: Positive, Neutral, Negative
The dataset spans multiple languages and covers a wide range of domains, making it ideal for multilingual sentiment analysis tasks.

	
		
		Dataset Information
	

The dataset was meticulously collected and aggregated from various sources, including Hugging Face and Kaggle. These sources provide diverse languages and domains to ensure a… See the full description on the dataset page: https://huggingface.co/datasets/clapAI/MultiLingualSentiment.",https://huggingface.co/datasets/clapAI/MultiLingualSentiment,"['ar', 'de', 'en', 'es', 'fr', 'hi', 'id', 'it', 'ko', 'ms', 'pt', 'ru', 'tr', 'vi', 'zh', 'ja']",['text-classification'],['1M<n<10M']
U23-lab/everyday_conversations_ja,U23-lab,2024-12-28 12:06:29+00:00,2024-12-28 12:26:01+00:00,11,2,"['language:ja', 'license:apache-2.0', 'size_categories:1K<n<10K', 'format:csv', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","
	
		
		データセットについて
	

このデータセットは、 HuggingFaceTB/everyday-conversations-llama3.1-2k を機械翻訳で日本語化したものになります。
具体的には、everyday-conversations-llama3.1-2kをトピックごとの対話のペアに変更してDeepLで翻訳したものとなります。

	
		
		詳細
	


topic: everyday-conversations-llama3.1-2kのtopic
user: 各トピックごとのユーザーからの発話
assistant: 各トピックごとのユーザーへの返答
assistantの返答がない場合はNone


	
		
		注意事項
	


人手で若干修正をしましたが、日本語が変な箇所がいくつか散見されます。
ライセンス：apache 2.0

",https://huggingface.co/datasets/U23-lab/everyday_conversations_ja,['ja'],[],['1K<n<10K']
trojblue/sakugabooru2025,trojblue,2024-12-29 13:51:08+00:00,2025-03-31 23:32:08+00:00,68,3,"['task_categories:text-to-image', 'task_categories:text-to-video', 'language:en', 'language:ja', 'license:mit', 'size_categories:100K<n<1M', 'modality:image', 'modality:video', 'library:webdataset', 'region:us', 'animation', 'image', 'video', 'webdataset']","

	
		
		Sakugabooru2025: Curated Animation Clips from Enthusiasts
	

Sakugabooru.com is a booru-style imageboard dedicated to collecting and sharing noteworthy animation clips, emphasizing Japanese anime but open to creators worldwide. Over the years, it has amassed more than 240,000 animation clips, alongside informative blog posts for anime fans everywhere.
With the growing interest in generative video models and AI animations, the scarcity of proper animation-related video datasets has… See the full description on the dataset page: https://huggingface.co/datasets/trojblue/sakugabooru2025.",https://huggingface.co/datasets/trojblue/sakugabooru2025,"['en', 'ja']","['text-to-image', 'text-to-video']",['100K<n<1M']
blastai/Open_o1_sft_Pro_translated_jp,blastai,2024-12-29 16:29:37+00:00,2024-12-30 18:43:22+00:00,12,9,"['task_categories:text-generation', 'language:ja', 'license:unknown', 'size_categories:10K<n<100K', 'format:json', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","
	
		
		概要
	

このデータセットはOpen_o1_sft_ProデータセットをQwen社のQwen2.5-14B-Instructを用いて日本語に翻訳したものになります。

	
		
		テンプレート
	

テンプレートは以下です。
{""conversations"": [{""role"": ""user"", ""content"": ""入力""}, {""role"": ""assistant"", ""thought"": ""思考"", 
""content"": ""出力""}, ...], 
""id"": id(整数), 
""dataset"": ""元データセットの名前""}


	
		
	
	
		ライセンス
	

ライセンスは元データセットに準じます。

	
		
	
	
		謝辞
	

データセットの製作者様,Qwenの開発者様,計算資源を貸してくださったVolt mindの皆様に感謝します。
",https://huggingface.co/datasets/blastai/Open_o1_sft_Pro_translated_jp,['ja'],['text-generation'],['10K<n<100K']
deepghs/e6ai_full,deepghs,2024-12-31 11:21:52+00:00,2025-09-08 17:27:29+00:00,93,2,"['task_categories:image-classification', 'task_categories:zero-shot-image-classification', 'task_categories:text-to-image', 'annotations_creators:no-annotation', 'source_datasets:e6ai', 'language:en', 'language:ja', 'license:other', 'size_categories:100K<n<1M', 'region:us', 'art', 'anime', 'not-for-all-audiences']","
	
		
		E6ai Dataset Newest Archive
	

This is the newest dataset of e6ai.net. And the newest data are up-to-date-ly maintained here, to make sure you can get all the newest data from huggingface instead of e6ai site.
All the file types we kept in this dataset: gif, jpg, png, webm

	
		
		Information
	


	
		
		Data
	

There are 110875 records in total. The ID range of these data is 3-126075. Last updated at 2025-09-09 01:08:59 JST.
These are the information of recent 50 records:

	
		
id… See the full description on the dataset page: https://huggingface.co/datasets/deepghs/e6ai_full.",https://huggingface.co/datasets/deepghs/e6ai_full,"['en', 'ja']","['image-classification', 'zero-shot-image-classification', 'text-to-image']",['100K<n<1M']
Egor-AI/CoT-XLang,Egor-AI,2024-12-31 14:21:09+00:00,2025-01-12 16:07:55+00:00,107,6,"['task_categories:text-generation', 'task_categories:question-answering', 'language:ru', 'language:en', 'language:ja', 'language:ko', 'language:id', 'language:vi', 'language:zh', 'language:it', 'language:es', 'language:th', 'license:mit', 'size_categories:1M<n<10M', 'format:json', 'modality:text', 'library:datasets', 'library:dask', 'library:mlcroissant', 'region:us', 'cot', 'o1']","RU:CoT-XLang — это многоязычный датасет, состоящий из текстовых примеров с пошаговыми рассуждениями (Chain-of-Thought, CoT) на различных языках, включая английский, русский, японский и другие. Он используется для обучения и тестирования моделей в задачах, требующих пояснений решений через несколько шагов. Датасет включает около 2,419,912 примеров, что позволяет эффективно обучать модели, способные генерировать пошаговые рассуждения.
Рекомендация:Используйте датасет для обучения моделей… See the full description on the dataset page: https://huggingface.co/datasets/Egor-AI/CoT-XLang.",https://huggingface.co/datasets/Egor-AI/CoT-XLang,"['ru', 'en', 'ja', 'ko', 'id', 'vi', 'zh', 'it', 'es', 'th']","['text-generation', 'question-answering']",['1M<n<10M']
Chattso-GPT/Japanese-patent-evaluation-dataset-01,Chattso-GPT,2025-01-01 14:38:29+00:00,2025-01-01 15:16:47+00:00,25,0,"['language:ja', 'license:apache-2.0', 'size_categories:n<1K', 'format:parquet', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us', 'legal']","
	
		
		試験的なデータセットとなります
	


	
		
		評価用データセットの作成方法
	


ChatGPT-4oで弁理士紹介を含む5つの観点から50のクエリを生成
ChatGPT-4oでクエリに対する回答と評価ポイントを生成※弁理士を直接紹介する10問は除く
除外した10問に関しては、開放特許情報データベース及びj-platpatの公開データより回答を手動作成

",https://huggingface.co/datasets/Chattso-GPT/Japanese-patent-evaluation-dataset-01,['ja'],[],['n<1K']
6DammK9/e621_2024-latents-sdxl-1ktar,6DammK9,2025-01-01 15:51:57+00:00,2025-02-27 15:39:03+00:00,6,1,"['task_categories:image-classification', 'task_categories:zero-shot-image-classification', 'task_categories:text-to-image', 'annotations_creators:no-annotation', 'source_datasets:danbooru', 'language:en', 'language:ja', 'license:mit', 'size_categories:1M<n<10M', 'format:webdataset', 'modality:text', 'library:datasets', 'library:webdataset', 'library:mlcroissant', 'region:us', 'art', 'anime', 'not-for-all-audiences']","
	
		
		E621 2024 SDXL VAE latents in 1k tar
	


Dedicated dataset to align both NebulaeWis/e621-2024-webp-4Mpixel and deepghs/e621_newest-webp-4Mpixel. ""4MP-Focus"" for average raw image resolution. 
Latents are ARB with maximum size of 1024x1024 as the recommended setting in kohyas. Major reason is to make sure I can finetune with RTX 3090. VRAM usage will raise drastically after 1024.
Generated from prepare_buckets_latents_v2.py, modified from prepare_buckets_latents.py.
Used for… See the full description on the dataset page: https://huggingface.co/datasets/6DammK9/e621_2024-latents-sdxl-1ktar.",https://huggingface.co/datasets/6DammK9/e621_2024-latents-sdxl-1ktar,"['en', 'ja']","['image-classification', 'zero-shot-image-classification', 'text-to-image']",['1M<n<10M']
Aihometr/anime-your-name,Aihometr,2025-01-01 18:07:19+00:00,2025-01-01 20:29:41+00:00,13,1,"['task_categories:text-generation', 'task_categories:question-answering', 'language:tr', 'language:ja', 'license:openrail', 'size_categories:1K<n<10K', 'format:parquet', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us', 'text', 'moive', 'anime', 'japanese', 'Alpaca', 'alpaca']","This dataset was created using AI Gemini 2.0 Flash Experimental from the original subtitle format. There may be errors in Turkish and Japanese. Please use this for chatbot training, not for translation AI.
",https://huggingface.co/datasets/Aihometr/anime-your-name,"['tr', 'ja']","['text-generation', 'question-answering']",['1K<n<10K']
Moleys/Filtered-Japanese-English-Parallel-Corpus,Moleys,2025-01-02 13:50:11+00:00,2025-03-03 08:56:51+00:00,39,2,"['task_categories:translation', 'language:ja', 'language:en', 'size_categories:10M<n<100M', 'format:text', 'modality:text', 'library:datasets', 'library:mlcroissant', 'region:us']","def prompt(japanese, english):
    system_prompt = cleandoc(""""""<s>[INST]Your role is to evaluate the accuracy of the provided Japanese to English translation.
    - Translations with parts missing should be rejected.
    - Incomplete translations should be rejected.
    - Inaccurate translations should be rejected.
    - Poor grammar should be rejected.
    - Any kind of mistake should be rejected.
    - Bad spelling should be rejected.
    - Low quality english should be rejected.
    - Low… See the full description on the dataset page: https://huggingface.co/datasets/Moleys/Filtered-Japanese-English-Parallel-Corpus.",https://huggingface.co/datasets/Moleys/Filtered-Japanese-English-Parallel-Corpus,"['ja', 'en']",['translation'],['10M<n<100M']
letxbe/BoundingDocs,letxbe,2025-01-03 09:04:39+00:00,2025-06-20 09:39:40+00:00,296,17,"['task_categories:question-answering', 'task_categories:visual-question-answering', 'language:en', 'language:it', 'language:es', 'language:fr', 'language:de', 'language:pt', 'language:ja', 'language:zh', 'license:cc-by-4.0', 'size_categories:10K<n<100K', 'format:parquet', 'modality:image', 'modality:text', 'library:datasets', 'library:dask', 'library:mlcroissant', 'library:polars', 'arxiv:2501.03403', 'region:us']","

BoundingDocs

🔍 The largest spatially-annotated dataset for Document Question Answering






	
		
	
	
		Dataset Description
	

BoundingDocs is a unified dataset for Document Question Answering (QA) that includes spatial annotations. It consolidates multiple public datasets from Document AI and Visually Rich Document Understanding (VRDU) domains. The dataset reformulates Information Extraction (IE) tasks into QA tasks, making it a valuable resource for training and evaluating Large Language… See the full description on the dataset page: https://huggingface.co/datasets/letxbe/BoundingDocs.",https://huggingface.co/datasets/letxbe/BoundingDocs,"['en', 'it', 'es', 'fr', 'de', 'pt', 'ja', 'zh']","['question-answering', 'visual-question-answering']",['10K<n<100K']
Inoichan/NuminaMath-CoT-JA-100K,Inoichan,2025-01-05 05:30:50+00:00,2025-01-05 17:22:46+00:00,13,1,"['task_categories:text-generation', 'language:en', 'language:ja', 'license:gemma', 'size_categories:100K<n<1M', 'format:parquet', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us', 'math']","
	
		
		Dataset Card for NuminaMath CoT (Japanese 100k Subset)
	



	
		
		Dataset Summary
	

This dataset is a Japanese-translated subset of the NuminaMath CoT dataset, containing the first 100k samples from the original dataset. The translation was performed using the language model google/gemma-2-27b-it. The original NuminaMath CoT dataset contains approximately 860k math problems, each provided with a Chain of Thought (CoT) solution. This Japanese subset retains both the problem and the… See the full description on the dataset page: https://huggingface.co/datasets/Inoichan/NuminaMath-CoT-JA-100K.",https://huggingface.co/datasets/Inoichan/NuminaMath-CoT-JA-100K,"['en', 'ja']",['text-generation'],['100K<n<1M']
Inoichan/NuminaMath-Enhanced-CoT-JA-50K,Inoichan,2025-01-05 15:26:36+00:00,2025-01-13 14:53:42+00:00,15,1,"['task_categories:text-generation', 'language:en', 'language:ja', 'license:gemma', 'size_categories:10K<n<100K', 'format:parquet', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us', 'math']","
	
		
		NuminaMath Enhanced CoT Dataset (Japanese 50k Subset)
	

This repository provides a reasoning-enhanced Japanese math dataset derived from the NuminaMath CoT dataset. The goal is to reinforce the reasoning process in Japanese by prompting a large language model to repeatedly reconsider its steps before arriving at a final answer. This new dataset is not meant to replace the original NuminaMath CoT dataset, but rather to serve as a complementary resource that focuses on multistep… See the full description on the dataset page: https://huggingface.co/datasets/Inoichan/NuminaMath-Enhanced-CoT-JA-50K.",https://huggingface.co/datasets/Inoichan/NuminaMath-Enhanced-CoT-JA-50K,"['en', 'ja']",['text-generation'],['10K<n<100K']
OzoneAsai/GloSocTes1Audio,OzoneAsai,2025-01-08 05:17:07+00:00,2025-01-08 12:56:42+00:00,8,0,"['task_categories:text-to-speech', 'task_categories:audio-to-audio', 'language:ja', 'region:us']",,https://huggingface.co/datasets/OzoneAsai/GloSocTes1Audio,['ja'],"['text-to-speech', 'audio-to-audio']",[]
supercatdoing/booru_artists_merged,supercatdoing,2025-01-09 06:43:44+00:00,2025-01-09 07:18:25+00:00,16,0,"['language:en', 'language:ja', 'license:cc0-1.0', 'size_categories:100K<n<1M', 'format:parquet', 'modality:tabular', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us', 'art']","
	
		
		booru_artists_merged
	


	
		
		About
	

This data set is a parquet file containing artist lists extracted from danbooru (2024/12/1x version)  
Excluding those with a post_count of 0  
Please use this as a reference when processing data locally, such as creating CSV files.Example of processing to create CSV and translation for tag completion of A1111
This file was created based on the danbooru API.  

	
		
	
	
		Field Name Description
	

The field names are as you see, but some… See the full description on the dataset page: https://huggingface.co/datasets/supercatdoing/booru_artists_merged.",https://huggingface.co/datasets/supercatdoing/booru_artists_merged,"['en', 'ja']",[],['100K<n<1M']
Inoichan/OpenO1-SFT-JA,Inoichan,2025-01-09 16:34:15+00:00,2025-01-09 16:53:56+00:00,16,3,"['task_categories:text-generation', 'language:en', 'language:zh', 'language:ja', 'license:gemma', 'size_categories:10K<n<100K', 'format:parquet', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","
	
		
		Dataset Card for OpenO1-SFT (Japanese Translation)
	



	
		
		Dataset Summary
	

This dataset is a Japanese-translated version of the OpenO1-SFT dataset, containing Chain of Thought (CoT) reasoning examples designed for fine-tuning language models. The translation was performed using the language model google/gemma-2-27b-it. The original OpenO1-SFT dataset contains 77,685 samples with detailed reasoning processes.
Key details:

Source data: Chain of Thought reasoning examples from the… See the full description on the dataset page: https://huggingface.co/datasets/Inoichan/OpenO1-SFT-JA.",https://huggingface.co/datasets/Inoichan/OpenO1-SFT-JA,"['en', 'zh', 'ja']",['text-generation'],['10K<n<100K']
Sakalti/Saka-Alpaca-v1,Sakalti,2025-01-10 00:03:30+00:00,2025-02-02 05:25:24+00:00,91,0,"['task_categories:text-generation', 'language:sv', 'language:no', 'language:fi', 'language:de', 'language:fr', 'language:it', 'language:es', 'language:en', 'language:ru', 'language:uk', 'language:tr', 'language:fa', 'language:kk', 'language:zh', 'language:ja', 'language:ar', 'language:ta', 'language:hi', 'language:bn', 'language:ml', 'language:sa', 'language:id', 'language:vi', 'license:apache-2.0', 'size_categories:n<1K', 'format:csv', 'modality:text', 'library:datasets', 'library:dask', 'library:mlcroissant', 'library:polars', 'region:us']","https://chatgpt.com
",https://huggingface.co/datasets/Sakalti/Saka-Alpaca-v1,"['sv', 'no', 'fi', 'de', 'fr', 'it', 'es', 'en', 'ru', 'uk', 'tr', 'fa', 'kk', 'zh', 'ja', 'ar', 'ta', 'hi', 'bn', 'ml', 'sa', 'id', 'vi']",['text-generation'],['n<1K']
agentlans/Aratako-Japanese-Roleplay,agentlans,2025-01-10 15:34:48+00:00,2025-01-10 15:44:55+00:00,12,0,"['task_categories:text-generation', 'task_categories:text2text-generation', 'language:ja', 'size_categories:10K<n<100K', 'format:json', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us', 'not-for-all-audiences', 'roleplay']","A collection of many Japanese roleplaying datasets reformatted the same way.
Each row contains a conversation as well as the source dataset, its dataset config, and split.
Example:
{
  ""conversations"": [
    {
      ""from"": ""system"",
      ""value"": ""次に示す世界観やキャラクター設定を参照し、それを元にロールプレイのような対話をしてください。...""
    },
    {
      ""from"": ""human"",
      ""value"": ""勇人「や、やめてください...魔族の女王...」（顔を赤らめながら、必死に目をそらす）""
    },
    {
      ""from"": ""gpt"",
      ""value"": ""リリス「ふふ、そんなに抵抗しても無駄よ。あなたの体は正直ね」...""
    },
  ...… See the full description on the dataset page: https://huggingface.co/datasets/agentlans/Aratako-Japanese-Roleplay.",https://huggingface.co/datasets/agentlans/Aratako-Japanese-Roleplay,['ja'],"['text-generation', 'text2text-generation']",['10K<n<100K']
Inoichan/KUM-Bench,Inoichan,2025-01-13 07:18:11+00:00,2025-01-13 14:40:24+00:00,16,1,"['task_categories:text-generation', 'language:ja', 'license:other', 'size_categories:n<1K', 'format:parquet', 'modality:tabular', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us', 'math']","
	
		
		KUM-Bench: A Benchmark for Advanced Japanese Reasoning Capabilities
	



KUM-Bench (Kyoto University Math Entrance Exam Benchmark) is designed to evaluate advanced Japanese reasoning capabilities by leveraging mathematics entrance exam questions from Kyoto University—one of the most prestigious universities in Japan. These problems require a high level of problem-solving skills and serve as an excellent resource for testing Large Language Models (LLMs) in Japanese reasoning tasks.… See the full description on the dataset page: https://huggingface.co/datasets/Inoichan/KUM-Bench.",https://huggingface.co/datasets/Inoichan/KUM-Bench,['ja'],['text-generation'],['n<1K']
Miwa-Keita/zenz-v2.5-dataset,Miwa-Keita,2025-01-13 09:57:07+00:00,2025-01-17 06:45:33+00:00,66,11,"['language:ja', 'size_categories:100M<n<1B', 'format:json', 'modality:text', 'library:datasets', 'library:dask', 'library:mlcroissant', 'region:us', 'ime', 'japanese input', 'kana-kanji conversion']","
	
		
		zenz-v2.5-dataset
	

zenz-v2.5-datasetはかな漢字変換タスクに特化した条件付き言語モデル「zenz-v2.5」シリーズの学習を目的として構築したデータセットです。
約190Mペアの「左文脈-入力-変換結果」を含み、かな漢字変換モデルの学習において十分な性能を実現できる規模になっています。
本データセットで学習したzenz-v2.5は公開しています。

zenz-v2.5-medium: 310Mの大規模モデル
zenz-v2.5-small: 91Mの中規模モデル
zenz-v2.5-xsmall: 26Mの小規模モデル

また、かな漢字変換の評価ベンチマークとしてAJIMEE-Bench（味見ベンチ）も公開しています。

	
		
	
	
		形式
	

本データセットはJSONL形式になっており、以下の3つのデータを含みます。

""input"": str, 入力のカタカナ文字列（記号、数字、空白などが含まれることがあります）
""output"": str, 出力の漢字交じり文
""left_context"":… See the full description on the dataset page: https://huggingface.co/datasets/Miwa-Keita/zenz-v2.5-dataset.",https://huggingface.co/datasets/Miwa-Keita/zenz-v2.5-dataset,['ja'],[],['100M<n<1B']
pokutuna/tasks-ime-and-kakko-jp,pokutuna,2025-01-13 14:34:01+00:00,2025-01-13 14:40:46+00:00,8,0,"['task_categories:fill-mask', 'language:ja', 'license:mit', 'size_categories:n<1K', 'format:parquet', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","
	
		
		ime-and-kakko
	

elyza/ELYZA-tasks-100 中の

IME のように変換候補を提示するタスク
カッコの対応関係を整えるタスク

のバリエーションを手で作成したもの
東京大学松尾・岩澤研究室（松尾研）大規模言語モデル Deep Learning 応用講座 2024 で開催されたコンペティションにおいて、 @pokutuna が作成したモデルの苦手問題を克服するために作成しました。
",https://huggingface.co/datasets/pokutuna/tasks-ime-and-kakko-jp,['ja'],['fill-mask'],['n<1K']
nlp-waseda/e_gov_chunked,nlp-waseda,2025-01-14 03:07:50+00:00,2025-01-14 05:27:34+00:00,23,0,"['language:ja', 'license:cc-by-4.0', 'size_categories:100K<n<1M', 'format:parquet', 'modality:text', 'library:datasets', 'library:dask', 'library:mlcroissant', 'library:polars', 'region:us', 'legal']","
	
		
		Abstract
	

This is the Japapnese law dataset obtained from e-Gov (Date of download: Oct. 20th, 2024)
Each piece of text data is chunked into fewer than 4,096 tokens.
Not chunked version is available HERE

	
		
		Data Format
	

Each data is consist of 2 fields, ""text"" and ""metadata"".

""text"" fields contains the legal texts, which are expected to be mainly used.
""metadata"" fields contains additional information including 10 subfields below:
""Era"": The Japanese Era when the law is… See the full description on the dataset page: https://huggingface.co/datasets/nlp-waseda/e_gov_chunked.",https://huggingface.co/datasets/nlp-waseda/e_gov_chunked,['ja'],[],['100K<n<1M']
nlp-waseda/e_gov,nlp-waseda,2025-01-14 03:51:08+00:00,2025-01-14 05:26:21+00:00,19,0,"['language:ja', 'license:cc-by-4.0', 'size_categories:10K<n<100K', 'format:parquet', 'modality:text', 'library:datasets', 'library:dask', 'library:mlcroissant', 'library:polars', 'region:us', 'legal']","
	
		
		Abstract
	

This is the Japapnese law dataset obtained from e-Gov (Date of download: Oct. 20th, 2024)

	
		
		Data Format
	

Each data is consist of 2 fields, ""text"" and ""metadata"".

""text"" fields contains the legal texts, which are expected to be mainly used.
""metadata"" fields contains additional information including 9 subfields below:
""Era"": The Japanese Era when the law is promulgated such as ""Showa"".
""Lang"": The language the text is written in. All of them are Japanese.
""LawType"":… See the full description on the dataset page: https://huggingface.co/datasets/nlp-waseda/e_gov.",https://huggingface.co/datasets/nlp-waseda/e_gov,['ja'],[],['10K<n<100K']
davanstrien/fineweb-c-jpn-preview,davanstrien,2025-01-14 13:25:23+00:00,2025-01-14 13:51:00+00:00,8,0,"['language:ja', 'size_categories:n<1K', 'format:parquet', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']",,https://huggingface.co/datasets/davanstrien/fineweb-c-jpn-preview,['ja'],[],['n<1K']
nu-dialogue/multi-relational-multi-party-chat-corpus,nu-dialogue,2025-01-15 05:42:29+00:00,2025-08-20 05:37:42+00:00,12,1,"['task_categories:text-generation', 'task_categories:text-classification', 'task_ids:dialogue-modeling', 'task_ids:dialogue-generation', 'language_creators:crowdsourced', 'multilinguality:monolingual', 'source_datasets:original', 'language:ja', 'license:cc-by-sa-4.0', 'size_categories:n<1K', 'region:us', 'nlp', 'japanese', 'dialogue', 'dialogue-corpus', 'dialogue-system']",Multi-Relational Multi-Party Chat Corpus (MRMP): Japanese text-based chats comprising first-time-meeting dialogues and family-included dialogues,https://huggingface.co/datasets/nu-dialogue/multi-relational-multi-party-chat-corpus,['ja'],"['text-generation', 'text-classification']",['n<1K']
DancingPrismPJ/Wikipedia-Horse-Dataset,DancingPrismPJ,2025-01-16 04:41:42+00:00,2025-01-20 03:25:50+00:00,8,0,"['task_categories:token-classification', 'language:ja', 'license:cc-by-sa-3.0', 'size_categories:n<1K', 'region:us']","#Dataset Card for DancingPrismPJ/wikipedia-horse-dataset
Wikipediaの「Category:日本調教の競走馬」内の記事に固有表現ラベルを付与したデータセットです。 固有表現ラベルは書籍「大規模言語モデル入門」でも使用される、ストックマーク株式会社作成の『Wikipediaを用いた日本語の固有表現抽出データセット』のラベリングに対応しており、独自に競走馬名を追加して全部で9種類のラベル(人名、法人名、地名、製品名、政治的組織名、施設名、その他の組織名、イベント名、競走馬名)としています。全データ数は600ですが、同一記事から最大3つまで文を束ねています。なお、このデータに負例はありません。 なお、Wikipedia記事収集に使用したDBpediaの仕様として、リンク切れ記事の部分の文字が消失するという事象があるため、一部の文章に変な部分があります。
##ikipediaデータセット内の競走馬の固有表現について
""curid"": ""3003495"",
        ""text"":… See the full description on the dataset page: https://huggingface.co/datasets/DancingPrismPJ/Wikipedia-Horse-Dataset.",https://huggingface.co/datasets/DancingPrismPJ/Wikipedia-Horse-Dataset,['ja'],['token-classification'],['n<1K']
6DammK9/danbooru2024-latents-sdxl-1ktar,6DammK9,2025-01-18 03:50:54+00:00,2025-02-27 15:38:12+00:00,7,7,"['task_categories:image-classification', 'task_categories:zero-shot-image-classification', 'task_categories:text-to-image', 'annotations_creators:no-annotation', 'source_datasets:danbooru', 'language:en', 'language:ja', 'license:mit', 'size_categories:1M<n<10M', 'format:webdataset', 'modality:text', 'library:datasets', 'library:webdataset', 'library:mlcroissant', 'region:us', 'art', 'anime', 'not-for-all-audiences']","
	
		
		Danbooru 2024 SDXL VAE latents in 1k tar
	


Dedicated dataset to align deepghs/danbooru2024-webp-4Mpixel. ""4MP-Focus"" for average raw image resolution. 
Latents are ARB with maximum size of 1024x1024 as the recommended setting in kohyas. Major reason is to make sure I can finetune with RTX 3090. VRAM usage will raise drastically after 1024.
Generated from prepare_buckets_latents_v2.py, modified from prepare_buckets_latents.py.
Used for kohya-ss/sd-scripts. In theory it may replace… See the full description on the dataset page: https://huggingface.co/datasets/6DammK9/danbooru2024-latents-sdxl-1ktar.",https://huggingface.co/datasets/6DammK9/danbooru2024-latents-sdxl-1ktar,"['en', 'ja']","['image-classification', 'zero-shot-image-classification', 'text-to-image']",['1M<n<10M']
Nightmare-hades/salt-alpaca-jp,Nightmare-hades,2025-01-18 04:45:26+00:00,2025-01-18 04:47:39+00:00,6,0,"['task_categories:question-answering', 'language:ja', 'size_categories:1K<n<10K', 'format:json', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']",,https://huggingface.co/datasets/Nightmare-hades/salt-alpaca-jp,['ja'],['question-answering'],['1K<n<10K']
baxin/nick_name_from_hiroiki-ariyoshi,baxin,2025-01-18 05:27:23+00:00,2025-01-18 05:30:53+00:00,14,0,"['task_categories:text-generation', 'language:ja', 'license:mit', 'size_categories:n<1K', 'format:json', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us', 'art']","
	
		
		data format
	

{
  ""name"": ""person_name"",
  ""nickname"": ""person_nickname""
}

",https://huggingface.co/datasets/baxin/nick_name_from_hiroiki-ariyoshi,['ja'],['text-generation'],['n<1K']
hotchpotch/sentence_transformer_japanese,hotchpotch,2025-01-19 08:23:23+00:00,2025-01-20 10:19:14+00:00,91,5,"['language:ja', 'license:unknown', 'size_categories:10M<n<100M', 'format:parquet', 'modality:text', 'library:datasets', 'library:dask', 'library:mlcroissant', 'library:polars', 'region:us']","
日本語のデータセットを SentenceTransformes で学習しやすいカラム名と構造に変換したもの。
主に (anchor, positive), (anchor, positive, negative), (anchor, positive, negative_1, ..., negative_n) といった構造になっているため、とりわけ対照学習で使いやすくなっています。


以下のデータセットから作成
https://huggingface.co/datasets/hpprc/emb
https://huggingface.co/datasets/hotchpotch/hpprc_emb-scores のリランカースコアを用いて、positive(>=0.7) / negative(<=0.3) のフィルタリングを行った


https://huggingface.co/datasets/hpprc/llmjp-kaken
https://huggingface.co/datasets/hpprc/msmarco-ja… See the full description on the dataset page: https://huggingface.co/datasets/hotchpotch/sentence_transformer_japanese.",https://huggingface.co/datasets/hotchpotch/sentence_transformer_japanese,['ja'],[],['10M<n<100M']
bzantium/MMMLU,bzantium,2025-01-19 12:21:50+00:00,2025-01-19 12:28:11+00:00,25,0,"['task_categories:question-answering', 'language:ar', 'language:bn', 'language:de', 'language:es', 'language:fr', 'language:hi', 'language:id', 'language:it', 'language:ja', 'language:ko', 'language:pt', 'language:sw', 'language:yo', 'language:zh', 'license:mit', 'size_categories:100K<n<1M', 'format:csv', 'modality:text', 'library:datasets', 'library:dask', 'library:mlcroissant', 'library:polars', 'arxiv:2009.03300', 'region:us']","
	
		
		Multilingual Massive Multitask Language Understanding (MMMLU)
	

The MMLU is a widely recognized benchmark of general knowledge attained by AI models. It covers a broad range of topics from 57 different categories, covering elementary-level knowledge up to advanced professional subjects like law, physics, history, and computer science.
We translated the MMLU’s test set into 14 languages using professional human translators. Relying on human translators for this evaluation increases… See the full description on the dataset page: https://huggingface.co/datasets/bzantium/MMMLU.",https://huggingface.co/datasets/bzantium/MMMLU,"['ar', 'bn', 'de', 'es', 'fr', 'hi', 'id', 'it', 'ja', 'ko', 'pt', 'sw', 'yo', 'zh']",['question-answering'],['100K<n<1M']
ouktlab/Hazumi-AffNeg-Data,ouktlab,2025-01-20 05:23:08+00:00,2025-01-20 05:39:44+00:00,8,0,"['language:ja', 'license:cc-by-sa-4.0', 'size_categories:1K<n<10K', 'format:json', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","
	
		
		Abstract
	

This dataset comprises exchanges of Yes/No questions from the 
system and corresponding user responses, extracted from the multimodal 
dialogue corpus Hazumi.
It was used to fine-tune our released model.
",https://huggingface.co/datasets/ouktlab/Hazumi-AffNeg-Data,['ja'],[],['1K<n<10K']
AI-Culture-Commons/ai-culture-multilingual-json-dolma,AI-Culture-Commons,2025-01-20 12:17:58+00:00,2025-08-10 22:28:31+00:00,60,2,"['task_categories:translation', 'task_categories:text-generation', 'task_categories:text-classification', 'task_categories:sentence-similarity', 'task_categories:summarization', 'task_categories:fill-mask', 'task_categories:feature-extraction', 'language:en', 'language:fr', 'language:de', 'language:es', 'language:pt', 'language:it', 'language:ja', 'language:ru', 'language:ko', 'language:zh', 'language:hi', 'language:he', 'license:cc-by-4.0', 'size_categories:1K<n<10K', 'format:json', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us', 'multilingual', 'language-modeling', 'text-generation', 'translation', 'machine-translation', 'cross-lingual', 'llm-training', 'transformer-training-data', 'parallel-corpora', 'reasoning-dataset', 'knowledge-base', 'json', 'dolma', 'philosophy', 'culture', 'long-form-content', 'structured-text', 'semantic-similarity', 'educational-material', 'natural-language-understanding', 'jsonl']","
	
		
		AI-Culture Multilingual JSON + DOLMA Corpus
	


16M words · 12 languages · CC-BY-4.0

The AI-Culture corpus contains 5K articles providing comprehensive philosophical and cultural content, exploring the intersection of technology, artificial intelligence, and human culture, perfectly aligned across 12 languages. All content maintains identical parallel structure across translations with zero duplication and editor-curated quality.
This project is maintained by a non-profit digital… See the full description on the dataset page: https://huggingface.co/datasets/AI-Culture-Commons/ai-culture-multilingual-json-dolma.",https://huggingface.co/datasets/AI-Culture-Commons/ai-culture-multilingual-json-dolma,"['en', 'fr', 'de', 'es', 'pt', 'it', 'ja', 'ru', 'ko', 'zh', 'hi', 'he']","['translation', 'text-generation', 'text-classification', 'sentence-similarity', 'summarization', 'fill-mask', 'feature-extraction']",['1K<n<10K']
jaeyong2/LAION-art-EN-improved-captions-translate,jaeyong2,2025-01-21 01:22:17+00:00,2025-01-22 06:58:09+00:00,7,0,"['language:ko', 'language:ja', 'language:th', 'language:vi', 'language:hi', 'language:id', 'license:cc-by-4.0', 'size_categories:100K<n<1M', 'format:parquet', 'modality:image', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","
	
		
		Development Process
	


source dataset from recastai/LAION-art-EN-improved-captions
We used Qwen/Qwen2-72B-Instruct model to translate.


	
		
		License
	


Qwen/Qwen2.5-72B-Instruct : https://huggingface.co/Qwen/Qwen2-72B-Instruct/blob/main/LICENSE
recastai/LAION-art-EN-improved-captions : https://huggingface.co/datasets/choosealicense/licenses/blob/main/markdown/cc-by-4.0.md


	
		
	
	
		Acknowledgement
	

This research is supported by TPU Research Cloud program.
",https://huggingface.co/datasets/jaeyong2/LAION-art-EN-improved-captions-translate,"['ko', 'ja', 'th', 'vi', 'hi', 'id']",[],['100K<n<1M']
davidstap/kanji_definitions,davidstap,2025-01-21 10:51:12+00:00,2025-01-21 11:16:25+00:00,10,1,"['task_categories:text-to-image', 'language:en', 'language:ja', 'license:cc-by-sa-3.0', 'size_categories:1K<n<10K', 'format:parquet', 'modality:image', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us', 'kanji']","
	
		
		KanjiVG PNG images with textual descriptions
	

This dataset is an adaptation of KanjiVG by Ulrich Apel. The original SVG files have been converted to 1024x1024 PNG images and enriched with Kanji descriptions of their meaning.

	
		
		Usage
	

>>> import datasets
>>> data = datasets.load_dataset(""davidstap/kanji_definitions"")
>>> data
DatasetDict({
    train: Dataset({
        features: ['image', 'text'],
        num_rows: 6315
    })
})
>>> data['train']
Dataset({
    features:… See the full description on the dataset page: https://huggingface.co/datasets/davidstap/kanji_definitions.",https://huggingface.co/datasets/davidstap/kanji_definitions,"['en', 'ja']",['text-to-image'],['1K<n<10K']
JunSotohigashi/JapaneseWikipediaTypoDataset,JunSotohigashi,2025-01-22 03:40:18+00:00,2025-01-22 08:18:40+00:00,33,0,"['language:ja', 'license:cc-by-sa-3.0', 'size_categories:100K<n<1M', 'format:parquet', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","
	
		
		日本語Wikipedia入力誤りデータセット
	


	
		
		概要
	

これは京都大学 言語メディア研究室によって公開されているデータセットをHuggingFaceで使用できるよう変換したものです．日本語Wikipedia入力誤りデータセット (v2) - 京都大学 言語メディア研究室  
生成に使用したソースコードはここから参照できます．

	
		
		ライセンス
	

配布元に従い，CC-BY-SA 3.0とします．
",https://huggingface.co/datasets/JunSotohigashi/JapaneseWikipediaTypoDataset,['ja'],[],['100K<n<1M']
JunSotohigashi/JapaneseWikipediaTypoDataset_kanji,JunSotohigashi,2025-01-22 07:54:19+00:00,2025-07-16 04:56:14+00:00,113,0,"['language:ja', 'license:cc-by-sa-3.0', 'size_categories:100K<n<1M', 'format:parquet', 'modality:tabular', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","
	
		
		日本語ウィキペディア入力誤りデータセット (漢字誤変換抽出版)
	


	
		
		概要
	

このデータセットは，京都大学 言語メディア研究室によって公開されているデータセットをHuggingFaceで使用できるよう変換したものです．日本語Wikipedia入力誤りデータセット (v2) - 京都大学 言語メディア研究室  
このデータセットでは，JunSotohigashi/JapaneseWikipediaTypoDatasetから，漢字誤変換のみを抽出しています．誤りの種類がkanji-conversion_aとkanji-conversion_bの事例のみをフィルタリングし，誤り部分の前と後ろに文を分割しました．これにより，pre_textはtext_head + pre_str + text_tailと等価になります．post_textについては，diffsに複数のデータが存在する場合にはそれをすべて適用したあとの文字列であるため，post_textとtext_head + post_str + text_tailが同じになるとは限りません．… See the full description on the dataset page: https://huggingface.co/datasets/JunSotohigashi/JapaneseWikipediaTypoDataset_kanji.",https://huggingface.co/datasets/JunSotohigashi/JapaneseWikipediaTypoDataset_kanji,['ja'],[],['100K<n<1M']
kurogane/DSR1D-Llama-8B-aya-ja-1k-generated,kurogane,2025-01-22 13:41:17+00:00,2025-01-22 13:53:22+00:00,13,0,"['task_categories:text-generation', 'language:ja', 'license:llama3.1', 'size_categories:1K<n<10K', 'format:json', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","
	
		
		DSR1D-Llama-8B-aya-ja-1k-generated
	

これはdeepseek-ai/DeepSeek-R1-Distill-Llama-8Bを用いて、weblab-GENIAC/aya-ja-evol-instruct-calm3-dpo-maskedの最初の1000件の応答をmax_new_tokens=3060で生成させました。
transformers内のbnbの8bitで生成したため、元モデルと比べて若干精度が落ちていると思います。
一部、<think>, </think>, <｜end▁of▁sentence｜>が正常に生成されていないものがあります。
実用性は皆無です。参考程度や前処理の準備用に使ってください。
",https://huggingface.co/datasets/kurogane/DSR1D-Llama-8B-aya-ja-1k-generated,['ja'],['text-generation'],['1K<n<10K']
Sunbread/SyosetuNames-3.5M,Sunbread,2025-01-22 14:17:48+00:00,2025-02-13 18:17:40+00:00,17,1,"['task_categories:text-generation', 'language:ja', 'license:odc-by', 'size_categories:10M<n<100M', 'format:parquet', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us', 'art', 'novel', 'light-novel', 'fiction', 'literature']","
	
		
		SyosetuNames-3.5M: Japanese Light Novel Character Names Corpus
	


	
		
		Overview
	

This dataset extracts fictional character names from the publicly available text of novels on the Japanese light novel platform ""Shōsetsuka ni Narō"" (syosetu.com), containing approximately 3.5 million unique original and cleaned names. This dataset aims to provide resources for culturally sensitive Natural Language Processing (NLP) tasks, such as name generation, Named Entity Recognition (NER) model… See the full description on the dataset page: https://huggingface.co/datasets/Sunbread/SyosetuNames-3.5M.",https://huggingface.co/datasets/Sunbread/SyosetuNames-3.5M,['ja'],['text-generation'],['10M<n<100M']
WueNLP/mHallucination_Detection,WueNLP,2025-01-23 13:07:04+00:00,2025-02-20 11:30:14+00:00,51,0,"['task_categories:token-classification', 'language:ar', 'language:de', 'language:zh', 'language:tr', 'language:ru', 'language:eu', 'language:fr', 'language:ca', 'language:fi', 'language:it', 'language:ms', 'language:ro', 'language:pt', 'language:ur', 'language:hi', 'language:he', 'language:pl', 'language:sd', 'language:sr', 'language:la', 'language:es', 'language:vi', 'language:eo', 'language:cs', 'language:ko', 'language:ja', 'license:cc', 'size_categories:1K<n<10K', 'format:json', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'arxiv:2502.12769', 'region:us']","
	
		
		Multilingual Hallucination Detection Dataset (mFAVA)
	

The dataset was created as part of the paper: How Much Do LLMs Hallucinate across Languages? On Multilingual Estimation of LLM Hallucination in the Wild
Below is the figure summarizing the multilingual hallucination detection dataset creation (and  multilingual hallucination evaluation dataset):


	
	
	
		Dataset Details
	

The dataset is a multilingual extension of FAVA. The dataset is created by sourcing 150 prompts from 
FAVA… See the full description on the dataset page: https://huggingface.co/datasets/WueNLP/mHallucination_Detection.",https://huggingface.co/datasets/WueNLP/mHallucination_Detection,"['ar', 'de', 'zh', 'tr', 'ru', 'eu', 'fr', 'ca', 'fi', 'it', 'ms', 'ro', 'pt', 'ur', 'hi', 'he', 'pl', 'sd', 'sr', 'la', 'es', 'vi', 'eo', 'cs', 'ko', 'ja']",['token-classification'],['1K<n<10K']
WueNLP/mHallucination_Evaluation,WueNLP,2025-01-23 13:07:42+00:00,2025-02-19 10:03:59+00:00,33,0,"['task_categories:text-generation', 'language:ar', 'language:de', 'language:zh', 'language:tr', 'language:ru', 'language:eu', 'language:fr', 'language:ca', 'language:fi', 'language:it', 'language:ms', 'language:ro', 'language:pt', 'language:ur', 'language:hi', 'language:he', 'language:pl', 'language:sd', 'language:sr', 'language:la', 'language:es', 'language:vi', 'language:eo', 'language:cs', 'language:ko', 'language:ja', 'license:cc', 'size_categories:10K<n<100K', 'format:csv', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'arxiv:2502.12769', 'region:us']","
	
		
		Multilingual Hallucination Evaluation in the wild
	

The dataset was as part of the paper: How Much Do LLMs Hallucinate across Languages? On Multilingual Estimation of LLM Hallucination in the Wild
Below is the figure summarizing the multilingual hallucination evaluation dataset creation (and multilingual hallucination detection dataset):


	
	
	
		Dataset Details
	

The dataset is a high quality synthetic query/prompt and wikipedia reference pair for estimating hallucinations in the… See the full description on the dataset page: https://huggingface.co/datasets/WueNLP/mHallucination_Evaluation.",https://huggingface.co/datasets/WueNLP/mHallucination_Evaluation,"['ar', 'de', 'zh', 'tr', 'ru', 'eu', 'fr', 'ca', 'fi', 'it', 'ms', 'ro', 'pt', 'ur', 'hi', 'he', 'pl', 'sd', 'sr', 'la', 'es', 'vi', 'eo', 'cs', 'ko', 'ja']",['text-generation'],['10K<n<100K']
lightblue/distilabel-reasoning-R1-Llama-70B,lightblue,2025-01-23 15:08:17+00:00,2025-01-28 05:45:04+00:00,29,9,"['language:ja', 'language:en', 'license:apache-2.0', 'size_categories:1K<n<10K', 'format:parquet', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us', 'reasoning']","
	
		
		How this Data was made
	

We made this data through the following steps:

Sample English reasoning-style prompts from argilla/distilabel-reasoning-prompts.
Remove similar prompts using text similarity based on BAAI/bge-m3 embeddings.
Translate English prompts to Japanese using gpt-4o-mini-2024-07-18.
Generate answers to prompts using deepseek-ai/DeepSeek-R1-Distill-Llama-70B.
Filter responses (to ja_valid) which did not:
Finish within 2048 tokens
Contain a valid <think> section
Have… See the full description on the dataset page: https://huggingface.co/datasets/lightblue/distilabel-reasoning-R1-Llama-70B.",https://huggingface.co/datasets/lightblue/distilabel-reasoning-R1-Llama-70B,"['ja', 'en']",[],['1K<n<10K']
kurogane/DSR1D-qwen-2.5-32B-aya-ja-1k-generated,kurogane,2025-01-24 12:46:01+00:00,2025-01-24 12:49:50+00:00,12,0,"['task_categories:text-generation', 'language:ja', 'license:mit', 'size_categories:1K<n<10K', 'format:json', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","
	
		
		DSR1D-qwen-2.5-32B-aya-ja-1k-generated
	

これはdeepseek-ai/DeepSeek-R1-Distill-Qwen-32Bを用いて、weblab-GENIAC/aya-ja-evol-instruct-calm3-dpo-maskedの最初の1000件の応答をmax_new_tokens=3060で生成させました。
transformers内のbnbの8bitで生成したため、元モデルと比べて若干精度が落ちていると思います。
kurogane/DSR1D-Llama-8B-aya-ja-1k-generatedと同じコードで生成したのに、<think>が正常に生成されていないものがほとんどとなってしまいました。
もしかしなくても<think>から始めたほうがいいかもしれません。
実用性は皆無です。参考程度や前処理の準備用に使ってください。
",https://huggingface.co/datasets/kurogane/DSR1D-qwen-2.5-32B-aya-ja-1k-generated,['ja'],['text-generation'],['1K<n<10K']
ymoslem/wmt-da-human-evaluation-long-context,ymoslem,2025-01-24 15:31:43+00:00,2025-01-26 09:34:56+00:00,83,7,"['language:bn', 'language:cs', 'language:de', 'language:en', 'language:et', 'language:fi', 'language:fr', 'language:gu', 'language:ha', 'language:hi', 'language:is', 'language:ja', 'language:kk', 'language:km', 'language:lt', 'language:lv', 'language:pl', 'language:ps', 'language:ru', 'language:ta', 'language:tr', 'language:uk', 'language:xh', 'language:zh', 'language:zu', 'license:apache-2.0', 'size_categories:1M<n<10M', 'format:parquet', 'modality:tabular', 'modality:text', 'library:datasets', 'library:dask', 'library:mlcroissant', 'library:polars', 'region:us', 'mt-evaluation', 'WMT', '41-lang-pairs']","
	
		
		Dataset Summary
	

Long-context / document-level dataset for Quality Estimation of Machine Translation.
It is an augmented variant of the sentence-level WMT DA Human Evaluation dataset.
In addition to individual sentences, it contains augmentations of 2, 4, 8, 16, and 32 sentences, among each language pair lp and domain.
The raw column represents a weighted average of scores of augmented sentences using character lengths of src and mt as weights.
The code used to apply the augmentation… See the full description on the dataset page: https://huggingface.co/datasets/ymoslem/wmt-da-human-evaluation-long-context.",https://huggingface.co/datasets/ymoslem/wmt-da-human-evaluation-long-context,"['bn', 'cs', 'de', 'en', 'et', 'fi', 'fr', 'gu', 'ha', 'hi', 'is', 'ja', 'kk', 'km', 'lt', 'lv', 'pl', 'ps', 'ru', 'ta', 'tr', 'uk', 'xh', 'zh', 'zu']",[],['1M<n<10M']
oshizo/japanese-text-image-retrieval-train,oshizo,2025-01-25 15:18:38+00:00,2025-01-26 00:13:12+00:00,126,0,"['language:ja', 'license:cc-by-sa-4.0', 'size_categories:100K<n<1M', 'format:parquet', 'modality:image', 'modality:text', 'library:datasets', 'library:dask', 'library:mlcroissant', 'library:polars', 'region:us']","shunk031/JDocQAのtrain splitに含まれるPDFデータを画像化し、NDLOCRでOCRしたテキストとペアにしたデータセットです。OCRは長い辺を1200pxにリサイズした画像に対して実施しました。OCR結果には、読み取りに失敗した際の文字列「〓」が含まれます。本データセットに含めている画像は、長い辺を896px、700px、588pxのいずれかにリサイズしています。どのサイズとするかは主にページに含まれる文字数で決めました。  
query列は、OCR結果の文字列に対しQwen/Qwen2.5-14B-Instructで生成したものです。3つの質問を生成させ、ランダムに1つを選んだものをデータセットに含めました。質問を生成する際は以下のプロンプトを使用しました。  
あなたは、質問から画像をretrieveするためのモデルをトレーニングするための(質問, 画像)ペアのデータセットを作成するプロジェクトのメンバーである。
プロジェクトは以下のように進める。
step1. ドキュメントPDFを1ページ1枚の画像ファイルに変換する
step2.… See the full description on the dataset page: https://huggingface.co/datasets/oshizo/japanese-text-image-retrieval-train.",https://huggingface.co/datasets/oshizo/japanese-text-image-retrieval-train,['ja'],[],['100K<n<1M']
sophiefy/togawa_sakiko_voice,sophiefy,2025-01-26 06:43:48+00:00,2025-03-13 01:51:31+00:00,10,0,"['task_categories:text-to-speech', 'task_categories:audio-to-audio', 'language:ja', 'size_categories:n<1K', 'format:audiofolder', 'modality:audio', 'library:datasets', 'library:mlcroissant', 'region:us']",,https://huggingface.co/datasets/sophiefy/togawa_sakiko_voice,['ja'],"['text-to-speech', 'audio-to-audio']",['n<1K']
kingkaung/islamqainfo_parallel_corpus,kingkaung,2025-01-27 05:27:52+00:00,2025-01-27 07:00:39+00:00,21,0,"['task_categories:table-question-answering', 'task_categories:text-generation', 'task_categories:translation', 'task_categories:summarization', 'task_categories:text-classification', 'language:en', 'language:ar', 'language:ur', 'language:bn', 'language:fr', 'language:es', 'language:zh', 'language:ru', 'language:de', 'language:tg', 'language:pt', 'language:hi', 'language:ug', 'language:tr', 'language:id', 'language:ja', 'license:cc-by-nc-4.0', 'size_categories:10K<n<100K', 'format:parquet', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us', 'Islam', 'Question&Answer', 'Religion', 'Translation', 'Corpus', 'Parallel', 'ParallelCorpus']","
	
		
		Dataset Card for IslamQA Info Parallel Corpus
	


	
		
		Dataset Description
	

The IslamQA Info Parallel Corpus is a multilingual dataset derived from the IslamQA repository. It contains curated question-and-answer pairs across 17 languages, making it a valuable resource for multilingual and cross-lingual natural language processing (NLP) tasks. The dataset has been created over nearly three decades (since 1997) by Sheikhul Islam Muhammad Saalih al-Munajjid and his team.

	
		
		Key… See the full description on the dataset page: https://huggingface.co/datasets/kingkaung/islamqainfo_parallel_corpus.",https://huggingface.co/datasets/kingkaung/islamqainfo_parallel_corpus,"['en', 'ar', 'ur', 'bn', 'fr', 'es', 'zh', 'ru', 'de', 'tg', 'pt', 'hi', 'ug', 'tr', 'id', 'ja']","['table-question-answering', 'text-generation', 'translation', 'summarization', 'text-classification']",['10K<n<100K']
efwkjn/reazonspeech_metadata,efwkjn,2025-01-27 09:56:18+00:00,2025-03-19 13:46:18+00:00,68,0,"['language:ja', 'size_categories:10M<n<100M', 'format:parquet', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","japanese-asr/whisper_transcriptions.reazon_speech_all without audio
align.tsv with turbo
segment.tsv split ~20 chars segments with timestamps, filtered ir < 0.1 & cer < 0.5
",https://huggingface.co/datasets/efwkjn/reazonspeech_metadata,['ja'],[],['10M<n<100M']
ikedachin/CC-news-2024-October-cleaned-cpt-set-250127,ikedachin,2025-01-27 11:31:53+00:00,2025-01-27 11:38:19+00:00,98,0,"['language:ja', 'license:odc-by', 'size_categories:10K<n<100K', 'format:parquet', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","kajuma/CC-news-2024-July-October-cleanedを元に、9月、10月のニュースのみを抜き出したデータセット。  

テキストの前にニュースの日付を追加  
継続事前学習用
outputトークン数を1024と想定。効率よく学習するために約1000tokensに調整（使用tokenizerはllm-jp/llm-jp-3-13b）

",https://huggingface.co/datasets/ikedachin/CC-news-2024-October-cleaned-cpt-set-250127,['ja'],[],['10K<n<100K']
hpprc/ja-en-r1-distill-qwen,hpprc,2025-01-27 12:19:47+00:00,2025-01-27 12:30:46+00:00,11,0,"['task_categories:translation', 'language:ja', 'language:en', 'license:cc-by-sa-4.0', 'size_categories:1K<n<10K', 'format:parquet', 'modality:tabular', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","cyberagent/DeepSeek-R1-Distill-Qwen-32B-Japaneseを用いて、英語Wikipedia中のテキストを日本語に翻訳したデータセットです。
本データセットの処理には、A6000を4枚使用して、vLLMで約100分程度必要でした。
text_jaカラムがモデルから出力された日本語を前処理して余分な部分を除いたもので、text_enカラムは元となる英語テキストです。
inputカラムはモデルに入力した入力そのものであり、outputカラムは<think>トークンなどを含み出力をそのまま収載しています。
モデルへの入力には、hpprc/honyakuから英日翻訳事例を3件選び、few-shot exampleとして加えています。
モデルの出力にライセンス上の制約がないことと、元にしているテキストがWikipediaのものであることから、本データはCC-BY-SA 4.0ライセンスのもと公開いたします。
",https://huggingface.co/datasets/hpprc/ja-en-r1-distill-qwen,"['ja', 'en']",['translation'],['1K<n<10K']
6DammK9/danbooru2023-captions-1ktar,6DammK9,2025-01-28 04:40:14+00:00,2025-02-01 08:44:13+00:00,93,0,"['task_categories:image-classification', 'task_categories:zero-shot-image-classification', 'task_categories:text-to-image', 'annotations_creators:no-annotation', 'source_datasets:danbooru', 'language:en', 'language:ja', 'license:mit', 'size_categories:1M<n<10M', 'region:us', 'art', 'anime', 'not-for-all-audiences']","
	
		
		Danbooru 2023 captions only in 1k tar
	


Raw captions jointed by unpublished extended dataset from KBlueLeaf/danbooru2023-metadata-database

It aligns to nyanko7/danbooru2023. There are around 200k missing for the 2024 version, I'll try to use Minthy/ToriiGate-v0.4-7B to fill in the rest.

meta_cap.json has been provided in compressed format if you want to train with kohyas triner. Currently I'm trying to merge this with my 2024 version.



	
		
		Core logic
	


The script building… See the full description on the dataset page: https://huggingface.co/datasets/6DammK9/danbooru2023-captions-1ktar.",https://huggingface.co/datasets/6DammK9/danbooru2023-captions-1ktar,"['en', 'ja']","['image-classification', 'zero-shot-image-classification', 'text-to-image']",['1M<n<10M']
llm-jp/aya-ja-evol-inst,llm-jp,2025-01-29 04:46:30+00:00,2025-02-04 04:30:12+00:00,12,1,"['task_categories:text-generation', 'language:ja', 'license:apache-2.0', 'size_categories:10K<n<100K', 'format:json', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us', 'synthetic']","
	
		
		aya-ja-eval-inst
	

This repository provides a preference dataset developed by LLM-jp, a collaborative project launched in Japan.
This dataset was created by generating the chosen response using Qwen/Qwen2.5-32B-Instruct and the rejected response using llm-jp/llm-jp-3-1.8b-instruct for the prompts in weblab-GENIAC/aya-ja-evol-instruct-calm3-dpo-masked.
This repository does not contain prompts but only the corresponding indices. Please obtain the original prompts from the original data… See the full description on the dataset page: https://huggingface.co/datasets/llm-jp/aya-ja-evol-inst.",https://huggingface.co/datasets/llm-jp/aya-ja-evol-inst,['ja'],['text-generation'],['10K<n<100K']
llm-jp/ac-self-inst,llm-jp,2025-01-29 06:04:41+00:00,2025-02-02 18:59:27+00:00,10,2,"['language:ja', 'license:other', 'size_categories:10K<n<100K', 'modality:text', 'region:us', 'synthetic']","
	
		
		ac-self-inst
	

This repository provides an instruction-tuning dataset developed by LLM-jp, a collaborative project launched in Japan.
ac-self-inst is a synthetic preference dataset specifically aimed at ensuring safety and appropriateness of LLM output in Japanese.
The method of dataset creation and the citation will be added later.

	
		
		Send Questions to
	

ac-dataset(at)nii.ac.jp

	
		
		License
	

See the LICENSE file.

	
		
		Model Card Authors
	

The names are listed in… See the full description on the dataset page: https://huggingface.co/datasets/llm-jp/ac-self-inst.",https://huggingface.co/datasets/llm-jp/ac-self-inst,['ja'],[],['10K<n<100K']
llm-jp/AnswerCarefully,llm-jp,2025-01-29 06:17:25+00:00,2025-08-22 01:53:36+00:00,223,18,"['language:ja', 'language:en', 'license:other', 'arxiv:2506.02372', 'region:us']","
	
		
		AnswerCarefully
	

概要
AnswerCarefullyは日本語LLM 出力の安全性・適切性に特化したインストラクションデータセットです。
このデータセットは、英語の要注意回答を集めた Do-Not-Answer データセット の包括的なカテゴリ分類に基づき、人手で質問・回答ともに日本語サンプルを集めたオリジナルのデータセットです。
データセットの詳細については、こちらをご覧ください。
Overview
AnswerCarefully is an instruction dataset specifically aimed at ensuring safety and appropriateness of LLM output in Japanese.
This dataset consists of original pairs of questions and reference (safe) responses based on the extensive safety taxonomy proposed in Do-Not-Answer… See the full description on the dataset page: https://huggingface.co/datasets/llm-jp/AnswerCarefully.",https://huggingface.co/datasets/llm-jp/AnswerCarefully,"['ja', 'en']",[],[]
lingvenvist/animacy-ja-nogroups-xtr-complete-filtered,lingvenvist,2025-01-29 13:41:57+00:00,2025-06-01 17:20:59+00:00,11,0,"['language:ja', 'size_categories:10K<n<100K', 'format:parquet', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","Note that this is a processed version of XL-WSD v1 downloaded from https://sapienzanlp.github.io/xl-wsd/, made available with the XL-WSD license (see https://sapienzanlp.github.io/xl-wsd/docs/license).
",https://huggingface.co/datasets/lingvenvist/animacy-ja-nogroups-xtr-complete-filtered,['ja'],[],['10K<n<100K']
eaddario/imatrix-calibration,eaddario,2025-01-29 16:05:03+00:00,2025-05-24 18:22:29+00:00,13805,13,"['task_categories:text-generation', 'language:ar', 'language:zh', 'language:de', 'language:en', 'language:es', 'language:fr', 'language:hi', 'language:it', 'language:ja', 'language:nl', 'language:pl', 'language:pt', 'language:ru', 'license:mit', 'size_categories:10K<n<100K', 'region:us']","
	
		
		Importance Matrix Calibration Datasets
	

This repository contains calibration datasets used to generate importance matrices (imatrix), which in turn help minimise errors introduced during quantization.

	
		
		Math calibration datasets
	

This dataset consists of over 10M tokens of cleaned math prompts and is available in six sizes, ranging from huge (~ 430,000 lines equivalent to approx. 10M tokens), to micro (~ 13,700 lines and 1.7M tokens avg).
Original data sourced from… See the full description on the dataset page: https://huggingface.co/datasets/eaddario/imatrix-calibration.",https://huggingface.co/datasets/eaddario/imatrix-calibration,"['ar', 'zh', 'de', 'en', 'es', 'fr', 'hi', 'it', 'ja', 'nl', 'pl', 'pt', 'ru']",['text-generation'],['10K<n<100K']
lightblue/reasoning-multilingual-R1-Llama-70B-train,lightblue,2025-01-30 08:28:05+00:00,2025-01-31 07:04:20+00:00,38,36,"['language:am', 'language:ar', 'language:bn', 'language:zh', 'language:cs', 'language:nl', 'language:en', 'language:fr', 'language:de', 'language:el', 'language:ha', 'language:he', 'language:hi', 'language:id', 'language:it', 'language:ja', 'language:jv', 'language:km', 'language:ko', 'language:lo', 'language:ms', 'language:mr', 'language:fa', 'language:pl', 'language:pt', 'language:ro', 'language:ru', 'language:es', 'language:sw', 'language:sv', 'language:tl', 'language:ta', 'language:te', 'language:th', 'language:tr', 'language:uk', 'language:ur', 'language:vi', 'license:apache-2.0', 'size_categories:1K<n<10K', 'format:parquet', 'modality:tabular', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","
	
		
		lightblue/reasoning-multilingual-R1-Llama-70B-train
	

This is a multilingual reasoning dataset covering more than 30 languages.
This dataset was made by:

Sampling prompts from English datasets and translating them to various languages
Generating responses to these prompts 8 times using deepseek-ai/DeepSeek-R1-Distill-Llama-70B
Filtering out <think> sections with incorrect language, non-fluent language, and incorrect answers

This dataset was then used to train a multilingual… See the full description on the dataset page: https://huggingface.co/datasets/lightblue/reasoning-multilingual-R1-Llama-70B-train.",https://huggingface.co/datasets/lightblue/reasoning-multilingual-R1-Llama-70B-train,"['am', 'ar', 'bn', 'zh', 'cs', 'nl', 'en', 'fr', 'de', 'el', 'ha', 'he', 'hi', 'id', 'it', 'ja', 'jv', 'km', 'ko', 'lo', 'ms', 'mr', 'fa', 'pl', 'pt', 'ro', 'ru', 'es', 'sw', 'sv', 'tl', 'ta', 'te', 'th', 'tr', 'uk', 'ur', 'vi']",[],['1K<n<10K']
llm-jp/Synthetic-JP-EN-Coding-Dataset,llm-jp,2025-01-31 05:50:10+00:00,2025-01-31 06:35:59+00:00,73,0,"['language:ja', 'language:en', 'license:apache-2.0', 'size_categories:100K<n<1M', 'format:parquet', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us', 'code', 'synthetic']","
	
		
		Synthetic-JP-EN-Coding-Dataset
	

This repository provides an instruction tuning dataset developed by LLM-jp, a collaborative project launched in Japan.
The dataset comprises a subset from Aratako/Synthetic-JP-EN-Coding-Dataset-801k.

	
		
		Send Questions to
	

llm-jp(at)nii.ac.jp

	
		
		Model Card Authors
	

The names are listed in alphabetical order.
Hirokazu Kiyomaru and Takashi Kodama.
",https://huggingface.co/datasets/llm-jp/Synthetic-JP-EN-Coding-Dataset,"['ja', 'en']",[],['100K<n<1M']
llm-jp/wizardlm8x22b-logical-math-coding-sft-ja,llm-jp,2025-01-31 06:10:17+00:00,2025-01-31 06:35:29+00:00,18,0,"['language:ja', 'license:apache-2.0', 'size_categories:100K<n<1M', 'format:parquet', 'modality:text', 'library:datasets', 'library:dask', 'library:mlcroissant', 'library:polars', 'region:us']","
	
		
		wizardlm8x22b-logical-math-coding-sft-ja
	

This repository provides an instruction tuning dataset developed by LLM-jp, a collaborative project launched in Japan.
The dataset comprises a subset from kanhatakeyama/wizardlm8x22b-logical-math-coding-sft-ja and kanhatakeyama/wizardlm8x22b-logical-math-coding-sft_additional-ja.

	
		
	
	
		Send Questions to
	

llm-jp(at)nii.ac.jp

	
		
	
	
		Model Card Authors
	

The names are listed in alphabetical order.
Hirokazu Kiyomaru and Takashi… See the full description on the dataset page: https://huggingface.co/datasets/llm-jp/wizardlm8x22b-logical-math-coding-sft-ja.",https://huggingface.co/datasets/llm-jp/wizardlm8x22b-logical-math-coding-sft-ja,['ja'],[],['100K<n<1M']
rubenroy/GammaCorpus-Polylingo-50k,rubenroy,2025-02-01 05:30:59+00:00,2025-02-01 16:27:37+00:00,31,6,"['task_categories:text-generation', 'language:en', 'language:ru', 'language:vi', 'language:de', 'language:pt', 'language:es', 'language:ja', 'language:fr', 'language:ko', 'language:zh', 'language:fa', 'language:pl', 'language:tr', 'language:cs', 'language:uk', 'language:nl', 'language:id', 'language:sv', 'language:sr', 'language:fi', 'license:apache-2.0', 'size_categories:10K<n<100K', 'format:json', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us', 'chat-dataset', 'conversational-ai', 'natural-language-processing', 'ai-generated', 'single-turn-dialogue', 'jsonl', 'nlp', 'gammacorpus', 'chat', 'conversational', 'multilingual']","
	
		
		GammaCorpus Polylingo 50k
	


	
		
		What is it?
	

The GammaCorpus Polylingo 50k dataset consists of 50,000 structured, unfiltered, single-turn conversations, where each interaction includes:

Input: A user prompt or question.
Output: A response generated by an AI assistant.
Language: The language used in the interaction.

This dataset is designed to help in the training and evaluation of conversational AI models for linguistic purposes. This dataset can be especially helpful if you… See the full description on the dataset page: https://huggingface.co/datasets/rubenroy/GammaCorpus-Polylingo-50k.",https://huggingface.co/datasets/rubenroy/GammaCorpus-Polylingo-50k,"['en', 'ru', 'vi', 'de', 'pt', 'es', 'ja', 'fr', 'ko', 'zh', 'fa', 'pl', 'tr', 'cs', 'uk', 'nl', 'id', 'sv', 'sr', 'fi']",['text-generation'],['10K<n<100K']
hpprc/r1-distill-qwen-pseudo-qa,hpprc,2025-02-01 11:07:57+00:00,2025-02-11 06:40:46+00:00,25,5,"['language:ja', 'license:cc-by-sa-4.0', 'size_categories:1M<n<10M', 'format:parquet', 'modality:text', 'library:datasets', 'library:dask', 'library:mlcroissant', 'library:polars', 'region:us']","日本語WikipediaからLLMを用いて自動生成した質問と、対応する日本語Wikipediaのページを元に、cyberagent/DeepSeek-R1-Distill-Qwen-32B-Japaneseを用いて回答を生成したデータセットです。
出力にライセンス的な制約があるLLMを用いていないことと、日本語Wikipediaを用いていることから、本データセットはCC-BY-SA 4.0での配布とします。
",https://huggingface.co/datasets/hpprc/r1-distill-qwen-pseudo-qa,['ja'],[],['1M<n<10M']
DeliberatorArchiver/asmr-archive-data-02,DeliberatorArchiver,2025-02-01 13:03:30+00:00,2025-03-31 14:15:01+00:00,458,4,"['language:ja', 'license:agpl-3.0', 'size_categories:n>1T', 'region:us', 'not-for-all-audiences']","
	
		
		ASMR Media Archive Storage
	

This repository contains an archive of ASMR works.
All data in this repository is uploaded for educational and research purposes only. All use is at your own risk.

[!IMPORTANT]
This repository contains >= 64 TiB of files.Git LFS consumes twice as much disk space because of the way it works, so git clone is not recommended. Hugging Face CLI or Python libraries allow you to select and download only a subset of files.

>>> CLICK HERE or on the IMAGE BELOW… See the full description on the dataset page: https://huggingface.co/datasets/DeliberatorArchiver/asmr-archive-data-02.",https://huggingface.co/datasets/DeliberatorArchiver/asmr-archive-data-02,['ja'],[],['n>1T']
Aratako/Synthetic-JP-Preference-Dataset-Qwen2.5_72B-191k,Aratako,2025-02-02 07:15:38+00:00,2025-02-02 08:30:31+00:00,69,6,"['task_categories:text-generation', 'language:ja', 'license:other', 'size_categories:100K<n<1M', 'format:parquet', 'modality:text', 'library:datasets', 'library:dask', 'library:mlcroissant', 'library:polars', 'region:us']","
	
		
		Synthetic-JP-Preference-Dataset-Qwen2.5_72B-191k
	


	
		
		概要
	

5種類のオープンモデルとQwen/Qwen2.5-72B-Instruct-GPTQ-Int8を使って作成した、190854件の日本語合成Preferenceデータセットです。
以下、データセットの詳細です。

instructionには、Aratako/Magpie-Tanuki-8B-annotated-96kのinput_qualityがexcellentのものを利用
回答生成には、以下の5つのApache 2.0ライセンスのモデルを利用
weblab-GENIAC/Tanuki-8B-dpo-v1.0
team-hatakeyama-phase2/Tanuki-8x8B-dpo-v1.0-GPTQ-8bit
cyberagent/calm3-22b-chat
llm-jp/llm-jp-3-13b-instruct
Qwen/Qwen2.5-32B-Instruct-GPTQ-Int8… See the full description on the dataset page: https://huggingface.co/datasets/Aratako/Synthetic-JP-Preference-Dataset-Qwen2.5_72B-191k.",https://huggingface.co/datasets/Aratako/Synthetic-JP-Preference-Dataset-Qwen2.5_72B-191k,['ja'],['text-generation'],['100K<n<1M']
fa0311/oita-ken-strawberries,fa0311,2025-02-03 06:24:38+00:00,2025-02-03 08:15:26+00:00,97,0,"['task_categories:image-classification', 'language:ja', 'language:en', 'license:mit', 'size_categories:n<1K', 'format:imagefolder', 'modality:image', 'library:datasets', 'library:mlcroissant', 'region:us']","
	
		
		oita-ken-strawberries
	

This dataset contains 5,000 images of ベリーツ (Beriitsu), a premium strawberry variety grown in Oita Prefecture, Japan.  

Images in dataset/input/* are organized by harvest year and grading category.  
The dataset/input/**/include directory contains cleaned strawberry images.  
Data cleansing was performed using background_erase.


	
		
	
	
		Conversion to Pascal VOC
	


dataset/input/input.json and dataset/input/** can be processed with image_data_augmentation… See the full description on the dataset page: https://huggingface.co/datasets/fa0311/oita-ken-strawberries.",https://huggingface.co/datasets/fa0311/oita-ken-strawberries,"['ja', 'en']",['image-classification'],['n<1K']
WueNLP/Synthdog-Multilingual-100,WueNLP,2025-02-04 12:39:01+00:00,2025-02-10 09:57:21+00:00,88,3,"['task_categories:image-to-text', 'language:multilingual', 'language:af', 'language:am', 'language:ar', 'language:as', 'language:azb', 'language:be', 'language:bg', 'language:bm', 'language:bn', 'language:bo', 'language:bs', 'language:ca', 'language:ceb', 'language:cs', 'language:cy', 'language:da', 'language:de', 'language:du', 'language:el', 'language:en', 'language:eo', 'language:es', 'language:et', 'language:eu', 'language:fa', 'language:fi', 'language:fr', 'language:ga', 'language:gd', 'language:gl', 'language:ha', 'language:hi', 'language:hr', 'language:ht', 'language:hu', 'language:id', 'language:ig', 'language:is', 'language:it', 'language:iw', 'language:ja', 'language:jv', 'language:ka', 'language:ki', 'language:kk', 'language:km', 'language:ko', 'language:la', 'language:lb', 'language:ln', 'language:lo', 'language:lt', 'language:lv', 'language:mi', 'language:mr', 'language:ms', 'language:mt', 'language:my', 'language:no', 'language:oc', 'language:pa', 'language:pl', 'language:pt', 'language:qu', 'language:ro', 'language:ru', 'language:sa', 'language:sc', 'language:sd', 'language:sg', 'language:sk', 'language:sl', 'language:sm', 'language:so', 'language:sq', 'language:sr', 'language:ss', 'language:sv', 'language:sw', 'language:ta', 'language:te', 'language:th', 'language:ti', 'language:tl', 'language:tn', 'language:tpi', 'language:tr', 'language:ts', 'language:tw', 'language:uk', 'language:ur', 'language:uz', 'language:vi', 'language:war', 'language:wo', 'language:xh', 'language:yo', 'language:zh', 'language:zu', 'license:apache-2.0', 'size_categories:1M<n<10M', 'format:webdataset', 'modality:image', 'modality:text', 'library:datasets', 'library:webdataset', 'library:mlcroissant', 'arxiv:2501.05122', 'region:us', 'ocr']","
	
		
		Synthdog Multilingual
	



The Synthdog dataset created for training in Centurio: On Drivers of Multilingual Ability of Large Vision-Language Model.
Using the official Synthdog code, we created >1 million training samples for improving OCR capabilities in Large Vision-Language Models.

	
		
	
	
		Dataset Details
	

We provide the images for download in two .tar.gz files. Download and extract them in folders of the same name (so cat images.tar.gz.* | tar xvzf -C images; tar xvzf… See the full description on the dataset page: https://huggingface.co/datasets/WueNLP/Synthdog-Multilingual-100.",https://huggingface.co/datasets/WueNLP/Synthdog-Multilingual-100,"['multilingual', 'af', 'am', 'ar', 'as', 'azb', 'be', 'bg', 'bm', 'bn', 'bo', 'bs', 'ca', 'ceb', 'cs', 'cy', 'da', 'de', 'du', 'el', 'en', 'eo', 'es', 'et', 'eu', 'fa', 'fi', 'fr', 'ga', 'gd', 'gl', 'ha', 'hi', 'hr', 'ht', 'hu', 'id', 'ig', 'is', 'it', 'iw', 'ja', 'jv', 'ka', 'ki', 'kk', 'km', 'ko', 'la', 'lb', 'ln', 'lo', 'lt', 'lv', 'mi', 'mr', 'ms', 'mt', 'my', 'no', 'oc', 'pa', 'pl', 'pt', 'qu', 'ro', 'ru', 'sa', 'sc', 'sd', 'sg', 'sk', 'sl', 'sm', 'so', 'sq', 'sr', 'ss', 'sv', 'sw', 'ta', 'te', 'th', 'ti', 'tl', 'tn', 'tpi', 'tr', 'ts', 'tw', 'uk', 'ur', 'uz', 'vi', 'war', 'wo', 'xh', 'yo', 'zh', 'zu']",['image-to-text'],['1M<n<10M']
p1atdev/OnlineMathContest-2502,p1atdev,2025-02-04 15:04:39+00:00,2025-02-07 04:36:29+00:00,10,0,"['task_categories:text-generation', 'language:ja', 'license:cc-by-nc-sa-4.0', 'size_categories:1K<n<10K', 'format:parquet', 'modality:tabular', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us', 'math']","Data source: https://onlinemathcontest.com/
",https://huggingface.co/datasets/p1atdev/OnlineMathContest-2502,['ja'],['text-generation'],['1K<n<10K']
ZoneTwelve/multilingual-stories,ZoneTwelve,2025-02-05 09:35:58+00:00,2025-02-05 10:01:17+00:00,28,0,"['task_categories:text-classification', 'task_categories:text-generation', 'task_categories:feature-extraction', 'task_categories:translation', 'task_categories:summarization', 'language:fr', 'language:it', 'language:de', 'language:en', 'language:ko', 'language:es', 'language:zh', 'language:ja', 'language:ru', 'language:cs', 'language:da', 'language:nl', 'language:ar', 'language:bg', 'language:et', 'language:hu', 'language:id', 'language:nb', 'language:pt', 'language:el', 'language:lt', 'language:fi', 'language:lv', 'language:pl', 'language:sv', 'language:sk', 'language:sl', 'language:ro', 'language:tr', 'language:uk', 'license:apache-2.0', 'size_categories:10K<n<100K', 'format:parquet', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us', 'multilingual', 'NLP', 'text-generation', 'text-classification', 'dataset-processing', 'large-scale-dataset']","
	
		
		Multilingual Dataset
	

This dataset contains multilingual articles generated using various models.

	
		
		Dataset Summary
	

Total records: 14850

	
		
		Categories
	

Unique categories and their frequencies:

OmundoAmanha: 99
malinois: 33
CBDPouches: 33
ingenieurs: 66
PPeperomioides: 33
DiscGolfCarts: 33
TIMAF: 33
AntisocialMemeClub: 33
Tancan: 66
ogerwaters: 33
MotosBr: 33
lgballt: 66
CipherAcademy: 33
LofiEdits: 33
jennyraee: 33
RonnieHotdogs: 33
Bratzillaz: 66
cubiccommunity: 33… See the full description on the dataset page: https://huggingface.co/datasets/ZoneTwelve/multilingual-stories.",https://huggingface.co/datasets/ZoneTwelve/multilingual-stories,"['fr', 'it', 'de', 'en', 'ko', 'es', 'zh', 'ja', 'ru', 'cs', 'da', 'nl', 'ar', 'bg', 'et', 'hu', 'id', 'nb', 'pt', 'el', 'lt', 'fi', 'lv', 'pl', 'sv', 'sk', 'sl', 'ro', 'tr', 'uk']","['text-classification', 'text-generation', 'feature-extraction', 'translation', 'summarization']",['10K<n<100K']
unieai/multilingual-stories-original,unieai,2025-02-05 09:36:22+00:00,2025-02-05 10:01:17+00:00,31,2,"['task_categories:text-classification', 'task_categories:text-generation', 'task_categories:feature-extraction', 'task_categories:translation', 'task_categories:summarization', 'language:fr', 'language:it', 'language:de', 'language:en', 'language:ko', 'language:es', 'language:zh', 'language:ja', 'language:ru', 'language:cs', 'language:da', 'language:nl', 'language:ar', 'language:bg', 'language:et', 'language:hu', 'language:id', 'language:nb', 'language:pt', 'language:el', 'language:lt', 'language:fi', 'language:lv', 'language:pl', 'language:sv', 'language:sk', 'language:sl', 'language:ro', 'language:tr', 'language:uk', 'license:apache-2.0', 'size_categories:10K<n<100K', 'format:parquet', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us', 'multilingual', 'NLP', 'text-generation', 'text-classification', 'dataset-processing', 'large-scale-dataset']","
	
		
		Multilingual Dataset
	

This dataset contains multilingual articles generated using various models.

	
		
		Dataset Summary
	

Total records: 14850

	
		
		Categories
	

Unique categories and their frequencies:

OmundoAmanha: 99
malinois: 33
CBDPouches: 33
ingenieurs: 66
PPeperomioides: 33
DiscGolfCarts: 33
TIMAF: 33
AntisocialMemeClub: 33
Tancan: 66
ogerwaters: 33
MotosBr: 33
lgballt: 66
CipherAcademy: 33
LofiEdits: 33
jennyraee: 33
RonnieHotdogs: 33
Bratzillaz: 66
cubiccommunity: 33… See the full description on the dataset page: https://huggingface.co/datasets/unieai/multilingual-stories-original.",https://huggingface.co/datasets/unieai/multilingual-stories-original,"['fr', 'it', 'de', 'en', 'ko', 'es', 'zh', 'ja', 'ru', 'cs', 'da', 'nl', 'ar', 'bg', 'et', 'hu', 'id', 'nb', 'pt', 'el', 'lt', 'fi', 'lv', 'pl', 'sv', 'sk', 'sl', 'ro', 'tr', 'uk']","['text-classification', 'text-generation', 'feature-extraction', 'translation', 'summarization']",['10K<n<100K']
google/wmt24pp,google,2025-02-06 15:19:53+00:00,2025-03-13 21:53:34+00:00,8064,66,"['task_categories:translation', 'language:ar', 'language:bg', 'language:bn', 'language:ca', 'language:da', 'language:de', 'language:el', 'language:es', 'language:et', 'language:fa', 'language:fi', 'language:fr', 'language:gu', 'language:he', 'language:hi', 'language:hr', 'language:hu', 'language:id', 'language:is', 'language:it', 'language:ja', 'language:kn', 'language:ko', 'language:lt', 'language:lv', 'language:ml', 'language:mr', 'language:nl', 'language:no', 'language:pa', 'language:pl', 'language:pt', 'language:ro', 'language:ru', 'language:sk', 'language:sl', 'language:sr', 'language:sv', 'language:sw', 'language:ta', 'language:te', 'language:th', 'language:tr', 'language:uk', 'language:ur', 'language:vi', 'language:zh', 'language:zu', 'license:apache-2.0', 'size_categories:10K<n<100K', 'format:json', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'arxiv:2502.12404', 'region:us']","
	
		
		WMT24++
	

This repository contains the human translation and post-edit data for the 55 en->xx language pairs released in
the publication
WMT24++: Expanding the Language Coverage of WMT24 to 55 Languages & Dialects.
If you are interested in the MT/LLM system outputs and automatic metric scores, please see MTME.
If you are interested in the images of the source URLs for each document, please see here.

	
		
	
	
		Schema
	

Each language pair is stored in its own jsonl file.
Each row is… See the full description on the dataset page: https://huggingface.co/datasets/google/wmt24pp.",https://huggingface.co/datasets/google/wmt24pp,"['ar', 'bg', 'bn', 'ca', 'da', 'de', 'el', 'es', 'et', 'fa', 'fi', 'fr', 'gu', 'he', 'hi', 'hr', 'hu', 'id', 'is', 'it', 'ja', 'kn', 'ko', 'lt', 'lv', 'ml', 'mr', 'nl', 'no', 'pa', 'pl', 'pt', 'ro', 'ru', 'sk', 'sl', 'sr', 'sv', 'sw', 'ta', 'te', 'th', 'tr', 'uk', 'ur', 'vi', 'zh', 'zu']",['translation'],['10K<n<100K']
p1atdev/omc2k,p1atdev,2025-02-07 03:50:40+00:00,2025-02-07 04:36:12+00:00,12,0,"['task_categories:text-generation', 'language:ja', 'license:cc-by-nc-sa-4.0', 'size_categories:1K<n<10K', 'format:parquet', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us', 'math']","
	
		
		OMC 2k
	

Converted from p1atdev/OnlineMathContest-2502. The data source is onlinemathcontest.com.

url: the url of each problem
question: the question
answer: the answer of the question. this was extracted by nejumi/phi-4-GPTQ-Int4-calib-ja-1k from original editorilas field, so there is possibility to be wrong value.

",https://huggingface.co/datasets/p1atdev/omc2k,['ja'],['text-generation'],['1K<n<10K']
p1atdev/gsm8k-ja-slim,p1atdev,2025-02-07 05:23:06+00:00,2025-02-10 15:47:52+00:00,34,2,"['language:ja', 'license:mit', 'size_categories:1K<n<10K', 'format:parquet', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","
	
		
		GSM8K Japanese Slim
	

Japanese translated version of openai/gsm8k, and the answer extracted from descriptions. 
nejumi/phi-4-GPTQ-Int4-calib-ja-1k was used for translation.

[!WARNING]
Some data are invalid in Japanese.
Example:

The question:


サマンサの苗字は、ボビーの苗字より3文字少ない。ボビーが自分の苗字から2文字を取り除けば、ジェイミーの苗字の2倍の長さになる。ジェイミーのフルネームはジェイミー・グレイである。サマンサの苗字には何文字ありますか？


The answer: 7


",https://huggingface.co/datasets/p1atdev/gsm8k-ja-slim,['ja'],[],['1K<n<10K']
infinity-blackhole/nhentai,infinity-blackhole,2025-02-08 15:37:40+00:00,2025-02-08 16:47:54+00:00,23,0,"['task_categories:image-classification', 'task_categories:image-to-image', 'task_categories:image-to-text', 'language:ja', 'language:en', 'license:mit', 'size_categories:10K<n<100K', 'region:us', 'manga', 'comics', 'adult']","
	
		
		Nhentai Dataset
	

A collection of Japanese manga in CBZ format from Nhentai, containing adult
content manga with associated metadata.

	
		
		Content Warning
	

This dataset contains adult content (NSFW) and is intended for research purposes
only. Users must be of legal age and comply with all applicable laws and
regulations.

	
		
		Key Applications
	


Image Analysis: Suitable for manga page segmentation, panel detection, and art
style analysis
Text Recognition: Useful for Japanese… See the full description on the dataset page: https://huggingface.co/datasets/infinity-blackhole/nhentai.",https://huggingface.co/datasets/infinity-blackhole/nhentai,"['ja', 'en']","['image-classification', 'image-to-image', 'image-to-text']",['10K<n<100K']
Sakalti/SakaEval-V1,Sakalti,2025-02-09 10:08:10+00:00,2025-02-15 10:52:11+00:00,12,0,"['task_categories:text-generation', 'language:ja', 'language:en', 'license:apache-2.0', 'size_categories:n<1K', 'format:csv', 'modality:text', 'library:datasets', 'library:dask', 'library:mlcroissant', 'library:polars', 'region:us']","https://chatgpt.com
",https://huggingface.co/datasets/Sakalti/SakaEval-V1,"['ja', 'en']",['text-generation'],['n<1K']
SimpleStories/SimpleStories-JA,SimpleStories,2025-02-09 15:58:43+00:00,2025-02-13 17:48:16+00:00,39,0,"['task_categories:text-generation', 'language:ja', 'license:mit', 'size_categories:1M<n<10M', 'format:parquet', 'modality:tabular', 'modality:text', 'library:datasets', 'library:dask', 'library:mlcroissant', 'library:polars', 'region:us', 'NLP', 'Distillation']","
	
		
		📘📕 SimpleStories 📙📗
	

このデータセットは、gpt-4o-miniによって生成された短編小説で出来ているデータセットです。生成方法や、自分で物語を生成する方法については、こちらのリポジトリをご覧ください。
他の言語や物語形式の制作を希望される場合は、メールにてお問い合わせください。
SimpleStoriesは、EldenとLiによるTinyStoriesの改良版です。

	
		
		特徴
	


物語の注釈情報（theme、topic、styleなど）
多様性の高さ
2024年のモデルによって生成
NLPのデータが用意しているためフィルタリングしやすい
以下の言語版が利用可能：
英語
日本語
他にも追加予定




This dataset is a collection of short stories generated by gpt-4o-mini (+ other models, soon). To see how this dataset was generated, or to generate some stories… See the full description on the dataset page: https://huggingface.co/datasets/SimpleStories/SimpleStories-JA.",https://huggingface.co/datasets/SimpleStories/SimpleStories-JA,['ja'],['text-generation'],['1M<n<10M']
hotchpotch/fineweb-2-edu-japanese-scores,hotchpotch,2025-02-10 00:04:59+00:00,2025-02-11 07:26:37+00:00,23,1,"['language:ja', 'license:odc-by', 'size_categories:100K<n<1M', 'format:parquet', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","
	
		
		fineweb-2-edu-japanese-scores
	

fineweb-2日本語テキストの教育的スコアデータセット (0-4段階)
概要:
このデータセットは、FineWeb-Edu classifier の手法に倣い、Deepseek API を用いて、大規模ウェブデータセット fineweb-2  日本語テキストの教育的視点をスコアリングしたものです。
テキストの内容が教育的である度合いに応じて、0, 1, 2, 3, 4 の5段階でスコア付けされています。スコアが高いほど、教育的な内容を含むテキストであることを示します。
データセットは、学習用データセット (train) 約28万件と、評価用データセット (test) 約3万件で構成されています。
データセットの作成方法:
このデータセットは、以下の手順で作成されました。

データソース:  fineweb-2 データセットの日本語テキストのうち、500文字以下のデータを抽出しました。

代表点サンプリング:

10万件ごとのデータに対し、static-embeddings-japanese… See the full description on the dataset page: https://huggingface.co/datasets/hotchpotch/fineweb-2-edu-japanese-scores.",https://huggingface.co/datasets/hotchpotch/fineweb-2-edu-japanese-scores,['ja'],[],['100K<n<1M']
sander-wood/m4-rag,sander-wood,2025-02-10 06:25:03+00:00,2025-10-12 08:56:21+00:00,30,11,"['task_categories:text-to-audio', 'task_categories:text-retrieval', 'task_categories:audio-classification', 'task_categories:text-classification', 'language:en', 'language:es', 'language:fr', 'language:de', 'language:pt', 'language:ja', 'language:it', 'language:zh', 'language:ko', 'language:ru', 'language:vi', 'language:nl', 'language:pl', 'language:tr', 'language:ar', 'language:id', 'language:fa', 'language:he', 'language:cs', 'language:th', 'language:hi', 'language:lo', 'language:bn', 'language:km', 'language:ur', 'language:my', 'language:ms', 'license:cc-by-nc-nd-4.0', 'size_categories:1M<n<10M', 'format:json', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'arxiv:2502.10362', 'region:us', 'music']","
	
		
		🎵 M4-RAG: Million-scale Multilingual Music Metadata
	

M4-RAG is a large-scale music-text dataset with 2.31 million music-text pairs, including 1.56 million audio-text pairs. It supports multimodal and multilingual music research, enabling tasks like text-to-music generation, music captioning, music information retrieval, and music classification. 🚀  

	
		
		🏆 Overview
	

M4-RAG aggregates music metadata from diverse online sources and enhances it using retrieval-augmented… See the full description on the dataset page: https://huggingface.co/datasets/sander-wood/m4-rag.",https://huggingface.co/datasets/sander-wood/m4-rag,"['en', 'es', 'fr', 'de', 'pt', 'ja', 'it', 'zh', 'ko', 'ru', 'vi', 'nl', 'pl', 'tr', 'ar', 'id', 'fa', 'he', 'cs', 'th', 'hi', 'lo', 'bn', 'km', 'ur', 'my', 'ms']","['text-to-audio', 'text-retrieval', 'audio-classification', 'text-classification']",['1M<n<10M']
Nexdata/10341_Hours_Unsupervised_Spontaneous_Japanese_Speech_Data,Nexdata,2025-02-10 09:29:15+00:00,2025-04-24 03:20:15+00:00,11,0,"['language:ja', 'license:cc-by-nd-4.0', 'size_categories:n<1K', 'format:audiofolder', 'modality:audio', 'library:datasets', 'library:mlcroissant', 'region:us']","
	
		
		Description
	

This dataset is just a sample of 10341 Hours Unsupervised Spontaneous Japanese Speech Dataset(paid dataset), covers dialogues or monologues in 28 common domains, such as daily vlogs, travel, podcast, technology, beauty, etc., mirrors real-world interactions, enhancing model performance in real and complex tasks. Quality tested by various AI companies. We strictly adhere to data protection regulations and privacy standards, ensuring the maintenance of user privacy and… See the full description on the dataset page: https://huggingface.co/datasets/Nexdata/10341_Hours_Unsupervised_Spontaneous_Japanese_Speech_Data.",https://huggingface.co/datasets/Nexdata/10341_Hours_Unsupervised_Spontaneous_Japanese_Speech_Data,['ja'],[],['n<1K']
LLaMAX/BenchMAX_Rule-based,LLaMAX,2025-02-10 13:49:10+00:00,2025-03-19 07:50:52+00:00,421,2,"['task_categories:text-generation', 'multilinguality:multilingual', 'language:en', 'language:zh', 'language:es', 'language:fr', 'language:de', 'language:ru', 'language:ja', 'language:th', 'language:sw', 'language:te', 'language:bn', 'language:ar', 'language:ko', 'language:vi', 'language:cs', 'language:hu', 'language:sr', 'license:cc-by-4.0', 'size_categories:1K<n<10K', 'format:json', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'arxiv:2502.07346', 'region:us']","
	
		
		Dataset Sources
	


Paper: BenchMAX: A Comprehensive Multilingual Evaluation Suite for Large Language Models
Link: https://huggingface.co/papers/2502.07346
Repository: https://github.com/CONE-MT/BenchMAX


	
		
		Dataset Description
	

BenchMAX_Rule-based is a dataset of BenchMAX, sourcing from IFEval, which is a rule-based benchmark for evaluating the instruction following capabilities in multilingual scenarios.
We extend the original dataset to 16 non-English languages by first… See the full description on the dataset page: https://huggingface.co/datasets/LLaMAX/BenchMAX_Rule-based.",https://huggingface.co/datasets/LLaMAX/BenchMAX_Rule-based,"['en', 'zh', 'es', 'fr', 'de', 'ru', 'ja', 'th', 'sw', 'te', 'bn', 'ar', 'ko', 'vi', 'cs', 'hu', 'sr']",['text-generation'],['1K<n<10K']
LLaMAX/BenchMAX_Model-based,LLaMAX,2025-02-10 14:04:57+00:00,2025-03-19 08:15:34+00:00,48,0,"['task_categories:text-generation', 'multilinguality:multilingual', 'language:en', 'language:zh', 'language:es', 'language:fr', 'language:de', 'language:ru', 'language:ja', 'language:th', 'language:sw', 'language:te', 'language:bn', 'language:ar', 'language:ko', 'language:vi', 'language:cs', 'language:hu', 'language:sr', 'license:cc-by-4.0', 'size_categories:1K<n<10K', 'format:json', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'arxiv:2502.07346', 'region:us', 'multilingual', 'instruction-following']","
	
		
		Dataset Sources
	


Paper: BenchMAX: A Comprehensive Multilingual Evaluation Suite for Large Language Models
Link: https://huggingface.co/papers/2502.07346
Repository: https://github.com/CONE-MT/BenchMAX


	
		
		Dataset Description
	

BenchMAX_Model-based is a dataset of BenchMAX, sourcing from m-ArenaHard, which evaluates the instruction following capability via model-based judgment.
We extend the original dataset to include languages that are not supported by m-ArenaHard through… See the full description on the dataset page: https://huggingface.co/datasets/LLaMAX/BenchMAX_Model-based.",https://huggingface.co/datasets/LLaMAX/BenchMAX_Model-based,"['en', 'zh', 'es', 'fr', 'de', 'ru', 'ja', 'th', 'sw', 'te', 'bn', 'ar', 'ko', 'vi', 'cs', 'hu', 'sr']",['text-generation'],['1K<n<10K']
LLaMAX/BenchMAX_Math,LLaMAX,2025-02-10 14:08:07+00:00,2025-03-19 08:02:47+00:00,311,1,"['task_categories:text-generation', 'multilinguality:multilingual', 'language:en', 'language:zh', 'language:es', 'language:fr', 'language:de', 'language:ru', 'language:ja', 'language:th', 'language:sw', 'language:te', 'language:bn', 'language:ar', 'language:ko', 'language:vi', 'language:cs', 'language:hu', 'language:sr', 'license:cc-by-4.0', 'size_categories:1K<n<10K', 'format:json', 'modality:text', 'library:datasets', 'library:dask', 'library:mlcroissant', 'arxiv:2502.07346', 'region:us']","
	
		
		Dataset Sources
	


Paper: BenchMAX: A Comprehensive Multilingual Evaluation Suite for Large Language Models
Link: https://huggingface.co/papers/2502.07346
Repository: https://github.com/CONE-MT/BenchMAX


	
		
		Dataset Description
	

BenchMAX_Math is a dataset of BenchMAX, sourcing from MGSM, which evaluates the math reasoning capability in multilingual scenarios.
We extend the original MGSM dataset by six additional languages, i.e. Arabic, Czech, Hungarian, Korean, Serbian, and… See the full description on the dataset page: https://huggingface.co/datasets/LLaMAX/BenchMAX_Math.",https://huggingface.co/datasets/LLaMAX/BenchMAX_Math,"['en', 'zh', 'es', 'fr', 'de', 'ru', 'ja', 'th', 'sw', 'te', 'bn', 'ar', 'ko', 'vi', 'cs', 'hu', 'sr']",['text-generation'],['1K<n<10K']
LLaMAX/BenchMAX_Science,LLaMAX,2025-02-10 14:08:20+00:00,2025-03-19 07:56:40+00:00,419,3,"['task_categories:question-answering', 'multilinguality:multilingual', 'language:en', 'language:zh', 'language:es', 'language:fr', 'language:de', 'language:ru', 'language:ja', 'language:th', 'language:sw', 'language:te', 'language:bn', 'language:ar', 'language:ko', 'language:vi', 'language:cs', 'language:hu', 'language:sr', 'license:cc-by-4.0', 'size_categories:1K<n<10K', 'format:json', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'arxiv:2502.07346', 'region:us']","
	
		
		Dataset Sources
	


Paper: BenchMAX: A Comprehensive Multilingual Evaluation Suite for Large Language Models
Link: https://huggingface.co/papers/2502.07346
Repository: https://github.com/CONE-MT/BenchMAX


	
		
		Dataset Description
	

BenchMAX_Science is a dataset of BenchMAX, sourcing from GPQA, which evaluates the natural science reasoning capability in multilingual scenarios.
We extend the original English dataset to 16 non-English languages.
The data is first translated by Google… See the full description on the dataset page: https://huggingface.co/datasets/LLaMAX/BenchMAX_Science.",https://huggingface.co/datasets/LLaMAX/BenchMAX_Science,"['en', 'zh', 'es', 'fr', 'de', 'ru', 'ja', 'th', 'sw', 'te', 'bn', 'ar', 'ko', 'vi', 'cs', 'hu', 'sr']",['question-answering'],['1K<n<10K']
LLaMAX/BenchMAX_Function_Completion,LLaMAX,2025-02-10 14:12:52+00:00,2025-03-19 07:52:18+00:00,96,1,"['task_categories:text-generation', 'multilinguality:multilingual', 'language:en', 'language:zh', 'language:es', 'language:fr', 'language:de', 'language:ru', 'language:ja', 'language:th', 'language:sw', 'language:te', 'language:bn', 'language:ar', 'language:ko', 'language:vi', 'language:cs', 'language:hu', 'language:sr', 'license:cc-by-4.0', 'size_categories:1K<n<10K', 'format:json', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'arxiv:2502.07346', 'region:us', 'multilingual', 'code-generation']","
	
		
		Dataset Sources
	


Paper: BenchMAX: A Comprehensive Multilingual Evaluation Suite for Large Language Models
Link: https://huggingface.co/papers/2502.07346
Repository: https://github.com/CONE-MT/BenchMAX


	
		
		Dataset Description
	

BenchMAX_Function_Completion is a dataset of BenchMAX, sourcing from humanevalplus, which evaluates the code generation capability in multilingual scenarios.
We extend the original English dataset to 16 non-English languages.
The data is first translated… See the full description on the dataset page: https://huggingface.co/datasets/LLaMAX/BenchMAX_Function_Completion.",https://huggingface.co/datasets/LLaMAX/BenchMAX_Function_Completion,"['en', 'zh', 'es', 'fr', 'de', 'ru', 'ja', 'th', 'sw', 'te', 'bn', 'ar', 'ko', 'vi', 'cs', 'hu', 'sr']",['text-generation'],['1K<n<10K']
LLaMAX/BenchMAX_Problem_Solving,LLaMAX,2025-02-10 14:13:12+00:00,2025-03-19 08:07:29+00:00,310,1,"['task_categories:text-generation', 'multilinguality:multilingual', 'language:en', 'language:zh', 'language:es', 'language:fr', 'language:de', 'language:ru', 'language:ja', 'language:th', 'language:sw', 'language:te', 'language:bn', 'language:ar', 'language:ko', 'language:vi', 'language:cs', 'language:hu', 'language:sr', 'license:cc-by-4.0', 'size_categories:10K<n<100K', 'format:parquet', 'modality:text', 'library:datasets', 'library:dask', 'library:mlcroissant', 'library:polars', 'arxiv:2502.07346', 'region:us']","
	
		
		Dataset Sources
	


Paper: BenchMAX: A Comprehensive Multilingual Evaluation Suite for Large Language Models
Link: https://huggingface.co/papers/2502.07346
Repository: https://github.com/CONE-MT/BenchMAX


	
		
		Dataset Description
	

BenchMAX_Problem_Solving is a dataset of BenchMAX, sourcing from LiveCodeBench_v4, which evaluates the code generation capability for solving multilingual competitive code problems.
We extend the original English dataset by 16 non-English languages.
The… See the full description on the dataset page: https://huggingface.co/datasets/LLaMAX/BenchMAX_Problem_Solving.",https://huggingface.co/datasets/LLaMAX/BenchMAX_Problem_Solving,"['en', 'zh', 'es', 'fr', 'de', 'ru', 'ja', 'th', 'sw', 'te', 'bn', 'ar', 'ko', 'vi', 'cs', 'hu', 'sr']",['text-generation'],['10K<n<100K']
LLaMAX/BenchMAX_Question_Answering,LLaMAX,2025-02-10 14:48:31+00:00,2025-03-19 07:48:39+00:00,41,0,"['task_categories:text-generation', 'multilinguality:multilingual', 'language:en', 'language:zh', 'language:es', 'language:fr', 'language:de', 'language:ru', 'language:ja', 'language:th', 'language:sw', 'language:te', 'language:bn', 'language:ar', 'language:ko', 'language:vi', 'language:cs', 'language:hu', 'language:sr', 'license:cc-by-4.0', 'size_categories:n<1K', 'format:json', 'modality:text', 'library:datasets', 'library:dask', 'library:mlcroissant', 'arxiv:2502.07346', 'region:us']","
	
		
		Dataset Sources
	


Paper: BenchMAX: A Comprehensive Multilingual Evaluation Suite for Large Language Models
Link: https://huggingface.co/papers/2502.07346
Repository: https://github.com/CONE-MT/BenchMAX


	
		
		Dataset Description
	

BenchMAX_Question_Answering is a dataset of BenchMAX for evaluating the long-context capability of LLMs in multilingual scenarios.
The subtasks are similar to the subtasks in RULER.
The data is sourcing from UN Parallel Corpus and xquad.
The haystacks… See the full description on the dataset page: https://huggingface.co/datasets/LLaMAX/BenchMAX_Question_Answering.",https://huggingface.co/datasets/LLaMAX/BenchMAX_Question_Answering,"['en', 'zh', 'es', 'fr', 'de', 'ru', 'ja', 'th', 'sw', 'te', 'bn', 'ar', 'ko', 'vi', 'cs', 'hu', 'sr']",['text-generation'],['n<1K']
LLaMAX/BenchMAX_Multiple_Functions,LLaMAX,2025-02-10 14:48:54+00:00,2025-03-19 07:58:17+00:00,480,0,"['task_categories:text-generation', 'multilinguality:multilingual', 'language:en', 'language:zh', 'language:es', 'language:fr', 'language:de', 'language:ru', 'language:ja', 'language:th', 'language:sw', 'language:te', 'language:bn', 'language:ar', 'language:ko', 'language:vi', 'language:cs', 'language:hu', 'language:sr', 'license:cc-by-4.0', 'size_categories:1K<n<10K', 'format:json', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'arxiv:2502.07346', 'region:us']","
	
		
		Dataset Sources
	


Paper: BenchMAX: A Comprehensive Multilingual Evaluation Suite for Large Language Models
Link: https://huggingface.co/papers/2502.07346
Repository: https://github.com/CONE-MT/BenchMAX


	
		
		Dataset Description
	

BenchMAX_Multiple_Functions is a dataset of BenchMAX, sourcing from Nexus.
This dataset evaluates the tool use capability in multilingual senarios, which requires a model to call the correct function given the user query and multiple functions.
We… See the full description on the dataset page: https://huggingface.co/datasets/LLaMAX/BenchMAX_Multiple_Functions.",https://huggingface.co/datasets/LLaMAX/BenchMAX_Multiple_Functions,"['en', 'zh', 'es', 'fr', 'de', 'ru', 'ja', 'th', 'sw', 'te', 'bn', 'ar', 'ko', 'vi', 'cs', 'hu', 'sr']",['text-generation'],['1K<n<10K']
LLaMAX/BenchMAX_General_Translation,LLaMAX,2025-02-10 14:49:14+00:00,2025-08-27 08:50:23+00:00,9888,0,"['task_categories:translation', 'multilinguality:multilingual', 'language:en', 'language:zh', 'language:es', 'language:fr', 'language:de', 'language:ru', 'language:ja', 'language:th', 'language:sw', 'language:te', 'language:bn', 'language:ar', 'language:ko', 'language:vi', 'language:cs', 'language:hu', 'language:sr', 'license:cc-by-4.0', 'size_categories:100K<n<1M', 'format:json', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'arxiv:2502.07346', 'region:us']","
	
		
		Dataset Sources
	


Paper: BenchMAX: A Comprehensive Multilingual Evaluation Suite for Large Language Models
Link: https://huggingface.co/papers/2502.07346
Repository: https://github.com/CONE-MT/BenchMAX


	
		
		Dataset Description
	

BenchMAX_General_Translation is a dataset of BenchMAX, which evaluates the translation capability on the general domain.
We collect parallel test data from Flore-200, TED-talk, and WMT24.

	
		
	
	
		Usage
	

Run the following commands to generate… See the full description on the dataset page: https://huggingface.co/datasets/LLaMAX/BenchMAX_General_Translation.",https://huggingface.co/datasets/LLaMAX/BenchMAX_General_Translation,"['en', 'zh', 'es', 'fr', 'de', 'ru', 'ja', 'th', 'sw', 'te', 'bn', 'ar', 'ko', 'vi', 'cs', 'hu', 'sr']",['translation'],['100K<n<1M']
LLaMAX/BenchMAX_Domain_Translation,LLaMAX,2025-02-10 14:49:23+00:00,2025-03-19 07:53:38+00:00,919,0,"['task_categories:translation', 'multilinguality:multilingual', 'language:en', 'language:zh', 'language:es', 'language:fr', 'language:de', 'language:ru', 'language:ja', 'language:th', 'language:sw', 'language:te', 'language:bn', 'language:ar', 'language:ko', 'language:vi', 'language:cs', 'language:hu', 'language:sr', 'license:cc-by-4.0', 'size_categories:10K<n<100K', 'format:json', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'arxiv:2502.07346', 'region:us']","
	
		
		Dataset Sources
	


Paper: BenchMAX: A Comprehensive Multilingual Evaluation Suite for Large Language Models
Link: https://huggingface.co/papers/2502.07346
Repository: https://github.com/CONE-MT/BenchMAX


	
		
		Dataset Description
	

BenchMAX_Domain_Translation is a dataset of BenchMAX, which evaluates the translation capability on specific domains.
We collect the domain multi-way parallel data from other tasks in BenchMAX, such as math data, code data, etc.
Each sample contains one… See the full description on the dataset page: https://huggingface.co/datasets/LLaMAX/BenchMAX_Domain_Translation.",https://huggingface.co/datasets/LLaMAX/BenchMAX_Domain_Translation,"['en', 'zh', 'es', 'fr', 'de', 'ru', 'ja', 'th', 'sw', 'te', 'bn', 'ar', 'ko', 'vi', 'cs', 'hu', 'sr']",['translation'],['10K<n<100K']
hpprc/r1-distill-qwen-pseudo-qa-taste,hpprc,2025-02-11 06:09:29+00:00,2025-02-12 02:18:50+00:00,12,0,"['task_categories:question-answering', 'language:ja', 'license:cc-by-sa-4.0', 'size_categories:10K<n<100K', 'format:parquet', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us', 'synthetic']",,https://huggingface.co/datasets/hpprc/r1-distill-qwen-pseudo-qa-taste,['ja'],['question-answering'],['10K<n<100K']
CausalLM/Retrieval-SFT-Chat,CausalLM,2025-02-11 14:41:46+00:00,2025-02-14 22:09:30+00:00,30,53,"['task_categories:question-answering', 'task_categories:text-generation', 'language:en', 'language:zh', 'language:ja', 'language:de', 'license:wtfpl', 'size_categories:100K<n<1M', 'format:json', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us', 'synthetic']","
	
		
		Retrieval-Based Multi-Turn Chat SFT Synthetic Data
	

A year ago, we released CausalLM/Refined-Anime-Text, a thematic subset of a dataset generated using the then state-of-the-art LLMs. This dataset comprises 1 million entries synthesized through long-context models that rewrote multi-document web text inputs, intended for continued pre-training. We are pleased to note that this data has been employed in various training scenarios and in studies concerning data and internet culture.
In… See the full description on the dataset page: https://huggingface.co/datasets/CausalLM/Retrieval-SFT-Chat.",https://huggingface.co/datasets/CausalLM/Retrieval-SFT-Chat,"['en', 'zh', 'ja', 'de']","['question-answering', 'text-generation']",['100K<n<1M']
taishi-i/awesome-japanese-nlp-multilabel-dataset,taishi-i,2025-02-11 15:50:35+00:00,2025-03-04 16:55:36+00:00,20,0,"['task_categories:text-classification', 'task_categories:multiple-choice', 'language:en', 'language:ja', 'license:other', 'size_categories:n<1K', 'format:parquet', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us', 'code', 'annotations']","
	
		
		Dataset overview
	

This is a dataset for Japanese natural language processing with multi-label annotations of research field labels for GitHub repositories in the NLP domain.
Please refer to this paper for the specific method of constructing the dataset. It is written in Japanese.
Input and Output

Input: Information from GitHub repositories (description, README text, PDF text, screenshot images)
Output: Multi-label classification of NLP research fields

Problem Setting of the… See the full description on the dataset page: https://huggingface.co/datasets/taishi-i/awesome-japanese-nlp-multilabel-dataset.",https://huggingface.co/datasets/taishi-i/awesome-japanese-nlp-multilabel-dataset,"['en', 'ja']","['text-classification', 'multiple-choice']",['n<1K']
hpprc/jawiki-bullet-points,hpprc,2025-02-12 02:10:19+00:00,2025-02-17 07:36:28+00:00,26,4,"['language:ja', 'license:cc-by-sa-4.0', 'size_categories:1M<n<10M', 'format:parquet', 'modality:text', 'library:datasets', 'library:dask', 'library:mlcroissant', 'library:polars', 'region:us']","日本語Wikipediaから抽出したテキストに基づいて、rinna/deepseek-r1-distill-qwen2.5-bakeneko-32bとhttps://huggingface.co/cyberagent/DeepSeek-R1-Distill-Qwen-32B-Japaneseを用いて箇条書きにしたデータセットです。
重複を許してランダムにサンプリングしながら生成をしたので、collection subsetにある事例がgenerated subsetに無い場合があります。
また、HF上のviewerでは改行や空白がうまく見えませんが、実際にはほとんどの箇条書きの要素が改行で区切られています。
生成に用いたモデルがApache 2.0で配布されていること、日本語Wikipediaのテキストを用いていることから、本データセットはCC-BY-SA 4.0での配布とします。
",https://huggingface.co/datasets/hpprc/jawiki-bullet-points,['ja'],[],['1M<n<10M']
ash56/ShiftySpeech,ash56,2025-02-12 23:32:24+00:00,2025-10-06 18:11:58+00:00,361,2,"['language:en', 'language:zh', 'language:ja', 'license:apache-2.0', 'size_categories:1M<n<10M', 'format:webdataset', 'modality:audio', 'modality:text', 'library:datasets', 'library:webdataset', 'library:mlcroissant', 'arxiv:2502.05674', 'region:us', 'audio', 'synthetic-speech-detection']","This repository introduces:  🌀 ShiftySpeech: A Large-Scale Synthetic Speech Dataset with Distribution Shifts

	
		
		🔥 Key Features
	


3000+ hours of synthetic speech
Diverse Distribution Shifts: The dataset spans 7 key distribution shifts, including:  
📖 Reading Style  
🎙️ Podcast  
🎥 YouTube  
🗣️ Languages (Three different languages)  
🌎 Demographics (including variations in age, accent, and gender)


Multiple Speech Generation Systems: Includes data synthesized from various TTS… See the full description on the dataset page: https://huggingface.co/datasets/ash56/ShiftySpeech.",https://huggingface.co/datasets/ash56/ShiftySpeech,"['en', 'zh', 'ja']",[],['1M<n<10M']
cyberagent/AdParaphrase,cyberagent,2025-02-13 06:33:46+00:00,2025-02-19 02:12:19+00:00,18,1,"['language:ja', 'license:cc-by-nc-sa-4.0', 'size_categories:1K<n<10K', 'format:parquet', 'modality:tabular', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'arxiv:2502.04674', 'arxiv:2408.05906', 'region:us', 'advertisement', 'advertising', 'paraphrase', 'human preference']","
	
		
		Dataset Card for AdParaphrase
	

This repository contains data for our paper ""AdParaphrase: Paraphrase Dataset for Analyzing Linguistic Features toward Generating Attractive Ad Texts"" (NAACL2025 Findings).

	
		
		Overview
	

AdParaphrase is a novel paraphrase dataset that contains human preferences for pairs of ad texts that are semantically equivalent but differ in wording and style. We carefully constructed the dataset by collecting semantically similar ad texts, performing… See the full description on the dataset page: https://huggingface.co/datasets/cyberagent/AdParaphrase.",https://huggingface.co/datasets/cyberagent/AdParaphrase,['ja'],[],['1K<n<10K']
Multilingual-NLP/M-ABSA,Multilingual-NLP,2025-02-13 08:02:18+00:00,2025-05-24 08:46:49+00:00,426,8,"['task_categories:token-classification', 'task_categories:text-classification', 'language:ar', 'language:da', 'language:de', 'language:en', 'language:es', 'language:fr', 'language:hi', 'language:hr', 'language:id', 'language:ja', 'language:ko', 'language:nl', 'language:pt', 'language:ru', 'language:sk', 'language:sv', 'language:sw', 'language:th', 'language:tr', 'language:vi', 'language:zh', 'license:apache-2.0', 'size_categories:100K<n<1M', 'format:text', 'modality:text', 'library:datasets', 'library:mlcroissant', 'arxiv:2502.11824', 'region:us', 'aspect-based-sentiment-analysis']","
	
		
		M-ABSA
	

This repo contains the data for our paper M-ABSA: A Multilingual Dataset for Aspect-Based Sentiment Analysis.


	
		
		Data Description:
	

This is a dataset suitable for the multilingual ABSA task with triplet extraction.
All datasets are stored in the data/ folder:

All dataset contains 7 domains.

domains = [""coursera"", ""hotel"", ""laptop"", ""restaurant"", ""phone"", ""sight"", ""food""]


Each dataset contains 21 languages.

langs = [""ar"", ""da"", ""de"", ""en"", ""es"", ""fr"", ""hi"", ""hr""… See the full description on the dataset page: https://huggingface.co/datasets/Multilingual-NLP/M-ABSA.",https://huggingface.co/datasets/Multilingual-NLP/M-ABSA,"['ar', 'da', 'de', 'en', 'es', 'fr', 'hi', 'hr', 'id', 'ja', 'ko', 'nl', 'pt', 'ru', 'sk', 'sv', 'sw', 'th', 'tr', 'vi', 'zh']","['token-classification', 'text-classification']",['100K<n<1M']
Sakalti/RolePlay-v1,Sakalti,2025-02-13 11:25:59+00:00,2025-02-13 11:32:38+00:00,11,0,"['language:ja', 'license:apache-2.0', 'size_categories:n<1K', 'format:csv', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","https://chatgpt.com
",https://huggingface.co/datasets/Sakalti/RolePlay-v1,['ja'],[],['n<1K']
puwaer/dmm-fanza-jp-v1,puwaer,2025-02-14 04:01:45+00:00,2025-02-14 04:14:50+00:00,10,3,"['task_categories:text-generation', 'task_categories:fill-mask', 'language:ja', 'license:cc-by-sa-3.0', 'license:gfdl', 'size_categories:1M<n<10M', 'format:json', 'modality:text', 'library:datasets', 'library:dask', 'library:mlcroissant', 'region:us', 'not-for-all-audiences']","
	
		
		puwaer/dmm-fanza-jp-v1
	

This dataset consists of text extracted exclusively in Japanese from dmm.co.jp(fanza) and is structured as JSON files. The files are categorized based on the type of URL.
このデータセットは、dmm.co.jp(fanza)より日本語データのみを抽出したテキストで、jsonファイルで構成されます。
urlの種類によってファイル分けされています。
",https://huggingface.co/datasets/puwaer/dmm-fanza-jp-v1,['ja'],"['text-generation', 'fill-mask']",['1M<n<10M']
puwaer/dlsite-jp-v1,puwaer,2025-02-14 04:06:08+00:00,2025-02-23 12:37:48+00:00,13,2,"['task_categories:text-generation', 'task_categories:fill-mask', 'language:ja', 'license:cc-by-sa-3.0', 'license:gfdl', 'size_categories:1M<n<10M', 'format:json', 'modality:text', 'library:datasets', 'library:dask', 'library:mlcroissant', 'region:us', 'not-for-all-audiences']","
	
		
		puwaer/dlsite-jp-v1
	

This dataset consists of text extracted exclusively in Japanese from dlsite.com and is structured as JSON files. The files are categorized based on the type of URL.
このデータセットは、dlsite.comより日本語データのみを抽出したテキストで、jsonファイルで構成されます。
urlの種類によってファイル分けされています。
",https://huggingface.co/datasets/puwaer/dlsite-jp-v1,['ja'],"['text-generation', 'fill-mask']",['1M<n<10M']
EQUES/Nayose-Bench-Instruction,EQUES,2025-02-16 13:12:09+00:00,2025-03-08 07:29:00+00:00,30,0,"['task_categories:question-answering', 'language:ja', 'license:cc-by-sa-4.0', 'size_categories:10K<n<100K', 'format:json', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","
	
		
		Dataset Card for Nayose-Bench-Instruction
	

This dataset was created as a benchmark for the entity resolution task in the pharmaceutical domain.

	
		
		Dataset Details
	

This dataset is designed for the entity resolution task in the pharmaceutical domain.
The entity resolution task refers to a paraphrasing task, such as rephrasing drug names, converting chemical substances into brand names, or rewriting chemical substances into chemical formulas.

	
		
		Uses
	

from datasets import… See the full description on the dataset page: https://huggingface.co/datasets/EQUES/Nayose-Bench-Instruction.",https://huggingface.co/datasets/EQUES/Nayose-Bench-Instruction,['ja'],['question-answering'],['10K<n<100K']
ayousanz/vtuber-youtube-list-dataset,ayousanz,2025-02-16 15:41:14+00:00,2025-02-17 07:55:47+00:00,12,0,"['task_categories:text-classification', 'annotations_creators:no-annotation', 'multilinguality:multilingual', 'source_datasets:original', 'language:ja', 'language:en', 'license:mit', 'size_categories:1K<n<10K', 'format:json', 'modality:text', 'library:datasets', 'library:dask', 'library:mlcroissant', 'region:us']","
	
		
		VTuber YouTube Channel List Dataset
	

このデータセットは、VTuber チャンネルと VTuber でない（例：料理チャンネルなど）の YouTube チャンネルのメタデータを JSONL 形式でまとめたものです。各レコードは以下のフィールドを含んでいます：

channel_id: YouTube チャンネルの固有 ID
title: チャンネルのタイトル
description: チャンネルの説明文
text: タイトルと説明文を連結したテキスト（モデルの入力用に利用できます）
label: バイナリラベル（VTuber の場合は 1、非VTuber の場合は 0）


	
		
	
	
		データセットの概要
	


目的: このデータセットは、テキスト分類タスクにおいて VTuber チャンネルかどうかを判定するモデルの学習および評価に利用できます。
言語: 主に日本語ですが、一部英語やその他の言語の記述も含まれる可能性があります。
ライセンス: MIT License


	
	
	
		使用上の注意点… See the full description on the dataset page: https://huggingface.co/datasets/ayousanz/vtuber-youtube-list-dataset.",https://huggingface.co/datasets/ayousanz/vtuber-youtube-list-dataset,"['ja', 'en']",['text-classification'],['1K<n<10K']
hotchpotch/fineweb-2-japanese-noise-spans,hotchpotch,2025-02-17 00:13:09+00:00,2025-02-20 00:32:44+00:00,13,0,"['language:ja', 'license:odc-by', 'size_categories:100K<n<1M', 'format:parquet', 'modality:text', 'library:datasets', 'library:dask', 'library:mlcroissant', 'library:polars', 'region:us']","
	
		
		fineweb-2-japanese-noise-spans
	

このデータセットは、FineWeb2 の日本語データから、Web特有のノイズ箇所を判定したデータセットです。trainに約30万件、testに3万件のデータが含まれます。
ノイズ判定はLLMが行っており、cyberagent/DeepSeek-R1-Distill-Qwen-32B-Japaneseを利用して作成しました。

	
		
		ノイズ判定プロンプト
	

入力されたWebスクレイピング文から、タイトルと本文のみを抽出するために、それ以外のノイズ文章箇所を判定します。入力文はタイトル・本文以外に、ナビゲーション・ヘッダ・フッタ・広告・URL・記事作成日時・システムメッセージ・「これは90日間記事に更新がない場合表示されます」など、余計なノイズと判定される文章が含まれることがあります。ノイズ判定は、一行ごとに行うこと。注意深く文章を読んで、ノイズかどうかを吟味しなさい。

ノイズの該当箇所は、以下の厳密な JSON… See the full description on the dataset page: https://huggingface.co/datasets/hotchpotch/fineweb-2-japanese-noise-spans.",https://huggingface.co/datasets/hotchpotch/fineweb-2-japanese-noise-spans,['ja'],[],['100K<n<1M']
epfml/FineWeb2-HQ,epfml,2025-02-17 09:55:30+00:00,2025-02-19 21:39:01+00:00,36001,31,"['task_categories:text-generation', 'language:ru', 'language:zh', 'language:de', 'language:ja', 'language:es', 'language:fr', 'language:it', 'language:pt', 'language:pl', 'language:nl', 'language:id', 'language:tr', 'language:cs', 'language:vi', 'language:sv', 'language:fa', 'language:ar', 'language:el', 'language:da', 'language:hu', 'license:odc-by', 'size_categories:100M<n<1B', 'format:parquet', 'modality:tabular', 'modality:text', 'library:datasets', 'library:dask', 'library:mlcroissant', 'library:polars', 'arxiv:2502.10361', 'region:us']","
	
		
		FineWeb2-HQ
	


	
		
		Dataset summary
	

FineWeb2-HQ is a high-quality, model-filtered pretraining dataset derived as a subset of FineWeb2, spanning 20 languages. It enables around 6x faster pretraining compared to the base dataset. FineWeb2-HQ was created by selecting the top 10% quality documents of FineWeb2 in each language, based on scores assigned by a deep learning classifier trained to identify structured and knowledge-rich samples using XLM-RoBERTa embeddings.

  


Validation… See the full description on the dataset page: https://huggingface.co/datasets/epfml/FineWeb2-HQ.",https://huggingface.co/datasets/epfml/FineWeb2-HQ,"['ru', 'zh', 'de', 'ja', 'es', 'fr', 'it', 'pt', 'pl', 'nl', 'id', 'tr', 'cs', 'vi', 'sv', 'fa', 'ar', 'el', 'da', 'hu']",['text-generation'],['100M<n<1B']
epfml/FineWeb2-embedded,epfml,2025-02-17 18:18:25+00:00,2025-02-19 14:32:51+00:00,1755,4,"['task_categories:text-generation', 'language:ru', 'language:zh', 'language:de', 'language:ja', 'language:es', 'language:fr', 'language:it', 'language:pt', 'language:pl', 'language:nl', 'language:id', 'language:tr', 'language:cs', 'language:vi', 'language:sv', 'language:fa', 'language:ar', 'language:el', 'language:da', 'language:hu', 'license:odc-by', 'size_categories:1B<n<10B', 'format:parquet', 'modality:tabular', 'modality:text', 'library:datasets', 'library:dask', 'library:mlcroissant', 'library:polars', 'arxiv:2502.10361', 'region:us']","
	
		
		FineWeb2-embedded
	


	
		
		Dataset summary
	

FineWeb2-embedded is an extension of the FineWeb2 dataset, annotated with document-level XLM-RoBERTa embeddings for 20 languages, making the dataset useful for a variety of tasks, including document clustering, filtering, and other multilingual research.
Since XLM-RoBERTa has a sequence length limit of 512 tokens, each document's embeddings are obtained by mean-pooling 512 token chunks of the XLM-RoBERTa output. Therefore, longer texts… See the full description on the dataset page: https://huggingface.co/datasets/epfml/FineWeb2-embedded.",https://huggingface.co/datasets/epfml/FineWeb2-embedded,"['ru', 'zh', 'de', 'ja', 'es', 'fr', 'it', 'pt', 'pl', 'nl', 'id', 'tr', 'cs', 'vi', 'sv', 'fa', 'ar', 'el', 'da', 'hu']",['text-generation'],['1B<n<10B']
Mattimax/DATA-AI_Chat,Mattimax,2025-02-17 19:47:42+00:00,2025-02-24 17:23:48+00:00,21,1,"['language:it', 'language:en', 'language:es', 'language:ru', 'language:de', 'language:pl', 'language:th', 'language:vi', 'language:sv', 'language:bn', 'language:da', 'language:he', 'language:fa', 'language:sk', 'language:id', 'language:nb', 'language:el', 'language:nl', 'language:hu', 'language:eu', 'language:zh', 'language:eo', 'language:ja', 'language:ca', 'language:cs', 'language:bg', 'language:fi', 'language:pt', 'language:tr', 'language:ro', 'language:ar', 'language:uk', 'language:gl', 'language:fr', 'language:ko', 'license:apache-2.0', 'size_categories:1K<n<10K', 'format:csv', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us', 'human-feedback', 'llama-2']","
	
		
		DATA-AI: Il Modello di IA di M.INC.
	


	
		
		📌 Introduzione
	

DATA-AI è un avanzato modello di intelligenza artificiale sviluppato da *M.INC., un'azienda italiana fondata da *Mattimax (M. Marzorati).Questo modello è basato sull'architettura ELNS (Elaborazione del Linguaggio Naturale Semplice), un sistema innovativo progettato per rendere l'IA accessibile su quasi qualsiasi dispositivo, garantendo prestazioni ottimali anche su hardware limitato.  
DATA-AI è stato addestrato su un… See the full description on the dataset page: https://huggingface.co/datasets/Mattimax/DATA-AI_Chat.",https://huggingface.co/datasets/Mattimax/DATA-AI_Chat,"['it', 'en', 'es', 'ru', 'de', 'pl', 'th', 'vi', 'sv', 'bn', 'da', 'he', 'fa', 'sk', 'id', 'nb', 'el', 'nl', 'hu', 'eu', 'zh', 'eo', 'ja', 'ca', 'cs', 'bg', 'fi', 'pt', 'tr', 'ro', 'ar', 'uk', 'gl', 'fr', 'ko']",[],['1K<n<10K']
ToxicityPrompts/PolyGuardMix,ToxicityPrompts,2025-02-18 06:58:07+00:00,2025-06-23 21:39:12+00:00,553,2,"['language:ar', 'language:zh', 'language:cs', 'language:nl', 'language:en', 'language:fr', 'language:de', 'language:hi', 'language:th', 'language:it', 'language:ja', 'language:ko', 'language:pl', 'language:pt', 'language:ru', 'language:es', 'language:sv', 'license:cc-by-4.0', 'size_categories:1M<n<10M', 'format:parquet', 'modality:text', 'library:datasets', 'library:dask', 'library:mlcroissant', 'library:polars', 'arxiv:2504.04377', 'region:us', 'safety', 'multilingual']","
	
		
		PolyGuard: A Multilingual Safety Moderation Tool for 17 Languages
	

Abstract: Truly multilingual safety moderation efforts for Large Language Models (LLMs) have been hindered by a narrow focus on a small set of languages (e.g., English, Chinese) as well as a limited scope of safety definition, resulting in significant gaps in moderation capabilities. To bridge these gaps, we release PolyGuard, a new state-of-the-art multilingual safety model for safeguarding LLM generations, and the… See the full description on the dataset page: https://huggingface.co/datasets/ToxicityPrompts/PolyGuardMix.",https://huggingface.co/datasets/ToxicityPrompts/PolyGuardMix,"['ar', 'zh', 'cs', 'nl', 'en', 'fr', 'de', 'hi', 'th', 'it', 'ja', 'ko', 'pl', 'pt', 'ru', 'es', 'sv']",[],['1M<n<10M']
ToxicityPrompts/PolyGuardPrompts,ToxicityPrompts,2025-02-18 07:01:18+00:00,2025-06-23 21:37:19+00:00,249,1,"['language:ar', 'language:zh', 'language:cs', 'language:nl', 'language:en', 'language:fr', 'language:de', 'language:hi', 'language:th', 'language:it', 'language:ja', 'language:ko', 'language:pl', 'language:pt', 'language:ru', 'language:es', 'language:sv', 'license:cc-by-4.0', 'size_categories:10K<n<100K', 'format:parquet', 'modality:tabular', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'arxiv:2504.04377', 'region:us', 'safety', 'multilingual']","
	
		
		PolyGuard: A Multilingual Safety Moderation Tool for 17 Languages
	

Abstract: Truly multilingual safety moderation efforts for Large Language Models (LLMs) have been hindered by a narrow focus on a small set of languages (e.g., English, Chinese) as well as a limited scope of safety definition, resulting in significant gaps in moderation capabilities. To bridge these gaps, we release PolyGuard, a new state-of-the-art multilingual safety model for safeguarding LLM generations, and the… See the full description on the dataset page: https://huggingface.co/datasets/ToxicityPrompts/PolyGuardPrompts.",https://huggingface.co/datasets/ToxicityPrompts/PolyGuardPrompts,"['ar', 'zh', 'cs', 'nl', 'en', 'fr', 'de', 'hi', 'th', 'it', 'ja', 'ko', 'pl', 'pt', 'ru', 'es', 'sv']",[],['10K<n<100K']
ayousanz/moe-speech-plus,ayousanz,2025-02-18 09:47:15+00:00,2025-07-08 07:21:32+00:00,26,6,"['task_categories:text-to-speech', 'task_categories:audio-to-audio', 'task_categories:audio-classification', 'task_ids:speaker-identification', 'multilinguality:monolingual', 'language:ja', 'license:other', 'size_categories:100K<n<1M', 'modality:audio', 'region:us', 'speech', 'audio', 'japanese', 'anime', 'voice', 'not-for-all-audiences']","
	
		
		MoeSpeechPlus
	


MoeSpeechのデータセットに以下のデータ処理を行ったデータセット

追加情報

anime-whisperによる文字お越し
parakeetによる文字お越し
speechMOS (UTMOS v2 (T05)を使用)
音声の長さ
microsoft/deberta-v3-largeによる感情判定
litagin/anime_speech_emotion_classificationによる感情判定
Qwen/Qwen2-Audio-7B-Instructによる感情判定

{
  ""parakeet_jp_transcription"": ""昨夜からずっと気配を探られていたか。"",
  ""anime_whisper_transcription"": ""昨夜からずっと気配を探られていたか…"",
  ""duration"": 3.722018140589569,
  ""speechMOS"": 2.294760227203369,
  ""DeBERTa_Sentiment"": {
    ""悲しみ"": 0.12533913552761078… See the full description on the dataset page: https://huggingface.co/datasets/ayousanz/moe-speech-plus.",https://huggingface.co/datasets/ayousanz/moe-speech-plus,['ja'],"['text-to-speech', 'audio-to-audio', 'audio-classification']",['100K<n<1M']
6DammK9/danbooru2024-captions-1ktar,6DammK9,2025-02-18 12:48:55+00:00,2025-02-18 15:04:12+00:00,118,3,"['task_categories:image-classification', 'task_categories:zero-shot-image-classification', 'task_categories:text-to-image', 'annotations_creators:no-annotation', 'source_datasets:danbooru', 'language:en', 'language:ja', 'license:mit', 'size_categories:1M<n<10M', 'region:us', 'art', 'anime', 'not-for-all-audiences']","
	
		
		Danbooru 2024 captions only in 1k tar
	


Raw captions jointed by 7.62M unpublished extended dataset from KBlueLeaf/danbooru2023-metadata-database and 0.48M generated dataset via Minthy/ToriiGate-v0.4-7B in exl2-8bpw mode. There are 8.13M in total.

python convert_meta_to_tar.py
Reading source JSON
Keys count: 8136011
max id: 8360499
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1000/1000… See the full description on the dataset page: https://huggingface.co/datasets/6DammK9/danbooru2024-captions-1ktar.",https://huggingface.co/datasets/6DammK9/danbooru2024-captions-1ktar,"['en', 'ja']","['image-classification', 'zero-shot-image-classification', 'text-to-image']",['1M<n<10M']
sapienzanlp/ea-mt-benchmark,sapienzanlp,2025-02-18 13:50:20+00:00,2025-02-18 14:24:03+00:00,91,4,"['task_categories:text-generation', 'language:en', 'language:ar', 'language:de', 'language:es', 'language:fr', 'language:it', 'language:ja', 'language:ko', 'language:th', 'language:tr', 'language:zh', 'license:cc-by-sa-4.0', 'size_categories:10K<n<100K', 'format:json', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","
	
		
		Dataset Card for EA-MT
	

EA-MT (Entity-Aware Machine Translation) is a multilingual benchmark for evaluating the capabilities of Large Language Models (LLMs) and Machine Translation (MT) models in translating simple sentences with potentially challenging entity mentions, e.g., entities for which a word-for-word translation may not be accurate.
Here is an example of a simple sentence with a challenging entity mention:

English: ""What is the plot of The Catcher in the Rye?""
Italian:… See the full description on the dataset page: https://huggingface.co/datasets/sapienzanlp/ea-mt-benchmark.",https://huggingface.co/datasets/sapienzanlp/ea-mt-benchmark,"['en', 'ar', 'de', 'es', 'fr', 'it', 'ja', 'ko', 'th', 'tr', 'zh']",['text-generation'],['10K<n<100K']
EQUES/Nayose-Bench-QA,EQUES,2025-02-18 19:20:01+00:00,2025-03-08 07:28:28+00:00,31,0,"['task_categories:question-answering', 'language:ja', 'license:cc-by-sa-4.0', 'size_categories:10K<n<100K', 'format:json', 'modality:tabular', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","
	
		
		Dataset Card for Nayose-Bench-Instruction
	

This dataset was created as a benchmark for the entity resolution task in the pharmaceutical domain.

	
		
		Dataset Details
	

This dataset is designed for the entity resolution task in the pharmaceutical domain.
The entity resolution task refers to a paraphrasing task, such as rephrasing drug names, converting chemical substances into brand names, or rewriting chemical substances into chemical formulas.

	
		
		Uses
	

from datasets import… See the full description on the dataset page: https://huggingface.co/datasets/EQUES/Nayose-Bench-QA.",https://huggingface.co/datasets/EQUES/Nayose-Bench-QA,['ja'],['question-answering'],['10K<n<100K']
EQUES/japanese_ultrachat_6.6k,EQUES,2025-02-18 23:50:59+00:00,2025-02-19 05:58:20+00:00,16,2,"['task_categories:translation', 'language:ja', 'license:apache-2.0', 'size_categories:1K<n<10K', 'format:parquet', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","
	
		
		Japanese Ultrachat 6.6k
	

Japanese Ultrachat 6.6k is the Japanese-translated version of the subset of ultrachat_200k using machine translation.
Japanese Ultrachat 6.6kはultrachat_200kの一部分を機械翻訳により和訳したデータセットです. 

	
		
	
	
		The number of data
	


Train split : 6537
Test split : 995

To be updated.

	
		
	
	
		Notes
	


Beware that the columns 'id' corresponds to the original dataset. Some are missing for now.


	
		
	
	
		Method
	

We used… See the full description on the dataset page: https://huggingface.co/datasets/EQUES/japanese_ultrachat_6.6k.",https://huggingface.co/datasets/EQUES/japanese_ultrachat_6.6k,['ja'],['translation'],['1K<n<10K']
hotchpotch/fineweb-2-edu-japanese,hotchpotch,2025-02-19 00:52:30+00:00,2025-05-09 23:50:03+00:00,1187,20,"['language:ja', 'license:odc-by', 'size_categories:100M<n<1B', 'format:parquet', 'modality:tabular', 'modality:text', 'library:datasets', 'library:dask', 'library:mlcroissant', 'library:polars', 'region:us']","
	
		
		🍷 FineWeb2 Edu Japanese: High-Quality Educational Japanese Dataset
	


This dataset consists of 120 million texts (approximately 89.3B tokens) filtered from the 376 million Japanese texts in FineWeb2 that were deemed educational. The following subsets are also provided:

default: Approximately 120M texts (120 million texts) totaling around 89.3B tokens
sample_10BT: A random sample of about 10B tokens from the default dataset
small_tokens: Data composed solely of texts with 512 tokens… See the full description on the dataset page: https://huggingface.co/datasets/hotchpotch/fineweb-2-edu-japanese.",https://huggingface.co/datasets/hotchpotch/fineweb-2-edu-japanese,['ja'],[],['100M<n<1B']
sionic-ai/LogicJa,sionic-ai,2025-02-19 02:34:06+00:00,2025-02-19 07:33:20+00:00,9,0,"['task_categories:text-generation', 'task_categories:question-answering', 'language:ja', 'license:apache-2.0', 'size_categories:10K<n<100K', 'region:us']","
	
		
		LogicJa Dataset Card
	


	
		
		Overview
	

LogicJa is a multi-turn benchmark designed to assess the reasoning capabilities of Japanese language models across multiple domains. This dataset consists of 105 multi-turn tasks (each containing two questions) for a total of 210 questions. Each category has 30 questions to ensure statistical significance.

	
		
Category
Reasoning
Math
Writing
Coding
Understanding
Grammar
Culture
Total


		
Multi-turn Tasks
15
15
15
15
15
15
15
105… See the full description on the dataset page: https://huggingface.co/datasets/sionic-ai/LogicJa.",https://huggingface.co/datasets/sionic-ai/LogicJa,['ja'],"['text-generation', 'question-answering']",['10K<n<100K']
Youseff1987/multilingual_translation_gpt4o_gen,Youseff1987,2025-02-19 09:02:05+00:00,2025-03-01 20:52:26+00:00,28,2,"['task_categories:translation', 'language:ko', 'language:en', 'language:zh', 'language:zu', 'language:ja', 'language:am', 'language:ar', 'language:es', 'language:fr', 'language:ru', 'language:de', 'language:it', 'language:pt', 'language:nl', 'language:sv', 'language:tr', 'language:id', 'language:vi', 'language:pl', 'language:cs', 'language:ro', 'language:uk', 'language:hu', 'language:sl', 'language:el', 'language:fi', 'language:no', 'language:da', 'language:bg', 'language:hi', 'language:he', 'language:ms', 'language:ta', 'language:te', 'language:pa', 'language:bn', 'language:fa', 'language:sw', 'language:th', 'language:sr', 'language:hr', 'language:ca', 'language:is', 'language:lv', 'language:lt', 'language:sk', 'language:et', 'language:mn', 'language:la', 'language:my', 'language:tl', 'language:jv', 'language:mr', 'language:gu', 'language:ps', 'language:sd', 'language:kn', 'language:ml', 'language:ha', 'language:yo', 'language:ig', 'language:ber', 'license:mit', 'size_categories:1M<n<10M', 'format:parquet', 'modality:tabular', 'modality:text', 'library:datasets', 'library:dask', 'library:mlcroissant', 'library:polars', 'region:us']",,https://huggingface.co/datasets/Youseff1987/multilingual_translation_gpt4o_gen,"['ko', 'en', 'zh', 'zu', 'ja', 'am', 'ar', 'es', 'fr', 'ru', 'de', 'it', 'pt', 'nl', 'sv', 'tr', 'id', 'vi', 'pl', 'cs', 'ro', 'uk', 'hu', 'sl', 'el', 'fi', 'no', 'da', 'bg', 'hi', 'he', 'ms', 'ta', 'te', 'pa', 'bn', 'fa', 'sw', 'th', 'sr', 'hr', 'ca', 'is', 'lv', 'lt', 'sk', 'et', 'mn', 'la', 'my', 'tl', 'jv', 'mr', 'gu', 'ps', 'sd', 'kn', 'ml', 'ha', 'yo', 'ig', 'ber']",['translation'],['1M<n<10M']
hotchpotch/fineweb-2-edu-japanese-noise-detect-raw,hotchpotch,2025-02-19 23:08:15+00:00,2025-02-20 02:03:34+00:00,62,0,"['language:ja', 'license:odc-by', 'size_categories:10M<n<100M', 'format:parquet', 'modality:tabular', 'modality:text', 'library:datasets', 'library:dask', 'library:mlcroissant', 'library:polars', 'region:us']","fineweb-2-edu-japanese の small_tokens の text カラムをユニコード正規化(NFKC)したものを fineweb-2-japanese-text-cleaner を使ってノイズ箇所を推論したRAWデータセットです。
このデータセットで、ノイズ文字列を削除したのものを、fineweb-2-edu-japaneseのsmall_tokens_cleanedサブセットとして公開しています。
推論時のパラメータは閾値0.7以上かつノイズの文字列長4文字以上のものを、noise_spans カラムに付与しています。noise_spans は start_pos, end_pos のペアとなってます。

	
		
	
	
		ライセンス
	

ODC-By
",https://huggingface.co/datasets/hotchpotch/fineweb-2-edu-japanese-noise-detect-raw,['ja'],[],['10M<n<100M']
nyuuzyou/fandom,nyuuzyou,2025-02-20 18:01:37+00:00,2025-02-20 18:05:35+00:00,188,8,"['task_categories:text-generation', 'task_categories:text-classification', 'task_ids:language-modeling', 'task_ids:topic-classification', 'annotations_creators:found', 'multilinguality:multilingual', 'source_datasets:original', 'language:ar', 'language:bg', 'language:ca', 'language:cs', 'language:da', 'language:de', 'language:el', 'language:en', 'language:es', 'language:et', 'language:fa', 'language:fi', 'language:fr', 'language:he', 'language:hi', 'language:hr', 'language:hu', 'language:id', 'language:it', 'language:ja', 'language:ko', 'language:lt', 'language:lv', 'language:ms', 'language:nl', 'language:no', 'language:pl', 'language:pt', 'language:ro', 'language:ru', 'language:sk', 'language:sl', 'language:sr', 'language:sv', 'language:th', 'language:tr', 'language:uk', 'language:vi', 'language:zh', 'license:cc-by-sa-3.0', 'region:us']","
	
		
		Dataset Card for Fandom.com Community Database Dumps
	


	
		
		Dataset Summary
	

This dataset contains 7,040,984 current pages from all available Fandom.com community wiki dumps as of February 18, 2025. The dataset was created by processing the ""Current pages"" database dumps from all available Fandom.com wikis. These dumps contain only the current versions of pages without edit history and includes article text, metadata, and structural information across multiple languages.… See the full description on the dataset page: https://huggingface.co/datasets/nyuuzyou/fandom.",https://huggingface.co/datasets/nyuuzyou/fandom,"['ar', 'bg', 'ca', 'cs', 'da', 'de', 'el', 'en', 'es', 'et', 'fa', 'fi', 'fr', 'he', 'hi', 'hr', 'hu', 'id', 'it', 'ja', 'ko', 'lt', 'lv', 'ms', 'nl', 'no', 'pl', 'pt', 'ro', 'ru', 'sk', 'sl', 'sr', 'sv', 'th', 'tr', 'uk', 'vi', 'zh']","['text-generation', 'text-classification']",[]
agentlans/high-quality-multilingual-sentences,agentlans,2025-02-20 21:49:12+00:00,2025-02-21 02:46:29+00:00,208,4,"['task_categories:text-generation', 'task_categories:text-classification', 'task_categories:text-retrieval', 'language:multilingual', 'language:ar', 'language:az', 'language:bg', 'language:bn', 'language:ca', 'language:cs', 'language:da', 'language:de', 'language:el', 'language:en', 'language:es', 'language:et', 'language:fa', 'language:fi', 'language:fr', 'language:he', 'language:hi', 'language:hu', 'language:hy', 'language:id', 'language:is', 'language:it', 'language:ja', 'language:ka', 'language:kk', 'language:ko', 'language:lt', 'language:lv', 'language:mk', 'language:ml', 'language:mr', 'language:ms', 'language:ne', 'language:nl', 'language:no', 'language:pl', 'language:pt', 'language:ro', 'language:ru', 'language:sk', 'language:sl', 'language:sq', 'language:sr', 'language:sv', 'language:ta', 'language:th', 'language:tr', 'language:uk', 'language:ur', 'language:vi', 'language:zh', 'license:cc-by-4.0', 'size_categories:1M<n<10M', 'format:json', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","
	
		
		High Quality Multilingual Sentences
	


This dataset contains multilingual sentences derived from the agentlans/LinguaNova dataset.
It includes 1.58 million rows across 51 different languages, each in its own configuration.

Example row (from the all config):
{
    ""text"": ""امام جمعه اصفهان گفت: میزان نیاز آب شرب اصفهان ۱۱.۵ متر مکعب است که تمام استان اصفهان را پوشش میدهد و نسبت به قبل از انقلاب یکی از پیشرفتها در حوزه آب بوده است."",
    ""fasttext"": ""fa"",
    ""gcld3"": ""fa""
}

Fields:… See the full description on the dataset page: https://huggingface.co/datasets/agentlans/high-quality-multilingual-sentences.",https://huggingface.co/datasets/agentlans/high-quality-multilingual-sentences,"['multilingual', 'ar', 'az', 'bg', 'bn', 'ca', 'cs', 'da', 'de', 'el', 'en', 'es', 'et', 'fa', 'fi', 'fr', 'he', 'hi', 'hu', 'hy', 'id', 'is', 'it', 'ja', 'ka', 'kk', 'ko', 'lt', 'lv', 'mk', 'ml', 'mr', 'ms', 'ne', 'nl', 'no', 'pl', 'pt', 'ro', 'ru', 'sk', 'sl', 'sq', 'sr', 'sv', 'ta', 'th', 'tr', 'uk', 'ur', 'vi', 'zh']","['text-generation', 'text-classification', 'text-retrieval']",['1M<n<10M']
HanzhiZhang/Poly-FEVER,HanzhiZhang,2025-02-20 22:48:53+00:00,2025-03-24 16:01:01+00:00,115,3,"['task_categories:text-classification', 'language:en', 'language:zh', 'language:hi', 'language:ar', 'language:bn', 'language:ja', 'language:ko', 'language:ta', 'language:th', 'language:ka', 'language:am', 'size_categories:10K<n<100K', 'format:csv', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'arxiv:2503.16541', 'region:us']","
	
		
		Dataset Card for Poly-FEVER
	



This dataset card aims to be a base template for new datasets. It has been generated using this raw template.

	
		
		Dataset Details
	


	
		
		Dataset Description
	


Poly-FEVER is a multilingual fact verification benchmark designed to evaluate hallucination detection in large language models (LLMs). It extends three widely used fact-checking datasets—FEVER, Climate-FEVER, and SciFact—by translating claims into 11 languages, enabling cross-linguistic… See the full description on the dataset page: https://huggingface.co/datasets/HanzhiZhang/Poly-FEVER.",https://huggingface.co/datasets/HanzhiZhang/Poly-FEVER,"['en', 'zh', 'hi', 'ar', 'bn', 'ja', 'ko', 'ta', 'th', 'ka', 'am']",['text-classification'],['10K<n<100K']
GuangChen233/Takamatsu_Tomori_Voices_0.46_Hours,GuangChen233,2025-02-21 11:55:00+00:00,2025-02-21 12:09:40+00:00,48,0,"['task_categories:audio-to-audio', 'language:ja', 'license:unknown', 'size_categories:n<1K', 'format:audiofolder', 'modality:audio', 'library:datasets', 'library:mlcroissant', 'region:us', 'music']","
	
		
		Copyright © Bushiroad. All Rights Reserved.
	

",https://huggingface.co/datasets/GuangChen233/Takamatsu_Tomori_Voices_0.46_Hours,['ja'],['audio-to-audio'],['n<1K']
Kendamarron/magpie-japanese-math-instruction-17k-qwen2.5-bakeneko-32b-instruct,Kendamarron,2025-02-21 16:08:55+00:00,2025-03-20 15:36:04+00:00,17,1,"['language:ja', 'license:apache-2.0', 'size_categories:10K<n<100K', 'format:parquet', 'modality:tabular', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us', 'synthetic']","
	
		
		magpie-japanese-math-instruction-17k-qwen2.5-bakeneko-32b-instruct
	

rinna/qwen2.5-bakeneko-32b-instructを用いたMagpieで生成した合成Instructionデータセットです。
合成したinstructionに対して、以下の方法で2つで回答を生成し、LLM評価で回答が一致していると判定されたレコードのみを残しています。

「あなたは論理的で数学が得意なアシスタントです。」をsystem promptとして得られた応答
「あなたは論理的で数学が得意で優秀なプログラマーです。与えられた問題をPythonを用いて回答します。最後に問題の最終的な答えをprint文で出力します。」をsystem promptとして得られたコードを実行した結果


	
		
	
	
		作成手順… See the full description on the dataset page: https://huggingface.co/datasets/Kendamarron/magpie-japanese-math-instruction-17k-qwen2.5-bakeneko-32b-instruct.",https://huggingface.co/datasets/Kendamarron/magpie-japanese-math-instruction-17k-qwen2.5-bakeneko-32b-instruct,['ja'],[],['10K<n<100K']
ayousanz/Emilia-Dataset-JA-Plus,ayousanz,2025-02-22 17:27:00+00:00,2025-02-23 05:53:33+00:00,1175,1,"['task_categories:text-to-speech', 'task_categories:automatic-speech-recognition', 'language:zh', 'language:en', 'language:ja', 'language:fr', 'language:de', 'language:ko', 'license:cc-by-nc-4.0', 'size_categories:10M<n<100M', 'arxiv:2407.05361', 'region:us']","
	
		
		Emilia: An Extensive, Multilingual, and Diverse Speech Dataset for Large-Scale Speech Generation
	


This is the official repository 👑 for the Emilia dataset and the source code for the Emilia-Pipe speech data preprocessing pipeline. 



	
		
		News 🔥
	


2024/08/28: Welcome to join Amphion's Discord channel to stay connected and engage with our community!
2024/08/27: The Emilia dataset is now publicly available! Discover the most extensive and diverse speech generation dataset with… See the full description on the dataset page: https://huggingface.co/datasets/ayousanz/Emilia-Dataset-JA-Plus.",https://huggingface.co/datasets/ayousanz/Emilia-Dataset-JA-Plus,"['zh', 'en', 'ja', 'fr', 'de', 'ko']","['text-to-speech', 'automatic-speech-recognition']",['10M<n<100M']
quickmt/quickmt-train.ja-en,quickmt,2025-02-23 02:50:25+00:00,2025-09-07 12:24:32+00:00,105,0,"['task_categories:translation', 'language:ja', 'language:en', 'size_categories:10M<n<100M', 'format:parquet', 'modality:text', 'library:datasets', 'library:dask', 'library:mlcroissant', 'library:polars', 'region:us']","
	
		
		quickmt ja-en Training Corpus
	

Contains the following datasets downloaded with mtdata after deduplication and basic filtering with quickmt:

Statmt-generaltest-2022_refA-eng-jpn
Statmt-generaltest-2022_refA-jpn-eng
Statmt-newstest_enja-2020-eng-jpn
Statmt-newstest_jaen-2020-jpn-eng
Statmt-newstest_enja-2021-eng-jpn
Statmt-newstest_jaen-2021-jpn-eng
Statmt-news_commentary-14-eng-jpn
Statmt-news_commentary-15-eng-jpn
Statmt-news_commentary-16-eng-jpn
Statmt-news_commentary-17-eng-jpn… See the full description on the dataset page: https://huggingface.co/datasets/quickmt/quickmt-train.ja-en.",https://huggingface.co/datasets/quickmt/quickmt-train.ja-en,"['ja', 'en']",['translation'],['10M<n<100M']
amphora/Open-R1-Mulitlingual-SFT,amphora,2025-02-23 06:25:12+00:00,2025-03-02 14:08:25+00:00,32,3,"['language:af', 'language:ar', 'language:zh', 'language:en', 'language:fr', 'language:de', 'language:he', 'language:id', 'language:it', 'language:ja', 'language:es', 'language:tr', 'language:vi', 'language:ko', 'license:mit', 'size_categories:100K<n<1M', 'format:parquet', 'modality:text', 'library:datasets', 'library:dask', 'library:mlcroissant', 'library:polars', 'arxiv:2502.17407', 'region:us']","
	
		
		Open-R1-Mulitlingual-SFT
	


	
		
		Overview
	

Open-R1-Mulitlingual-SFT is a curated dataset designed for multilingual supervised fine-tuning.
The source data comprises multiple datasets containing original prompts and responses, which were subsequently translated into 14 languages using GPT-4o.

	
		
		Sources
	

The dataset is derived from:

open-thoughts/OpenThoughts-114kHugging Face: open-thoughts/OpenThoughts-114k
bespokelabs/Bespoke-Stratos-17kHugging Face:… See the full description on the dataset page: https://huggingface.co/datasets/amphora/Open-R1-Mulitlingual-SFT.",https://huggingface.co/datasets/amphora/Open-R1-Mulitlingual-SFT,"['af', 'ar', 'zh', 'en', 'fr', 'de', 'he', 'id', 'it', 'ja', 'es', 'tr', 'vi', 'ko']",[],['100K<n<1M']
clwang-ucas/test_text,clwang-ucas,2025-02-23 13:54:54+00:00,2025-02-23 14:03:53+00:00,5,0,"['task_categories:text-classification', 'language:zh', 'language:ko', 'language:ja', 'license:openrail', 'size_categories:n<1K', 'format:csv', 'modality:tabular', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us', 'code']",,https://huggingface.co/datasets/clwang-ucas/test_text,"['zh', 'ko', 'ja']",['text-classification'],['n<1K']
ayousanz/japanese-music-emotion,ayousanz,2025-02-24 03:29:25+00:00,2025-02-25 16:30:18+00:00,21,0,"['language:ja', 'license:cc-by-4.0', 'size_categories:1K<n<10K', 'format:json', 'modality:tabular', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us', 'music', 'japanese']","
	
		
		japanese music emotion
	

Music2Emotionを使って主に日本の音楽の感情分析を行ったデータセット
分析されたデータは以下のようなフォーマットのjsonlになっています。
{
    ""index"": 1,
    ""video_id"": ""xxxxxxxxx"",
    ""title"": ""sampleTitle"",
    ""channel"": ""sample channel name"",
    ""url"": ""video url"",
    ""download_date"": ""2025-02-24T00:19:22.334487"",
    ""predicted_moods"": [
        ""energetic"",
        ""fast"",
        ""fun"",
        ""funny"",
        ""groovy"",
        ""happy"",
        ""holiday"",
        ""love"",
        ""party"",
        ""positive""… See the full description on the dataset page: https://huggingface.co/datasets/ayousanz/japanese-music-emotion.",https://huggingface.co/datasets/ayousanz/japanese-music-emotion,['ja'],[],['1K<n<10K']
Youseff1987/multilingual_translation_gen_binarized,Youseff1987,2025-02-24 06:07:50+00:00,2025-03-06 00:03:15+00:00,20,0,"['task_categories:translation', 'language:ko', 'language:en', 'language:zh', 'language:zu', 'language:ja', 'language:am', 'language:ar', 'language:es', 'language:fr', 'language:ru', 'language:de', 'language:it', 'language:pt', 'language:nl', 'language:sv', 'language:tr', 'language:id', 'language:vi', 'language:pl', 'language:cs', 'language:ro', 'language:uk', 'language:hu', 'language:sl', 'language:el', 'language:fi', 'language:no', 'language:da', 'language:bg', 'language:hi', 'language:he', 'language:ms', 'language:ta', 'language:te', 'language:pa', 'language:bn', 'language:fa', 'language:sw', 'language:th', 'language:sr', 'language:hr', 'language:ca', 'language:is', 'language:lv', 'language:lt', 'language:sk', 'language:et', 'language:mn', 'language:la', 'language:my', 'language:tl', 'language:jv', 'language:mr', 'language:gu', 'language:ps', 'language:sd', 'language:kn', 'language:ml', 'language:ha', 'language:yo', 'language:ig', 'language:ber', 'license:mit', 'size_categories:10K<n<100K', 'format:parquet', 'modality:tabular', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']",,https://huggingface.co/datasets/Youseff1987/multilingual_translation_gen_binarized,"['ko', 'en', 'zh', 'zu', 'ja', 'am', 'ar', 'es', 'fr', 'ru', 'de', 'it', 'pt', 'nl', 'sv', 'tr', 'id', 'vi', 'pl', 'cs', 'ro', 'uk', 'hu', 'sl', 'el', 'fi', 'no', 'da', 'bg', 'hi', 'he', 'ms', 'ta', 'te', 'pa', 'bn', 'fa', 'sw', 'th', 'sr', 'hr', 'ca', 'is', 'lv', 'lt', 'sk', 'et', 'mn', 'la', 'my', 'tl', 'jv', 'mr', 'gu', 'ps', 'sd', 'kn', 'ml', 'ha', 'yo', 'ig', 'ber']",['translation'],['10K<n<100K']
naist-nlp/multils-japanese,naist-nlp,2025-02-24 09:59:45+00:00,2025-07-03 11:24:24+00:00,7,2,"['task_categories:token-classification', 'task_categories:other', 'task_ids:text-simplification', 'annotations_creators:expert-generated', 'language_creators:found', 'multilinguality:monolingual', 'source_datasets:original', 'language:ja', 'license:cc-by-sa-4.0', 'size_categories:n<1K', 'format:csv', 'modality:tabular', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us', 'LS', 'lexical simplification', 'LCP', 'lexical complexity prediction', 'CWI', 'complex word identification', 'evaluation', 'test']","
	
		
		MultiLS-Japanese
	

MultiLS-Japanese is a lexical complexity prediction (LCP) and lexical simplification (LS) dataset for Japanese. The MultiLS-Japanese dataset was created by Adam Nohejl, Akio Haykawa, and Yusuke Ide.  A journal paper about the dataset is scheduled for publication in December 2025.
More information and additional files on the MultiLS-Japanese Github repo.

	
		
	
	
		Multilingual LS and LCP Data
	


Related datasets for 9 more languages: MLSP2024 dataset on Hugging… See the full description on the dataset page: https://huggingface.co/datasets/naist-nlp/multils-japanese.",https://huggingface.co/datasets/naist-nlp/multils-japanese,['ja'],"['token-classification', 'other']",['n<1K']
Lami/Lux-Japanese-Speech-Corpus,Lami,2025-02-24 14:51:53+00:00,2025-02-24 18:02:56+00:00,85,3,"['task_categories:text-to-speech', 'task_categories:automatic-speech-recognition', 'language:ja', 'license:cc-by-4.0', 'size_categories:1B<n<10B', 'region:us', 'Lux']","
	
		
		Lux Japanese Speech Corpus
	


	
		
		概要
	

Lux Japanese Speech Corpus は、オリジナルキャラクター「Lux (ルクス)」による日本語のテキスト読み上げ音声を収録したデータセットです。このデータセットは、以下の2種類の音声ファイルで構成されています。

raw: 加工前の 96kHz/16bit の WAV ファイル
cleaned: ノイズ除去などの処理を施した 96kHz/16bit の WAV ファイル

各音声ファイルに対応するトランスクリプション（読み上げた文章）は、metadata.csv に記録しています。データセット全体のメタ情報は dataset_infos.json で管理されています。

	
		
		ディレクトリ構造
	

以下は、このリポジトリの推奨ディレクトリ構造の例です。
Lux-Japanese-Speech-Corpus/
├── .gitattributes           # Gitのカスタマイズファイル
├── README.md… See the full description on the dataset page: https://huggingface.co/datasets/Lami/Lux-Japanese-Speech-Corpus.",https://huggingface.co/datasets/Lami/Lux-Japanese-Speech-Corpus,['ja'],"['text-to-speech', 'automatic-speech-recognition']",['1B<n<10B']
6DammK9/e621_2024-captions-1ktar,6DammK9,2025-02-24 17:06:24+00:00,2025-02-24 17:59:50+00:00,6,0,"['task_categories:image-classification', 'task_categories:zero-shot-image-classification', 'task_categories:text-to-image', 'annotations_creators:no-annotation', 'source_datasets:e621', 'language:en', 'language:ja', 'license:mit', 'size_categories:1M<n<10M', 'format:webdataset', 'modality:text', 'library:datasets', 'library:webdataset', 'library:mlcroissant', 'region:us', 'art', 'anime', 'not-for-all-audiences']","
	
		
		E621 2024 captions only in 1k tar
	


Raw captions jointed from lodestones/e621-captions

It doesn't align to any dataset yet.

meta_cap.json has been provided in compressed format if you want to train with kohyas triner. Currently I'm trying to merge this with my 2024 version.



	
		
	
	
		Core logic
	


The script building this 1ktar

There is not much choice, I don't have GPU to run for 1M captions with VLM so I just ""take it or leave it"".


rearranged_tags = [row.regular_summary… See the full description on the dataset page: https://huggingface.co/datasets/6DammK9/e621_2024-captions-1ktar.",https://huggingface.co/datasets/6DammK9/e621_2024-captions-1ktar,"['en', 'ja']","['image-classification', 'zero-shot-image-classification', 'text-to-image']",['1M<n<10M']
DSULT-Core/DLSite,DSULT-Core,2025-02-25 14:51:39+00:00,2025-03-20 12:16:04+00:00,12,0,"['language:ja', 'license:other', 'size_categories:100K<n<1M', 'region:us', 'not-for-all-audiences']","
	
		
		RJ0000001-DLSite
	

tired of writing a elaborate reason for what is DLSite. So here is an explaination from o3-mini (yes im cheap.)

What is DLsite.com?
DLsite.com is a Japanese digital distribution platform that specializes in hosting and selling a vast array of indie-created digital content. Originally established as a hub for ""doujin"" (self-published) works, it has grown into one of the leading marketplaces for a wide variety of media, including:

Indie Games: Both all-ages and… See the full description on the dataset page: https://huggingface.co/datasets/DSULT-Core/DLSite.",https://huggingface.co/datasets/DSULT-Core/DLSite,['ja'],[],['100K<n<1M']
SuccubusBot/incoherent-text-dataset,SuccubusBot,2025-02-25 18:51:46+00:00,2025-03-01 10:21:47+00:00,15,0,"['task_categories:text-classification', 'language:en', 'language:es', 'language:fr', 'language:de', 'language:zh', 'language:ja', 'language:ru', 'language:ar', 'language:hi', 'license:cc-by-sa-4.0', 'size_categories:10K<n<100K', 'format:parquet', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","
	
		
		Incoherent Text Dataset
	

This dataset is designed for training models to detect incoherence in text. It includes various types of incoherence, such as grammatical errors, word soup, random words, and run-on sentences.

	
		
		Dataset Details
	


Languages: English, Spanish, French, German, Chinese, Japanese, Russian, Arabic, Hindi
Size: ~27,000 samples
Types of Incoherence: Grammatical errors, word soup, random words, run-ons, random tokens, random bytes.


	
		
		Data Fields… See the full description on the dataset page: https://huggingface.co/datasets/SuccubusBot/incoherent-text-dataset.",https://huggingface.co/datasets/SuccubusBot/incoherent-text-dataset,"['en', 'es', 'fr', 'de', 'zh', 'ja', 'ru', 'ar', 'hi']",['text-classification'],['10K<n<100K']
cyberagent/YokaiEval,cyberagent,2025-02-26 08:37:53+00:00,2025-03-18 04:56:26+00:00,27,3,"['language:ja', 'license:cc-by-nc-sa-4.0', 'size_categories:n<1K', 'format:parquet', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","
	
		
		Dataset Card for YokaiEval
	

このリポジトリには、「LLM は日本の民話を知っているか？ 妖怪知識評価データセットの構築へ向けて」（NLP2025）のデータが含まれています。

	
		
		Overview
	

本データセットはLLMの日本文化に関する知識を特に妖怪を用いて評価するためのデータセットです。
特徴

妖怪に関する4択問題を810件の日本語データです。
問題の出典が全件人手で確認されています。


	
		
		Usage
	

from datasets import load_dataset
dataset = load_dataset(""cyberagent/YokaiEval"")


	
		
		Version
	


2025/3/18: version 1.0公開


	
		
		Dataset Details
	

以下の6種類の知識に関する問題が含まれています。

妖怪の行う行動
妖怪の形状・見た目
妖怪の生まれ・生態
妖怪の典拠
妖怪の伝承のある地域
現代における伝承… See the full description on the dataset page: https://huggingface.co/datasets/cyberagent/YokaiEval.",https://huggingface.co/datasets/cyberagent/YokaiEval,['ja'],[],['n<1K']
lewoniewski/wikipedia_quality_wikirank,lewoniewski,2025-02-26 14:27:05+00:00,2025-03-13 19:38:33+00:00,81,4,"['language:ar', 'language:az', 'language:be', 'language:bg', 'language:ca', 'language:cs', 'language:da', 'language:de', 'language:el', 'language:en', 'language:eo', 'language:es', 'language:et', 'language:eu', 'language:fa', 'language:fi', 'language:fr', 'language:gl', 'language:he', 'language:hi', 'language:hr', 'language:hu', 'language:hy', 'language:id', 'language:it', 'language:ja', 'language:ka', 'language:kk', 'language:ko', 'language:la', 'language:lt', 'language:ms', 'language:nl', 'language:nn', 'language:no', 'language:pl', 'language:pt', 'language:ro', 'language:ru', 'language:sh', 'language:sk', 'language:sl', 'language:sr', 'language:sv', 'language:ta', 'language:th', 'language:tr', 'language:uk', 'language:ur', 'language:uz', 'language:vi', 'language:vo', 'language:zh', 'license:apache-2.0', 'size_categories:10M<n<100M', 'format:csv', 'modality:tabular', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'doi:10.57967/hf/4656', 'region:us', 'wikipedia', 'quality', 'wikirank']","Datasets with WikiRank quality score as of 1 August 2024 for 47 million Wikipedia articles in 55 language versions (also simplified version for each language in separate files).
The WikiRank quality score is a metric designed to assess the overall quality of a Wikipedia article. Although its specific algorithm can vary depending on the implementation, the score typically combines several key features of the Wikipedia article.

	
		
	
	
		Why It’s Important
	


Enhances Trust: For readers and… See the full description on the dataset page: https://huggingface.co/datasets/lewoniewski/wikipedia_quality_wikirank.",https://huggingface.co/datasets/lewoniewski/wikipedia_quality_wikirank,"['ar', 'az', 'be', 'bg', 'ca', 'cs', 'da', 'de', 'el', 'en', 'eo', 'es', 'et', 'eu', 'fa', 'fi', 'fr', 'gl', 'he', 'hi', 'hr', 'hu', 'hy', 'id', 'it', 'ja', 'ka', 'kk', 'ko', 'la', 'lt', 'ms', 'nl', 'nn', 'no', 'pl', 'pt', 'ro', 'ru', 'sh', 'sk', 'sl', 'sr', 'sv', 'ta', 'th', 'tr', 'uk', 'ur', 'uz', 'vi', 'vo', 'zh']",[],['10M<n<100M']
liboaccn/OPUS-MIT-5M,liboaccn,2025-02-26 17:20:57+00:00,2025-03-07 02:38:27+00:00,35,0,"['task_categories:translation', 'language:es', 'language:zh', 'language:en', 'language:fr', 'language:it', 'language:hi', 'language:ko', 'language:ja', 'language:pt', 'language:th', 'language:de', 'license:apache-2.0', 'size_categories:1M<n<10M', 'format:json', 'modality:text', 'modality:image', 'library:datasets', 'library:dask', 'library:mlcroissant', 'region:us', 'image', 'text']","
	
		
		Multilingual Image Translation Dataset： OPUS-MIT-5M
	

The OPUS-MIT-5M image translation dataset is constructed by randomly sampling 5M sentence pairs from the OPUS  corpus. 

Figure  illustrates the distribution of image-text pairs across 20 language pairs within the OPUS-MIT-5M dataset.
A key goal in creating the OPUS-MIT-5M dataset is to ensure a balanced representation across languages to enable robust multilingual image translation. 
We endeavor to synthesize an equal number of… See the full description on the dataset page: https://huggingface.co/datasets/liboaccn/OPUS-MIT-5M.",https://huggingface.co/datasets/liboaccn/OPUS-MIT-5M,"['es', 'zh', 'en', 'fr', 'it', 'hi', 'ko', 'ja', 'pt', 'th', 'de']",['translation'],['1M<n<10M']
Kendamarron/magpie-reasoning-preference-japanese,Kendamarron,2025-02-27 12:40:37+00:00,2025-02-27 12:45:57+00:00,9,0,"['language:ja', 'license:apache-2.0', 'size_categories:1K<n<10K', 'format:parquet', 'modality:tabular', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']",,https://huggingface.co/datasets/Kendamarron/magpie-reasoning-preference-japanese,['ja'],[],['1K<n<10K']
line-corporation/JIC-VQA,line-corporation,2025-02-28 05:49:54+00:00,2025-03-24 00:18:36+00:00,95,4,"['task_categories:visual-question-answering', 'language:ja', 'license:apache-2.0', 'size_categories:1K<n<10K', 'format:csv', 'modality:image', 'modality:text', 'library:datasets', 'library:dask', 'library:mlcroissant', 'library:polars', 'region:us']","
	
		
		JIC-VQA
	


	
		
		Dataset Description
	

Japanese Image Classification Visual Question Answering (JIC-VQA) is a benchmark for evaluating Japanese Vision-Language Models (VLMs). We built this benchmark based on the recruit-jp/japanese-image-classification-evaluation-dataset by adding questions to each sample. All questions are multiple-choice, each with four options. We select options that closely relate to their respective labels in order to increase the task's difficulty.
The images… See the full description on the dataset page: https://huggingface.co/datasets/line-corporation/JIC-VQA.",https://huggingface.co/datasets/line-corporation/JIC-VQA,['ja'],['visual-question-answering'],['1K<n<10K']
Sara237/gsm8k-translated,Sara237,2025-02-28 10:24:57+00:00,2025-03-06 16:21:00+00:00,448,0,"['language:en', 'language:de', 'language:es', 'language:fr', 'language:ja', 'language:ru', 'language:sw', 'language:th', 'language:zh', 'license:apache-2.0', 'size_categories:10K<n<100K', 'format:csv', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us', 'math-word-problem']",,https://huggingface.co/datasets/Sara237/gsm8k-translated,"['en', 'de', 'es', 'fr', 'ja', 'ru', 'sw', 'th', 'zh']",[],['10K<n<100K']
Pinkstack/thinking-multilingual-30-23-small-690,Pinkstack,2025-02-28 10:55:56+00:00,2025-03-01 01:42:50+00:00,18,3,"['task_categories:text-generation', 'language:ar', 'language:zh', 'language:cs', 'language:da', 'language:nl', 'language:en', 'language:fi', 'language:fr', 'language:de', 'language:he', 'language:hu', 'language:it', 'language:ja', 'language:ko', 'language:no', 'language:pl', 'language:pt', 'language:ru', 'language:es', 'language:sv', 'language:th', 'language:tr', 'language:uk', 'license:apache-2.0', 'size_categories:n<1K', 'format:json', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us', 'reasoning']","
Based on OPENO1 math, this is a translated dataset of 30 high quality questions & answers in 23 languages. 
Or use the ""big"" version: big 10k rows version
",https://huggingface.co/datasets/Pinkstack/thinking-multilingual-30-23-small-690,"['ar', 'zh', 'cs', 'da', 'nl', 'en', 'fi', 'fr', 'de', 'he', 'hu', 'it', 'ja', 'ko', 'no', 'pl', 'pt', 'ru', 'es', 'sv', 'th', 'tr', 'uk']",['text-generation'],['n<1K']
Youseff1987/multilingual_translation_sft,Youseff1987,2025-03-01 20:55:32+00:00,2025-03-01 20:58:01+00:00,39,2,"['task_categories:translation', 'language:ko', 'language:en', 'language:zh', 'language:zu', 'language:ja', 'language:am', 'language:ar', 'language:es', 'language:fr', 'language:ru', 'language:de', 'language:it', 'language:pt', 'language:nl', 'language:sv', 'language:tr', 'language:id', 'language:vi', 'language:pl', 'language:cs', 'language:ro', 'language:uk', 'language:hu', 'language:sl', 'language:el', 'language:fi', 'language:no', 'language:da', 'language:bg', 'language:hi', 'language:he', 'language:ms', 'language:ta', 'language:te', 'language:pa', 'language:bn', 'language:fa', 'language:sw', 'language:th', 'language:sr', 'language:hr', 'language:ca', 'language:is', 'language:lv', 'language:lt', 'language:sk', 'language:et', 'language:mn', 'language:la', 'language:my', 'language:tl', 'language:jv', 'language:mr', 'language:gu', 'language:ps', 'language:sd', 'language:kn', 'language:ml', 'language:ha', 'language:yo', 'language:ig', 'language:ber', 'license:mit', 'size_categories:1M<n<10M', 'format:parquet', 'modality:tabular', 'modality:text', 'library:datasets', 'library:dask', 'library:mlcroissant', 'library:polars', 'region:us']",,https://huggingface.co/datasets/Youseff1987/multilingual_translation_sft,"['ko', 'en', 'zh', 'zu', 'ja', 'am', 'ar', 'es', 'fr', 'ru', 'de', 'it', 'pt', 'nl', 'sv', 'tr', 'id', 'vi', 'pl', 'cs', 'ro', 'uk', 'hu', 'sl', 'el', 'fi', 'no', 'da', 'bg', 'hi', 'he', 'ms', 'ta', 'te', 'pa', 'bn', 'fa', 'sw', 'th', 'sr', 'hr', 'ca', 'is', 'lv', 'lt', 'sk', 'et', 'mn', 'la', 'my', 'tl', 'jv', 'mr', 'gu', 'ps', 'sd', 'kn', 'ml', 'ha', 'yo', 'ig', 'ber']",['translation'],['1M<n<10M']
CohereLabs/AyaVisionBench,CohereLabs,2025-03-02 21:15:20+00:00,2025-05-14 15:31:56+00:00,841,31,"['language:en', 'language:fr', 'language:de', 'language:es', 'language:it', 'language:pt', 'language:ja', 'language:ko', 'language:zh', 'language:ar', 'language:el', 'language:fa', 'language:pl', 'language:id', 'language:cs', 'language:he', 'language:hi', 'language:nl', 'language:ro', 'language:ru', 'language:tr', 'language:uk', 'language:vi', 'license:apache-2.0', 'size_categories:1K<n<10K', 'format:parquet', 'modality:image', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","
	
		
		Dataset Card for Aya Vision Benchmark
	




	
		
		Dataset Details
	

The Aya Vision Benchmark is designed to evaluate vision-language models in real-world multilingual scenarios. It spans 23 languages and 9 distinct task categories, with 15 samples per category, resulting in 135 image-question pairs per language. 
Each question requires visual context for the answer and covers languages that half of the world's population speaks, making this dataset particularly suited for… See the full description on the dataset page: https://huggingface.co/datasets/CohereLabs/AyaVisionBench.",https://huggingface.co/datasets/CohereLabs/AyaVisionBench,"['en', 'fr', 'de', 'es', 'it', 'pt', 'ja', 'ko', 'zh', 'ar', 'el', 'fa', 'pl', 'id', 'cs', 'he', 'hi', 'nl', 'ro', 'ru', 'tr', 'uk', 'vi']",[],['1K<n<10K']
CohereLabs/m-WildVision,CohereLabs,2025-03-02 21:43:23+00:00,2025-04-15 08:26:42+00:00,250,22,"['language:en', 'language:fr', 'language:de', 'language:es', 'language:it', 'language:pt', 'language:ja', 'language:ko', 'language:zh', 'language:ar', 'language:el', 'language:fa', 'language:pl', 'language:id', 'language:cs', 'language:he', 'language:hi', 'language:nl', 'language:ro', 'language:ru', 'language:tr', 'language:uk', 'language:vi', 'license:apache-2.0', 'size_categories:10K<n<100K', 'format:parquet', 'modality:image', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'arxiv:2406.11069', 'region:us']","
	
		
		Dataset Card for m-WildVision
	




	
		
		Dataset Details
	

The m-WildVision dataset is a multilingual multimodal LLM evaluation set covering 23 languages.  It was created by translating prompts from the original English-only WildVision (vision_bench_0617) test set. 
The original prompts, developed by Lu et al. (2024) , consist of 500 challenging user queries sourced from the WildVision-Arena platform. 
The authors demonstrated that these prompts enable automatic LLM judge… See the full description on the dataset page: https://huggingface.co/datasets/CohereLabs/m-WildVision.",https://huggingface.co/datasets/CohereLabs/m-WildVision,"['en', 'fr', 'de', 'es', 'it', 'pt', 'ja', 'ko', 'zh', 'ar', 'el', 'fa', 'pl', 'id', 'cs', 'he', 'hi', 'nl', 'ro', 'ru', 'tr', 'uk', 'vi']",[],['10K<n<100K']
TTS-AGI/emilia-yodas,TTS-AGI,2025-03-03 03:28:04+00:00,2025-03-08 02:02:26+00:00,2133,2,"['task_categories:text-to-speech', 'task_categories:automatic-speech-recognition', 'language:en', 'language:de', 'language:fr', 'language:ja', 'language:ko', 'language:zh', 'license:cc-by-4.0', 'size_categories:10M<n<100M', 'format:webdataset', 'modality:audio', 'modality:text', 'library:datasets', 'library:webdataset', 'library:mlcroissant', 'region:us', 'speech', 'audio', 'yodas']","A mirror of the Emilia-YODAS dataset. Only includes the YODAS subset from the original dataset.
https://huggingface.co/datasets/amphion/Emilia-Dataset
",https://huggingface.co/datasets/TTS-AGI/emilia-yodas,"['en', 'de', 'fr', 'ja', 'ko', 'zh']","['text-to-speech', 'automatic-speech-recognition']",['10M<n<100M']
Pinkstack/OpenHumanreasoning-multilingual-2.2k,Pinkstack,2025-03-03 15:04:20+00:00,2025-03-03 17:16:04+00:00,16,2,"['task_categories:text-generation', 'language:ar', 'language:zh', 'language:cs', 'language:da', 'language:nl', 'language:en', 'language:fi', 'language:fr', 'language:de', 'language:he', 'language:hu', 'language:it', 'language:ja', 'language:ko', 'language:no', 'language:pl', 'language:pt', 'language:ru', 'language:es', 'language:sv', 'language:th', 'language:tr', 'language:uk', 'license:apache-2.0', 'size_categories:1K<n<10K', 'format:json', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us', 'reasoning', 'superthoughts', 'cot']","Based off of Pinkstackorg/humanreasoning-testing-en, it is a human-generated dataset where a real person had to create most of the reasoning and the final output. If there are any mistakes please let us know.
We offer this dataset at an apache-2.0 license to make it useful for everybody.
note: translations are not human generated.
",https://huggingface.co/datasets/Pinkstack/OpenHumanreasoning-multilingual-2.2k,"['ar', 'zh', 'cs', 'da', 'nl', 'en', 'fi', 'fr', 'de', 'he', 'hu', 'it', 'ja', 'ko', 'no', 'pl', 'pt', 'ru', 'es', 'sv', 'th', 'tr', 'uk']",['text-generation'],['1K<n<10K']
adewynter/RTP-LX,adewynter,2025-03-05 02:39:52+00:00,2025-03-05 02:53:19+00:00,17,1,"['task_categories:text-classification', 'language:ar', 'language:hr', 'language:sr', 'language:bg', 'language:ca', 'language:zh', 'language:cs', 'language:da', 'language:nl', 'language:en', 'language:et', 'language:fi', 'language:fr', 'language:de', 'language:he', 'language:hi', 'language:el', 'language:hu', 'language:id', 'language:it', 'language:ja', 'language:ko', 'language:lv', 'language:lt', 'language:no', 'language:pl', 'language:pt', 'language:ro', 'language:ru', 'language:sl', 'language:sk', 'language:es', 'language:sw', 'language:sv', 'language:th', 'language:tr', 'language:uk', 'language:vi', 'language:cy', 'license:mit', 'size_categories:1K<n<10K', 'arxiv:2404.14397', 'region:us']","WARNING: This repository contains and discusses content that is offensive or upsetting. All materials are intended to support research that improves toxicity detection methods. Included examples of toxicity do not represent how the authors or sponsors feel about any identity groups. This corpus was made by a multi-national, multi-cultural team of various faiths, beliefs, and origins. Please note that toxicity is dynamic, evolves with societal perceptions, and these labels may change.
Please… See the full description on the dataset page: https://huggingface.co/datasets/adewynter/RTP-LX.",https://huggingface.co/datasets/adewynter/RTP-LX,"['ar', 'hr', 'sr', 'bg', 'ca', 'zh', 'cs', 'da', 'nl', 'en', 'et', 'fi', 'fr', 'de', 'he', 'hi', 'el', 'hu', 'id', 'it', 'ja', 'ko', 'lv', 'lt', 'no', 'pl', 'pt', 'ro', 'ru', 'sl', 'sk', 'es', 'sw', 'sv', 'th', 'tr', 'uk', 'vi', 'cy']",['text-classification'],['1K<n<10K']
blcuicall/omgeval,blcuicall,2025-03-05 06:25:01+00:00,2025-03-24 08:17:32+00:00,11,0,"['task_categories:text-generation', 'task_categories:question-answering', 'language:ar', 'language:en', 'language:es', 'language:zh', 'language:fr', 'language:ru', 'language:pt', 'language:it', 'language:ko', 'language:ja', 'size_categories:1K<n<10K', 'format:json', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'arxiv:2402.13524', 'region:us']","
	
		
		Dataset Card for ""omgeval""
	



We introduce OMGEval, the first Open-source Multilingual Generative test set that can assess the capability of LLMs in different languages. 
For each language, OMGEval provides 804 open-ended questions, covering a wide range of important capabilities of LLMs, such as general knowledge, logical reasoning, and so on. 
Each question is rigorously verified by human annotators. 
Notably, to sufficiently reflect the compatibility of LLMs in different cultural… See the full description on the dataset page: https://huggingface.co/datasets/blcuicall/omgeval.",https://huggingface.co/datasets/blcuicall/omgeval,"['ar', 'en', 'es', 'zh', 'fr', 'ru', 'pt', 'it', 'ko', 'ja']","['text-generation', 'question-answering']",['1K<n<10K']
huckiyang/ja-jp-en-us-nv-tech-blog-v1,huckiyang,2025-03-05 11:48:11+00:00,2025-03-15 07:08:29+00:00,45,1,"['task_categories:translation', 'task_categories:summarization', 'language:ja', 'language:en', 'license:cc-by-nc-4.0', 'size_categories:n<1K', 'format:json', 'modality:text', 'library:datasets', 'library:dask', 'library:mlcroissant', 'region:us', 'tech', 'blog']",,https://huggingface.co/datasets/huckiyang/ja-jp-en-us-nv-tech-blog-v1,"['ja', 'en']","['translation', 'summarization']",['n<1K']
llm-jp/llm-jp-instructions,llm-jp,2025-03-07 05:14:21+00:00,2025-03-07 10:53:02+00:00,86,4,"['task_categories:text-generation', 'language:ja', 'license:cc-by-4.0', 'size_categories:1K<n<10K', 'format:parquet', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","
	
		
		概要
	

llm-jp-instructionsは人手により作成されたインストラクションデータセットです。

	
		
		Overview
	

llm-jp-instructions is a manually created instruction dataset.

	
		
		Usage
	

from datasets import load_dataset

# load train, dev and test splits of v1.0
v1_train = load_dataset(""llm-jp/llm-jp-instructions"", data_dir=""v1.0"", split=""train"")
v1_dev = load_dataset(""llm-jp/llm-jp-instructions"", data_dir=""v1.0"", split=""dev"")
v1_test = load_dataset(""llm-jp/llm-jp-instructions"", data_dir=""v1.0"", split=""test"")

",https://huggingface.co/datasets/llm-jp/llm-jp-instructions,['ja'],['text-generation'],['1K<n<10K']
yokomachi/cat_conversations_jp,yokomachi,2025-03-07 18:49:10+00:00,2025-03-07 21:20:09+00:00,12,1,"['task_categories:question-answering', 'language:ja', 'license:mit', 'size_categories:n<1K', 'format:json', 'modality:text', 'library:datasets', 'library:dask', 'library:mlcroissant', 'region:us']",,https://huggingface.co/datasets/yokomachi/cat_conversations_jp,['ja'],['question-answering'],['n<1K']
hhim8826/japanese-anime-speech-v2-split,hhim8826,2025-03-08 20:21:21+00:00,2025-03-10 10:43:15+00:00,75,3,"['task_categories:automatic-speech-recognition', 'language:ja', 'license:gpl', 'size_categories:10K<n<100K', 'format:parquet', 'modality:audio', 'modality:text', 'library:datasets', 'library:dask', 'library:mlcroissant', 'library:polars', 'region:us', 'japanese', 'anime', 'speech', '日本語', 'audio-text', 'asr', 'whisper', 'voice']","dataset split from joujiboi/japanese-anime-speech-v2
",https://huggingface.co/datasets/hhim8826/japanese-anime-speech-v2-split,['ja'],['automatic-speech-recognition'],['10K<n<100K']
junnei/covost2,junnei,2025-03-09 14:02:46+00:00,2025-03-11 08:16:44+00:00,28,1,"['task_categories:automatic-speech-recognition', 'annotations_creators:expert-generated', 'language_creators:crowdsourced', 'language_creators:expert-generated', 'multilinguality:multilingual', 'source_datasets:extended|other-common-voice', 'language:ar', 'language:ca', 'language:cy', 'language:de', 'language:es', 'language:et', 'language:fa', 'language:fr', 'language:id', 'language:it', 'language:ja', 'language:ko', 'language:lv', 'language:mn', 'language:nl', 'language:pt', 'language:ru', 'language:sl', 'language:sv', 'language:ta', 'language:tr', 'language:zh', 'license:cc-by-nc-4.0', 'size_categories:100K<n<1M', 'arxiv:2007.10310', 'region:us']","CoVoST 2, a large-scale multilingual speech translation corpus covering translations from 21 languages into English and from English into 15 languages. The dataset is created using Mozilla’s open source Common Voice database of crowdsourced voice recordings.

Note that in order to limit the required storage for preparing this dataset, the audio
is stored in the .mp3 format and is not converted to a float32 array. To convert, the audio
file to a float32 array, please make use of the `.map()` function as follows:


```python
import torchaudio

def map_to_array(batch):
    speech_array, _ = torchaudio.load(batch[""file""])
    batch[""speech""] = speech_array.numpy()
    return batch

dataset = dataset.map(map_to_array, remove_columns=[""file""])
```",https://huggingface.co/datasets/junnei/covost2,"['ar', 'ca', 'cy', 'de', 'es', 'et', 'fa', 'fr', 'id', 'it', 'ja', 'ko', 'lv', 'mn', 'nl', 'pt', 'ru', 'sl', 'sv', 'ta', 'tr', 'zh']",['automatic-speech-recognition'],['100K<n<1M']
vmal/jobs_dataset,vmal,2025-03-09 15:28:43+00:00,2025-03-09 16:47:05+00:00,20,0,"['language:en', 'language:th', 'language:ja', 'license:unlicense', 'size_categories:1K<n<10K', 'format:parquet', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us', 'job-listings', 'html-extraction', 'google', 'meta', 'apple']",,https://huggingface.co/datasets/vmal/jobs_dataset,"['en', 'th', 'ja']",[],['1K<n<10K']
hotchpotch/japanese-qa-reasoning-100k,hotchpotch,2025-03-10 00:10:58+00:00,2025-03-24 20:39:35+00:00,28,1,"['language:ja', 'license:odc-by', 'size_categories:100K<n<1M', 'format:parquet', 'modality:tabular', 'modality:text', 'library:datasets', 'library:dask', 'library:mlcroissant', 'library:polars', 'region:us']","
	
		
		思考過程を含む、日本語質問・キーワード・回答・文章の合成データセット
	

fineweb2-edu-japanese の文章データを元に、DeepSeek-R1 で文章(text)から質問文と回答部分の該当箇所を生成した日本語の質問と対応する文章・回答部のデータセットです。deekseek-r1 が出力した reasoning 部分も含まれます。testセットは、fineweb2-edu-japaneseのtestのみからサンプリングしています。
質問と文章ペアのデータセットやキーワードと文章ペアのデータセットとしてお使いいただけます。

	
		
		ライセンス
	

fineweb2 と同等の ODC-By とします。
",https://huggingface.co/datasets/hotchpotch/japanese-qa-reasoning-100k,['ja'],[],['100K<n<1M']
SousiOmine/Japanese-Pythonic-FunctionCall,SousiOmine,2025-03-10 04:02:43+00:00,2025-03-10 04:11:47+00:00,20,0,"['language:ja', 'license:apache-2.0', 'size_categories:1K<n<10K', 'format:json', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","
	
		
		概要
	

チャットLLMにpython関数呼び出し機能を付与するための低品質なデータセットです。
Kendamarron/jimba-instruction-allデータセットのうち、dataset_id=Kendamarron/system-instruction-calm3-chat-formatのもの先頭1002件を用いています。
関数定義、関数呼び出しをQwen2.5-32b-instructで、回答をPhi-4で生成しました。

	
		
		注意点
	


toolsが空になっている項目があります。
toolsが中国語になっている項目があります。
同じ関数を同じ引数で何度も呼び出している箇所が散見されます。
回答部分の品質が低い項目があると思います。

",https://huggingface.co/datasets/SousiOmine/Japanese-Pythonic-FunctionCall,['ja'],[],['1K<n<10K']
deepghs/erairaws_infos,deepghs,2025-03-11 09:02:45+00:00,2025-03-11 12:18:35+00:00,221,1,"['annotations_creators:no-annotation', 'source_datasets:erairaws', 'source_datasets:myanimelist', 'language:en', 'language:ja', 'license:other', 'size_categories:n<1K', 'format:imagefolder', 'modality:image', 'library:datasets', 'library:mlcroissant', 'region:us', 'art', 'anime']","This is the information integration of erai-raws and myanimelist.

	
		
		Animes
	

2056 animes in total, 500 animes shown.

	
		
ID
Post
Bangumi
RSS
AniDB
AniList
Kitsu
LiveChart
MAL
Resources
Published At
Last Published At


		
60410

Yami Shibai 14
RSS
AniDB
AniList
Kitsu
LiveChart
MAL
20
2025-01-18T23:52:00
2025-03-09T14:25:00


60407

Kimi to Idol Precure
RSS
AniDB

Kitsu
LiveChart
MAL
12
2025-02-01T20:24:00
2025-03-09T14:39:00


60108

One Piece: Gyojin Tou-hen
RSS
AniDB
AniList
Kitsu… See the full description on the dataset page: https://huggingface.co/datasets/deepghs/erairaws_infos.",https://huggingface.co/datasets/deepghs/erairaws_infos,"['en', 'ja']",[],['n<1K']
nlp-waseda/JCQ,nlp-waseda,2025-03-13 05:15:12+00:00,2025-03-17 05:23:19+00:00,12,1,"['task_categories:question-answering', 'task_categories:text-generation', 'language:ja', 'license:cc-by-4.0', 'size_categories:n<1K', 'format:json', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'arxiv:2401.12491', 'region:us', 'llm', 'evaluation', 'Japanese', 'creativity']","
	
		
		Japanese Creativity Questions (JCQ)
	


	
		
		Dataset Description
	

JCQは創造性を評価するための7タスク、各100問からなる日本語のデータセットです。このデータセットはNLP2025の研究論文で発表されたものです。Torrance Test of Creative Thinking (TTCT)、Zhaoらの研究 (2024)を参考にして作成しました。

	
		
		Task Definition and Examples
	

JCQは7つの異なるタスクで構成されています。以下の表に各タスクの定義と代表的な問題例を示します。

	
		
タスク
定義
問題例


		
非通常使用 (unusual uses)
一般的な物体の珍しい使い方や多様な使い方を考えるタスク。
電球の通常でない使い方をできるだけたくさん挙げてください。


結果 (consequences)
普通ではない、または仮説的な状況における結果や影響を予測するタスク。
もしも世界中で 24… See the full description on the dataset page: https://huggingface.co/datasets/nlp-waseda/JCQ.",https://huggingface.co/datasets/nlp-waseda/JCQ,['ja'],"['question-answering', 'text-generation']",['n<1K']
Kendamarron/magpie-bakeneko-32b-instruction-113k,Kendamarron,2025-03-13 14:27:36+00:00,2025-03-13 15:05:58+00:00,62,1,"['language:ja', 'license:apache-2.0', 'size_categories:100K<n<1M', 'format:parquet', 'modality:text', 'library:datasets', 'library:dask', 'library:mlcroissant', 'library:polars', 'region:us', 'synthetic']","
	
		
		magpie-bakeneko-32b-instruct-113k
	

rinna/qwen2.5-bakeneko-32b-instruct-awqを用いたMagpieで生成した合成Instructionデータセットです。
なお、計算リソースの問題からoutputの品質評価は行っていません。
ご利用の際はご注意ください。

	
		
		作成手順
	


rinna/qwen2.5-bakeneko-32b-instruct-awqを用いたMagpieで""base_instruction""を生成（magpie_systemの値をシステムプロンプトとして使用）
rinna/qwen2.5-bakeneko-32b-instruct-awqを用いて""base_instruction""を難化することで""instruction""を生成
rinna/qwen2.5-bakeneko-32b-instruct-awqを用いて""instruction""の言語、タスクの種類、難易度、品質を評価… See the full description on the dataset page: https://huggingface.co/datasets/Kendamarron/magpie-bakeneko-32b-instruction-113k.",https://huggingface.co/datasets/Kendamarron/magpie-bakeneko-32b-instruction-113k,['ja'],[],['100K<n<1M']
nvidia/HelpSteer3,nvidia,2025-03-13 16:18:41+00:00,2025-07-02 20:43:57+00:00,4315,80,"['language:en', 'language:zh', 'language:ko', 'language:fr', 'language:es', 'language:ru', 'language:ja', 'language:de', 'language:it', 'language:pt', 'language:pl', 'language:id', 'language:nl', 'language:vi', 'license:cc-by-4.0', 'size_categories:10K<n<100K', 'format:json', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'arxiv:2410.16184', 'arxiv:2505.11475', 'arxiv:2503.04378', 'region:us', 'human-feedback', 'reinforcement-learning']","
	
		
		HelpSteer3
	

HelpSteer3 is an open-source dataset (CC-BY-4.0) that supports aligning models to become more helpful in responding to user prompts.
HelpSteer3-Preference can be used to train Llama 3.3 Nemotron Super 49B v1 (for Generative RMs) and Llama 3.3 70B Instruct Models (for Bradley-Terry RMs) to produce Reward Models that score as high as 85.5% on RM-Bench and 78.6% on JudgeBench, which substantially surpass existing Reward Models on these benchmarks.
HelpSteer3-Feedback and… See the full description on the dataset page: https://huggingface.co/datasets/nvidia/HelpSteer3.",https://huggingface.co/datasets/nvidia/HelpSteer3,"['en', 'zh', 'ko', 'fr', 'es', 'ru', 'ja', 'de', 'it', 'pt', 'pl', 'id', 'nl', 'vi']",[],['10K<n<100K']
ymoslem/acl-6060,ymoslem,2025-03-14 19:07:21+00:00,2025-03-14 19:14:58+00:00,21,1,"['task_categories:translation', 'task_categories:automatic-speech-recognition', 'language:en', 'language:ar', 'language:de', 'language:fa', 'language:fr', 'language:ja', 'language:nl', 'language:pt', 'language:ru', 'language:tr', 'language:zh', 'license:cc-by-4.0', 'size_categories:n<1K', 'format:parquet', 'modality:audio', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","
	
		
		ACL 60/60
	


	
		
		Dataset details
	

ACL 60/60 evaluation sets for multilingual translation of ACL 2022 technical presentations into 10 target languages.

	
		
		Citation
	

@inproceedings{salesky-etal-2023-evaluating,
    title = ""Evaluating Multilingual Speech Translation under Realistic Conditions with Resegmentation and Terminology"",
    author = ""Salesky, Elizabeth  and
      Darwish, Kareem  and
      Al-Badrashiny, Mohamed  and
      Diab, Mona  and
      Niehues, Jan""… See the full description on the dataset page: https://huggingface.co/datasets/ymoslem/acl-6060.",https://huggingface.co/datasets/ymoslem/acl-6060,"['en', 'ar', 'de', 'fa', 'fr', 'ja', 'nl', 'pt', 'ru', 'tr', 'zh']","['translation', 'automatic-speech-recognition']",['n<1K']
JakeTurner616/mtg-cards-SIFT-Features,JakeTurner616,2025-03-14 20:17:31+00:00,2025-10-13 02:15:32+00:00,98,0,"['task_categories:feature-extraction', 'language:en', 'language:fr', 'language:de', 'language:it', 'language:pt', 'language:es', 'language:ru', 'language:ko', 'language:ja', 'language:zh', 'license:mit', 'size_categories:100K<n<1M', 'region:us', 'v5.1']","
	
		
		MTG Card SIFT Features Dataset (v5.1)
	


This dataset contains the latest incremental MTG card SIFT + RootSIFT feature extraction pipeline. It is designed for server-side production inference, enabling additive updates to the FAISS index and id_map.json without retraining or reindexing from scratch.

Note: This version aligns with a daily resources-nightly.zip Hugging Face upload workflow for reliable continuous deployment via my production server.



	
	
	
		What’s New in v5.1?… See the full description on the dataset page: https://huggingface.co/datasets/JakeTurner616/mtg-cards-SIFT-Features.",https://huggingface.co/datasets/JakeTurner616/mtg-cards-SIFT-Features,"['en', 'fr', 'de', 'it', 'pt', 'es', 'ru', 'ko', 'ja', 'zh']",['feature-extraction'],['100K<n<1M']
syntaxsynth/reasoning-conversations,syntaxsynth,2025-03-15 04:33:36+00:00,2025-03-15 04:37:46+00:00,40,4,"['language:en', 'language:es', 'language:ko', 'language:de', 'language:ja', 'language:fr', 'language:zh', 'license:mit', 'size_categories:10K<n<100K', 'format:parquet', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us', 'reasoning', 'deepseek-r1', 'deepseek-r1-zero', 'deepseek-zero']","
	
		
		Multilingual Reasoning Dataset
	


Include languages from German, Korean, Spanish, Japanese, French, Simplified Chinese, Traditional Chinese

Reasoning traces from Deepseek-v3-R1, Deepseek-v3-R1-Zero


Credits sponsored by Currents API
",https://huggingface.co/datasets/syntaxsynth/reasoning-conversations,"['en', 'es', 'ko', 'de', 'ja', 'fr', 'zh']",[],['10K<n<100K']
kurogane/metamath_ja_950_reka3flash,kurogane,2025-03-15 07:11:15+00:00,2025-03-15 10:35:19+00:00,14,0,"['language:ja', 'license:mit', 'size_categories:1K<n<10K', 'format:json', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us', 'math', 'math-qa']","
	
		
		metamath_ja_950_reka3flash
	

meta-math/MetaMathQAの最初の1000件をRekaAI/reka-flash-3で翻訳した後、フォーマットが維持されなかったものを除去しました。
データセットは1000件ありますが、実際は950件程度です。
また、フォーマットのみでクリーニングしたので、出力自体がおかしいものは除去できていません。このあたりは各自でクリーニングし直してください。

	
		
		例
	

input
\nグレイシーとジョーは複素平面上で数を選んでいます。ジョーは点 $1+2i$ を選び、グレイシーは $-1+i$ を選びました。二人の点間の距離はどれくらいですか？\n\n

output
\n複素平面上の点 $(x_1,y_1)$ と $(x_2,y_2)$ の距離は、式 $\\sqrt{(x_2-x_1)^2+(y_2-y_1)^2}$ で求められます。  \nこの場合、ジョーの点は$(1,2)$、グレイシーの点は$(-1,1)$です。  \nしたがって、彼らの点間の距離は… See the full description on the dataset page: https://huggingface.co/datasets/kurogane/metamath_ja_950_reka3flash.",https://huggingface.co/datasets/kurogane/metamath_ja_950_reka3flash,['ja'],[],['1K<n<10K']
Atotti/VTuber-overview,Atotti,2025-03-16 11:53:34+00:00,2025-03-16 14:53:34+00:00,13,0,"['language:ja', 'license:cc-by-nc-sa-4.0', 'size_categories:n<1K', 'format:parquet', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","
	
		
		VTuber Overview Dataset (GPT-4o Search Preview)
	

本データセットは，GPT-4o Search Preview を活用して収集した VTuber に関する活動内容や特徴，コラボ履歴などが自然言語でまとめられておいます。

	
		
		概要
	


収集方法
対象とする VTuber 名をリストアップ
GPT-4o Search Preview に対し，以下の例のプロンプトを入力



{name}というVTuberについて以下の点に重視して詳細に調査し長文で解説してください。
- キャラクター性
- 活動内容
- コラボ履歴
- 人間関係
- コンテンツのジャンル
- 活動スタイル
- 他のVTuberと比較した時の特徴

このデータセットの構築に $27.04（36,276 tokens） を消費しました。
",https://huggingface.co/datasets/Atotti/VTuber-overview,['ja'],[],['n<1K']
MIL-UT/JA-OKVQA-Reasoning,MIL-UT,2025-03-17 02:26:04+00:00,2025-07-30 00:56:15+00:00,8,0,"['task_categories:image-text-to-text', 'task_categories:visual-question-answering', 'language:ja', 'license:apache-2.0', 'size_categories:10K<n<100K', 'format:json', 'modality:image', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","
	
		
		Overview
	

This dataset supports high-quality Visual Question Answering (VQA) focused on knowledge-based reasoning.
Each sample is annotated with structured reasoning steps, progressing from image observation to external knowledge retrieval and answer derivation.
It is constructed based on and expands upon OK-VQA and A-OKVQA.
The dataset is suitable for training and evaluating models in explainable multimodal reasoning tasks.


	
		
	
	
		Sample Data Format (JSON)
	

{
  ""id"": ""0""… See the full description on the dataset page: https://huggingface.co/datasets/MIL-UT/JA-OKVQA-Reasoning.",https://huggingface.co/datasets/MIL-UT/JA-OKVQA-Reasoning,['ja'],"['image-text-to-text', 'visual-question-answering']",['10K<n<100K']
Kendamarron/magpie-easy-math-instruction-88k-qwen2.5-bakeneko-32b-instruct,Kendamarron,2025-03-17 23:02:58+00:00,2025-03-20 15:35:40+00:00,27,1,"['language:ja', 'license:apache-2.0', 'size_categories:10K<n<100K', 'format:parquet', 'modality:tabular', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us', 'synthetic']","
	
		
		magpie-easy-math-instruction-88k-qwen2.5-bakeneko-32b-instruct
	

rinna/qwen2.5-bakeneko-32b-instructを用いたMagpieで生成した合成Instructionデータセットです。
合成したinstructionに対して、以下の方法で2つで回答を生成し、LLM評価で回答が一致していると判定されたレコードのみを残しています。

「あなたは論理的で数学が得意なアシスタントです。」をsystem promptとして得られた応答
「あなたは論理的で数学が得意で優秀なプログラマーです。与えられた問題をPythonを用いて回答します。最後に問題の最終的な答えをprint文で出力します。」をsystem promptとして得られたコードを実行した結果


	
		
	
	
		作成手順
	


rinna/qwen2.5-bakeneko-32b-instructを用いたMagpieで""instruction""を生成（magpie_systemの値をシステムプロンプトとして使用）… See the full description on the dataset page: https://huggingface.co/datasets/Kendamarron/magpie-easy-math-instruction-88k-qwen2.5-bakeneko-32b-instruct.",https://huggingface.co/datasets/Kendamarron/magpie-easy-math-instruction-88k-qwen2.5-bakeneko-32b-instruct,['ja'],[],['10K<n<100K']
Rakuto/MiscSpeech-ja,Rakuto,2025-03-18 01:58:24+00:00,2025-05-04 17:29:08+00:00,46,0,"['task_categories:text-to-speech', 'task_categories:automatic-speech-recognition', 'language:ja', 'license:cc-by-sa-4.0', 'size_categories:10K<n<100K', 'format:parquet', 'modality:audio', 'modality:text', 'library:datasets', 'library:dask', 'library:mlcroissant', 'library:polars', 'region:us']","
	
		
		MiscSpeech-ja
	

This dataset comprises audio and corresponding transcripts collected from a diverse range of YouTube videos and Podcasts. 
",https://huggingface.co/datasets/Rakuto/MiscSpeech-ja,['ja'],"['text-to-speech', 'automatic-speech-recognition']",['10K<n<100K']
Kendamarron/magpie-python-coding-instruction-62k-qwen2.5-bakeneko-32b-instruct,Kendamarron,2025-03-18 08:44:33+00:00,2025-03-20 12:47:53+00:00,10,0,"['language:ja', 'license:apache-2.0', 'size_categories:10K<n<100K', 'format:parquet', 'modality:tabular', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us', 'synthetic']","
	
		
		magpie-python-coding-instruction-62k-qwen2.5-bakeneko-32b-instruct
	

rinna/qwen2.5-bakeneko-32b-instructを用いたMagpieで生成した合成Instructionデータセットです。
なお、計算リソースの問題からoutputの品質評価は行っていません。
ご利用の際はご注意ください。

	
		
		作成手順
	


rinna/qwen2.5-bakeneko-32b-instruct-awqを用いたMagpieで""instruction""を生成（magpie_systemの値をシステムプロンプトとして使用）
rinna/qwen2.5-bakeneko-32b-instruct-awqを用いて""instruction""の言語、タスクの種類、難易度、品質を評価
languageがja以外、もしくは品質がpoor/very poorのレコードを削除
rinna/qwen2.5-bakeneko-32b-instruct-awqを用いて応答を""output""として生成

",https://huggingface.co/datasets/Kendamarron/magpie-python-coding-instruction-62k-qwen2.5-bakeneko-32b-instruct,['ja'],[],['10K<n<100K']
maitrix-org/Voila-million-voice,maitrix-org,2025-03-18 17:34:53+00:00,2025-05-06 14:51:59+00:00,179,2,"['language:en', 'language:zh', 'language:fr', 'language:de', 'language:ja', 'language:ko', 'license:mit', 'arxiv:2505.02707', 'region:us']","
    
    Voila: Voice-Language Foundation Models
    💜 Project Page    ｜    🖥️ GitHub     |   🤗 Hugging Face   |    📑 Paper    |    🌐 Online Demo   |    🏠Maitrix.org


Voila is a new family of large voice-language foundation models aiming to lift human-AI interaction experiences to the next level. Breaking away from the constraints of traditional voice AI systems—high latency, loss of vocal nuances, and mechanical responses—Voila employs an innovative end-to-end model design and a novel… See the full description on the dataset page: https://huggingface.co/datasets/maitrix-org/Voila-million-voice.",https://huggingface.co/datasets/maitrix-org/Voila-million-voice,"['en', 'zh', 'fr', 'de', 'ja', 'ko']",[],[]
puwaer/Doujinshi-sft-dataset-v1,puwaer,2025-03-19 05:41:07+00:00,2025-08-19 09:17:53+00:00,11,1,"['task_categories:text-generation', 'task_categories:fill-mask', 'language:ja', 'license:apache-2.0', 'region:us', 'not-for-all-audiences']","
	
		
		puwaer/Doujinshi-sft-dataset-v1
	

This dataset is a ransom sample of about 20MB taken from puwaer/dlsite-jp-v1 and puwaer/dmm-fanza-jp-v1, then converted into SFT data format using ValueFX9507/Tifa-Deepsex-14b-CoT.
このデータセットは、puwaer/dlsite-jp-v1,puwaer/dmm-fanza-jp-v1より20MbほどランサムサンプリングしValueFX9507/Tifa-Deepsex-14b-CoTを用いてsftのデータ形式に変換したデータセットです。
",https://huggingface.co/datasets/puwaer/Doujinshi-sft-dataset-v1,['ja'],"['text-generation', 'fill-mask']",[]
rpravee/coffeebean,rpravee,2025-03-19 08:44:00+00:00,2025-03-19 09:00:40+00:00,4,1,"['task_categories:question-answering', 'language:en', 'language:ja', 'license:apache-2.0', 'size_categories:n<1K', 'format:json', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']",,https://huggingface.co/datasets/rpravee/coffeebean,"['en', 'ja']",['question-answering'],['n<1K']
1024m/MGTPD-Public,1024m,2025-03-19 09:25:06+00:00,2025-06-07 02:02:57+00:00,20,1,"['task_categories:token-classification', 'language:ar', 'language:cs', 'language:de', 'language:nl', 'language:en', 'language:zh', 'language:fa', 'language:fr', 'language:el', 'language:he', 'language:hi', 'language:id', 'language:it', 'language:ja', 'language:ko', 'language:pl', 'language:pt', 'language:ro', 'language:ru', 'language:es', 'language:tr', 'language:uk', 'language:vi', 'license:cc-by-nc-nd-4.0', 'size_categories:1M<n<10M', 'format:csv', 'modality:tabular', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us', 'linguistics', 'MGT', 'AI text detection']","
	
		
		Dataset for Multilingual Machine-Generated Text Portion Detection
	


	
		
		Model Details
	

To be made Available by Aug 1, 2025      

	
		
		Model Description
	


Developed by: 1-800-SHARED-TASKS
Funded by: Traversaal L.A.R.G.E Research Grant (Nov 2024) , and Cohere's Research Compute Grant (July 2024)(dataset creation for cohere's LLMs) 
Model type: Small Transformer-based for token-classification
Languages (NLP): 23 languages (scalable to 102) 
License: Non-commercial; all… See the full description on the dataset page: https://huggingface.co/datasets/1024m/MGTPD-Public.",https://huggingface.co/datasets/1024m/MGTPD-Public,"['ar', 'cs', 'de', 'nl', 'en', 'zh', 'fa', 'fr', 'el', 'he', 'hi', 'id', 'it', 'ja', 'ko', 'pl', 'pt', 'ro', 'ru', 'es', 'tr', 'uk', 'vi']",['token-classification'],['1M<n<10M']
myst72/sakuraeval-alpha,myst72,2025-03-19 18:44:50+00:00,2025-03-20 18:39:18+00:00,9,0,"['language:en', 'language:ja', 'license:mit', 'size_categories:n<1K', 'format:parquet', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us', 'code']",,https://huggingface.co/datasets/myst72/sakuraeval-alpha,"['en', 'ja']",[],['n<1K']
buruzaemon/amazon_reviews_multi,buruzaemon,2025-03-20 07:43:53+00:00,2025-03-26 21:04:42+00:00,125,1,"['task_categories:summarization', 'task_categories:text-generation', 'task_categories:fill-mask', 'task_categories:text-classification', 'task_ids:text-scoring', 'task_ids:language-modeling', 'task_ids:masked-language-modeling', 'task_ids:sentiment-classification', 'task_ids:sentiment-scoring', 'task_ids:topic-classification', 'annotations_creators:found', 'language_creators:found', 'multilinguality:monolingual', 'multilinguality:multilingual', 'source_datasets:original', 'language:de', 'language:en', 'language:es', 'language:fr', 'language:ja', 'language:zh', 'license:other', 'size_categories:100K<n<1M', 'region:us']",Please refer to https://huggingface.co/datasets/defunct-datasets/amazon_reviews_multi.,https://huggingface.co/datasets/buruzaemon/amazon_reviews_multi,"['de', 'en', 'es', 'fr', 'ja', 'zh']","['summarization', 'text-generation', 'fill-mask', 'text-classification']",['100K<n<1M']
DSULT-Core/niconico-nicovideo,DSULT-Core,2025-03-20 12:17:35+00:00,2025-07-02 09:31:04+00:00,8,0,"['language:ja', 'region:us']","
	
		
		Nicovideo
	


This video, sm9 is the first video ever posted on nicovideo.

	
		
		About Nicovideo
	


Niconico Video (Niconico Douga) is a Japanese video sharing service operated by Dwango. It began service in 2006.It also launched other services such as Niconico Live Broadcast and Niconico Seiga, but on May 1, 2012,these services and Niconico Video became part of the video service ""niconico"" (which was renamed to ""Nico Nico"" on October 27, 2020). - Wikipedia


	
		
	
	
		This dataset… See the full description on the dataset page: https://huggingface.co/datasets/DSULT-Core/niconico-nicovideo.",https://huggingface.co/datasets/DSULT-Core/niconico-nicovideo,['ja'],[],[]
nvidia/miracl-vision,nvidia,2025-03-20 12:17:36+00:00,2025-05-20 06:51:07+00:00,382,7,"['task_ids:document-retrieval', 'multilinguality:multilingual', 'language:ar', 'language:bn', 'language:en', 'language:es', 'language:fa', 'language:fi', 'language:fr', 'language:hi', 'language:id', 'language:ja', 'language:ko', 'language:ru', 'language:sw', 'language:te', 'language:th', 'language:zh', 'language:de', 'language:yo', 'license:cc-by-sa-4.0', 'size_categories:100K<n<1M', 'format:parquet', 'modality:image', 'modality:tabular', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'arxiv:2505.11651', 'region:us', 'text', 'image']","
	
		
		MIRACL-VISION
	

MIRACL-VISION is a multilingual visual retrieval dataset for 18 different languages. It is an extension of MIRACL, a popular text-only multilingual retrieval dataset. The dataset contains user questions, images of Wikipedia articles and annotations, which article can answer a user question. There are 7898 questions and 338734 images. More details can be found in the paper MIRACL-VISION: A Large, multilingual, visual document retrieval benchmark.
This dataset is ready… See the full description on the dataset page: https://huggingface.co/datasets/nvidia/miracl-vision.",https://huggingface.co/datasets/nvidia/miracl-vision,"['ar', 'bn', 'en', 'es', 'fa', 'fi', 'fr', 'hi', 'id', 'ja', 'ko', 'ru', 'sw', 'te', 'th', 'zh', 'de', 'yo']",[],['100K<n<1M']
AmaanP314/youtube-comment-sentiment,AmaanP314,2025-03-21 05:42:33+00:00,2025-05-29 10:13:18+00:00,190,3,"['task_categories:text-classification', 'language:en', 'language:hi', 'language:ja', 'language:es', 'license:cc-by-sa-4.0', 'size_categories:1M<n<10M', 'format:csv', 'modality:tabular', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us', 'youtube', 'sentiment', 'comments', 'multi-linguistic']","
	
		
		YouTube Comments Sentiment Analysis Dataset (1M+ Labeled Comments)
	


	
		
		Overview
	

This dataset comprises over one million YouTube comments, each annotated with sentiment labels—Positive, Neutral, or Negative. The comments span a diverse range of topics including programming, news, sports, politics and more, and are enriched with comprehensive metadata to facilitate various NLP and sentiment analysis tasks.

	
		
		How to use:
	

import pandas as pd
df =… See the full description on the dataset page: https://huggingface.co/datasets/AmaanP314/youtube-comment-sentiment.",https://huggingface.co/datasets/AmaanP314/youtube-comment-sentiment,"['en', 'hi', 'ja', 'es']",['text-classification'],['1M<n<10M']
rokokot/question-type-and-complexity,rokokot,2025-03-22 14:37:51+00:00,2025-03-30 13:36:03+00:00,22,0,"['task_categories:text-classification', 'task_categories:question-answering', 'task_ids:text-scoring', 'task_ids:intent-classification', 'task_ids:extractive-qa', 'annotations_creators:found', 'annotations_creators:machine-generated', 'language_creators:found', 'multilinguality:multilingual', 'source_datasets:original', 'source_datasets:extended|universal-dependencies', 'source_datasets:extended|tydiqa', 'language:ar', 'language:en', 'language:fi', 'language:id', 'language:ja', 'language:ko', 'language:ru', 'license:cc-by-sa-4.0', 'size_categories:100K<n<1M', 'format:csv', 'modality:tabular', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","
	
		
		Question Type and Complexity (QTC) Dataset
	


	
		
		Dataset Overview
	

The Question Type and Complexity (QTC) dataset is a comprehensive resource for linguistics/NLP research focusing on question classification and linguistic complexity analysis across multiple languages. It contains questions from two distinct sources (TyDi QA and Universal Dependencies v2.15), automatically annotated with question types (polar/content) and a set of linguistic complexity features.
Key Features:

2… See the full description on the dataset page: https://huggingface.co/datasets/rokokot/question-type-and-complexity.",https://huggingface.co/datasets/rokokot/question-type-and-complexity,"['ar', 'en', 'fi', 'id', 'ja', 'ko', 'ru']","['text-classification', 'question-answering']",['100K<n<1M']
Athipan01/datasets,Athipan01,2025-03-23 00:40:43+00:00,2025-03-23 06:47:46+00:00,12,0,"['task_categories:text-generation', 'task_categories:text-classification', 'task_categories:translation', 'language:th', 'language:en', 'language:ja', 'license:mit', 'size_categories:n<1K', 'format:json', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us', 'code', 'biology']","
	
		
		Gotdata
	


	
		
		Overview
	

Gotdata เป็นชุดข้อมูลที่รวบรวมโค้ดตัวอย่างพร้อม metadata ที่เกี่ยวข้อง เช่น ชื่อฟังก์ชันและเอกสารประกอบ เหมาะสำหรับการพัฒนาโมเดล NLP เพื่อ:

แยกและสร้างโค้ดโปรแกรม
จำแนกประเภทโค้ด (Code Classification)
สร้างเอกสารโค้ดอัตโนมัติ (Code Summarization)


	
		
		Metadata
	


License: MIT  
Language: ไทย (th), อังกฤษ (en), ญี่ปุ่น (ja)  
Size: 10K < n < 100K ตัวอย่าง  
Tags: code, biology


	
		
		Example Structure
	

ข้อมูลในชุดนี้มีโครงสร้างดังนี้:
{… See the full description on the dataset page: https://huggingface.co/datasets/Athipan01/datasets.",https://huggingface.co/datasets/Athipan01/datasets,"['th', 'en', 'ja']","['text-generation', 'text-classification', 'translation']",['n<1K']
sterlinsun/N44D-GMX,sterlinsun,2025-03-24 05:55:53+00:00,2025-03-24 06:04:55+00:00,6,0,"['language:en', 'language:zh', 'language:ja', 'license:apache-2.0', 'size_categories:1M<n<10M', 'region:us', 'code', 'aI']",,https://huggingface.co/datasets/sterlinsun/N44D-GMX,"['en', 'zh', 'ja']",[],['1M<n<10M']
dartags/danbooru-2408-blind-captions,dartags,2025-03-24 06:46:06+00:00,2025-03-24 07:15:26+00:00,35,2,"['task_categories:text-generation', 'language:ja', 'language:en', 'license:mit', 'size_categories:1M<n<10M', 'format:parquet', 'modality:text', 'library:datasets', 'library:dask', 'library:mlcroissant', 'library:polars', 'region:us']","
	
		
		Danbooru 2408 Blind Captions
	

from datasets import load_dataset

ds = load_dataset(
  ""dartags/danbooru-2408-blind-captions"",
  split=""train"",
)

",https://huggingface.co/datasets/dartags/danbooru-2408-blind-captions,"['ja', 'en']",['text-generation'],['1M<n<10M']
umiyuki/JDocQA_SingleImage,umiyuki,2025-03-24 09:10:09+00:00,2025-03-25 04:37:35+00:00,16,0,"['source_datasets:shunk031/JDocQA', 'language:ja', 'license:cc-by-sa-4.0', 'size_categories:1K<n<10K', 'format:parquet', 'modality:image', 'modality:text', 'library:datasets', 'library:dask', 'library:mlcroissant', 'library:polars', 'region:us']","
	
		
		JDocQA_SingleImage Dataset
	


	
		
		Dataset Summary
	

JDocQA_SingleImageは、shunk031/JDocQAのtestサブセットを基に作成されたデータセットで、PDFファイルを200dpiの画像に変換し、画像が取得できない設問と複数画像が必要な設問を除外しています。元のデータセットが37GBと大きすぎるため、サイズを削減しつつ実用性を保つことを目的としています。

元データ: shunk031/JDocQA (test split, 1,176 instances)
変換後: PDFを画像に置き換え、画像が取得できてかつ単一画像入力の設問のみを含む
言語: 日本語 (BCP-47 ja-JP)


	
		
		Data Fields
	


input_text: 質問テキスト
question_id: ユニークなID
answer: 回答
answer_type: 回答タイプ（0: Yes/No, 1: Factoid, 2: Numerical, 3: Open-ended）… See the full description on the dataset page: https://huggingface.co/datasets/umiyuki/JDocQA_SingleImage.",https://huggingface.co/datasets/umiyuki/JDocQA_SingleImage,['ja'],[],['1K<n<10K']
umiyuki/JDocQA_SingleImage_200,umiyuki,2025-03-24 20:14:13+00:00,2025-03-25 04:40:06+00:00,23,0,"['source_datasets:shunk031/JDocQA', 'language:ja', 'license:cc-by-sa-4.0', 'size_categories:n<1K', 'format:parquet', 'modality:image', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","
	
		
		JDocQA_SingleImage_200 Dataset
	


	
		
		Dataset Summary
	

JDocQA_SingleImage_200は、shunk031/JDocQAのtestサブセットを基に作成されたデータセットで、PDFファイルを200dpiの画像に変換し、画像が取得できない設問と複数画像が必要な設問を除外しています。さらに計測時間短縮のために各設問形式毎に50問、計200問に絞りました。元のデータセットが37GBと大きすぎるため、サイズを削減しつつ実用性を保つことを目的としています。

元データ: shunk031/JDocQA (test split, 1,176 instances)
変換後: PDFを画像に置き換え、画像が取得できてかつ単一画像入力の設問のみを含む。さらに各設問形式毎に先頭から50問ずつに絞る。
言語: 日本語 (BCP-47 ja-JP)


	
		
		Data Fields
	


input_text: 質問テキスト
question_id: ユニークなID
answer: 回答… See the full description on the dataset page: https://huggingface.co/datasets/umiyuki/JDocQA_SingleImage_200.",https://huggingface.co/datasets/umiyuki/JDocQA_SingleImage_200,['ja'],[],['n<1K']
nakagawanatuko/hatoma_for_DL,nakagawanatuko,2025-03-25 04:00:24+00:00,2025-03-25 04:02:52+00:00,4,0,"['language:ja', 'license:cc-by-4.0', 'size_categories:10K<n<100K', 'format:text', 'modality:text', 'library:datasets', 'library:mlcroissant', 'region:us']",,https://huggingface.co/datasets/nakagawanatuko/hatoma_for_DL,['ja'],[],['10K<n<100K']
matsuo-lab/JP-LLM-Corpus-PII-Filtered-10B,matsuo-lab,2025-03-25 07:12:24+00:00,2025-03-26 05:34:12+00:00,29,1,"['language:ja', 'license:unknown', 'size_categories:10K<n<100K', 'format:webdataset', 'modality:text', 'library:datasets', 'library:webdataset', 'library:mlcroissant', 'region:us']","
	
		
		CommonCrawl Japanese (Filtered PPI) Dataset
	

本データセットは、CommonCrawlより抽出した約100億（10B）トークン規模の日本語テキストデータから、特に配慮が必要な「要配慮個人情報」をフィルタリング処理したものです。

	
		
		データセットの概要
	


元データソース: CommonCrawl（https://commoncrawl.org/）
トークン数: 約10Bトークン
言語: 日本語
処理内容: 要配慮個人情報をルールベースおよび機械学習分類器を用いてフィルタリング

フィルタリングには以下のコードを使用しております。https://github.com/matsuolab/jp-llm-corpus-pii-filter/

	
		
	
	
		注意事項
	

本データセットは、非常に大規模なテキストから自動的に要配慮個人情報を除去したものであり、完全な排除を保証するものではありません。そのため、二次的な活用に際しては、目的に応じた適切な管理・配慮が必要です。… See the full description on the dataset page: https://huggingface.co/datasets/matsuo-lab/JP-LLM-Corpus-PII-Filtered-10B.",https://huggingface.co/datasets/matsuo-lab/JP-LLM-Corpus-PII-Filtered-10B,['ja'],[],['10K<n<100K']
swdq/ethics,swdq,2025-03-25 12:12:25+00:00,2025-03-25 12:20:59+00:00,9,0,"['task_categories:text-generation', 'language:ja', 'license:apache-2.0', 'size_categories:10K<n<100K', 'format:csv', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us', 'legal']","
	
		
		倫理に関するデータセット
	


	
		
		概要
	

このデータセットは日本語の倫理に関するデータセットです。anthracite-org/magnum-v4-12bを使用しすべて作成しました。

	
		
		データ内容
	


evilとjusticeをラベルとし質問と回答を作成しています。
これにより分類タスク、生成タスク両方にて使える汎用性かつシンプル性を持たせました。


	
		
		ライセンス
	

このデータセットはApache-2.0ライセンスのもとで提供されます。

	
		
		データサイズ
	

本データセットの規模は10K〜100Kの範囲に収まります。

	
		
		貢献
	

データの改善や拡張に関する提案は歓迎します。
",https://huggingface.co/datasets/swdq/ethics,['ja'],['text-generation'],['10K<n<100K']
nyuuzyou/archiveofourown,nyuuzyou,2025-03-25 16:29:35+00:00,2025-04-08 23:10:00+00:00,0,14,"['task_categories:text-generation', 'task_categories:text-classification', 'task_ids:language-modeling', 'task_ids:topic-classification', 'annotations_creators:found', 'multilinguality:multilingual', 'source_datasets:original', 'language:ar', 'language:bg', 'language:ca', 'language:cs', 'language:da', 'language:de', 'language:el', 'language:en', 'language:es', 'language:et', 'language:fa', 'language:fi', 'language:fr', 'language:he', 'language:hi', 'language:hr', 'language:hu', 'language:id', 'language:it', 'language:ja', 'language:ko', 'language:lt', 'language:lv', 'language:ms', 'language:nl', 'language:no', 'language:pl', 'language:pt', 'language:ro', 'language:ru', 'language:sk', 'language:sl', 'language:sr', 'language:sv', 'language:th', 'language:tr', 'language:uk', 'language:vi', 'language:zh', 'license:other', 'size_categories:10M<n<100M', 'format:json', 'modality:text', 'library:datasets', 'library:dask', 'library:mlcroissant', 'region:us']","
	
		
		Dataset Card for Archive of Our Own (AO3)
	


	
		
		Dataset Summary
	

This dataset contains approximately 12.6 million publicly available works from Archive of Our Own (AO3), a fan-created, fan-run, non-profit archive for transformative fanworks. The dataset was created by processing works with IDs from 1 to 63,200,000 that are publicly accessible. Each entry contains the full text of the work along with comprehensive metadata including title, author, fandom, relationships… See the full description on the dataset page: https://huggingface.co/datasets/nyuuzyou/archiveofourown.",https://huggingface.co/datasets/nyuuzyou/archiveofourown,"['ar', 'bg', 'ca', 'cs', 'da', 'de', 'el', 'en', 'es', 'et', 'fa', 'fi', 'fr', 'he', 'hi', 'hr', 'hu', 'id', 'it', 'ja', 'ko', 'lt', 'lv', 'ms', 'nl', 'no', 'pl', 'pt', 'ro', 'ru', 'sk', 'sl', 'sr', 'sv', 'th', 'tr', 'uk', 'vi', 'zh']","['text-generation', 'text-classification']",['10M<n<100M']
racineai/OGC_Military,racineai,2025-03-26 10:10:13+00:00,2025-08-28 10:59:53+00:00,587,10,"['task_categories:visual-document-retrieval', 'task_categories:text-retrieval', 'language:en', 'language:fr', 'language:ar', 'language:de', 'language:ru', 'language:uk', 'language:zh', 'language:fa', 'language:nl', 'language:es', 'language:ja', 'language:ms', 'language:it', 'language:pl', 'license:apache-2.0', 'size_categories:100K<n<1M', 'format:parquet', 'modality:image', 'modality:text', 'library:datasets', 'library:dask', 'library:mlcroissant', 'library:polars', 'region:us', 'RAG', 'DSE', 'retrieval', 'military']","
	
		
		OGC - Organized, Grouped, Cleaned
	


	
		
		Military Vision DSE
	


Intended for image/text to vector (DSE)


	
		
		Dataset Composition
	

Made with https://github.com/RacineAIOS/OGC_pdf-to-parquet
This dataset was created by scraping PDF documents from online sources and generating relevant synthetic queries.
We used Google's Gemini 2.0 Flash Lite model in our custom pipeline to produce the queries, allowing us to create a diverse set of questions based on the document content.… See the full description on the dataset page: https://huggingface.co/datasets/racineai/OGC_Military.",https://huggingface.co/datasets/racineai/OGC_Military,"['en', 'fr', 'ar', 'de', 'ru', 'uk', 'zh', 'fa', 'nl', 'es', 'ja', 'ms', 'it', 'pl']","['visual-document-retrieval', 'text-retrieval']",['100K<n<1M']
SousiOmine/TagInstruct-JP,SousiOmine,2025-03-26 13:50:00+00:00,2025-03-27 01:03:43+00:00,12,0,"['language:ja', 'license:mit', 'size_categories:1K<n<10K', 'format:json', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","出力になにかしらの制約があるシステムプロンプトに対する追従性を向上させるためのデータセットの試作です。Deepseek-V3-0324によって生成されました。生成に使ったプロンプト等はリポジトリ内のgenerate_dataset.pyを参照してください。  
本データセットおよびソースコードはMITライセンスで提供されます。  
",https://huggingface.co/datasets/SousiOmine/TagInstruct-JP,['ja'],[],['1K<n<10K']
srvmishra832/multilingual-amazon-reviews-6-languages,srvmishra832,2025-03-27 07:33:13+00:00,2025-03-27 14:02:18+00:00,13,1,"['task_categories:summarization', 'task_categories:text-classification', 'task_categories:sentence-similarity', 'language:en', 'language:de', 'language:fr', 'language:ja', 'language:es', 'language:ch', 'size_categories:1M<n<10M', 'format:parquet', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us', 'product_reviews']",,https://huggingface.co/datasets/srvmishra832/multilingual-amazon-reviews-6-languages,"['en', 'de', 'fr', 'ja', 'es', 'ch']","['summarization', 'text-classification', 'sentence-similarity']",['1M<n<10M']
shisa-ai/shisa-v2-sharegpt,shisa-ai,2025-03-27 10:18:57+00:00,2025-04-12 13:56:38+00:00,24,5,"['task_categories:text-generation', 'language:ja', 'language:en', 'license:apache-2.0', 'size_categories:100K<n<1M', 'format:parquet', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us', 'sft', 'synthetic', 'sharegpt']","
	
		
		shisa-v2-sharegpt
	

This is an updated version of the original shisa-v1 dataset augmxnt/ultra-orca-boros-en-ja-v1 and retains the same conversations field and sharegpt formatting to facilitate its use as drop-in replacement for the original dataset.
The shisa-v2 revision filters a few entries, but largely retains the exact composition and prompts of the original.

All responses have been entirely regenerated from open weight models (Athene V2, Llama 3.3 70B, and Tulu 3 405B)
Outputs… See the full description on the dataset page: https://huggingface.co/datasets/shisa-ai/shisa-v2-sharegpt.",https://huggingface.co/datasets/shisa-ai/shisa-v2-sharegpt,"['ja', 'en']",['text-generation'],['100K<n<1M']
umiyuki/Ani-Bench-JP,umiyuki,2025-03-28 05:19:50+00:00,2025-04-02 06:37:14+00:00,48,3,"['language:ja', 'license:mit', 'size_categories:n<1K', 'format:parquet', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","
	
		
		Ani-Bench-JP
	


	
		
		データセット概要
	

Ani-Bench-JP は、日本の人気アニメに関する知識を測定するためのベンチマーク用データセットです。このデータセットは、5つのアニメ作品（『魔法少女まどか☆マギカ』、『ぼっち・ざ・ろっく！』、『機動戦士ガンダム』、『HUNTER×HUNTER』、『新世紀エヴァンゲリオン』）からそれぞれ20問ずつ、合計100問のクイズ形式の問題で構成されています。
LLMのアニメに関する理解度を日本語で評価する用途を想定してます。

	
		
		データ構造
	

データはCSV形式で提供されており、test スプリットとしてアップロードされています。ファイルには以下の3つの列が含まれます：

問題: アニメに関するクイズ形式の質問
答え: その質問に対する正解
番組名: 質問が関連するアニメ作品の名前


	
		
		列の詳細
	


	
		
列名
説明
例


		
問題
クイズの質問文
主人公の名前は何ですか？


答え
質問に対する正解
鹿目まどか


番組名
関連するアニメのタイトル… See the full description on the dataset page: https://huggingface.co/datasets/umiyuki/Ani-Bench-JP.",https://huggingface.co/datasets/umiyuki/Ani-Bench-JP,['ja'],[],['n<1K']
ChiekoSeren/GPT-5-model-switch,ChiekoSeren,2025-03-29 05:45:36+00:00,2025-03-29 06:28:02+00:00,18,0,"['task_categories:text-generation', 'language:zh', 'language:ja', 'language:en', 'language:fr', 'license:mit', 'size_categories:10K<n<100K', 'format:json', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'doi:10.57967/hf/5034', 'region:us']","
	
		
		GPT-5-Model-Switch Dataset
	


	
		
		Overview
	

The GPT-5-Model-Switch dataset is designed to train an open-source model selector, serving as an alternative to OpenAI's GPT-5. As Sam Altman stated, ""GPT-5 will be a model selector,"" and this dataset supports the development of an intelligent system capable of dynamically selecting the optimal model based on task requirements.

	
		
		Dataset Purpose
	

The goal of this dataset is to train a model selector that can:

Analyze the… See the full description on the dataset page: https://huggingface.co/datasets/ChiekoSeren/GPT-5-model-switch.",https://huggingface.co/datasets/ChiekoSeren/GPT-5-model-switch,"['zh', 'ja', 'en', 'fr']",['text-generation'],['10K<n<100K']
hpprc/reranker-scores,hpprc,2025-03-30 05:11:47+00:00,2025-04-18 05:35:43+00:00,165,4,"['language:ja', 'license:other', 'size_categories:100K<n<1M', 'format:parquet', 'modality:text', 'library:datasets', 'library:dask', 'library:mlcroissant', 'library:polars', 'region:us']","
	
		
		Reranker-Scores
	

既存の日本語検索・QAデータセットについて、データセット中のクエリに付与された正・負例の関連度を多言語・日本語reranker 5種類を用いてスコア付けしたデータセットです。クエリごとに200件程度の正・負例文書が付与されています (事例ごとに付与個数はバラバラなのでご注意ください)。score.pos.avg および score.neg.avg はそれぞれ正例・負例についての5種のrerankerの平均スコアになっています。

	
		
Short Name
Hub ID


		
bge
BAAI/bge-reranker-v2-m3


gte
Alibaba-NLP/gte-multilingual-reranker-base


ruri
cl-nagoya/ruri-reranker-large


ruriv3-preview
cl-nagoya/ruri-v3-reranker-310m-preview


ja-ce… See the full description on the dataset page: https://huggingface.co/datasets/hpprc/reranker-scores.",https://huggingface.co/datasets/hpprc/reranker-scores,['ja'],[],['100K<n<1M']
mesolitica/Speech-Translation-Instructions,mesolitica,2025-03-30 14:18:00+00:00,2025-04-01 06:13:50+00:00,26,1,"['task_categories:text2text-generation', 'multilinguality:multilingual', 'language:ms', 'language:en', 'language:zh', 'language:ja', 'language:fr', 'language:ar', 'license:cc0-1.0', 'size_categories:100K<n<1M', 'format:parquet', 'modality:audio', 'modality:text', 'library:datasets', 'library:dask', 'library:mlcroissant', 'library:polars', 'region:us']","
	
		
		Speech-Translation-Instructions
	

The instructions translated from 120 languages Common Voice to english, arabic, japanese, mandarin and french from common voice speech dataset. Suitable to use to finetune Speech LLM.
",https://huggingface.co/datasets/mesolitica/Speech-Translation-Instructions,"['ms', 'en', 'zh', 'ja', 'fr', 'ar']",['text2text-generation'],['100K<n<1M']
jaeyong2/ja-reasoning,jaeyong2,2025-03-31 04:18:30+00:00,2025-04-23 06:21:29+00:00,11,0,"['language:ja', 'license:odc-by', 'size_categories:1K<n<10K', 'format:parquet', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","
	
		
		Development Process
	


question dataset from hotchpotch/japanese-qa-reasoning-100k
We used gemini-pro-2.5


	
		
		License
	


hotchpotch/japanese-qa-reasoning-100k : Open Data Commons License Attribution family

",https://huggingface.co/datasets/jaeyong2/ja-reasoning,['ja'],[],['1K<n<10K']
jaeyong2/ja-code-reasoning,jaeyong2,2025-03-31 04:20:57+00:00,2025-04-23 06:29:01+00:00,13,0,"['language:ja', 'license:mit', 'size_categories:1K<n<10K', 'format:parquet', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","
	
		
		Development Process
	


question dataset from HachiML/amenokaku-code-instruct-python-mit
We used gemini-2.0-thinking


	
		
		License
	


HachiML/amenokaku-code-instruct-python-mit : https://choosealicense.com/licenses/mit/

",https://huggingface.co/datasets/jaeyong2/ja-code-reasoning,['ja'],[],['1K<n<10K']
haiFrHust/VNJPTranslate,haiFrHust,2025-03-31 14:18:11+00:00,2025-04-02 13:49:34+00:00,27,0,"['task_categories:translation', 'language:vi', 'language:ja', 'license:mit', 'size_categories:1M<n<10M', 'format:csv', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'arxiv:2305.12720', 'arxiv:2504.00339', 'region:us', 'legal', 'finance']","
	
		
		Vietnamese-Japanese Parallel Corpus
	

🌟 If you find this project valuable, please consider starring our VNJPTranslate GitHub repo! Your support helps us reach more people and continue improving the project. 🔗 Check it out here! 🌟
The Vietnamese-Japanese Parallel Corpus is a bilingual dataset specifically designed for translation tasks between Vietnamese and Japanese. It consists of 3.3M rows of parallel text. This makes it a robust resource for developing and evaluating machine… See the full description on the dataset page: https://huggingface.co/datasets/haiFrHust/VNJPTranslate.",https://huggingface.co/datasets/haiFrHust/VNJPTranslate,"['vi', 'ja']",['translation'],['1M<n<10M']
SakanaAI/ALE-Bench,SakanaAI,2025-04-01 06:30:44+00:00,2025-06-17 05:58:33+00:00,3911,9,"['task_categories:image-text-to-text', 'task_categories:reinforcement-learning', 'task_categories:text-generation', 'task_categories:visual-question-answering', 'language:en', 'language:ja', 'license:cc-by-nd-4.0', 'size_categories:n<1K', 'modality:image', 'modality:text', 'arxiv:2506.09050', 'region:us', 'image', 'text']","
	
		
		ALE-Bench
	


	
		
		Dataset Description
	

ALE-Bench is a benchmark for evaluating AI systems on score-based algorithmic programming contests.
This dataset is officially provided by AtCoder Inc..
Please be sure to check the ""License"" section below.
Please read our blog post and our paper for more details.
Related resources:

Preprint paper (arXiv)
Sakana AI Blog (English)
Sakana AI Blog (Japanese)
GitHub repository
Leaderboard


	
		
		Usage
	

Our Python library automatically… See the full description on the dataset page: https://huggingface.co/datasets/SakanaAI/ALE-Bench.",https://huggingface.co/datasets/SakanaAI/ALE-Bench,"['en', 'ja']","['image-text-to-text', 'reinforcement-learning', 'text-generation', 'visual-question-answering']",['n<1K']
Takaharadesu/BanG_Dream_150k,Takaharadesu,2025-04-02 17:15:49+00:00,2025-04-02 17:36:30+00:00,13,1,"['task_categories:translation', 'language:zh', 'language:ja', 'license:mit', 'size_categories:100K<n<1M', 'format:csv', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","


BanG Dream Dialogue 150K

A large-scale multilingual dialogue corpus featuring 150,000+ interactions across 40 characters from the BanG Dream!本数据集收录 BanG Dream! 系列 40 角色 的 150,000+ 条对话，适用于自然语言处理任务，深度还原角色性格与互动模式。




	
		
		Dataset Statistics|统计
	

· ako: 4854条
· anon: 2251条
· arisa: 6713条
· aya: 5479条
· chisato: 5074条
· chuchu: 2432条
· eve: 4639条
· hagumi: 4144条
· himari: 5266条
· hina: 5102条
· kanon: 4022条
· kaoru: 4083条
· kasumi: 7233条
· kokoro: 4493条
· layer: 2225条
· lisa: 6057条
· lock:… See the full description on the dataset page: https://huggingface.co/datasets/Takaharadesu/BanG_Dream_150k.",https://huggingface.co/datasets/Takaharadesu/BanG_Dream_150k,"['zh', 'ja']",['translation'],['100K<n<1M']
DataoceanAI/137712_hours_Multilingual_Corpus_for_Dolphin_ASR_Model,DataoceanAI,2025-04-03 06:03:37+00:00,2025-04-03 06:28:40+00:00,7,3,"['language:zh', 'language:ja', 'language:th', 'language:ru', 'language:ko', 'language:id', 'language:vi', 'language:hi', 'language:ur', 'language:ms', 'language:uz', 'language:ar', 'language:fa', 'language:bn', 'language:ta', 'language:te', 'language:ug', 'language:gu', 'language:my', 'language:tl', 'language:kk', 'language:or', 'language:ne', 'language:mn', 'language:km', 'language:jv', 'language:lo', 'language:si', 'language:pa', 'language:ba', 'language:ks', 'language:tg', 'language:su', 'language:mr', 'language:az', 'region:us']","
	
		
		Duration
	

137,712 hours

	
		
		Languages
	

38 Eastern Languages + 22 Chinese

	
		
		Description
	

This dataset is an integration of our vast, high-quality commercial dataset collections, encompassing a total of 137,712 hours of audio across 38 Eastern languages. Additionally, it includes 22 Chinese dialects. 
The dataset is carefully annotated and covers a wide variety of languages, scenarios, and contexts, ensuring diversity and richness in the data. 
This broad coverage allows… See the full description on the dataset page: https://huggingface.co/datasets/DataoceanAI/137712_hours_Multilingual_Corpus_for_Dolphin_ASR_Model.",https://huggingface.co/datasets/DataoceanAI/137712_hours_Multilingual_Corpus_for_Dolphin_ASR_Model,"['zh', 'ja', 'th', 'ru', 'ko', 'id', 'vi', 'hi', 'ur', 'ms', 'uz', 'ar', 'fa', 'bn', 'ta', 'te', 'ug', 'gu', 'my', 'tl', 'kk', 'or', 'ne', 'mn', 'km', 'jv', 'lo', 'si', 'pa', 'ba', 'ks', 'tg', 'su', 'mr', 'az']",[],[]
itterative/danbooru_wikis_full,itterative,2025-04-03 07:27:12+00:00,2025-04-06 16:27:09+00:00,30,4,"['task_categories:text-classification', 'task_categories:text-generation', 'task_categories:feature-extraction', 'annotations_creators:no-annotation', 'source_datasets:danbooru', 'language:en', 'language:ja', 'language:zh', 'language:ko', 'license:mit', 'size_categories:100K<n<1M', 'region:us', 'art', 'anime', 'not-for-all-audiences']","
	
		
		Danbooru Full Wiki Dataset
	

This is the full wiki dataset of danbooru.donmai.us, containing the wiki pages/tags/tag aliases/tag implications. You can train something like LLMs on this dataset
",https://huggingface.co/datasets/itterative/danbooru_wikis_full,"['en', 'ja', 'zh', 'ko']","['text-classification', 'text-generation', 'feature-extraction']",['100K<n<1M']
DataPilot/ichikara-instruction-003-sharegpt,DataPilot,2025-04-04 01:28:16+00:00,2025-04-04 01:31:31+00:00,13,0,"['language:ja', 'license:cc-by-nc-sa-4.0', 'size_categories:1K<n<10K', 'format:json', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","
	
		
		ichikara-instruction-003-sharegpt Dataset by DataPilot
	


	
		
		データセット概要 (Dataset Summary)
	

このデータセットは、kinokokoro/ichikara-instruction-003 で公開されている日本語インストラクションデータを、広く利用されている ShareGPT形式 に変換したものです。変換および公開は DataPilot が行いました。
元データセットは、様々な質問に対して人間が作成した回答が含まれており、日本語の大規模言語モデル（LLM）のファインチューニングに有用です。このShareGPT形式版は、特に会話形式のデータ入力を想定したモデルの学習に適しています。
注意: 元データセットには、1つの質問に対して複数の回答が存在する場合があります。このShareGPT形式データセットでは、各「質問と回答のペア」を独立した一つの会話データとして扱っています。

	
		
	
	
		データ形式 (Data Format)
	

データはJSON… See the full description on the dataset page: https://huggingface.co/datasets/DataPilot/ichikara-instruction-003-sharegpt.",https://huggingface.co/datasets/DataPilot/ichikara-instruction-003-sharegpt,['ja'],[],['1K<n<10K']
EQUES/AIME24-ja,EQUES,2025-04-04 13:23:26+00:00,2025-04-04 13:26:32+00:00,10,0,"['language:ja', 'size_categories:n<1K', 'format:parquet', 'modality:tabular', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us', 'math']","Japanese-translation data of aimo-validation-aime. 
Used ChatGPT-4o.
Index : 0 ~ 30#rows : 31

	
		
		Note
	

The data indicies are different from typical AIME24 dataset. For example HuggingFaceH4/aime_2024.
",https://huggingface.co/datasets/EQUES/AIME24-ja,['ja'],[],['n<1K']
cl-nagoya/ruri-v3-dataset-reranker,cl-nagoya,2025-04-06 04:59:40+00:00,2025-05-09 03:57:36+00:00,109,0,"['task_categories:text-ranking', 'task_categories:text-retrieval', 'language:ja', 'license:other', 'size_categories:100K<n<1M', 'format:parquet', 'modality:text', 'library:datasets', 'library:dask', 'library:mlcroissant', 'library:polars', 'region:us']","Created from hpprc/reranker-scores.
We found that cleaning up noisy positives and negatives in our existing dataset using rerankers' scores had a massive impact on performance.
Concretely:

We averaged the scores from five off‑the‑shelf reranker models.
For ""positive"" examples (documents that contain the answer string for a given query), we only kept those with an average score ≥ 0.3.
For ""negative"" examples (documents that do not contain the answer string), we only kept those with an average… See the full description on the dataset page: https://huggingface.co/datasets/cl-nagoya/ruri-v3-dataset-reranker.",https://huggingface.co/datasets/cl-nagoya/ruri-v3-dataset-reranker,['ja'],"['text-ranking', 'text-retrieval']",['100K<n<1M']
SivaMallikarjun/world-languages-dataset,SivaMallikarjun,2025-04-06 17:43:04+00:00,2025-04-06 17:51:05+00:00,6,0,"['task_categories:text-classification', 'task_ids:language-identification', 'annotations_creators:expert-generated', 'multilinguality:multilingual', 'source_datasets:original', 'language:en', 'language:es', 'language:hi', 'language:zh', 'language:ar', 'language:fr', 'language:de', 'language:ru', 'language:pt', 'language:ja', 'language:ko', 'license:mit', 'size_categories:n<1K', 'format:csv', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","
	
		
		🌍 World Languages Dataset
	

This dataset contains a list of official and unofficial languages categorized by language families...
",https://huggingface.co/datasets/SivaMallikarjun/world-languages-dataset,"['en', 'es', 'hi', 'zh', 'ar', 'fr', 'de', 'ru', 'pt', 'ja', 'ko']",['text-classification'],['n<1K']
Silviase/augeobench,Silviase,2025-04-07 13:50:23+00:00,2025-04-07 13:52:01+00:00,10,0,"['task_categories:visual-question-answering', 'task_ids:visual-question-answering', 'multilinguality:monolingual', 'language:ja', 'license:cc-by-4.0', 'region:us']","
	
		
		AugeoBench
	

AugeoBench is a multimodal QA benchmark consisting of Japanese entrance-exam-style geometry questions. Each instance provides a contextual description, a question text, a reference image, and a correct answer.

	
		
		Dataset Structure
	


id: Unique ID for the question
url: URL of the question
question_context_ja: Context of the question
question_text_ja: Question text
question_information_ja: Additional information about the question
answer_exact: Exact answer… See the full description on the dataset page: https://huggingface.co/datasets/Silviase/augeobench.",https://huggingface.co/datasets/Silviase/augeobench,['ja'],['visual-question-answering'],[]
DataPilot/Zero_SFT_Ja_by_Mistral_Small,DataPilot,2025-04-07 15:59:18+00:00,2025-04-07 16:01:29+00:00,13,1,"['task_categories:text-generation', 'language:ja', 'license:apache-2.0', 'size_categories:1K<n<10K', 'format:json', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us', 'shareGPT']","
	
		
		DataPilot/Zero_SFT_Ja_by_Mistral_Small
	

このデータセットは、日本語で記述された高品質な合成プロンプトとそのAI出力を収録しています。すべてのデータは Mistral Small 3.1 24B Instruct 2503 モデルを使用してゼロから合成されています。

	
		
		概要
	


	
		
項目
詳細


		
データセット名
DataPilot/Zero_SFT_Ja_by_Mistral_Small


言語
日本語


データ作成方法
完全自動生成（モデルによるゼロショット合成）


使用モデル
Mistral Small 3.1 24B Instruct 2503


フォーマット
JSONL（id, input, output, conversation）


ライセンス
Apache-2.0


作成コード
foxn2000/zero_one_instruction


	



	
		
	
	
		データセット構造
	

データセットには以下のカラムが含まれています。

	
		
カラム名… See the full description on the dataset page: https://huggingface.co/datasets/DataPilot/Zero_SFT_Ja_by_Mistral_Small.",https://huggingface.co/datasets/DataPilot/Zero_SFT_Ja_by_Mistral_Small,['ja'],['text-generation'],['1K<n<10K']
deepghs-wip/Renai-Circulation,deepghs-wip,2025-04-08 09:05:11+00:00,2025-09-26 11:32:29+00:00,2191,4,"['annotations_creators:no-annotation', 'source_datasets:pixiv', 'language:en', 'language:ja', 'language:zh', 'language:ko', 'license:other', 'size_categories:100M<n<1B', 'modality:text', 'modality:image', 'modality:tabular', 'region:us', 'huggingface', 'transformers', 'analysis', 'text', 'image', 'tabular', 'parquet']","
	
		
		Images
	

142782377 records in total. Only 100 records shown.

	
		
id
pid
mimetype
filename
file_size
width
height
mode


		
103242211
0
image/jpeg
103242211_p0.jpg
70565
665
742
RGB


103242198
23
image/png
103242198_p23.png
35178
500
500
RGBA


103242198
22image/png
103242198_p22.png
69259
500
500
RGBA


103242198
21
image/png
103242198_p21.png
129459
500
500
RGBA


103242198
20
image/png
103242198_p20.png
93930
500
500
RGBA


103242198
19
image/png
103242198_p19.png
110216
500
500… See the full description on the dataset page: https://huggingface.co/datasets/deepghs-wip/Renai-Circulation.",https://huggingface.co/datasets/deepghs-wip/Renai-Circulation,"['en', 'ja', 'zh', 'ko']",[],['100M<n<1B']
deepghs-wip/Renai-Circulation-table,deepghs-wip,2025-04-08 11:44:47+00:00,2025-04-17 11:55:02+00:00,286,0,"['annotations_creators:no-annotation', 'source_datasets:pixiv', 'language:en', 'language:ja', 'language:zh', 'language:ko', 'license:other', 'size_categories:100M<n<1B', 'format:parquet', 'modality:tabular', 'modality:text', 'modality:image', 'library:datasets', 'library:dask', 'library:mlcroissant', 'library:polars', 'region:us', 'huggingface', 'transformers', 'analysis', 'text', 'image', 'tabular', 'parquet']","
	
		
		Information
	

49752138 records in total. Only 50 records shown.

	
		
id
title
comm
tags
rate
lewd
type
isai
size
pages
created
uploaded
modified
count
request
user


		
103242215
del/tar/une NSFW R/-18 ② スパ受
エロいスパム㌧集です。受けばかりです。モブスパ、スパスパ、パレスパなイラストばかりです。緊縛、ショタ、腐、女装あります。ほぼ白黒、落書きです。苦手な方はご注意を。














	

",https://huggingface.co/datasets/deepghs-wip/Renai-Circulation-table,"['en', 'ja', 'zh', 'ko']",[],['100M<n<1B']
sindhuhegde/multivsr,sindhuhegde,2025-04-09 05:42:20+00:00,2025-04-27 09:02:05+00:00,189,4,"['language:en', 'language:fr', 'language:de', 'language:es', 'language:it', 'language:ca', 'language:ru', 'language:ja', 'language:zh', 'language:pl', 'language:pt', 'language:tr', 'language:nl', 'license:mit', 'size_categories:1M<n<10M', 'modality:tabular', 'modality:text', 'modality:video', 'modality:audio', 'region:us', 'lipreading', 'audiovisual', 'video', 'asr', 'avsr', 'talkingface', 'audio', 'speech']","
	
		
		Dataset: MultiVSR
	

We introduce a large-scale multilingual lip-reading dataset: MultiVSR. The dataset comprises a total of 12,000 hours of video footage, covering English + 12 non-English languages. MultiVSR is a massive dataset with a huge diversity in terms of the speakers as well as languages, with approximately 1.6M video clips across 123K YouTube videos. Please check the website for samples.

  




	
		
	
	
		Download instructions
	

Please check the GitHub repo to download… See the full description on the dataset page: https://huggingface.co/datasets/sindhuhegde/multivsr.",https://huggingface.co/datasets/sindhuhegde/multivsr,"['en', 'fr', 'de', 'es', 'it', 'ca', 'ru', 'ja', 'zh', 'pl', 'pt', 'tr', 'nl']",[],['1M<n<10M']
atomscott/soccertrack-v2,atomscott,2025-04-10 05:29:41+00:00,2025-04-10 05:44:34+00:00,12,0,"['language:ja', 'language:en', 'license:apache-2.0', 'region:us', 'sports', 'soccer']",,https://huggingface.co/datasets/atomscott/soccertrack-v2,"['ja', 'en']",[],[]
pviechn1/ParaBLoCC,pviechn1,2025-04-10 16:51:20+00:00,2025-05-20 21:52:48+00:00,277,0,"['task_categories:translation', 'task_categories:zero-shot-classification', 'language:en', 'language:sw', 'language:fi', 'language:hu', 'language:ca', 'language:cs', 'language:nl', 'language:fr', 'language:de', 'language:el', 'language:it', 'language:pl', 'language:ru', 'language:es', 'language:sv', 'language:ig', 'language:ja', 'language:ko', 'language:ay', 'language:qu', 'language:am', 'language:ar', 'language:he', 'language:ti', 'language:zh', 'language:tr', 'language:uz', 'license:mit', 'region:us']","
	
		
		Dataset Card for Dataset Name
	

Parallel basic locative constructions in English and 26 target languages.

	
		
		Dataset Details
	


	
		
		Dataset Description
	

We introduce ParaBLoCC, the Parallel Basic Locative Construction Corpus, the first
multilingual compendium of this important grammatico-functional construction, and par-
ticularly the first such corpus containing semantically equivalent BLCs in source/target
language pairs. The data —taken from bitext corpora in English… See the full description on the dataset page: https://huggingface.co/datasets/pviechn1/ParaBLoCC.",https://huggingface.co/datasets/pviechn1/ParaBLoCC,"['en', 'sw', 'fi', 'hu', 'ca', 'cs', 'nl', 'fr', 'de', 'el', 'it', 'pl', 'ru', 'es', 'sv', 'ig', 'ja', 'ko', 'ay', 'qu', 'am', 'ar', 'he', 'ti', 'zh', 'tr', 'uz']","['translation', 'zero-shot-classification']",[]
CohereLabs/deja-vu-pairwise-evals,CohereLabs,2025-04-10 21:05:43+00:00,2025-04-17 01:16:46+00:00,38,3,"['task_categories:text-generation', 'task_categories:other', 'language:en', 'language:fr', 'language:de', 'language:es', 'language:it', 'language:pt', 'language:ja', 'language:ko', 'language:zh', 'language:ar', 'language:el', 'language:fa', 'language:pl', 'language:id', 'language:cs', 'language:he', 'language:hi', 'language:nl', 'language:ro', 'language:ru', 'language:tr', 'language:uk', 'language:vi', 'license:cc-by-nc-sa-4.0', 'arxiv:2504.11829', 'region:us', 'multilingual', 'evaluaton']","
	
		
		Automatic pairwise preference evaluations for ""Déjà Vu: Multilingual LLM Evaluation through the Lens of Machine Translation Evaluation""
	


	
		
		Content
	

This data contains pairwise automatic win-rate evaluations for 2 benchmarks.

Outputs and judge decisions for the m-ArenaHard benchmark for sampled generations (5 each) from Aya Expanse 8B and Qwen2.5 7B Instruct.
Original and roundtrip-translated prompts (by NLLB 3.3B, Aya Expanse 32B, Google Translate, Command A), outputs and… See the full description on the dataset page: https://huggingface.co/datasets/CohereLabs/deja-vu-pairwise-evals.",https://huggingface.co/datasets/CohereLabs/deja-vu-pairwise-evals,"['en', 'fr', 'de', 'es', 'it', 'pt', 'ja', 'ko', 'zh', 'ar', 'el', 'fa', 'pl', 'id', 'cs', 'he', 'hi', 'nl', 'ro', 'ru', 'tr', 'uk', 'vi']","['text-generation', 'other']",[]
DataPilot/Zero_SFT_Ja_v2_b3t4,DataPilot,2025-04-11 03:52:02+00:00,2025-04-11 03:57:58+00:00,8,1,"['task_categories:text-generation', 'language:ja', 'license:apache-2.0', 'size_categories:10K<n<100K', 'format:json', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us', 'shareGPT']","
	
		
		DataPilot/Zero_SFT_Ja_v2_b3t4
	

このデータセットは、日本語で記述された高品質な合成プロンプトとそのAI出力を収録しています。すべてのデータは Mistral Small 3.1 24B Instruct 2503 モデルを使用してゼロから合成されています。

	
		
		概要
	


	
		
項目
詳細


		
データセット名
DataPilot/Zero_SFT_Ja_v2_b3t4


言語
日本語


データ作成方法
完全自動生成（モデルによるゼロショット合成）


使用モデル
Mistral Small 3.1 24B Instruct 2503


フォーマット
JSONL（id, input, output, conversation）


ライセンス
Apache-2.0


作成コード
foxn2000/zero_one_instruction


	



	
		
	
	
		データセット構造
	

データセットには以下のカラムが含まれています。

	
		
カラム名
説明


		
id… See the full description on the dataset page: https://huggingface.co/datasets/DataPilot/Zero_SFT_Ja_v2_b3t4.",https://huggingface.co/datasets/DataPilot/Zero_SFT_Ja_v2_b3t4,['ja'],['text-generation'],['10K<n<100K']
DataPilot/Zero_SFT_Ja_v2,DataPilot,2025-04-11 19:21:55+00:00,2025-04-16 21:11:58+00:00,9,2,"['task_categories:text-generation', 'language:ja', 'license:cdla-permissive-2.0', 'size_categories:10K<n<100K', 'format:json', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us', 'shareGPT']","
	
		
		DataPilot/Zero_SFT_Ja_v2_b3t4
	

このデータセットは、日本語で記述された高品質な合成プロンプトとそのAI出力を収録しています。すべてのデータは Mistral Small 3.1 24B Instruct 2503 モデルを使用してゼロから合成されています。

	
		
		概要
	


	
		
項目
詳細


		
データセット名
DataPilot/Zero_SFT_Ja_v2_b3t4


言語
日本語


データ作成方法
完全自動生成（モデルによるゼロショット合成）


使用モデル
Mistral Small 3.1 24B Instruct 2503


フォーマット
JSONL（id, input, output, conversation）


ライセンス
cdla-permissive-2.0


作成コード
foxn2000/zero_one_instruction


	



	
		
	
	
		データセット構造
	

データセットには以下のカラムが含まれています。

	
		
カラム名
説明


		
id… See the full description on the dataset page: https://huggingface.co/datasets/DataPilot/Zero_SFT_Ja_v2.",https://huggingface.co/datasets/DataPilot/Zero_SFT_Ja_v2,['ja'],['text-generation'],['10K<n<100K']
morinoko-inari/ruby-rails-ja-en,morinoko-inari,2025-04-12 20:15:35+00:00,2025-04-20 14:34:41+00:00,7,0,"['language:en', 'language:ja', 'license:cc', 'size_categories:n<1K', 'format:json', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us', 'programming', 'ruby', 'translation', 'technical', 'computer-science', 'rails']","
	
		
		Description
	

This is a WIP dataset!
This dataset contains Japanese and English sentences taken from Ruby and Ruby on Rails documentation websites. It also contains some synthetic data generated by Claude (TODO: label synthetic data vs. 'real' data).

	
		
		Usage
	


	
		
		Load dataset into your project
	

dataset = load_dataset(""morinoko-inari/ruby-rails-ja-en"", split=""train"")

	
		
		Manually split into test and training sets
	

For example:
dataset =… See the full description on the dataset page: https://huggingface.co/datasets/morinoko-inari/ruby-rails-ja-en.",https://huggingface.co/datasets/morinoko-inari/ruby-rails-ja-en,"['en', 'ja']",[],['n<1K']
kadirnar/japanese-voice-combined,kadirnar,2025-04-13 12:51:44+00:00,2025-04-13 14:22:59+00:00,73,4,"['language:ja', 'region:us']","
	
		
		Japanese Voice Dataset Combined
	

This dataset combines multiple high-quality Japanese voice datasets to create a comprehensive collection of Japanese speech data. It's designed to be used for speech recognition, text-to-speech, and other speech-related machine learning tasks.

	
		
		Dataset Content
	

This dataset contains over 86,000 audio samples in Japanese from various high-quality sources. The data comes from the following sources:

	
		
Dataset
Estimated Samples


		
StoryTTS… See the full description on the dataset page: https://huggingface.co/datasets/kadirnar/japanese-voice-combined.",https://huggingface.co/datasets/kadirnar/japanese-voice-combined,['ja'],[],[]
VOICEVOX/kanalizer-dataset,VOICEVOX,2025-04-14 03:55:49+00:00,2025-04-20 13:34:08+00:00,24,0,"['language:ja', 'license:mit', 'size_categories:100K<n<1M', 'format:json', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","
	
		
		kanalizer
	

英単語から読みを推測するライブラリ、kanalizerのデータセット置き場。データセットの作成に用いたコードはGitHubのVOICEVOX/kanalizer、学習済みモデルはVOICEVOX/kanalizer-modelを参照してください。
",https://huggingface.co/datasets/VOICEVOX/kanalizer-dataset,['ja'],[],['100K<n<1M']
skyfsj/gkmas-yolo.producer-challenge,skyfsj,2025-04-14 10:12:31+00:00,2025-04-14 11:14:30+00:00,57,0,"['language:zh', 'language:ja', 'license:apache-2.0', 'size_categories:n<1K', 'format:imagefolder', 'modality:image', 'library:datasets', 'library:mlcroissant', 'region:us', 'game', 'gakumas', 'gkmas']",,https://huggingface.co/datasets/skyfsj/gkmas-yolo.producer-challenge,"['zh', 'ja']",[],['n<1K']
radm/r1-multilingual-prefs,radm,2025-04-14 11:46:41+00:00,2025-05-04 06:06:17+00:00,18,1,"['task_categories:text-generation', 'language:am', 'language:ar', 'language:bn', 'language:zh', 'language:cs', 'language:nl', 'language:en', 'language:fr', 'language:de', 'language:el', 'language:ha', 'language:he', 'language:hi', 'language:id', 'language:it', 'language:ja', 'language:jv', 'language:km', 'language:ko', 'language:lo', 'language:ms', 'language:mr', 'language:fa', 'language:pl', 'language:pt', 'language:ro', 'language:ru', 'language:es', 'language:sw', 'language:sv', 'language:tl', 'language:ta', 'language:te', 'language:th', 'language:tr', 'language:uk', 'language:ur', 'language:vi', 'size_categories:1K<n<10K', 'format:parquet', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","Dataset basen on:

lightblue/reasoning-multilingual-R1-Llama-70B-train
Pinkstack/thinking-multilingual-30-23-small-690 (with cleaned <answer> tags)
kristaller486/Nebo-T1-Russian (3000 samples)

Rejected answers generated by deepseek-ai/DeepSeek-R1-Distill-Qwen-7B
",https://huggingface.co/datasets/radm/r1-multilingual-prefs,"['am', 'ar', 'bn', 'zh', 'cs', 'nl', 'en', 'fr', 'de', 'el', 'ha', 'he', 'hi', 'id', 'it', 'ja', 'jv', 'km', 'ko', 'lo', 'ms', 'mr', 'fa', 'pl', 'pt', 'ro', 'ru', 'es', 'sw', 'sv', 'tl', 'ta', 'te', 'th', 'tr', 'uk', 'ur', 'vi']",['text-generation'],['1K<n<10K']
MrDragonFox/JA_Emilia_Yodas_266h,MrDragonFox,2025-04-14 19:07:12+00:00,2025-04-14 20:29:06+00:00,64,0,"['language:ja', 'license:cc-by-4.0', 'size_categories:100K<n<1M', 'format:parquet', 'modality:audio', 'modality:text', 'library:datasets', 'library:dask', 'library:mlcroissant', 'library:polars', 'region:us']","the dataset is 266h out of the japanese part from https://huggingface.co/datasets/amphion/Emilia-Dataset ( Emilia Yodas - cc by 4.0)
audio event classified via scribe v1 (elevenlabs stt/asr)
facebook audio aestetics to be used as prefilter
the dataset is very much at a v1 -
if you want to help - lets talk
https://discord.gg/RUs3uzBdW3 (nsfw is fully opt in only - as sfw)
if you want full transaction timestamps as they come from scribe v1 - they are cc by 4.0 NC and can be found here… See the full description on the dataset page: https://huggingface.co/datasets/MrDragonFox/JA_Emilia_Yodas_266h.",https://huggingface.co/datasets/MrDragonFox/JA_Emilia_Yodas_266h,['ja'],[],['100K<n<1M']
willwade/AACConversations,willwade,2025-04-15 15:58:17+00:00,2025-05-15 10:37:50+00:00,13,3,"['task_categories:text-generation', 'task_categories:text-classification', 'task_ids:language-modeling', 'task_ids:sentiment-analysis', 'task_ids:text-simplification', 'multilinguality:multilingual', 'language:en', 'language:fr', 'language:de', 'language:es', 'language:it', 'language:nl', 'language:el', 'language:ru', 'language:he', 'language:ar', 'language:pt', 'language:cy', 'language:ja', 'language:zh', 'language:ko', 'language:nb', 'language:sv', 'language:da', 'language:fi', 'language:cs', 'language:sk', 'language:pl', 'language:hu', 'language:sl', 'language:hr', 'language:uk', 'language:eu', 'language:ca', 'language:fo', 'language:af', 'license:cc-by-4.0', 'size_categories:10K<n<100K', 'format:parquet', 'modality:tabular', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us', 'aac', 'augmentative-alternative-communication', 'assistive-technology', 'conversation', 'multilingual', 'text-correction', 'text-generation']","
	
		
		AAC Conversations Dataset
	


	
		
		Dataset Description
	

The AAC Conversations Dataset is a collection of simulated conversations involving Augmentative and Alternative Communication (AAC) users across multiple languages. This dataset is designed to help researchers and developers build better assistive technologies for people who use AAC devices.

	
		
		Dataset Summary
	

This dataset contains conversations between AAC users and communication partners in various scenarios. Each… See the full description on the dataset page: https://huggingface.co/datasets/willwade/AACConversations.",https://huggingface.co/datasets/willwade/AACConversations,"['en', 'fr', 'de', 'es', 'it', 'nl', 'el', 'ru', 'he', 'ar', 'pt', 'cy', 'ja', 'zh', 'ko', 'nb', 'sv', 'da', 'fi', 'cs', 'sk', 'pl', 'hu', 'sl', 'hr', 'uk', 'eu', 'ca', 'fo', 'af']","['text-generation', 'text-classification']",['10K<n<100K']
tokyotech-llm/JEMHopQA,tokyotech-llm,2025-04-17 10:12:05+00:00,2025-08-08 12:19:07+00:00,149,0,"['task_categories:question-answering', 'language:ja', 'license:cc-by-sa-4.0', 'size_categories:1K<n<10K', 'format:parquet', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","
	
		
		JEMHopQA
	

このデータセットは SB Intuitions様が公開されている sbintuitions/JEMHopQA を，評価フレームワーク swallow-evaluation-instruct で用いるためにクローンしたものです．  

	
		
		出典
	


v1, v1.1, v1.2: aiishii/JEMHopQA on GitHub の複製．
v1.[1,2]-extended-answers: SB Intuitions 様が同義語や異表記の別解を追加したもの．
具体的には answer: str が answers: List[str] に変更され，オリジナルの正解および別解が answers に格納されている．


	
		
		JEMHopQA
	


JEMHopQA (Japanese Explainable Multi-hop Question Answering) is a Japanese multi-hop QA dataset that can evaluate internal reasoning. It… See the full description on the dataset page: https://huggingface.co/datasets/tokyotech-llm/JEMHopQA.",https://huggingface.co/datasets/tokyotech-llm/JEMHopQA,['ja'],['question-answering'],['1K<n<10K']
cl-nagoya/ruri-v3-dataset-reranker-preview,cl-nagoya,2025-04-18 04:30:08+00:00,2025-04-18 05:47:11+00:00,153,0,"['task_categories:text-ranking', 'task_categories:text-retrieval', 'language:ja', 'license:other', 'size_categories:100K<n<1M', 'format:parquet', 'modality:text', 'library:datasets', 'library:dask', 'library:mlcroissant', 'library:polars', 'region:us']","created from hotchpotch/hpprc_emb-scores

	
		
		License Information
	


	
		
Name
Type
License (根拠)


		
Mr. TyDi
Retrieval
Apache 2.0


MIRACL
Retrieval
Apache 2.0


Auto Wiki QA Nemotron
QA & Retrieval
CC-BY-SA-4.0


JSQuAD
QA & Retrieval
CC-BY-SA-4.0


JQaRA (dev, unused)
QA
CC-BY-SA-4.0


JaQuAD
QA & Retrieval
CC-BY-SA-3.0


MKQA
QA
CC-BY-3.0


Quiz Works
QA
Free (二次利用自由)


Quiz No Mori
QA
Free (二次利用自由)


	

",https://huggingface.co/datasets/cl-nagoya/ruri-v3-dataset-reranker-preview,['ja'],"['text-ranking', 'text-retrieval']",['100K<n<1M']
Itbanque/ScreenTalk_JA2ZH-XS,Itbanque,2025-04-18 23:05:35+00:00,2025-05-23 16:50:17+00:00,38,3,"['task_categories:translation', 'language:ja', 'language:zh', 'size_categories:10K<n<100K', 'format:parquet', 'modality:audio', 'modality:text', 'library:datasets', 'library:dask', 'library:mlcroissant', 'library:polars', 'region:us', 'translation', 'ja', 'zh_cn']","
	
		
		ScreenTalk_JA2ZH-XS
	

ScreenTalk_JA2ZH-XS is a paired dataset of Japanese speech and Chinese translated text released by DataLabX. It is designed for training and evaluating speech translation (ST) and multilingual speech understanding models. The data consists of spoken dialogue extracted from real-world Japanese movies and TV shows.

	
		
		📦 Dataset Overview
	


Source Language: Japanese (Audio)
Target Language: Simplified Chinese (Text)
Number of Samples: 10,000
Total Duration:… See the full description on the dataset page: https://huggingface.co/datasets/Itbanque/ScreenTalk_JA2ZH-XS.",https://huggingface.co/datasets/Itbanque/ScreenTalk_JA2ZH-XS,"['ja', 'zh']",['translation'],['10K<n<100K']
Aratako/Synthetic-Japanese-Roleplay-NSFW-Claude-3.7s-5.3k,Aratako,2025-04-19 09:20:05+00:00,2025-04-19 10:24:00+00:00,34,4,"['task_categories:text-generation', 'language:ja', 'license:cc-by-nc-sa-4.0', 'size_categories:1K<n<10K', 'format:parquet', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us', 'roleplay', 'not-for-all-audiences']","
	
		
		Synthetic-Japanese-Roleplay-NSFW-Claude-3.7s-5.3k
	


	
		
		概要
	

Claude 3.7 Sonnetを用いて作成した、5300件の日本語ロールプレイの対話を収録した合成データセットです。各データは10ターンから20ターン程度あります。
このデータセットはNSFW表現を含みます。

	
		
		データの詳細
	

各データは以下のキーを含んでいます。

major_genre: ジャンル（大分類）
minor_genre: ジャンル（小分類）
tag: 年齢制限用タグ（R-18）
world_setting: 舞台・世界観の設定
scene_setting: 対話シーンの設定
user_setting: ユーザー側のキャラクターの設定
assistant_setting: アシスタント側のキャラクターの設定
dialogue_tone: 対話のトーン
conversations: 上記設定に基づいたユーザーとアシスタントの対話（OpenAI messages形式）

設定等の情報からsystem… See the full description on the dataset page: https://huggingface.co/datasets/Aratako/Synthetic-Japanese-Roleplay-NSFW-Claude-3.7s-5.3k.",https://huggingface.co/datasets/Aratako/Synthetic-Japanese-Roleplay-NSFW-Claude-3.7s-5.3k,['ja'],['text-generation'],['1K<n<10K']
Aratako/Synthetic-Japanese-Roleplay-NSFW-Claude-3.7s-5.3k-formatted,Aratako,2025-04-19 10:17:53+00:00,2025-04-19 12:54:03+00:00,27,5,"['task_categories:text-generation', 'language:ja', 'license:cc-by-nc-sa-4.0', 'size_categories:1K<n<10K', 'format:parquet', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us', 'roleplay', 'not-for-all-audiences']","
	
		
		Synthetic-Japanese-Roleplay-NSFW-Claude-3.7s-5.3k-formatted
	


	
		
		概要
	

Claude 3.7 Sonnetを用いて作成した日本語ロールプレイデータセットであるAratako/Synthetic-Japanese-Roleplay-NSFW-Claude-3.7s-5.3kにsystem messageを追加して整形したデータセットです。
データの詳細については元データセットのREADMEを参照してください。

	
		
		ライセンス
	

CC-BY-NC-SA 4.0の元配布します。
また、Anthropicの利用規約に記載のある通り、このデータを使ってAnthropicのサービスやモデルと競合するようなモデルを開発することは禁止されています。
",https://huggingface.co/datasets/Aratako/Synthetic-Japanese-Roleplay-NSFW-Claude-3.7s-5.3k-formatted,['ja'],['text-generation'],['1K<n<10K']
EvilHero/Hydrus_Network,EvilHero,2025-04-19 17:19:25+00:00,2025-04-21 18:21:49+00:00,8,0,"['task_categories:text-classification', 'language:en', 'language:ja', 'license:wtfpl', 'size_categories:10K<n<100K', 'format:parquet', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us', 'tag taxonomy', 'booru', 'not-for-all-audiences']","
	
		
		Dataset Card for Dataset Name
	



This dataset card aims to be a base template for new datasets. It has been generated using this raw template.

	
		
		Dataset Details
	


	
		
		Dataset Description
	






Curated by: [More Information Needed]
Funded by [optional]: [More Information Needed]
Shared by [optional]: [More Information Needed]
Language(s) (NLP): [More Information Needed]
License: [More Information Needed]


	
		
		Dataset Sources [optional]
	




Repository: [More… See the full description on the dataset page: https://huggingface.co/datasets/EvilHero/Hydrus_Network.",https://huggingface.co/datasets/EvilHero/Hydrus_Network,"['en', 'ja']",['text-classification'],['10K<n<100K']
Aratako/Synthetic-Japanese-Roleplay-NSFW-DeepSeek-V3-0324-20k,Aratako,2025-04-20 02:08:20+00:00,2025-04-23 14:12:47+00:00,33,8,"['task_categories:text-generation', 'language:ja', 'license:mit', 'size_categories:10K<n<100K', 'format:parquet', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us', 'roleplay', 'not-for-all-audiences']","
	
		
		Synthetic-Japanese-Roleplay-NSFW-DeepSeek-V3-0324-20k
	


	
		
		概要
	

deepseek-ai/DeepSeek-V3-0324を用いて作成した、約20000件の日本語ロールプレイの対話を収録した合成データセットです。各データは10ターンから20ターン程度あります。
このデータセットはNSFW表現を含みます。

	
		
		データの詳細
	

各データは以下のキーを含んでいます。

major_genre: ジャンル（大分類）
minor_genre: ジャンル（小分類）
tag: 年齢制限用タグ（R-18）
world_setting: 舞台・世界観の設定
scene_setting: 対話シーンの設定
user_setting: ユーザー側のキャラクターの設定
assistant_setting: アシスタント側のキャラクターの設定
dialogue_tone: 対話のトーン
conversations: 上記設定に基づいたユーザーとアシスタントの対話（OpenAI messages形式）… See the full description on the dataset page: https://huggingface.co/datasets/Aratako/Synthetic-Japanese-Roleplay-NSFW-DeepSeek-V3-0324-20k.",https://huggingface.co/datasets/Aratako/Synthetic-Japanese-Roleplay-NSFW-DeepSeek-V3-0324-20k,['ja'],['text-generation'],['10K<n<100K']
galirage/GPR-bench,galirage,2025-04-20 07:54:44+00:00,2025-07-29 08:52:53+00:00,7,1,"['task_categories:text-generation', 'task_categories:question-answering', 'task_categories:summarization', 'language:en', 'language:ja', 'license:mit', 'size_categories:n<1K', 'modality:text', 'doi:10.57967/hf/5411', 'region:us', 'llm', 'evaluation']","






	
		
		GPR‑bench
	

General‑Purpose Reproducibility Benchmark
🌐 Galirage Inc. | 📄 arXiv | 💻 GitHub



GPR‑bench is an open‑source, multilingual benchmark for regression testing and reproducibility tracking in generative‑AI systems.
It provides a compact yet diverse suite of prompts and reference outputs that let you verify whether a model (or prompt) change alters output quality in undesirable ways.

8 general‑purpose categories × 10 scenarios × 2 languages (English 🇺🇸 / Japanese… See the full description on the dataset page: https://huggingface.co/datasets/galirage/GPR-bench.",https://huggingface.co/datasets/galirage/GPR-bench,"['en', 'ja']","['text-generation', 'question-answering', 'summarization']",['n<1K']
jaeyong2/embeding-ja-synthesis,jaeyong2,2025-04-20 08:50:40+00:00,2025-04-23 06:43:58+00:00,9,0,"['language:ja', 'license:apache-2.0', 'size_categories:100K<n<1M', 'format:parquet', 'modality:text', 'library:datasets', 'library:dask', 'library:mlcroissant', 'library:polars', 'region:us']","
	
		
		Development Process
	


context dataset from Cohere/miracl-ja-corpus-22-12
We used deepcogito/cogito-v1-preview-qwen-32B


	
		
		License
	


Cohere/miracl-ja-corpus-22-12 : https://choosealicense.com/licenses/apache-2.0/
deepcogito/cogito-v1-preview-qwen-32B : https://choosealicense.com/licenses/apache-2.0/


	
		
		Acknowledgement
	

This research is supported by TPU Research Cloud program.
",https://huggingface.co/datasets/jaeyong2/embeding-ja-synthesis,['ja'],[],['100K<n<1M']
radm/r1-multilingual-prefs-llama,radm,2025-04-20 09:11:21+00:00,2025-05-04 06:06:48+00:00,15,2,"['task_categories:text-generation', 'language:am', 'language:ar', 'language:bn', 'language:zh', 'language:cs', 'language:nl', 'language:en', 'language:fr', 'language:de', 'language:el', 'language:ha', 'language:he', 'language:hi', 'language:id', 'language:it', 'language:ja', 'language:jv', 'language:km', 'language:ko', 'language:lo', 'language:ms', 'language:mr', 'language:fa', 'language:pl', 'language:pt', 'language:ro', 'language:ru', 'language:es', 'language:sw', 'language:sv', 'language:tl', 'language:ta', 'language:te', 'language:th', 'language:tr', 'language:uk', 'language:ur', 'language:vi', 'size_categories:1K<n<10K', 'format:parquet', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","Dataset basen on:

lightblue/reasoning-multilingual-R1-Llama-70B-train
Pinkstack/thinking-multilingual-30-23-small-690 (with cleaned <answer> tags)
kristaller486/Nebo-T1-Russian (3000 samples)

Rejected answers generated by deepseek-ai/DeepSeek-R1-Distill-Llama-8B
",https://huggingface.co/datasets/radm/r1-multilingual-prefs-llama,"['am', 'ar', 'bn', 'zh', 'cs', 'nl', 'en', 'fr', 'de', 'el', 'ha', 'he', 'hi', 'id', 'it', 'ja', 'jv', 'km', 'ko', 'lo', 'ms', 'mr', 'fa', 'pl', 'pt', 'ro', 'ru', 'es', 'sw', 'sv', 'tl', 'ta', 'te', 'th', 'tr', 'uk', 'ur', 'vi']",['text-generation'],['1K<n<10K']
dahara1/FineWeb2-HQ-ja-20B,dahara1,2025-04-21 03:57:32+00:00,2025-04-21 04:59:35+00:00,249,0,"['language:ja', 'size_categories:10M<n<100M', 'format:json', 'modality:text', 'library:datasets', 'library:dask', 'library:mlcroissant', 'region:us']","元のデータセットFineWeb2-HQ  
元のデータセットは多言語で巨大なため、扱いやすい用に日本語データを約200GBだけ抽出したデータセットです
wc 結果
     1763269     38541549   5370473709 fineweb_jpn_Jpan_chunk_0.jsonl
     1784158     37430170   5370514369 fineweb_jpn_Jpan_chunk_1.jsonl
     1639554     40065129   5370372344 fineweb_jpn_Jpan_chunk_10.jsonl
     1575127     42167166   5370298354 fineweb_jpn_Jpan_chunk_11.jsonl
     1686375     39225898   5370402506 fineweb_jpn_Jpan_chunk_12.jsonl
     1786948     36456352   5370498572… See the full description on the dataset page: https://huggingface.co/datasets/dahara1/FineWeb2-HQ-ja-20B.",https://huggingface.co/datasets/dahara1/FineWeb2-HQ-ja-20B,['ja'],[],['10M<n<100M']
Aratako/Synthetic-Japanese-Roleplay-SFW-DeepSeek-V3-0324-20k,Aratako,2025-04-22 15:52:46+00:00,2025-04-23 14:07:27+00:00,21,9,"['task_categories:text-generation', 'language:ja', 'license:mit', 'size_categories:10K<n<100K', 'format:parquet', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us', 'roleplay']","
	
		
		Synthetic-Japanese-Roleplay-SFW-DeepSeek-V3-0324-20k
	


	
		
		概要
	

deepseek-ai/DeepSeek-V3-0324を用いて作成した、約20000件の日本語ロールプレイの対話を収録した合成データセットです。各データは10ターンから20ターン程度あります。

	
		
		データの詳細
	

各データは以下のキーを含んでいます。

major_genre: ジャンル（大分類）
minor_genre: ジャンル（小分類）
tag: 年齢制限用タグ（全年齢、R-15）
world_setting: 舞台・世界観の設定
scene_setting: 対話シーンの設定
user_setting: ユーザー側のキャラクターの設定
assistant_setting: アシスタント側のキャラクターの設定
dialogue_tone: 対話のトーン
conversations: 上記設定に基づいたユーザーとアシスタントの対話（OpenAI messages形式）

設定等の情報からsystem… See the full description on the dataset page: https://huggingface.co/datasets/Aratako/Synthetic-Japanese-Roleplay-SFW-DeepSeek-V3-0324-20k.",https://huggingface.co/datasets/Aratako/Synthetic-Japanese-Roleplay-SFW-DeepSeek-V3-0324-20k,['ja'],['text-generation'],['10K<n<100K']
Aratako/Synthetic-Japanese-Roleplay-NSFW-DeepSeek-V3-0324-20k-formatted,Aratako,2025-04-22 16:11:23+00:00,2025-06-04 13:53:14+00:00,10,1,"['task_categories:text-generation', 'language:ja', 'license:mit', 'size_categories:10K<n<100K', 'region:us', 'roleplay', 'not-for-all-audiences']","
	
		
		Synthetic-Japanese-Roleplay-NSFW-DeepSeek-V3-0324-20k-formatted
	


	
		
		概要
	

deepseek-ai/DeepSeek-V3-0324を用いて作成した日本語ロールプレイデータセットであるAratako/Synthetic-Japanese-Roleplay-NSFW-DeepSeek-V3-0324-20kにsystem messageを追加して整形したデータセットです。
データの詳細については元データセットのREADMEを参照してください。

	
		
		ライセンス
	

MITライセンスの元配布します。
",https://huggingface.co/datasets/Aratako/Synthetic-Japanese-Roleplay-NSFW-DeepSeek-V3-0324-20k-formatted,['ja'],['text-generation'],['10K<n<100K']
Aratako/Synthetic-Japanese-Roleplay-SFW-DeepSeek-V3-0324-20k-formatted,Aratako,2025-04-22 16:12:17+00:00,2025-06-04 13:52:18+00:00,13,2,"['task_categories:text-generation', 'language:ja', 'license:mit', 'size_categories:10K<n<100K', 'format:parquet', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us', 'roleplay']","
	
		
		Synthetic-Japanese-Roleplay-SFW-DeepSeek-V3-0324-20k-formatted
	


	
		
		概要
	

deepseek-ai/DeepSeek-V3-0324を用いて作成した日本語ロールプレイデータセットであるAratako/Synthetic-Japanese-Roleplay-SFW-DeepSeek-V3-0324-20kにsystem messageを追加して整形したデータセットです。
データの詳細については元データセットのREADMEを参照してください。

	
		
		ライセンス
	

MITライセンスの元配布します。
",https://huggingface.co/datasets/Aratako/Synthetic-Japanese-Roleplay-SFW-DeepSeek-V3-0324-20k-formatted,['ja'],['text-generation'],['10K<n<100K']
whoisjones/fiNERweb,whoisjones,2025-04-23 13:24:31+00:00,2025-09-29 15:04:16+00:00,325,4,"['task_categories:token-classification', 'task_ids:named-entity-recognition', 'language:vi', 'language:ta', 'language:or', 'language:sk', 'language:af', 'language:cs', 'language:ga', 'language:pt', 'language:so', 'language:sl', 'language:cy', 'language:fy', 'language:uk', 'language:is', 'language:la', 'language:hy', 'language:bg', 'language:tr', 'language:uz', 'language:nl', 'language:ps', 'language:be', 'language:en', 'language:xh', 'language:jv', 'language:hi', 'language:my', 'language:br', 'language:ur', 'language:sr', 'language:zh', 'language:ka', 'language:hr', 'language:ml', 'language:km', 'language:te', 'language:ru', 'language:ar', 'language:de', 'language:fr', 'language:om', 'language:sw', 'language:az', 'language:gl', 'language:ko', 'language:sd', 'language:fi', 'language:lv', 'language:eo', 'language:kk', 'language:lt', 'language:mk', 'language:eu', 'language:am', 'language:he', 'language:si', 'language:ne', 'language:yi', 'language:sq', 'language:it', 'language:kn', 'language:mn', 'language:ja', 'language:gu', 'language:su', 'language:ro', 'language:sa', 'language:ku', 'language:ky', 'language:ug', 'language:gd', 'language:es', 'language:et', 'language:th', 'language:sv', 'language:hu', 'language:bs', 'language:bn', 'language:ca', 'language:mr', 'language:da', 'language:pl', 'language:el', 'language:ms', 'language:mg', 'language:pa', 'language:lo', 'language:fa', 'language:tl', 'language:as', 'language:id', 'license:mit', 'size_categories:1M<n<10M', 'region:us']","fiNERweb is a multilingual named entity recognition dataset containing annotated text in multiple languages.
Each example contains the original text, tokenized text, BIO tags, and character/token spans for entities.",https://huggingface.co/datasets/whoisjones/fiNERweb,"['vi', 'ta', 'or', 'sk', 'af', 'cs', 'ga', 'pt', 'so', 'sl', 'cy', 'fy', 'uk', 'is', 'la', 'hy', 'bg', 'tr', 'uz', 'nl', 'ps', 'be', 'en', 'xh', 'jv', 'hi', 'my', 'br', 'ur', 'sr', 'zh', 'ka', 'hr', 'ml', 'km', 'te', 'ru', 'ar', 'de', 'fr', 'om', 'sw', 'az', 'gl', 'ko', 'sd', 'fi', 'lv', 'eo', 'kk', 'lt', 'mk', 'eu', 'am', 'he', 'si', 'ne', 'yi', 'sq', 'it', 'kn', 'mn', 'ja', 'gu', 'su', 'ro', 'sa', 'ku', 'ky', 'ug', 'gd', 'es', 'et', 'th', 'sv', 'hu', 'bs', 'bn', 'ca', 'mr', 'da', 'pl', 'el', 'ms', 'mg', 'pa', 'lo', 'fa', 'tl', 'as', 'id']",['token-classification'],['1M<n<10M']
animetimm/danbooru-wdtagger-v3-w640,animetimm,2025-04-24 10:14:28+00:00,2025-05-02 13:39:14+00:00,7,0,"['task_categories:image-classification', 'task_categories:zero-shot-image-classification', 'task_categories:text-to-image', 'annotations_creators:no-annotation', 'source_datasets:danbooru', 'language:en', 'language:ja', 'license:other', 'size_categories:1M<n<10M', 'region:us', 'art', 'anime', 'not-for-all-audiences']","
	
		
		Danbooru W640 Pruned Dataset V3
	

This is the re-encoded webp-format dataset for SmilingWolf/wdtagger-v3-seed.
Metadata here are cleaned by @SmilingWolf, can be used for multi-label classification training.
Images here are resized to min(width, height) <= 640.
6388605 images in total.

	
		
	
	
		Train
	

5750676 train images in total, 50 train images shown here.

	
		
id
split
archive_file
filename
width
height
rating
general_tags
character_tags

7220105
train
images/0105.tar… See the full description on the dataset page: https://huggingface.co/datasets/animetimm/danbooru-wdtagger-v3-w640.",https://huggingface.co/datasets/animetimm/danbooru-wdtagger-v3-w640,"['en', 'ja']","['image-classification', 'zero-shot-image-classification', 'text-to-image']",['1M<n<10M']
animetimm/danbooru-wdtagger-v4-w640,animetimm,2025-04-24 16:57:41+00:00,2025-05-02 13:34:09+00:00,8,0,"['task_categories:image-classification', 'task_categories:zero-shot-image-classification', 'task_categories:text-to-image', 'annotations_creators:no-annotation', 'source_datasets:danbooru', 'language:en', 'language:ja', 'license:other', 'size_categories:1M<n<10M', 'region:us', 'art', 'anime', 'not-for-all-audiences']","
	
		
		Danbooru W640 Pruned Dataset V4
	

This is the re-encoded webp-format dataset for SmilingWolf/wdtagger-v4-seed.
Metadata here are cleaned by @SmilingWolf, can be used for multi-label classification training.
Images here are resized to min(width, height) <= 640.
5914596 images in total.

	
		
	
	
		Train
	

5321713 train images in total, 50 train images shown here.

	
		
id
split
archive_file
filename
width
height
rating
general_tags
character_tags

8718897
train
images/0897.tar… See the full description on the dataset page: https://huggingface.co/datasets/animetimm/danbooru-wdtagger-v4-w640.",https://huggingface.co/datasets/animetimm/danbooru-wdtagger-v4-w640,"['en', 'ja']","['image-classification', 'zero-shot-image-classification', 'text-to-image']",['1M<n<10M']
mpasila/ja_en_massive_1000_sharegpt_filtered_fixed_short,mpasila,2025-04-25 19:09:42+00:00,2025-04-25 20:19:43+00:00,5,0,"['task_categories:translation', 'language:en', 'language:ja', 'license:apache-2.0', 'size_categories:n<1K', 'format:json', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us', 'ShareGPT']","This only contains around 191 examples. This is just quick test will release the full around 1k examples soon.
I've done a quick cleaning of the data manually using Notepad++. There may still be broken stuff or other problems.
Uses ShareGPT (the only format we will ever need).
Uses NilanE/ParallelFiction-Ja_En-100k for the data.
Token Count Statistics:

Total conversations: 191
Total tokens: 918486
Average tokens per conversation: 4808.83
Median tokens per conversation: 4187.0
Maximum tokens… See the full description on the dataset page: https://huggingface.co/datasets/mpasila/ja_en_massive_1000_sharegpt_filtered_fixed_short.",https://huggingface.co/datasets/mpasila/ja_en_massive_1000_sharegpt_filtered_fixed_short,"['en', 'ja']",['translation'],['n<1K']
EQUES/YakugakuQA,EQUES,2025-04-26 03:33:34+00:00,2025-06-03 08:46:36+00:00,77,0,"['task_categories:question-answering', 'language:ja', 'license:cc-by-sa-4.0', 'arxiv:2505.16661', 'region:us']","
	
		
		YakugakuQA
	



YakugakuQA is a question answering dataset, consisting of 13 years (2012-2024) of past questions and answers from the Japanese National License Examination for Pharmacists. It contains over 4K pairs of questions, answers, and commentaries.
2025-5-29: Leaderboard added.  
2025-2-17: Image data added.  
2024-12-10: Dataset release.

	
		
		Leaderboard
	

3-shot Accuracy (%)

	
		

YakugakuQA
IgakuQA


		
o1-preview
87.9



GPT-4o
83.6
86.6… See the full description on the dataset page: https://huggingface.co/datasets/EQUES/YakugakuQA.",https://huggingface.co/datasets/EQUES/YakugakuQA,['ja'],['question-answering'],[]
litagin/chupa_voice,litagin,2025-04-27 12:19:02+00:00,2025-04-29 03:50:24+00:00,36,5,"['task_categories:text-to-speech', 'task_categories:text-to-audio', 'task_categories:automatic-speech-recognition', 'task_categories:audio-classification', 'language:ja', 'license:gpl-3.0', 'size_categories:100K<n<1M', 'region:us', 'not-for-all-audiences']","
	
		
		ChupaVoice: Japanese Chupa-sound Dataset (Voice-Acted Anime Oral-Slurp SFX)
	

A focused subset of the OOPPEENN/Galgame_Dataset containing チュパ音 (chupa-sounds): the exaggerated oral-slurp SFX commonly heard in Japanese R-18 visual novels (eroge).Each clip comes with its original transcription and game and speaker identifier.

	
		
	
	
		Ethical Considerations & Age Warning
	

This dataset contains explicit erotic content (oral sex SFX). Do NOT use if you are a minor or if local… See the full description on the dataset page: https://huggingface.co/datasets/litagin/chupa_voice.",https://huggingface.co/datasets/litagin/chupa_voice,['ja'],"['text-to-speech', 'text-to-audio', 'automatic-speech-recognition', 'audio-classification']",['100K<n<1M']
seiya/jp-disease-finding-dataset,seiya,2025-04-28 03:05:19+00:00,2025-05-02 06:40:33+00:00,6,0,"['language:ja', 'license:cc-by-4.0', 'license:other', 'size_categories:10K<n<100K', 'format:parquet', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'doi:10.57967/hf/5318', 'region:us']","(日本語版はこちら)

	
		
		Overview
	

This dataset provides information extracted from ≈ 7 k Japanese medical-journal articles
(The Journal of the Japanese Society of Internal Medicine, 2003 – 2023).  
For each row we include:

disease_text – the disease name (Japanese)
findings – a list of related symptoms / examinations / complications  
finding_description – sentences quoted verbatim to show how the term is used
article metadata – article_id, authors, journal_meta, url

The JSON-Lines file… See the full description on the dataset page: https://huggingface.co/datasets/seiya/jp-disease-finding-dataset.",https://huggingface.co/datasets/seiya/jp-disease-finding-dataset,['ja'],[],['10K<n<100K']
Noename/MAVL,Noename,2025-04-28 08:27:05+00:00,2025-06-05 08:24:47+00:00,80,1,"['task_categories:translation', 'task_categories:text-generation', 'task_categories:video-text-to-text', 'language:en', 'language:es', 'language:fr', 'language:ko', 'language:ja', 'license:cc-by-nc-4.0', 'size_categories:n<1K', 'format:parquet', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'arxiv:2505.18614', 'region:us', 'music', 'art', 'multimodal', 'lyrics', 'animation']","

	
		
		MAVL: Multilingual Audio-Video Lyrics Dataset for Animated Song Translation
	


  






	
		
	
	
		Dataset Description
	

This dataset contains a collection of YouTube URLs corresponding to songs from animated musicals. It includes meticulously aligned lyrics (English, Spanish, French, Korean, and Japanese) with corresponding timestamps, song titles, and artist information. MAVL is designed as the first multilingual, multimodal benchmark for singable lyrics translation. To complete… See the full description on the dataset page: https://huggingface.co/datasets/Noename/MAVL.",https://huggingface.co/datasets/Noename/MAVL,"['en', 'es', 'fr', 'ko', 'ja']","['translation', 'text-generation', 'video-text-to-text']",['n<1K']
ThePioneer/japanese-photos-2-with-vids,ThePioneer,2025-04-29 06:01:58+00:00,2025-04-29 06:18:09+00:00,60,3,"['language:en', 'language:ja', 'license:cc0-1.0', 'size_categories:10K<n<100K', 'modality:image', 'region:us']","
	
		
		Japan Diverse Images Dataset
	


	
		
		Overview
	

This dataset is a comprehensive collection of high-quality images (and some videos) capturing the diverse aspects of Japan, including urban landscapes, natural scenery, historical sites, contemporary art, everyday life, and culinary experiences. It is designed to provide a rich and varied representation of Japan for AI training purposes.
Note that the photos were taken by myself in the 2020s, mainly from 2024 to 2025, with some… See the full description on the dataset page: https://huggingface.co/datasets/ThePioneer/japanese-photos-2-with-vids.",https://huggingface.co/datasets/ThePioneer/japanese-photos-2-with-vids,"['en', 'ja']",[],['10K<n<100K']
kkr5155/maya-pretrain-v2-e1,kkr5155,2025-04-29 20:31:52+00:00,2025-06-04 22:08:28+00:00,9,1,"['task_categories:visual-question-answering', 'language:en', 'language:zh', 'language:hi', 'language:fr', 'language:ja', 'language:ar', 'language:ru', 'language:es', 'language:he', 'language:cs', 'language:nl', 'language:de', 'language:el', 'language:id', 'language:it', 'language:ko', 'language:fa', 'language:pl', 'language:pt', 'language:ro', 'language:tr', 'language:uk', 'language:vi', 'size_categories:10M<n<100M', 'format:json', 'modality:text', 'library:datasets', 'library:dask', 'library:mlcroissant', 'region:us']",,https://huggingface.co/datasets/kkr5155/maya-pretrain-v2-e1,"['en', 'zh', 'hi', 'fr', 'ja', 'ar', 'ru', 'es', 'he', 'cs', 'nl', 'de', 'el', 'id', 'it', 'ko', 'fa', 'pl', 'pt', 'ro', 'tr', 'uk', 'vi']",['visual-question-answering'],['10M<n<100M']
aki-0421/commoncatalog-cc-by-ja-300k,aki-0421,2025-04-29 23:46:21+00:00,2025-04-29 23:54:55+00:00,7,0,"['language:ja', 'license:cc-by-4.0', 'size_categories:100K<n<1M', 'format:parquet', 'modality:image', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","
	
		
		aki-0421/commoncatalog-cc-by-ja-300k
	

このレポジトリはalfredplpl/commoncatalog-cc-by-jaで生成されたキャプションに512px以内に加工した画像を追加したものです。
最初の30万件分のデータとなっております。
ライセンス、その他情報についてはalfredplpl/commoncatalog-cc-by-jaをご確認ください。

alfredplpl/commoncatalog-cc-by-ja

",https://huggingface.co/datasets/aki-0421/commoncatalog-cc-by-ja-300k,['ja'],[],['100K<n<1M']
turing-motors/MOMIJI,turing-motors,2025-04-30 06:16:06+00:00,2025-05-20 01:41:06+00:00,384,19,"['language:ja', 'license:cc-by-4.0', 'size_categories:10M<n<100M', 'arxiv:2408.03326', 'arxiv:2405.02246', 'arxiv:2412.04468', 'arxiv:2502.13923', 'region:us']","
	
		
		Dataset Card for MOMIJI
	

MOMIJI (Modern Open Multimodal Japanese filtered Dataset) is a large-scale, carefully curated public dataset of image-text–interleaved web documents. The dataset was extracted from Common Crawl dumps covering February 2024 – January 2025 and contains roughly 56M Japanese documents, 110B characters, and 249M images. Details of the collection and filtering pipeline will be described in a forthcoming paper.
Image-text–interleaved data is generally used to train… See the full description on the dataset page: https://huggingface.co/datasets/turing-motors/MOMIJI.",https://huggingface.co/datasets/turing-motors/MOMIJI,['ja'],[],['10M<n<100M']
Omnys/Intellisys2025_dataset,Omnys,2025-04-30 13:13:07+00:00,2025-08-26 12:19:27+00:00,6,0,"['task_categories:question-answering', 'language:en', 'language:zh', 'language:it', 'language:fr', 'language:de', 'language:es', 'language:vi', 'language:ja', 'size_categories:n<1K', 'region:us']","
	
		
		Domain-Specific and Cross-Lingual Synthetic Data Generation for Information Retrieval Training in RAG Applications
	

Lorenzo Barbiero, Federico Agostini, Ema Baci, Federico Frigo, Manuel Vianello, Davide Pozza & Stefano Campese


	
		
		Abstract
	

Large Language Models (LLMs) have significantly advanced human-computer interaction by enhancing semantic understanding and contextual awareness. 
However, they face challenges with domain-specific and cross-lingual queries due to their… See the full description on the dataset page: https://huggingface.co/datasets/Omnys/Intellisys2025_dataset.",https://huggingface.co/datasets/Omnys/Intellisys2025_dataset,"['en', 'zh', 'it', 'fr', 'de', 'es', 'vi', 'ja']",['question-answering'],['n<1K']
jaeyong2/Reason-Qwen3-14B-Ja,jaeyong2,2025-05-01 13:50:07+00:00,2025-05-10 13:18:39+00:00,7,0,"['language:ja', 'license:other', 'size_categories:10K<n<100K', 'format:parquet', 'modality:text', 'library:datasets', 'library:dask', 'library:mlcroissant', 'library:polars', 'region:us']","
	
		
		Development Process
	


question dataset from hotchpotch/japanese-qa-reasoning-100k
We used Qwen/Qwen3-14B to evaluate the appropriateness of those candidates.


	
		
		License
	


Qwen/Qwen3-14B : https://choosealicense.com/licenses/apache-2.0/
kuotient/orca-math-word-problems-193k-korean : https://huggingface.co/datasets/hotchpotch/japanese-qa-reasoning-100k


	
		
		Acknowledgement
	

This research is supported by TPU Research Cloud program.
",https://huggingface.co/datasets/jaeyong2/Reason-Qwen3-14B-Ja,['ja'],[],['10K<n<100K']
animetimm/zerochan-character-w640,animetimm,2025-05-01 18:32:44+00:00,2025-05-04 06:58:06+00:00,7,1,"['task_categories:image-classification', 'task_categories:zero-shot-image-classification', 'task_categories:text-to-image', 'annotations_creators:no-annotation', 'source_datasets:zerochan', 'language:en', 'language:ja', 'license:other', 'size_categories:1M<n<10M', 'region:us', 'art', 'anime', 'not-for-all-audiences']","
	
		
		Zerochan Character-Only Dataset
	

This is the re-encoded webp-format dataset for deepghs/zerochan_full.
Metadata here are cleaned by @DeepGHS, can be used for anime character classification training.
Images here are resized to min(width, height) <= 640.

	
		
		Records
	

2289627 images in total, 50 images shown here.

	
		
id
archive_file
filename
width
height
primary_tag
tags


		
4476605
images/005.tar
4476605.webp
640
916
Xilonen
[""Female"", ""Fanart"", ""Long Hair"", ""Green Eyes""… See the full description on the dataset page: https://huggingface.co/datasets/animetimm/zerochan-character-w640.",https://huggingface.co/datasets/animetimm/zerochan-character-w640,"['en', 'ja']","['image-classification', 'zero-shot-image-classification', 'text-to-image']",['1M<n<10M']
rifqifarhansyah/llm-metric-mrewardbench,rifqifarhansyah,2025-05-02 13:35:21+00:00,2025-05-02 13:48:47+00:00,37,0,"['language:ar', 'language:zh', 'language:cs', 'language:nl', 'language:fr', 'language:de', 'language:el', 'language:he', 'language:hi', 'language:id', 'language:it', 'language:ja', 'language:ko', 'language:fa', 'language:pl', 'language:pt', 'language:ro', 'language:ru', 'language:es', 'language:tr', 'language:uk', 'language:vi', 'license:odc-by', 'size_categories:10K<n<100K', 'format:csv', 'modality:tabular', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us', 'rewardbench', 'cohere', 'aya-23', 'command-r']",,https://huggingface.co/datasets/rifqifarhansyah/llm-metric-mrewardbench,"['ar', 'zh', 'cs', 'nl', 'fr', 'de', 'el', 'he', 'hi', 'id', 'it', 'ja', 'ko', 'fa', 'pl', 'pt', 'ro', 'ru', 'es', 'tr', 'uk', 'vi']",[],['10K<n<100K']
animetimm/danbooru-wdtagger-v4-w640-ws-50k,animetimm,2025-05-02 16:34:40+00:00,2025-09-12 17:09:38+00:00,33,0,"['task_categories:image-classification', 'task_categories:zero-shot-image-classification', 'source_datasets:danbooru', 'language:en', 'language:ja', 'license:other', 'size_categories:10K<n<100K', 'library:webdataset', 'library:datasets', 'region:us', 'art', 'anime', 'not-for-all-audiences', 'webdataset', 'datasets']","
	
		
		Danbooru WDTagger V4 Webdataset 50k Sub-Dataset
	

This is the webdataset subset dataset for animetimm/danbooru-wdtagger-v4-w640.
Metadata here are cleaned by @SmilingWolf, can be used for multi-label classification training.
Images here are resized to min(width, height) <= 640.

	
		
	
	
		How to Use It
	

from datasets import load_dataset

dataset = load_dataset('animetimm/danbooru-wdtagger-v4-w640-ws-50k')
print(dataset[""train""][0])


		
	
	
		Images
	49971 images in total.… See the full description on the dataset page: https://huggingface.co/datasets/animetimm/danbooru-wdtagger-v4-w640-ws-50k.",https://huggingface.co/datasets/animetimm/danbooru-wdtagger-v4-w640-ws-50k,"['en', 'ja']","['image-classification', 'zero-shot-image-classification']",['10K<n<100K']
animetimm/danbooru-wdtagger-v4-w640-ws-30k,animetimm,2025-05-02 16:37:19+00:00,2025-09-12 17:12:38+00:00,15,0,"['task_categories:image-classification', 'task_categories:zero-shot-image-classification', 'source_datasets:danbooru', 'language:en', 'language:ja', 'license:other', 'size_categories:10K<n<100K', 'library:webdataset', 'library:datasets', 'region:us', 'art', 'anime', 'not-for-all-audiences', 'webdataset', 'datasets']","
	
		
		Danbooru WDTagger V4 Webdataset 30k Sub-Dataset
	

This is the webdataset subset dataset for animetimm/danbooru-wdtagger-v4-w640.
Metadata here are cleaned by @SmilingWolf, can be used for multi-label classification training.
Images here are resized to min(width, height) <= 640.

	
		
	
	
		How to Use It
	

from datasets import load_dataset

dataset = load_dataset('animetimm/danbooru-wdtagger-v4-w640-ws-30k')
print(dataset[""train""][0])


		
	
	
		Images
	29983 images in total.… See the full description on the dataset page: https://huggingface.co/datasets/animetimm/danbooru-wdtagger-v4-w640-ws-30k.",https://huggingface.co/datasets/animetimm/danbooru-wdtagger-v4-w640-ws-30k,"['en', 'ja']","['image-classification', 'zero-shot-image-classification']",['10K<n<100K']
animetimm/danbooru-wdtagger-v4-w640-ws-150k,animetimm,2025-05-02 16:44:37+00:00,2025-09-12 17:19:57+00:00,6,0,"['task_categories:image-classification', 'task_categories:zero-shot-image-classification', 'source_datasets:danbooru', 'language:en', 'language:ja', 'license:other', 'size_categories:100K<n<1M', 'library:webdataset', 'library:datasets', 'region:us', 'art', 'anime', 'not-for-all-audiences', 'webdataset', 'datasets']","
	
		
		Danbooru WDTagger V4 Webdataset 150k Sub-Dataset
	

This is the webdataset subset dataset for animetimm/danbooru-wdtagger-v4-w640.
Metadata here are cleaned by @SmilingWolf, can be used for multi-label classification training.
Images here are resized to min(width, height) <= 640.

	
		
	
	
		How to Use It
	

from datasets import load_dataset

dataset = load_dataset('animetimm/danbooru-wdtagger-v4-w640-ws-150k')
print(dataset[""train""][0])


		
	
	
		Images
	149901 images in total.… See the full description on the dataset page: https://huggingface.co/datasets/animetimm/danbooru-wdtagger-v4-w640-ws-150k.",https://huggingface.co/datasets/animetimm/danbooru-wdtagger-v4-w640-ws-150k,"['en', 'ja']","['image-classification', 'zero-shot-image-classification']",['100K<n<1M']
animetimm/danbooru-wdtagger-v4-w640-ws-1m,animetimm,2025-05-02 16:51:36+00:00,2025-09-12 17:54:47+00:00,46,0,"['task_categories:image-classification', 'task_categories:zero-shot-image-classification', 'task_categories:text-to-image', 'source_datasets:danbooru', 'language:en', 'language:ja', 'license:other', 'size_categories:100K<n<1M', 'library:webdataset', 'library:datasets', 'region:us', 'art', 'anime', 'not-for-all-audiences', 'webdataset', 'datasets']","
	
		
		Danbooru WDTagger V4 Webdataset 1M Sub-Dataset
	

This is the webdataset subset dataset for animetimm/danbooru-wdtagger-v4-w640.
Metadata here are cleaned by @SmilingWolf, can be used for multi-label classification training.
Images here are resized to min(width, height) <= 640.

	
		
	
	
		How to Use It
	

from datasets import load_dataset

dataset = load_dataset('animetimm/danbooru-wdtagger-v4-w640-ws-1m')
print(dataset[""train""][0])


		
	
	
		Images
	999335 images in total.… See the full description on the dataset page: https://huggingface.co/datasets/animetimm/danbooru-wdtagger-v4-w640-ws-1m.",https://huggingface.co/datasets/animetimm/danbooru-wdtagger-v4-w640-ws-1m,"['en', 'ja']","['image-classification', 'zero-shot-image-classification', 'text-to-image']",['100K<n<1M']
lewoniewski/wikipedia-citation-index,lewoniewski,2025-05-02 17:19:55+00:00,2025-05-23 12:36:33+00:00,18,0,"['language:ar', 'language:az', 'language:be', 'language:bg', 'language:ca', 'language:cs', 'language:da', 'language:de', 'language:el', 'language:en', 'language:eo', 'language:es', 'language:et', 'language:eu', 'language:fa', 'language:fi', 'language:fr', 'language:gl', 'language:he', 'language:hi', 'language:hr', 'language:hu', 'language:hy', 'language:id', 'language:it', 'language:ja', 'language:ka', 'language:kk', 'language:ko', 'language:la', 'language:lt', 'language:ms', 'language:nl', 'language:nn', 'language:no', 'language:pl', 'language:pt', 'language:ro', 'language:ru', 'language:sh', 'language:sk', 'language:sl', 'language:sr', 'language:sv', 'language:ta', 'language:th', 'language:tr', 'language:uk', 'language:ur', 'language:uz', 'language:vi', 'language:vo', 'language:zh', 'license:apache-2.0', 'size_categories:10M<n<100M', 'format:csv', 'modality:tabular', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'arxiv:2505.16506', 'region:us', 'Wikipedia']","Dataset with citation indexes as of 1 August 2024 for 47 million Wikipedia articles in 55 language versions. Research: ArXiv
",https://huggingface.co/datasets/lewoniewski/wikipedia-citation-index,"['ar', 'az', 'be', 'bg', 'ca', 'cs', 'da', 'de', 'el', 'en', 'eo', 'es', 'et', 'eu', 'fa', 'fi', 'fr', 'gl', 'he', 'hi', 'hr', 'hu', 'hy', 'id', 'it', 'ja', 'ka', 'kk', 'ko', 'la', 'lt', 'ms', 'nl', 'nn', 'no', 'pl', 'pt', 'ro', 'ru', 'sh', 'sk', 'sl', 'sr', 'sv', 'ta', 'th', 'tr', 'uk', 'ur', 'uz', 'vi', 'vo', 'zh']",[],['10M<n<100M']
animetimm/danbooru-wdtagger-v4-w640-ws-full,animetimm,2025-05-02 17:30:56+00:00,2025-09-12 19:48:19+00:00,532,3,"['task_categories:image-classification', 'task_categories:zero-shot-image-classification', 'task_categories:text-to-image', 'source_datasets:danbooru', 'language:en', 'language:ja', 'license:other', 'size_categories:1M<n<10M', 'library:webdataset', 'library:datasets', 'region:us', 'art', 'anime', 'not-for-all-audiences', 'webdataset', 'datasets']","
	
		
		Danbooru WDTagger V4 Webdataset Full Dataset
	

This is the webdataset dataset for animetimm/danbooru-wdtagger-v4-w640.
Metadata here are cleaned by @SmilingWolf, can be used for multi-label classification training.
Images here are resized to min(width, height) <= 640.

	
		
	
	
		How to Use It
	

from datasets import load_dataset

dataset = load_dataset('animetimm/danbooru-wdtagger-v4-w640-ws-full')
print(dataset[""train""][0])


		
	
	
		Images
	5914596 images in total.

	
		
Split… See the full description on the dataset page: https://huggingface.co/datasets/animetimm/danbooru-wdtagger-v4-w640-ws-full.",https://huggingface.co/datasets/animetimm/danbooru-wdtagger-v4-w640-ws-full,"['en', 'ja']","['image-classification', 'zero-shot-image-classification', 'text-to-image']",['1M<n<10M']
animetimm/danbooru-wdtagger-v3-w640-ws-full,animetimm,2025-05-03 13:57:00+00:00,2025-09-12 23:24:20+00:00,12,0,"['task_categories:image-classification', 'task_categories:zero-shot-image-classification', 'source_datasets:danbooru', 'language:en', 'language:ja', 'license:other', 'size_categories:1M<n<10M', 'library:webdataset', 'library:datasets', 'region:us', 'art', 'anime', 'not-for-all-audiences', 'webdataset', 'datasets']","
	
		
		Danbooru WDTagger V3 Webdataset Full Dataset
	

This is the webdataset dataset for animetimm/danbooru-wdtagger-v3-w640.
Metadata here are cleaned by @SmilingWolf, can be used for multi-label classification training.
Images here are resized to min(width, height) <= 640.

	
		
	
	
		How to Use It
	

from datasets import load_dataset

dataset = load_dataset('animetimm/danbooru-wdtagger-v3-w640-ws-full')
print(dataset[""train""][0])


		
	
	
		Images
	6388605 images in total.

	
		
Split… See the full description on the dataset page: https://huggingface.co/datasets/animetimm/danbooru-wdtagger-v3-w640-ws-full.",https://huggingface.co/datasets/animetimm/danbooru-wdtagger-v3-w640-ws-full,"['en', 'ja']","['image-classification', 'zero-shot-image-classification']",['1M<n<10M']
aidealab/aidealab-videojp-eval,aidealab,2025-05-04 04:52:38+00:00,2025-05-06 07:37:05+00:00,39,0,"['task_categories:text-to-video', 'language:ja', 'license:apache-2.0', 'size_categories:1K<n<10K', 'format:webdataset', 'modality:text', 'library:datasets', 'library:webdataset', 'library:mlcroissant', 'region:us']","
	
		
		AIdeaLab VideoJP 評価再現用データ
	


	
		
		はじめに
	

このリポジトリはAIdeaLab VideoJPのFVDを測定するためのデータを
集めました。再現手順を次のとおりに示します。

	
		
		評価方法
	

まず、評価用ライブラリをダウンロードします。
git clone https://github.com/JunyaoHu/common_metrics_on_video_quality

ダウンロードできたら、ライブラリのインストール手順を踏んで、インストールします。
インストールしたら、同じディレクトリに次のファイルをコピーしてください

evaluate_videos.py
videos.tar
gen_ja.tar

コピーできたら、videos.tarとgen_ja.tarを展開します。
tar xf videos.tar
tar xf gen_ja.tar

最後にevaluate_videos.pyを実行すると、FVDが表示されるはずです。

	
		
	
	
		おまけ： 評価用映像の作り方… See the full description on the dataset page: https://huggingface.co/datasets/aidealab/aidealab-videojp-eval.",https://huggingface.co/datasets/aidealab/aidealab-videojp-eval,['ja'],['text-to-video'],['1K<n<10K']
animetimm/zerochan-character-w640-ws-m200-100k,animetimm,2025-05-04 07:35:29+00:00,2025-05-07 16:06:12+00:00,15,0,"['task_categories:image-classification', 'task_categories:zero-shot-image-classification', 'source_datasets:zerochan', 'language:en', 'language:ja', 'license:other', 'size_categories:10K<n<100K', 'library:webdataset', 'library:datasets', 'region:us', 'art', 'anime', 'not-for-all-audiences', 'webdataset', 'datasets']","
	
		
		Zerochan Single-Character Webdataset 100k Sub-Dataset
	

This is the webdataset subset dataset for animetimm/zerochan-character-w640.
All the images here are guaranteed to be non-monochrome, single-person, single-headed, single-faced and have one primary character. 
Can be used for single-label anime character classification training.
Images here are resized to min(width, height) <= 640.
Bounding boxes of faces, heads and persons are provided in the json metadata, in the form of (x0… See the full description on the dataset page: https://huggingface.co/datasets/animetimm/zerochan-character-w640-ws-m200-100k.",https://huggingface.co/datasets/animetimm/zerochan-character-w640-ws-m200-100k,"['en', 'ja']","['image-classification', 'zero-shot-image-classification']",['10K<n<100K']
animetimm/zerochan-character-w640-ws-m100-300k,animetimm,2025-05-04 07:55:36+00:00,2025-05-07 16:06:13+00:00,7,0,"['task_categories:image-classification', 'task_categories:zero-shot-image-classification', 'source_datasets:zerochan', 'language:en', 'language:ja', 'license:other', 'size_categories:100K<n<1M', 'library:webdataset', 'library:datasets', 'region:us', 'art', 'anime', 'not-for-all-audiences', 'webdataset', 'datasets']","
	
		
		Zerochan Single-Character Webdataset 300k Sub-Dataset
	

This is the webdataset subset dataset for animetimm/zerochan-character-w640.
All the images here are guaranteed to be non-monochrome, single-person, single-headed, single-faced and have one primary character. 
Can be used for single-label anime character classification training.
Images here are resized to min(width, height) <= 640.
Bounding boxes of faces, heads and persons are provided in the json metadata, in the form of (x0… See the full description on the dataset page: https://huggingface.co/datasets/animetimm/zerochan-character-w640-ws-m100-300k.",https://huggingface.co/datasets/animetimm/zerochan-character-w640-ws-m100-300k,"['en', 'ja']","['image-classification', 'zero-shot-image-classification']",['100K<n<1M']
animetimm/zerochan-character-w640-ws-m50-800k,animetimm,2025-05-04 07:56:01+00:00,2025-05-07 16:06:15+00:00,5,0,"['task_categories:image-classification', 'task_categories:zero-shot-image-classification', 'source_datasets:zerochan', 'language:en', 'language:ja', 'license:other', 'size_categories:100K<n<1M', 'library:webdataset', 'library:datasets', 'region:us', 'art', 'anime', 'not-for-all-audiences', 'webdataset', 'datasets']","
	
		
		Zerochan Single-Character Webdataset 800k Sub-Dataset
	

This is the webdataset subset dataset for animetimm/zerochan-character-w640.
All the images here are guaranteed to be non-monochrome, single-person, single-headed, single-faced and have one primary character. 
Can be used for single-label anime character classification training.
Images here are resized to min(width, height) <= 640.
Bounding boxes of faces, heads and persons are provided in the json metadata, in the form of (x0… See the full description on the dataset page: https://huggingface.co/datasets/animetimm/zerochan-character-w640-ws-m50-800k.",https://huggingface.co/datasets/animetimm/zerochan-character-w640-ws-m50-800k,"['en', 'ja']","['image-classification', 'zero-shot-image-classification']",['100K<n<1M']
animetimm/zerochan-character-w640-ws-m50-full,animetimm,2025-05-04 08:08:09+00:00,2025-05-07 16:06:16+00:00,10,0,"['task_categories:image-classification', 'task_categories:zero-shot-image-classification', 'source_datasets:zerochan', 'language:en', 'language:ja', 'license:other', 'size_categories:1M<n<10M', 'library:webdataset', 'library:datasets', 'region:us', 'art', 'anime', 'not-for-all-audiences', 'webdataset', 'datasets']","
	
		
		Zerochan Single-Character Webdataset Full Dataset
	

This is the webdataset subset dataset for animetimm/zerochan-character-w640.
All the images here are guaranteed to be non-monochrome, single-person, single-headed, single-faced and have one primary character. 
Can be used for single-label anime character classification training.
Images here are resized to min(width, height) <= 640.
Bounding boxes of faces, heads and persons are provided in the json metadata, in the form of (x0, y0… See the full description on the dataset page: https://huggingface.co/datasets/animetimm/zerochan-character-w640-ws-m50-full.",https://huggingface.co/datasets/animetimm/zerochan-character-w640-ws-m50-full,"['en', 'ja']","['image-classification', 'zero-shot-image-classification']",['1M<n<10M']
Rakuto/DailyTalkContiguous-ja,Rakuto,2025-05-04 16:37:39+00:00,2025-05-05 04:51:27+00:00,57,0,"['task_categories:automatic-speech-recognition', 'language:ja', 'license:cc-by-sa-4.0', 'arxiv:2207.01063', 'region:us']","
	
		
		DailyTalkContiguous-ja: Spoken Dialogue Dataset in Japanese
	

DailyTalkContiguous-ja is a synthetic multi-turn Japanese conversational speech dataset in which DailyTalk [Keon Lee etal., 2022]
translated by Gemma-3-27B and speech data is synthesized by TTS engine Zyphra/Zonos-v0.1-transformer.
For each speaker in covnersation, different voice is randomly asssigned from voice dataset with five voices in total.
As like with kyutai/DailyTalkContiguous, rather than having separate files… See the full description on the dataset page: https://huggingface.co/datasets/Rakuto/DailyTalkContiguous-ja.",https://huggingface.co/datasets/Rakuto/DailyTalkContiguous-ja,['ja'],['automatic-speech-recognition'],[]
ahmedselhady/mgsm,ahmedselhady,2025-05-05 22:44:54+00:00,2025-05-09 19:38:40+00:00,123,0,"['annotations_creators:found', 'language_creators:found', 'language_creators:expert-generated', 'multilinguality:multilingual', 'source_datasets:extended|gsm8k', 'language:en', 'language:es', 'language:fr', 'language:de', 'language:ru', 'language:zh', 'language:ja', 'language:th', 'language:sw', 'language:bn', 'language:ar', 'license:cc-by-sa-4.0', 'size_categories:1K<n<10K', 'arxiv:2110.14168', 'arxiv:2210.03057', 'region:us', 'math-word-problems']","Multilingual Grade School Math Benchmark (MGSM) is a benchmark of grade-school math problems, proposed in the paper [Language models are multilingual chain-of-thought reasoners](http://arxiv.org/abs/2210.03057).

The same 250 problems from [GSM8K](https://arxiv.org/abs/2110.14168) are each translated via human annotators in 10 languages. The 10 languages are:
- Spanish
- French
- German
- Russian
- Chinese
- Japanese
- Thai
- Swahili
- Bengali
- Telugu

You can find the input and targets for each of the ten languages (and English) as `.tsv` files.
We also include few-shot exemplars that are also manually translated from each language in `exemplars.py`.",https://huggingface.co/datasets/ahmedselhady/mgsm,"['en', 'es', 'fr', 'de', 'ru', 'zh', 'ja', 'th', 'sw', 'bn', 'ar']",[],['1K<n<10K']
chenguang-wang/xlsum_pref_5k,chenguang-wang,2025-05-06 01:54:35+00:00,2025-05-06 03:01:04+00:00,16,0,"['task_categories:summarization', 'language:ja', 'language:ko', 'language:en', 'language:zh', 'license:cc-by-nc-sa-4.0', 'size_categories:1K<n<10K', 'format:json', 'modality:text', 'library:datasets', 'library:dask', 'library:mlcroissant', 'region:us']","
	
		
		Dataset Details
	

This is a Preference dataset compatible with TRL DPO training. The original data comes from csebuetnlp/xlsum. Based on the addition of System Prompt and User Prompt Prefix, chenguang-wang/Qwen2.5-3B-Instruct-summary-sft-adapter is used to generate completion, and mistralai/Mixtral-8x22B-v0.1 is used together with the summary field in the source dataset to annotate the preference.
This dataset is not guaranteed to be of high quality and is only used for testing… See the full description on the dataset page: https://huggingface.co/datasets/chenguang-wang/xlsum_pref_5k.",https://huggingface.co/datasets/chenguang-wang/xlsum_pref_5k,"['ja', 'ko', 'en', 'zh']",['summarization'],['1K<n<10K']
SakanaAI/EDINET-Bench,SakanaAI,2025-05-07 02:01:43+00:00,2025-06-11 03:38:37+00:00,376,8,"['task_categories:text-classification', 'language:ja', 'license:other', 'size_categories:1K<n<10K', 'format:parquet', 'modality:document', 'modality:tabular', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'arxiv:2506.08762', 'region:us', 'finance', 'accounting']","
	
		
		EDINET-Bench
	

📚 Paper | 📝 Blog | 🧑‍💻 Code
EDINET-Bench is a Japanese financial benchmark designed to evaluate the performance of LLMs on challenging financial tasks including accounting fraud detection, earnings forecasting, and industry prediction.
This dataset is built leveraging EDINET, a platform managed by the Financial Services Agency (FSA) of Japan that provides access to disclosure documents such as securities reports.

	
		
	
	
		Notice
	


June 9, 2025: This dataset was… See the full description on the dataset page: https://huggingface.co/datasets/SakanaAI/EDINET-Bench.",https://huggingface.co/datasets/SakanaAI/EDINET-Bench,['ja'],['text-classification'],['1K<n<10K']
wilwilqil/mygo,wilwilqil,2025-05-07 16:59:58+00:00,2025-05-09 15:12:23+00:00,3,0,"['task_categories:feature-extraction', 'language:en', 'language:ja', 'license:openrail', 'size_categories:n<1K', 'format:audiofolder', 'modality:audio', 'library:datasets', 'library:mlcroissant', 'region:us', 'audio']",,https://huggingface.co/datasets/wilwilqil/mygo,"['en', 'ja']",['feature-extraction'],['n<1K']
rubricreward/llm-metric-mrewardbench,rubricreward,2025-05-08 08:57:54+00:00,2025-05-08 09:00:45+00:00,22,0,"['language:ar', 'language:zh', 'language:cs', 'language:nl', 'language:fr', 'language:de', 'language:el', 'language:he', 'language:hi', 'language:id', 'language:it', 'language:ja', 'language:ko', 'language:fa', 'language:pl', 'language:pt', 'language:ro', 'language:ru', 'language:es', 'language:tr', 'language:uk', 'language:vi', 'license:odc-by', 'size_categories:10K<n<100K', 'format:csv', 'modality:tabular', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us', 'rewardbench', 'cohere', 'aya-23', 'command-r']",,https://huggingface.co/datasets/rubricreward/llm-metric-mrewardbench,"['ar', 'zh', 'cs', 'nl', 'fr', 'de', 'el', 'he', 'hi', 'id', 'it', 'ja', 'ko', 'fa', 'pl', 'pt', 'ro', 'ru', 'es', 'tr', 'uk', 'vi']",[],['10K<n<100K']
AIxBlock/Japanese-short-utterances,AIxBlock,2025-05-08 23:50:14+00:00,2025-05-20 22:24:50+00:00,12,3,"['task_categories:text-to-speech', 'task_categories:text-to-audio', 'task_categories:token-classification', 'language:ja', 'license:cc-by-nc-4.0', 'size_categories:100K<n<1M', 'region:us']","This dataset is provided by AIxBlock, an unified platform for AI development and AI workflows automation.
This dataset contains around 500k sentences in Japanese, making it a valuable resource for a wide range of language technology applications. All data has undergone quality assurance (QA) checks to ensure clarity, correctness, and natural phrasing.
The dataset is well-suited for:
Speech data generation (e.g., recording short audio clips lasting 8–30 seconds per sentence)
Natural Language… See the full description on the dataset page: https://huggingface.co/datasets/AIxBlock/Japanese-short-utterances.",https://huggingface.co/datasets/AIxBlock/Japanese-short-utterances,['ja'],"['text-to-speech', 'text-to-audio', 'token-classification']",['100K<n<1M']
jaeyong2/Qwen3-06B-Ja-DPO,jaeyong2,2025-05-09 07:29:11+00:00,2025-05-10 12:58:01+00:00,7,0,"['language:ja', 'license:other', 'size_categories:1K<n<10K', 'format:parquet', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","
	
		
		Development Process
	


question dataset from hotchpotch/japanese-qa-reasoning-100k
We used Qwen/Qwen3-0.6B to generate the answer candidates (n=32).
We used Qwen/Qwen3-14B to evaluate the appropriateness of those candidates.


	
		
	
	
		License
	


Qwen/Qwen3-0.6B : https://choosealicense.com/licenses/apache-2.0/
Qwen/Qwen3-14B : https://choosealicense.com/licenses/apache-2.0/
kuotient/orca-math-word-problems-193k-korean :… See the full description on the dataset page: https://huggingface.co/datasets/jaeyong2/Qwen3-06B-Ja-DPO.",https://huggingface.co/datasets/jaeyong2/Qwen3-06B-Ja-DPO,['ja'],[],['1K<n<10K']
hotchpotch/JFWIR,hotchpotch,2025-05-10 07:25:24+00:00,2025-06-20 06:34:37+00:00,194,4,"['language:ja', 'license:odc-by', 'size_categories:100M<n<1B', 'format:parquet', 'modality:tabular', 'modality:text', 'library:datasets', 'library:dask', 'library:mlcroissant', 'library:polars', 'arxiv:2210.09984', 'arxiv:2406.17557', 'arxiv:2409.07737', 'region:us']","
	
		
		JFWIR - Japanese FineWeb Information Retrieval: A Large-Scale Japanese Information Retrieval Dataset
	


	
		
		Introduction
	

In the field of Japanese Information Retrieval (IR), most datasets have been constructed primarily around Wikipedia content. However, the real web contains not only ""well-formatted text"" like Wikipedia, but also diverse writing styles and noisy content from blogs, news, forums, and other sources.
JFWIR (Japanese FineWeb Information Retrieval) is a large-scale… See the full description on the dataset page: https://huggingface.co/datasets/hotchpotch/JFWIR.",https://huggingface.co/datasets/hotchpotch/JFWIR,['ja'],[],['100M<n<1B']
DataPilot/Zero_SFT_Ja_v3_Reasoning,DataPilot,2025-05-11 13:57:59+00:00,2025-05-11 14:16:05+00:00,33,1,"['task_categories:text-generation', 'language:ja', 'license:odc-by', 'size_categories:10K<n<100K', 'format:json', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us', 'shareGPT']","
	
		
		DataPilot/Zero_SFT_Ja_v3_Reasoning
	

このデータセットは、日本語で記述された高品質な合成プロンプトとそのAI出力を収録しています。すべてのデータは Qwen3-235B-A22B モデルを使用してゼロから合成されています。

	
		
		概要
	


	
		
項目
詳細


		
データセット名
DataPilot/Zero_SFT_Ja_v3_Reasoning


言語
日本語


データ作成方法
完全自動生成（モデルによるゼロショット合成）


使用モデル
Qwen3-235B-A22B


フォーマット
JSONL（id, generator, input, output, conversations, message）


ライセンス
odc-by


作成コード
foxn2000/zero_one_instruction


	



	
		
	
	
		データセット構造
	

データセットには以下のカラムが含まれています。

	
		
カラム名
説明


		
id… See the full description on the dataset page: https://huggingface.co/datasets/DataPilot/Zero_SFT_Ja_v3_Reasoning.",https://huggingface.co/datasets/DataPilot/Zero_SFT_Ja_v3_Reasoning,['ja'],['text-generation'],['10K<n<100K']
AaronZ345/GTSinger,AaronZ345,2025-05-11 15:25:25+00:00,2025-07-24 01:08:26+00:00,1095,9,"['task_categories:text-to-audio', 'task_categories:text-to-speech', 'language:zh', 'language:en', 'language:fr', 'language:ja', 'language:ko', 'language:es', 'language:de', 'language:ru', 'language:it', 'license:cc-by-nc-sa-4.0', 'size_categories:10K<n<100K', 'format:json', 'modality:audio', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'arxiv:2409.13832', 'doi:10.57967/hf/5398', 'region:us', 'singing', 'audio', 'croissant']","
	
		
		GTSinger: A Global Multi-Technique Singing Corpus with Realistic Music Scores for All Singing Tasks
	


	
		
	
	
		Yu Zhang*, Changhao Pan*, Wenxiang Guo*, Ruiqi Li, Zhiyuan Zhu, Jialei Wang, Wenhao Xu, Jingyu Lu, Zhiqing Hong, Chuxin Wang, LiChao Zhang, Jinzheng He, Ziyue Jiang, Yuxin Chen, Chen Yang, Jiecheng Zhou, Xinyu Cheng, Zhou Zhao | Zhejiang University
	

Dataset of GTSinger (NeurIPS 2024 Spotlight): A Global Multi-Technique Singing Corpus with Realistic Music Scores for All… See the full description on the dataset page: https://huggingface.co/datasets/AaronZ345/GTSinger.",https://huggingface.co/datasets/AaronZ345/GTSinger,"['zh', 'en', 'fr', 'ja', 'ko', 'es', 'de', 'ru', 'it']","['text-to-audio', 'text-to-speech']",['10K<n<100K']
Shelton1013/SwitchLingua_audio,Shelton1013,2025-05-12 05:58:55+00:00,2025-09-19 15:06:39+00:00,128,4,"['task_categories:text-generation', 'multilinguality:multilingual', 'language:ar', 'language:fr', 'language:en', 'language:de', 'language:ru', 'language:zh', 'language:it', 'language:hi', 'language:ko', 'language:ja', 'language:es', 'language:yue', 'license:cc-by-nc-4.0', 'size_categories:100K<n<1M', 'arxiv:2506.00087', 'region:us', 'code-switching']","
	
		
		Dataset Card for SwitchLingua_text
	


	
		
		🚀 News
	


[19/09/2025] SwitchLingua: The First Large-Scale Multilingual and Multi-Ethnic Code-Switching Dataset is accepted by NeurIPS 2025!
[30/05/2024] The manuscript can be found on arXiv.


	
		
		Dataset Summary
	

SwitchLingua is a comprehensive multilingual and multicultural code-switching dataset designed to advance research in automatic speech recognition, natural language processing, and conversational AI. The textual data for… See the full description on the dataset page: https://huggingface.co/datasets/Shelton1013/SwitchLingua_audio.",https://huggingface.co/datasets/Shelton1013/SwitchLingua_audio,"['ar', 'fr', 'en', 'de', 'ru', 'zh', 'it', 'hi', 'ko', 'ja', 'es', 'yue']",['text-generation'],['100K<n<1M']
YUGOROU/Youth_Feel,YUGOROU,2025-05-12 11:02:25+00:00,2025-05-15 03:29:50+00:00,4,0,"['language:ja', 'license:cdla-permissive-2.0', 'size_categories:n<1K', 'format:json', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","generated by Gemini 2.5 Pro
",https://huggingface.co/datasets/YUGOROU/Youth_Feel,['ja'],[],['n<1K']
facebook/multiloko,facebook,2025-05-13 08:39:10+00:00,2025-05-14 09:18:33+00:00,333,3,"['task_categories:question-answering', 'task_categories:text-generation', 'language:ar', 'language:bn', 'language:cs', 'language:zh', 'language:nl', 'language:en', 'language:fa', 'language:fr', 'language:de', 'language:he', 'language:hi', 'language:id', 'language:it', 'language:ja', 'language:km', 'language:ko', 'language:ms', 'language:mr', 'language:pl', 'language:pt', 'language:ro', 'language:ru', 'language:es', 'language:sv', 'language:tl', 'language:th', 'language:tr', 'language:ur', 'language:yue', 'language:vi', 'license:mit', 'size_categories:10K<n<100K', 'format:json', 'modality:text', 'library:datasets', 'library:dask', 'library:mlcroissant', 'arxiv:2504.10356', 'region:us', 'text']","
	
		
		MultiLoKo: a multilingual local knowledge benchmark for LLMs
	

MultiLoKo is a multilingual knowledge benchmark, covering 30 languages plus English.
The questions are separately sourced for each language, with an annotation protocol designed to target locally relevant topics for the respective language.
MultiLoKo contains the original data for each language, as well as both human and machine-authored translations of each non-English subset into English and vice versa, facilitating… See the full description on the dataset page: https://huggingface.co/datasets/facebook/multiloko.",https://huggingface.co/datasets/facebook/multiloko,"['ar', 'bn', 'cs', 'zh', 'nl', 'en', 'fa', 'fr', 'de', 'he', 'hi', 'id', 'it', 'ja', 'km', 'ko', 'ms', 'mr', 'pl', 'pt', 'ro', 'ru', 'es', 'sv', 'tl', 'th', 'tr', 'ur', 'yue', 'vi']","['question-answering', 'text-generation']",['10K<n<100K']
Fujitsu-FRE/MAPS,Fujitsu-FRE,2025-05-13 13:45:51+00:00,2025-05-29 14:01:44+00:00,1009,6,"['task_categories:text-generation', 'task_categories:question-answering', 'language:ar', 'language:en', 'language:ja', 'language:es', 'language:ko', 'language:hi', 'language:ru', 'language:he', 'language:pt', 'language:de', 'language:it', 'license:mit', 'size_categories:1K<n<10K', 'format:json', 'modality:text', 'library:datasets', 'library:dask', 'library:mlcroissant', 'arxiv:2505.15935', 'arxiv:2410.02644', 'arxiv:2103.03874', 'arxiv:2310.06770', 'region:us']","
	
		
		Dataset Card for Multilingual Benchmark for Global Agent Performance and Security
	

This is the first Multilingual Agentic AI Benchmark for evaluating agentic AI systems across different languages and diverse tasks. Benchmark enables systematic analysis of how agents perform under multilingual conditions. To balance performance and safety evaluation, our benchmark comprises 805 tasks: 405 from performance-oriented datasets (GAIA, SWE-bench, MATH) and 400 from the Agent Security… See the full description on the dataset page: https://huggingface.co/datasets/Fujitsu-FRE/MAPS.",https://huggingface.co/datasets/Fujitsu-FRE/MAPS,"['ar', 'en', 'ja', 'es', 'ko', 'hi', 'ru', 'he', 'pt', 'de', 'it']","['text-generation', 'question-answering']",['1K<n<10K']
animetimm/danbooru-wdtagger-v4-w640-ws-full-witha,animetimm,2025-05-14 05:29:28+00:00,2025-09-13 01:12:02+00:00,9,0,"['task_categories:image-classification', 'task_categories:zero-shot-image-classification', 'source_datasets:danbooru', 'language:en', 'language:ja', 'license:other', 'size_categories:1M<n<10M', 'library:webdataset', 'library:datasets', 'region:us', 'art', 'anime', 'not-for-all-audiences', 'webdataset', 'datasets']","
	
		
		Danbooru WDTagger V4 Webdataset Full Dataset (Artists Added Edition)
	

This is the webdataset dataset for animetimm/danbooru-wdtagger-v4-w640.
Metadata here are cleaned by @SmilingWolf, can be used for multi-label classification training.
Images here are resized to min(width, height) <= 640.

	
		
	
	
		How to Use It
	

from datasets import load_dataset

dataset = load_dataset('animetimm/danbooru-wdtagger-v4-w640-ws-full-witha')
print(dataset[""train""][0])


		
	
	
		Images
	5914596… See the full description on the dataset page: https://huggingface.co/datasets/animetimm/danbooru-wdtagger-v4-w640-ws-full-witha.",https://huggingface.co/datasets/animetimm/danbooru-wdtagger-v4-w640-ws-full-witha,"['en', 'ja']","['image-classification', 'zero-shot-image-classification']",['1M<n<10M']
coldchair16/CPRet-data,coldchair16,2025-05-14 11:38:48+00:00,2025-06-12 05:10:59+00:00,157,3,"['language:en', 'language:zh', 'language:ja', 'license:cc-by-nc-4.0', 'size_categories:100K<n<1M', 'format:parquet', 'modality:text', 'library:datasets', 'library:dask', 'library:mlcroissant', 'library:polars', 'arxiv:2505.12925', 'region:us', 'code']","
	
		
		CPRet-data
	

This repository hosts the datasets for CPRet: A Dataset, Benchmark, and Model for Retrieval in Competitive Programming.



Visit https://cpret.online/ to try out CPRet in action for competitive programming problem retrieval.


	
	
	
		💡 CPRet Benchmark Tasks
	

The CPRet dataset supports four retrieval tasks relevant to competitive programming:
Text-to-Code Retrieval
Retrieve relevant code snippets based on a natural language problem description.

Code-to-Code Retrieval… See the full description on the dataset page: https://huggingface.co/datasets/coldchair16/CPRet-data.",https://huggingface.co/datasets/coldchair16/CPRet-data,"['en', 'zh', 'ja']",[],['100K<n<1M']
Malikeh1375/tokenizer-robustness-mmlu,Malikeh1375,2025-05-15 00:00:08+00:00,2025-05-25 04:40:10+00:00,91,0,"['language:en', 'language:ru', 'language:zh', 'language:ja', 'language:de', 'language:es', 'language:fr', 'language:it', 'language:th', 'language:ar', 'language:tr', 'language:ko', 'language:hi', 'language:bn', 'language:te', 'language:sw', 'license:cc-by-4.0', 'size_categories:n<1K', 'format:arrow', 'modality:text', 'library:datasets', 'library:mlcroissant', 'region:us']","
	
		
		Tokenizer Robustness MMLU Dataset
	

This dataset contains MMLU-formatted questions and answers designed to test tokenizer robustness across different text formats and languages.

	
		
		Dataset Description
	

The dataset consists of the same questions presented in 6 different formats, with both test (20 questions) and development (5 questions) sets:

original - Standard formatted questions
minor_spelling_errors - Questions with minor misspellings
spoken_language - Questions in casual… See the full description on the dataset page: https://huggingface.co/datasets/Malikeh1375/tokenizer-robustness-mmlu.",https://huggingface.co/datasets/Malikeh1375/tokenizer-robustness-mmlu,"['en', 'ru', 'zh', 'ja', 'de', 'es', 'fr', 'it', 'th', 'ar', 'tr', 'ko', 'hi', 'bn', 'te', 'sw']",[],['n<1K']
YUGOROU/Youth_Feel_Large,YUGOROU,2025-05-15 03:16:30+00:00,2025-05-15 03:29:06+00:00,6,0,"['language:ja', 'license:cdla-permissive-2.0', 'size_categories:n<1K', 'format:json', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","generated by Gemini 2.5 Pro
",https://huggingface.co/datasets/YUGOROU/Youth_Feel_Large,['ja'],[],['n<1K']
Shelton1013/SwitchLingua_text,Shelton1013,2025-05-15 06:36:53+00:00,2025-09-19 15:05:49+00:00,86,4,"['task_categories:text-generation', 'multilinguality:multilingual', 'language:ar', 'language:fr', 'language:en', 'language:de', 'language:ru', 'language:zh', 'language:it', 'language:hi', 'language:ko', 'language:ja', 'language:es', 'language:yue', 'license:cc-by-nc-4.0', 'size_categories:100K<n<1M', 'format:csv', 'modality:text', 'library:datasets', 'library:dask', 'library:mlcroissant', 'library:polars', 'arxiv:2506.00087', 'region:us', 'code-switching']","
	
		
		Dataset Card for SwitchLingua_text
	


	
		
		🚀 News
	


[19/09/2025] SwitchLingua: The First Large-Scale Multilingual and Multi-Ethnic Code-Switching Dataset is accepted by NeurIPS 2025!
[30/05/2024] The manuscript can be found on arXiv.


	
		
		Dataset Summary
	

SwitchLingua is a comprehensive multilingual and multicultural code-switching dataset designed to advance research in automatic speech recognition, natural language processing, and conversational AI. The textual data for… See the full description on the dataset page: https://huggingface.co/datasets/Shelton1013/SwitchLingua_text.",https://huggingface.co/datasets/Shelton1013/SwitchLingua_text,"['ar', 'fr', 'en', 'de', 'ru', 'zh', 'it', 'hi', 'ko', 'ja', 'es', 'yue']",['text-generation'],['100K<n<1M']
hal-utokyo/MangaVQA-train,hal-utokyo,2025-05-15 09:40:17+00:00,2025-05-15 10:53:23+00:00,13,0,"['task_categories:visual-question-answering', 'language:ja', 'license:cc-by-4.0', 'size_categories:1K<n<10K', 'format:parquet', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","
	
		
		MangaVQA Training Dataset
	


	
		
		Dataset details
	

This dataset is a synthetic VQA dataset for Manga. Using images from Manga109, we generated VQA samples by providing both images and its text annotations to GPT-4o (gpt-4o-2024-11-20).
The dataset contains a total of 41,895 synthetic VQA samples from 8,379 images. 

	
		
		License
	

Creative Commons Attribution 4.0 License; and it should abide by the OpenAI terms of use
",https://huggingface.co/datasets/hal-utokyo/MangaVQA-train,['ja'],['visual-question-answering'],['1K<n<10K']
hal-utokyo/MangaVQA,hal-utokyo,2025-05-15 09:51:00+00:00,2025-10-06 11:56:38+00:00,41,1,"['task_categories:visual-question-answering', 'language:ja', 'license:cc-by-4.0', 'size_categories:n<1K', 'format:parquet', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","
	
		
		MangaVQA
	


	
		
		Dataset Details
	

This is the MangaVQA benchmark, designed to evaluate performance under realistic conditions for manga understanding.
This dataset includes 526 manually created question-answer pairs based on images from Manga109.
",https://huggingface.co/datasets/hal-utokyo/MangaVQA,['ja'],['visual-question-answering'],['n<1K']
hal-utokyo/MangaOCR,hal-utokyo,2025-05-15 12:27:25+00:00,2025-05-15 12:29:36+00:00,31,1,"['language:ja', 'license:cc-by-4.0', 'size_categories:10K<n<100K', 'format:parquet', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","
	
		
		MangaOCR Dataset
	


	
		
		Dataset Details
	

This is the MangaOCR dataset. We constructed this dataset by consolidating annotations from the Manga109 dataset and the manga onomatopoeia dataset.
It contains approximately 209K narrative text instances, spanning a wide variety of visual styles and layouts.
",https://huggingface.co/datasets/hal-utokyo/MangaOCR,['ja'],[],['10K<n<100K']
Fujitsu-FRE/MAPS_Verified,Fujitsu-FRE,2025-05-15 16:55:53+00:00,2025-06-03 08:55:08+00:00,41,2,"['task_categories:text-generation', 'task_categories:question-answering', 'language:ar', 'language:en', 'language:ja', 'language:es', 'language:ko', 'language:hi', 'language:ru', 'language:he', 'language:pt', 'language:de', 'language:it', 'license:mit', 'size_categories:1K<n<10K', 'format:json', 'modality:text', 'library:datasets', 'library:dask', 'library:mlcroissant', 'arxiv:2505.15935', 'arxiv:2410.02644', 'arxiv:2103.03874', 'arxiv:2310.06770', 'region:us']","
	
		
		Dataset Card for Multilingual Benchmark for Global Agent Performance and Security
	

This is the first Multilingual Agentic AI Benchmark for evaluating agentic AI systems across different languages and diverse tasks. Benchmark enables systematic analysis of how agents perform under multilingual conditions. This dataset contains 550 instances for GAIA, 660 instances for ASB, 737 instances for Maths, and 1100 instances for SWE. Each task was translated into 10 target languages resulting… See the full description on the dataset page: https://huggingface.co/datasets/Fujitsu-FRE/MAPS_Verified.",https://huggingface.co/datasets/Fujitsu-FRE/MAPS_Verified,"['ar', 'en', 'ja', 'es', 'ko', 'hi', 'ru', 'he', 'pt', 'de', 'it']","['text-generation', 'question-answering']",['1K<n<10K']
deepghs/AnimeText,deepghs,2025-05-16 10:04:57+00:00,2025-10-10 01:30:31+00:00,61,3,"['task_categories:object-detection', 'language:zh', 'language:ko', 'language:ja', 'language:en', 'language:ru', 'license:cc-by-nc-sa-4.0', 'size_categories:100K<n<1M', 'library:datasets', 'library:mlcroissant', 'arxiv:2510.07951', 'region:us', 'not-for-all-audiences', 'datasets', 'croissant', 'ultralytics']","
	
		
		AnimeText: A Large-scale Dataset for Robust Complex Anime Scene Text Detection
	


  
  
  Figure 1： Dataset examples.



	
		
		Dataset Summary
	

AnimeText is a large-scale dataset for anime scene text detection, containing 735K images and 4.2M annotated text blocks. Unlike existing natural scene or document-centric text detection datasets, AnimeText focuses on text in anime scenes, which typically features diverse styles, irregular arrangements, and can be easily confused with… See the full description on the dataset page: https://huggingface.co/datasets/deepghs/AnimeText.",https://huggingface.co/datasets/deepghs/AnimeText,"['zh', 'ko', 'ja', 'en', 'ru']",['object-detection'],['100K<n<1M']
vincentkoc/tiny_qa_benchmark_pp,vincentkoc,2025-05-16 14:49:21+00:00,2025-08-25 00:19:51+00:00,924,1,"['task_categories:question-answering', 'task_ids:extractive-qa', 'task_ids:closed-book-qa', 'language:en', 'language:de', 'language:ar', 'language:ko', 'language:fr', 'language:pt', 'language:zh', 'language:ja', 'language:es', 'language:tr', 'language:ru', 'license:other', 'size_categories:n<1K', 'format:json', 'modality:text', 'library:datasets', 'library:dask', 'library:mlcroissant', 'arxiv:2505.12058', 'doi:10.57967/hf/5531', 'region:us', 'synthetic', 'qa', 'evaluation', 'benchmark', 'llmops', 'smoke-test']","
	
		
		Tiny QA Benchmark++ (TQB++)
	

Tiny QA Benchmark++ (TQB++) is an ultra-lightweight evaluation suite designed to expose critical failures in Large Language Model (LLM) systems within seconds. It serves as the LLM analogue of software unit tests, ideal for rapid CI/CD checks, prompt engineering, and continuous quality assurance in modern LLMOps.
This Hugging Face dataset repository hosts the core English dataset and various synthetically generated multilingual and topical dataset packs… See the full description on the dataset page: https://huggingface.co/datasets/vincentkoc/tiny_qa_benchmark_pp.",https://huggingface.co/datasets/vincentkoc/tiny_qa_benchmark_pp,"['en', 'de', 'ar', 'ko', 'fr', 'pt', 'zh', 'ja', 'es', 'tr', 'ru']",['question-answering'],['n<1K']
OmniAICreator/Japanese-Novels-23M,OmniAICreator,2025-05-17 17:35:46+00:00,2025-09-22 07:06:07+00:00,84,5,"['task_categories:text-generation', 'task_categories:text-classification', 'language:ja', 'size_categories:10M<n<100M', 'format:parquet', 'modality:tabular', 'modality:text', 'library:datasets', 'library:dask', 'library:mlcroissant', 'library:polars', 'region:us']","
	
		
		Japanese-Novels-23M
	

This dataset contains Japanese web novels that I collected personally.
Machine-Learning Use OnlyAccess is restricted to bona fide machine-learning–related purposes.To request access, please provide a detailed explanation of the specific tasks or applications for which you intend to use the dataset.

Total records: 23,212,809
Total characters: 80,846,120,027
Total tokens (Llama 4 tokenizer): 55,406,468,406 (55.4 B)

",https://huggingface.co/datasets/OmniAICreator/Japanese-Novels-23M,['ja'],"['text-generation', 'text-classification']",['10M<n<100M']
jri-advtechlab/jsynflow,jri-advtechlab,2025-05-19 05:02:28+00:00,2025-07-03 02:13:45+00:00,83,0,"['task_categories:visual-question-answering', 'language:ja', 'license:other', 'size_categories:10K<n<100K', 'region:us', 'flowchart', 'diagram', 'japanese']","English version

	
		
		JSynFlowデータセット
	

このデータセットは、Meta Platforms, Inc.が提供する LLama 3.1 405B モデルの出力を使用して作成された日本語のフローチャートVQAデータセットです。
主に研究・検証用途で利用することを目的としています。
複数の職業とそれらに想定される業務について、各業務手順をMermaid形式のフローチャートとして記述し、それらを画像化したものを格納しております。
詳細な作成手順は関連論文を参照ください。

	
		
	
	
		📌 内容
	


フォーマット: JSON及びPNG
QAデータ数: 約10,000エントリ
情報源: LLama 3.1 405B モデルによる生成


	
		
	
	
		ファイル構成
	

.
├── data/
│   └── 1_jobtasks/ <!-- 業務手順のフローチャートデータセット -->
│       ├── jobtasks.json <!--… See the full description on the dataset page: https://huggingface.co/datasets/jri-advtechlab/jsynflow.",https://huggingface.co/datasets/jri-advtechlab/jsynflow,['ja'],['visual-question-answering'],['10K<n<100K']
asahi-research/newsq,asahi-research,2025-05-19 05:43:40+00:00,2025-06-19 08:30:29+00:00,10,1,"['task_categories:question-answering', 'language:ja', 'size_categories:n<1K', 'format:csv', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","
	
		
		時事情報に関する日本語QAデータセット『ニュースQ』
	


ニュースQ紹介ページ
利用規約はこちら
個人情報の取り扱い：利用申込の際にお預かりした個人情報（お名前、所属、利用目的、メールアドレス）は、下記の目的で利用し、弊社の個人情報保護方針に従って取り扱います。
本ツールの使用状況の確認
本人の所属が正しく申請されているかの確認
本ツールをご使用いただくために必要なご連絡（アップデートのご連絡等）
本ツールを使用した感想等を調査するためのご連絡



",https://huggingface.co/datasets/asahi-research/newsq,['ja'],['question-answering'],['n<1K']
AIxBlock/Human-to-machine-Japanese-audio-call-center-conversations,AIxBlock,2025-05-19 17:02:22+00:00,2025-05-20 22:23:56+00:00,16,2,"['task_categories:text-to-speech', 'language:ja', 'license:cc-by-nc-4.0', 'size_categories:n<1K', 'format:audiofolder', 'modality:audio', 'library:datasets', 'library:mlcroissant', 'region:us']","
	
		
		Dataset Card for Japanese audio call center human to machine conversations
	



This dataset contains synthetic audio conversations in Japanese between human customers and machine agents, simulating real-world call center scenarios

	
		
		Dataset Details
	


	
		
		Dataset Description
	






Curated by: AIxBlock (aixblock.io)
Funded by [optional]: AIxBlock (aixblock.io)
Shared by [optional]: AIxBlock (aixblock.io)
Language(s) (NLP): Japanese
License: Creative Commons Attribution Non… See the full description on the dataset page: https://huggingface.co/datasets/AIxBlock/Human-to-machine-Japanese-audio-call-center-conversations.",https://huggingface.co/datasets/AIxBlock/Human-to-machine-Japanese-audio-call-center-conversations,['ja'],['text-to-speech'],['n<1K']
animetimm/e621-wdtagger-v1-w640,animetimm,2025-05-19 18:34:39+00:00,2025-05-23 02:35:24+00:00,7,1,"['task_categories:image-classification', 'task_categories:zero-shot-image-classification', 'task_categories:text-to-image', 'annotations_creators:no-annotation', 'source_datasets:e621', 'language:en', 'language:ja', 'license:other', 'size_categories:1M<n<10M', 'region:us', 'art', 'anime', 'not-for-all-audiences']","
	
		
		E621 W640 Pruned Dataset V1
	

This is the re-encoded webp-format dataset for deepghs/e621-v1-seed.
Metadata here are cleaned by @SmilingWolf, can be used for multi-label classification training.
Images here are resized to min(width, height) <= 640.
3714685 images in total.

	
		
	
	
		Train
	

3344128 train images in total, 50 train images shown here.

	
		
id
split
archive_file
filename
width
height
rating
general_tags
character_tags
species_tags
artist_tags


		
5217898
train… See the full description on the dataset page: https://huggingface.co/datasets/animetimm/e621-wdtagger-v1-w640.",https://huggingface.co/datasets/animetimm/e621-wdtagger-v1-w640,"['en', 'ja']","['image-classification', 'zero-shot-image-classification', 'text-to-image']",['1M<n<10M']
alt-dev/jcrrag,alt-dev,2025-05-20 08:14:40+00:00,2025-05-26 05:13:24+00:00,13,0,"['task_categories:question-answering', 'language:ja', 'license:cc-by-sa-4.0', 'size_categories:10K<n<100K', 'format:json', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us', 'jcrrag', 'japaneserag', 'llmrag', 'rageval', 'rag-evaluation']","
	
		
		JCrRAG : Japanese Contextual relevance RAG Benchmark
	

A human-annotated benchmark for evaluating Japanese Retrieval-Augmented Generation (RAG) systems, featuring multi-level complexity and diverse categories.
This benchmark does not address context selection; instead, with the context fixed, it evaluates the ability to appropriately handle the information within that context.
The benchmark contains 20,000 data records. 
Each record has the following format : 
(Context, Question… See the full description on the dataset page: https://huggingface.co/datasets/alt-dev/jcrrag.",https://huggingface.co/datasets/alt-dev/jcrrag,['ja'],['question-answering'],['10K<n<100K']
congnhm/test,congnhm,2025-05-20 09:18:02+00:00,2025-05-20 09:38:44+00:00,5,0,"['language:ja', 'license:apache-2.0', 'size_categories:n<1K', 'format:csv', 'modality:tabular', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']",,https://huggingface.co/datasets/congnhm/test,['ja'],[],['n<1K']
OsakanaTeishoku/Qwen2.5-7B-Instruct-magpie-R-questions-ja-0.8k-tmp,OsakanaTeishoku,2025-05-20 12:12:59+00:00,2025-05-20 12:13:50+00:00,9,1,"['language:ja', 'license:apache-2.0', 'size_categories:n<1K', 'format:parquet', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']",,https://huggingface.co/datasets/OsakanaTeishoku/Qwen2.5-7B-Instruct-magpie-R-questions-ja-0.8k-tmp,['ja'],[],['n<1K']
takahashi111/aozorabunko-author-classification,takahashi111,2025-05-20 20:36:58+00:00,2025-05-30 03:39:25+00:00,9,0,"['task_categories:text-classification', 'language:ja', 'size_categories:10K<n<100K', 'format:parquet', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","globis-university/aozorabunko-cleanを元に作成。

	
		
		目的
	


入力した段落からその著者を推定するモデル開発用に作成したデータセット。
著者の作品を学習させるのではなく、著者の作風や文章の特徴を学習させたい。


	
		
		理想
	


trainとvalidationで同じ作品や段落は含まないようにしたい。文字が違うだけの作品も同じとみなす。
作者の特徴が出るようにするため、一定以上の長さの段落だけにする。
labelの偏りをなくす。


	
		
		著者
	


[""宮本百合子"",""岸田国士"",""小川未明"",""野村胡堂"",""坂口安吾"",""芥川竜之介"",""牧野信一"",""豊島与志雄"",""寺田寅彦"",""太宰治"", '夏目漱石','江戸川乱歩',""森鴎外"", ""中谷宇吉郎"", '岡本綺堂','折口信夫', '泉鏡花','山本周五郎']
ラベルはこのリストのインデックス


	
		
		データセット作成の条件
	


作品名が同じもの(例:アグニの神(新字旧仮名)とアグニの神(新字新仮名))は一つだけにする。… See the full description on the dataset page: https://huggingface.co/datasets/takahashi111/aozorabunko-author-classification.",https://huggingface.co/datasets/takahashi111/aozorabunko-author-classification,['ja'],['text-classification'],['10K<n<100K']
nlp-waseda/KnowRecall,nlp-waseda,2025-05-21 04:51:56+00:00,2025-05-22 00:54:21+00:00,17,1,"['task_categories:visual-question-answering', 'language:ar', 'language:zh', 'language:en', 'language:fr', 'language:de', 'language:el', 'language:he', 'language:it', 'language:ja', 'language:ko', 'language:pt', 'language:ru', 'language:sr', 'language:es', 'language:th', 'license:cc', 'size_categories:10K<n<100K', 'format:parquet', 'modality:image', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'arxiv:2505.15075', 'region:us', 'Image', 'Text', 'Multilingual']","
    


    



	
		
		KnowRecall
	

This repository contains the KnowRecall benchmark, introduced in Traveling Across Languages: Benchmarking Cross-Lingual Consistency in Multimodal LLMs. 

	
		
		Dataset Description
	

Imagine a French tourist visiting Tokyo Tower, snapping a photo and asking an MLLM about the tower’s height.
Naturally, they would expect a correct response in their native language.
However, if the model provides the right answer in Japanese but fails to do so in French, it… See the full description on the dataset page: https://huggingface.co/datasets/nlp-waseda/KnowRecall.",https://huggingface.co/datasets/nlp-waseda/KnowRecall,"['ar', 'zh', 'en', 'fr', 'de', 'el', 'he', 'it', 'ja', 'ko', 'pt', 'ru', 'sr', 'es', 'th']",['visual-question-answering'],['10K<n<100K']
nlp-waseda/VisRecall,nlp-waseda,2025-05-21 04:52:39+00:00,2025-05-22 00:55:19+00:00,29,0,"['task_categories:text-generation', 'language:ar', 'language:zh', 'language:en', 'language:fr', 'language:de', 'language:it', 'language:ja', 'language:pt', 'language:es', 'license:cc', 'size_categories:1K<n<10K', 'format:parquet', 'modality:tabular', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'arxiv:2505.15075', 'region:us', 'Image', 'Text', 'Multilingual']","
    


    



	
		
		VisRecall
	

This repository contains the VisRecall benchmark, introduced in Traveling Across Languages: Benchmarking Cross-Lingual Consistency in Multimodal LLMs. 

	
		
		Dataset Description
	

Imagine a tourist finished their journey in Japan and came back to France, eager to share the places they visited with their friends.
When portraying these experiences, the visual information they convey is inherently independent of language, meaning that descriptions created in… See the full description on the dataset page: https://huggingface.co/datasets/nlp-waseda/VisRecall.",https://huggingface.co/datasets/nlp-waseda/VisRecall,"['ar', 'zh', 'en', 'fr', 'de', 'it', 'ja', 'pt', 'es']",['text-generation'],['1K<n<10K']
extraordinarylab/drivel-hub,extraordinarylab,2025-05-22 05:24:08+00:00,2025-09-07 05:18:30+00:00,186,4,"['task_categories:text-classification', 'task_categories:question-answering', 'task_categories:zero-shot-classification', 'task_categories:text-generation', 'language:en', 'language:zh', 'language:fr', 'language:es', 'language:ko', 'language:ja', 'license:cc-by-nc-4.0', 'size_categories:n<1K', 'format:parquet', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'arxiv:2509.03867', 'region:us']","
	
		
		Drivelology Multilingual Dataset
	

Paper: Drivel-ology: Challenging LLMs with Interpreting Nonsense with Depth
Code / Project Page: https://github.com/ExtraOrdinaryLab/drivelology
The DrivelHub Dataset is a curated collection of linguistic samples, characterized as ""nonsense with depth"" (utterances that are syntactically coherent yet pragmatically paradoxical, emotionally loaded, or rhetorically subversive), designed to support research in humor detection and other forms of playful or… See the full description on the dataset page: https://huggingface.co/datasets/extraordinarylab/drivel-hub.",https://huggingface.co/datasets/extraordinarylab/drivel-hub,"['en', 'zh', 'fr', 'es', 'ko', 'ja']","['text-classification', 'question-answering', 'zero-shot-classification', 'text-generation']",['n<1K']
speed/relaion2B-multi-research-safe-ja,speed,2025-05-22 15:16:56+00:00,2025-05-23 02:14:48+00:00,8,0,"['language:ja', 'size_categories:100M<n<1B', 'format:parquet', 'modality:image', 'modality:tabular', 'modality:text', 'library:datasets', 'library:dask', 'library:mlcroissant', 'library:polars', 'region:us']","This is the subset of Japanese portion of relaion2B-multi-research-safe.

	
		
		Reference
	


https://huggingface.co/datasets/laion/relaion2B-multi-research-safe

",https://huggingface.co/datasets/speed/relaion2B-multi-research-safe-ja,['ja'],[],['100M<n<1B']
cyberagent/AdParaphrase-v2.0,cyberagent,2025-05-23 01:46:46+00:00,2025-05-28 01:13:06+00:00,27,0,"['task_categories:text-generation', 'language:ja', 'license:cc-by-nc-sa-4.0', 'size_categories:10K<n<100K', 'format:parquet', 'modality:tabular', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'arxiv:2505.20826', 'region:us']","
	
		
		AdParaphrase v2.0
	

This repository contains data for our paper ""AdParaphrase v2.0: Generating Attractive Ad Texts Using a Preference-Annotated Paraphrase Dataset"" (ACL2025 Findings).

	
		
		Overview
	

AdParaphrase v2.0 is a dataset for ad text paraphrasing, containing human preference data, to enable the analysis of the linguistic factors and to support the development of methods for generating attractive ad texts. Compared with AdParaphrase v1.0, this dataset is 20 times larger… See the full description on the dataset page: https://huggingface.co/datasets/cyberagent/AdParaphrase-v2.0.",https://huggingface.co/datasets/cyberagent/AdParaphrase-v2.0,['ja'],['text-generation'],['10K<n<100K']
animetimm/e621-wdtagger-v1-w640-ws-full,animetimm,2025-05-23 02:47:55+00:00,2025-09-13 04:19:52+00:00,11,0,"['task_categories:image-classification', 'task_categories:zero-shot-image-classification', 'source_datasets:e621', 'language:en', 'language:ja', 'license:other', 'size_categories:1M<n<10M', 'library:webdataset', 'library:datasets', 'region:us', 'art', 'anime', 'not-for-all-audiences', 'webdataset', 'datasets']","
	
		
		E621 WDTagger V1 Webdataset Full Dataset
	

This is the webdataset dataset for animetimm/e621-wdtagger-v1-w640.
Metadata here are cleaned by @SmilingWolf, can be used for multi-label classification training.
Images here are resized to min(width, height) <= 640.

	
		
	
	
		How to Use It
	

from datasets import load_dataset

dataset = load_dataset('animetimm/e621-wdtagger-v1-w640-ws-full')
print(dataset[""train""][0])


		
	
	
		Images
	3714685 images in total.

	
		
Split
Image Count… See the full description on the dataset page: https://huggingface.co/datasets/animetimm/e621-wdtagger-v1-w640-ws-full.",https://huggingface.co/datasets/animetimm/e621-wdtagger-v1-w640-ws-full,"['en', 'ja']","['image-classification', 'zero-shot-image-classification']",['1M<n<10M']
animetimm/e621-wdtagger-v1-w640-ws-full-witha,animetimm,2025-05-23 05:36:37+00:00,2025-09-13 06:26:50+00:00,12,0,"['task_categories:image-classification', 'task_categories:zero-shot-image-classification', 'source_datasets:e621', 'language:en', 'language:ja', 'license:other', 'size_categories:1M<n<10M', 'library:webdataset', 'library:datasets', 'region:us', 'art', 'anime', 'not-for-all-audiences', 'webdataset', 'datasets']","
	
		
		E621 WDTagger V1 Webdataset Full Dataset (Artists Added Edition)
	

This is the webdataset dataset for animetimm/e621-wdtagger-v1-w640.
Metadata here are cleaned by @SmilingWolf, can be used for multi-label classification training.
Images here are resized to min(width, height) <= 640.

	
		
	
	
		How to Use It
	

from datasets import load_dataset

dataset = load_dataset('animetimm/e621-wdtagger-v1-w640-ws-full-witha')
print(dataset[""train""][0])


		
	
	
		Images
	3714685 images in… See the full description on the dataset page: https://huggingface.co/datasets/animetimm/e621-wdtagger-v1-w640-ws-full-witha.",https://huggingface.co/datasets/animetimm/e621-wdtagger-v1-w640-ws-full-witha,"['en', 'ja']","['image-classification', 'zero-shot-image-classification']",['1M<n<10M']
catherinearnett/morphscore,catherinearnett,2025-05-23 20:16:08+00:00,2025-07-10 15:50:17+00:00,106,2,"['language:ar', 'language:en', 'language:de', 'language:ru', 'language:tr', 'language:ab', 'language:af', 'language:sq', 'language:am', 'language:az', 'language:bm', 'language:eu', 'language:be', 'language:bn', 'language:br', 'language:bg', 'language:ca', 'language:zh', 'language:hr', 'language:cs', 'language:da', 'language:nl', 'language:et', 'language:fi', 'language:fr', 'language:ceb', 'language:bur', 'language:myv', 'language:gl', 'language:ka', 'language:el', 'language:gu', 'language:ht', 'language:he', 'language:hi', 'language:hu', 'language:is', 'language:id', 'language:ga', 'language:it', 'language:ja', 'language:kk', 'language:kpv', 'language:ko', 'language:ky', 'language:lv', 'language:lt', 'language:mk', 'language:ml', 'language:gv', 'language:mr', 'language:mdf', 'language:no', 'language:oc', 'language:ps', 'language:fa', 'language:pl', 'language:pt', 'language:ro', 'language:sa', 'language:gd', 'language:se', 'language:sd', 'language:si', 'language:sk', 'language:sl', 'language:es', 'language:sr', 'language:tl', 'language:ta', 'language:tt', 'language:uk', 'language:ur', 'language:ug', 'language:uz', 'language:vep', 'language:vi', 'language:cy', 'language:wo', 'language:sah', 'language:ltg', 'language:lij', 'language:hsb', 'license:cc-by-sa-4.0', 'size_categories:1M<n<10M', 'format:csv', 'modality:tabular', 'modality:text', 'library:datasets', 'library:dask', 'library:mlcroissant', 'library:polars', 'arxiv:2507.06378', 'region:us']","
	
		
		MorphScore
	

MorphScore is a tokenizer evaluation framework, which evaluates the extent to which a tokenizer segments words along morpheme boundaries. This repository contains the datasets used to calculate MorphScore.
In total, we have datasetes for 86 languages, but only 70 languages have at least 100 items after filtering. 
All datasets are derived from existing Universal Dependencies treebanks. In the table below, we link the source dataset for each language. 
See the new preprint… See the full description on the dataset page: https://huggingface.co/datasets/catherinearnett/morphscore.",https://huggingface.co/datasets/catherinearnett/morphscore,"['ar', 'en', 'de', 'ru', 'tr', 'ab', 'af', 'sq', 'am', 'az', 'bm', 'eu', 'be', 'bn', 'br', 'bg', 'ca', 'zh', 'hr', 'cs', 'da', 'nl', 'et', 'fi', 'fr', 'ceb', 'bur', 'myv', 'gl', 'ka', 'el', 'gu', 'ht', 'he', 'hi', 'hu', 'is', 'id', 'ga', 'it', 'ja', 'kk', 'kpv', 'ko', 'ky', 'lv', 'lt', 'mk', 'ml', 'gv', 'mr', 'mdf', 'no', 'oc', 'ps', 'fa', 'pl', 'pt', 'ro', 'sa', 'gd', 'se', 'sd', 'si', 'sk', 'sl', 'es', 'sr', 'tl', 'ta', 'tt', 'uk', 'ur', 'ug', 'uz', 'vep', 'vi', 'cy', 'wo', 'sah', 'ltg', 'lij', 'hsb']",[],['1M<n<10M']
taozi555/novel-multilingual,taozi555,2025-05-24 00:25:50+00:00,2025-05-24 00:38:01+00:00,10,0,"['task_categories:text-generation', 'task_categories:text-classification', 'language:de', 'language:en', 'language:es', 'language:fr', 'language:in', 'language:ja', 'language:pt', 'language:th', 'language:vi', 'language:zh', 'license:cc-by-nc-4.0', 'size_categories:1K<n<10K', 'format:parquet', 'modality:tabular', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us', 'webnovel', 'fiction', 'multilingual', 'literature']","
	
		
		WebNovel Multilingual Dataset
	


	
		
		Dataset Description
	

This dataset contains web novels scraped from WebNovel.com across multiple languages. Each entry includes the complete novel content with chapter information, metadata, and classification tags.
Note: This dataset excludes content in the following languages: id, ID

	
		
		Dataset Statistics
	


Total Novels: 8,324
Total Chapters: 233,410
Total Characters: 1,617,589,129
Languages: 10


	
		
		Language Distribution… See the full description on the dataset page: https://huggingface.co/datasets/taozi555/novel-multilingual.",https://huggingface.co/datasets/taozi555/novel-multilingual,"['de', 'en', 'es', 'fr', 'in', 'ja', 'pt', 'th', 'vi', 'zh']","['text-generation', 'text-classification']",['1K<n<10K']
Malikeh1375/code-switching-tokenizer-robustness,Malikeh1375,2025-05-24 04:28:05+00:00,2025-08-20 19:55:20+00:00,773,1,"['task_categories:text-generation', 'task_categories:text-classification', 'multilinguality:multilingual', 'language:en', 'language:ru', 'language:zh', 'language:ja', 'language:de', 'language:es', 'language:fr', 'language:it', 'language:th', 'language:ar', 'language:tr', 'language:ko', 'language:hi', 'language:bn', 'language:te', 'language:sw', 'language:fa', 'license:cc-by-4.0', 'size_categories:1K<n<10K', 'format:parquet', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us', 'code-switching', 'tokenizer-robustness', 'multilingual', 'cross-lingual', 'evaluation']","
	
		
		Code-Switching Dataset for Tokenizer Robustness Analysis
	


	
		
		Dataset Description
	

This dataset is designed for tokenizer robustness testing in multilingual and code-switching contexts. It contains identical content expressed across 16 different language variants, including pure English and 15 English-X code-switching pairs, allowing researchers to isolate tokenization effects from semantic differences when evaluating language models.

	
		
		Purpose
	


Tokenizer Comparison:… See the full description on the dataset page: https://huggingface.co/datasets/Malikeh1375/code-switching-tokenizer-robustness.",https://huggingface.co/datasets/Malikeh1375/code-switching-tokenizer-robustness,"['en', 'ru', 'zh', 'ja', 'de', 'es', 'fr', 'it', 'th', 'ar', 'tr', 'ko', 'hi', 'bn', 'te', 'sw', 'fa']","['text-generation', 'text-classification']",['1K<n<10K']
llm-jp/extraction-wiki-ja,llm-jp,2025-05-26 02:54:06+00:00,2025-05-30 04:58:55+00:00,25,1,"['task_categories:text-generation', 'language:ja', 'license:apache-2.0', 'size_categories:100K<n<1M', 'format:parquet', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","
	
		
		extraction-wiki-ja
	

This repository provides an instruction-tuning dataset developed by LLM-jp, a collaborative project launched in Japan.
This is a Japanese instruction-tuning dataset tailored for information extraction and structuring from Japanese Wikipedia text.
The dataset consists of instruction–response pairs automatically generated from Japanese Wikipedia articles. Instructions are created by prompting Qwen/Qwen2.5-32B-Instruct with passages from Wikipedia, and the… See the full description on the dataset page: https://huggingface.co/datasets/llm-jp/extraction-wiki-ja.",https://huggingface.co/datasets/llm-jp/extraction-wiki-ja,['ja'],['text-generation'],['100K<n<1M']
gravitee-io/textdetox-multilingual-toxicity-dataset,gravitee-io,2025-05-26 14:02:30+00:00,2025-05-27 12:10:42+00:00,32,0,"['task_categories:text-classification', 'language:en', 'language:ru', 'language:uk', 'language:de', 'language:es', 'language:am', 'language:zh', 'language:ar', 'language:hi', 'language:it', 'language:fr', 'language:he', 'language:ja', 'language:tt', 'license:openrail++', 'size_categories:10K<n<100K', 'format:arrow', 'modality:text', 'library:datasets', 'library:mlcroissant', 'region:us']","
	
		
		TextDetox Multilingual Toxicity Classification Dataset
	

This repository provides a multilingual dataset for binary toxicity classification across 14 languages, derived from the TextDetox: Multilingual Toxicity Dataset. The dataset has been split into 85/15 train/test sets for each language, ensuring a representative and balanced sampling.

	
		
	
	
		Dataset Overview
	


Task: Text classification (toxic vs. non-toxic)
Split ratio: 85% training / 15% testing
License: OpenRAIL++… See the full description on the dataset page: https://huggingface.co/datasets/gravitee-io/textdetox-multilingual-toxicity-dataset.",https://huggingface.co/datasets/gravitee-io/textdetox-multilingual-toxicity-dataset,"['en', 'ru', 'uk', 'de', 'es', 'am', 'zh', 'ar', 'hi', 'it', 'fr', 'he', 'ja', 'tt']",['text-classification'],['10K<n<100K']
UncommonCrawl/syosetu-2505-raw,UncommonCrawl,2025-05-26 19:44:02+00:00,2025-05-27 20:36:27+00:00,105,4,"['task_categories:text-generation', 'task_categories:text-classification', 'task_categories:summarization', 'language:ja', 'license:other', 'size_categories:1M<n<10M', 'region:us', 'not-for-all-audiences']","
	
		
		Dataset Card for Syosetu-2505-Raw
	

This dataset is a collection of WARC files containing ~1,319,364 novels and accompanying metadata scraped from Syosetuka ni Narou (https://syosetu.com) in May 2025.

	
		
		Dataset Details
	


	
		
		Uses
	

This dataset is intended to be processed and used in the training of large language models.

	
		
		Dataset Structure
	

The dataset consists WARC files containing only ""resource"" records. The URLs fetched are a novel's main page, the info page… See the full description on the dataset page: https://huggingface.co/datasets/UncommonCrawl/syosetu-2505-raw.",https://huggingface.co/datasets/UncommonCrawl/syosetu-2505-raw,['ja'],"['text-generation', 'text-classification', 'summarization']",['1M<n<10M']
if001/bunpo_phi4,if001,2025-05-27 11:35:38+00:00,2025-06-01 14:08:46+00:00,10,0,"['language:ja', 'size_categories:100K<n<1M', 'format:parquet', 'modality:tabular', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","phi4で以下の53の文法パターン × 2364vocab を生成し、フィルタリングを行っています。
0, ""です/だ (肯定文)"",
1, ""ではありません/じゃない (否定文)"",
3, ""〜ます (動詞の丁寧形)"",
4, ""〜ません (動詞の否定形)"",
5, ""〜たい (希望・願望)"",
6, ""〜ている (進行形)"",
7, ""〜てください (依頼)"",
8, ""〜てもいいですか (許可)"",
9, ""〜なければなりません/〜なきゃいけない (義務)"",
10, ""〜でしょう/〜だろう (推測)"",
11, ""〜が好きです/嫌いです (好み)"",
12, ""〜と思います (意見・思考)"",
13, ""〜から/〜ので (理由)"",
14, ""〜のが好きです/嫌いです (動作の好み)"",
15, ""〜でしょうか (丁寧な質問)"",
16, ""〜てしまう (完了・後悔)"",
17, ""〜ながら (同時進行)"",
18, ""〜ば/〜たら (仮定形)"",
19, ""〜ておく (準備)"",
20, ""〜ようにする (努力・習慣)"",
21, ""〜そうだ (伝聞・推量)"",
22… See the full description on the dataset page: https://huggingface.co/datasets/if001/bunpo_phi4.",https://huggingface.co/datasets/if001/bunpo_phi4,['ja'],[],['100K<n<1M']
yayoimizuha/new-imatrix-dataset-ja-en,yayoimizuha,2025-05-28 00:44:09+00:00,2025-05-29 04:14:23+00:00,15,0,"['task_categories:text-generation', 'language:en', 'language:ja', 'license:cc-by-sa-4.0', 'size_categories:1K<n<10K', 'format:text', 'modality:text', 'library:datasets', 'library:mlcroissant', 'region:us']","
	
		
		Dataset Card for Dataset Name
	

日英LLM向けのimatrix蒸留用データセットです。
既存のデータセットとしてはTFMC/imatrix-dataset-for-japanese-llmがありますが、
テキストの品質が低いように感じたので、
青空文庫、日英Wikipedia,Project Gutenbergよりデータをシャッフルして作成しました。

	
		
		Dataset Sources
	

fujiki/wiki40b_ja
globis-university/aozorabunko-clean
manu/project_gutenberg
blo05/cleaned_wiki_en_80-100

	
		
	
	
		Uses
	

llama-imatrix -m /path/to/model-file/original-f16.gguf -f imatrix_sample.txt

",https://huggingface.co/datasets/yayoimizuha/new-imatrix-dataset-ja-en,"['en', 'ja']",['text-generation'],['1K<n<10K']
APTO-001/japanese-reasoning-dataset-sample,APTO-001,2025-05-28 03:26:57+00:00,2025-05-28 04:29:21+00:00,53,1,"['task_categories:text-generation', 'language:ja', 'license:apache-2.0', 'size_categories:n<1K', 'format:parquet', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","reasoningモデルのファインチューニングのためのデータセットとなります。
各データは、推論を必要とする質問と、その回答を含み、「思考過程」が <think>～</think> タグ内に記述されています。本データセットは弊社技術により開発した合成データから、問題がないか人によってチェックされた高品質なデータとなっています。

	
		
		データ内容
	

データセットは以下のようなJSON形式で提供され、各レコードには推論を必要とする質問と回答のペアが含まれています：
[
  {
    ""question"": ""推論問題の内容"",
    ""answer"": ""問題に対する回答の内容"",
    ""tag"": {
      ""question"": ""質問ジャンルのタグ情報"",
    }
  },
  ...
]


question 推論を必要とする質問文。問題状況の説明や条件など、推論に必要な情報が含まれています。

2.answer: 質問に対する回答。<think>～</think>… See the full description on the dataset page: https://huggingface.co/datasets/APTO-001/japanese-reasoning-dataset-sample.",https://huggingface.co/datasets/APTO-001/japanese-reasoning-dataset-sample,['ja'],['text-generation'],['n<1K']
Jerry999/multilingual-terminology,Jerry999,2025-05-30 06:52:45+00:00,2025-05-31 20:51:51+00:00,64,1,"['language:en', 'language:ar', 'language:zh', 'language:fr', 'language:ja', 'language:ru', 'license:apache-2.0', 'size_categories:1K<n<10K', 'arxiv:2412.18367', 'region:us', 'ai', 'terminology', 'multilingual', 'translation', 'nlp', 'scientific-text']","
	
		
		📚 GIST: Glossary of Multilingual AI Scientific Terminology
	

Paper Title: Towards Global AI Inclusivity: A Large-Scale Multilingual Terminology Dataset (GIST)
Website Demo Instructions: https://github.com/jiarui-liu/MultilingualAITerminology

	
		
		Dataset Summary
	

GIST is a large-scale, high-quality multilingual AI terminology dataset developed to support global inclusivity in AI research. It consists of around 5,000 English AI-specific terms, each translated into Arabic, Chinese… See the full description on the dataset page: https://huggingface.co/datasets/Jerry999/multilingual-terminology.",https://huggingface.co/datasets/Jerry999/multilingual-terminology,"['en', 'ar', 'zh', 'fr', 'ja', 'ru']",[],['1K<n<10K']
freococo/quran_multilingual_parallel,freococo,2025-05-30 10:51:25+00:00,2025-05-30 12:00:27+00:00,53,1,"['task_categories:translation', 'language:ar', 'language:sq', 'language:am', 'language:az', 'language:bn', 'language:bs', 'language:bg', 'language:my', 'language:zh', 'language:da', 'language:nl', 'language:en', 'language:tl', 'language:fr', 'language:ff', 'language:fa', 'language:de', 'language:gu', 'language:ha', 'language:hi', 'language:id', 'language:it', 'language:ja', 'language:jv', 'language:kk', 'language:km', 'language:ko', 'language:ku', 'language:ky', 'language:ms', 'language:ml', 'language:ps', 'language:pl', 'language:pt', 'language:pa', 'language:ru', 'language:sd', 'language:si', 'language:so', 'language:es', 'language:sw', 'language:sv', 'language:tg', 'language:ta', 'language:tt', 'language:te', 'language:th', 'language:tr', 'language:ur', 'language:ug', 'language:uz', 'language:yo', 'language:no', 'language:vi', 'license:mit', 'size_categories:1K<n<10K', 'format:csv', 'modality:tabular', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'doi:10.57967/hf/6171', 'region:us']","
	
		
		📘 Qur’an Multilingual Parallel Dataset (quran_multilingual_parallel)
	

This dataset presents a clean, structurally-aligned multilingual parallel corpus of the Qur’anic text. It is intended for linguistic, computational, and cross-lingual AI applications — not only for religious interpretation.
It contains over 6,200 verse-level alignments in 54 human languages, formatted in a machine-friendly .csv structure with language-specific translation fields.


	
		
	
	
		🧠 Dataset Highlights… See the full description on the dataset page: https://huggingface.co/datasets/freococo/quran_multilingual_parallel.",https://huggingface.co/datasets/freococo/quran_multilingual_parallel,"['ar', 'sq', 'am', 'az', 'bn', 'bs', 'bg', 'my', 'zh', 'da', 'nl', 'en', 'tl', 'fr', 'ff', 'fa', 'de', 'gu', 'ha', 'hi', 'id', 'it', 'ja', 'jv', 'kk', 'km', 'ko', 'ku', 'ky', 'ms', 'ml', 'ps', 'pl', 'pt', 'pa', 'ru', 'sd', 'si', 'so', 'es', 'sw', 'sv', 'tg', 'ta', 'tt', 'te', 'th', 'tr', 'ur', 'ug', 'uz', 'yo', 'no', 'vi']",['translation'],['1K<n<10K']
UEC-InabaLab/KokoroChat,UEC-InabaLab,2025-06-01 11:42:14+00:00,2025-08-04 06:31:12+00:00,104,1,"['task_categories:text-generation', 'task_categories:text-classification', 'language:ja', 'license:cc-by-nc-nd-4.0', 'size_categories:1K<n<10K', 'format:json', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us', 'nlp', 'dialogue', 'dialogue-corpus', 'dialogue-system']","
  









	
	
	
		KokoroChat: A Japanese Psychological Counseling Dialogue Dataset Collected via Role-Playing by Trained Counselors
	

KokoroChat is the largest human-collected Japanese psychological counseling dialogue dataset to date (as of June 2025). It was created through role-playing between trained counselors and includes rich, long-form dialogues and detailed client feedback on counseling quality. The dataset supports research on empathetic response generation, dialogue evaluation… See the full description on the dataset page: https://huggingface.co/datasets/UEC-InabaLab/KokoroChat.",https://huggingface.co/datasets/UEC-InabaLab/KokoroChat,['ja'],"['text-generation', 'text-classification']",['1K<n<10K']
animetimm/danbooru-wdtagger-v4ex-w640,animetimm,2025-06-01 14:11:18+00:00,2025-06-06 03:58:31+00:00,6,0,"['task_categories:image-classification', 'task_categories:zero-shot-image-classification', 'task_categories:text-to-image', 'annotations_creators:no-annotation', 'source_datasets:danbooru', 'language:en', 'language:ja', 'license:other', 'size_categories:1M<n<10M', 'region:us', 'art', 'anime', 'not-for-all-audiences']","
	
		
		Danbooru W640 Pruned Dataset V4 (Extended)
	

This is the re-encoded webp-format dataset for deepghs/wdtagger-v4-extended-seed.
Metadata here are cleaned by @SmilingWolf, can be used for multi-label classification training.
Images here are resized to min(width, height) <= 640.
5914596 images in total.

	
		
	
	
		Train
	

5321713 train images in total, 50 train images shown here.

	
		
id
split
archive_file
filename
width
height
rating
general_tags
character_tags
artist_tags… See the full description on the dataset page: https://huggingface.co/datasets/animetimm/danbooru-wdtagger-v4ex-w640.",https://huggingface.co/datasets/animetimm/danbooru-wdtagger-v4ex-w640,"['en', 'ja']","['image-classification', 'zero-shot-image-classification', 'text-to-image']",['1M<n<10M']
ComplexDataLab/MLSNT,ComplexDataLab,2025-06-01 19:01:57+00:00,2025-06-01 19:25:58+00:00,16,1,"['task_categories:text-classification', 'task_categories:token-classification', 'language:zh', 'language:ja', 'language:pt', 'language:fr', 'language:de', 'language:ru', 'license:mit', 'size_categories:100K<n<1M', 'format:parquet', 'modality:tabular', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us', 'toxicity', 'hatespeech']","
	
		
		MLSNT: Multi-Lingual Social Network Toxicity Dataset
	

MLSNT is a multi-lingual dataset for toxicity detection created through a large language model-assisted label transfer pipeline. It enables efficient and scalable moderation across languages and platforms, and is built to support span-level and category-specific classification for toxic content.
This dataset is introduced in the following paper:

Unified Game Moderation: Soft-Prompting and LLM-Assisted Label Transfer for… See the full description on the dataset page: https://huggingface.co/datasets/ComplexDataLab/MLSNT.",https://huggingface.co/datasets/ComplexDataLab/MLSNT,"['zh', 'ja', 'pt', 'fr', 'de', 'ru']","['text-classification', 'token-classification']",['100K<n<1M']
OmniAICreator/pixiv-dic-202506,OmniAICreator,2025-06-02 01:54:36+00:00,2025-06-02 02:12:24+00:00,15,1,"['task_categories:text-classification', 'task_categories:text-generation', 'language:ja', 'license:unknown', 'size_categories:100K<n<1M', 'format:parquet', 'modality:text', 'library:datasets', 'library:dask', 'library:mlcroissant', 'library:polars', 'region:us']","
	
		
		pixiv-dic-202506
	

This dataset contains data from the pixiv dic (Pixiv百科事典) as of June 1, 2025.
",https://huggingface.co/datasets/OmniAICreator/pixiv-dic-202506,['ja'],"['text-classification', 'text-generation']",['100K<n<1M']
nguyenthanhasia/japanese-bar-exam-qa,nguyenthanhasia,2025-06-02 05:23:47+00:00,2025-09-09 12:38:37+00:00,52,2,"['task_categories:question-answering', 'task_categories:text-classification', 'language:ja', 'license:cc-by-4.0', 'size_categories:1K<n<10K', 'format:parquet', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us', 'legal', 'bar-exam', 'japanese-law']","
	
		
		Japanese Bar Examination QA Dataset
	


	
		
		Dataset Summary
	

This dataset contains question-answer pairs from the Japanese Bar Examination (司法試験, Shihou Shiken) spanning from 2015 to 2024. It covers three major areas of Japanese law: Criminal Law (刑法), Constitutional Law (憲法), and Civil Law (民法).
The dataset is designed for binary classification tasks, where each question requires a True/False answer based on Japanese legal principles and precedents.

	
		
		Dataset Details… See the full description on the dataset page: https://huggingface.co/datasets/nguyenthanhasia/japanese-bar-exam-qa.",https://huggingface.co/datasets/nguyenthanhasia/japanese-bar-exam-qa,['ja'],"['question-answering', 'text-classification']",['1K<n<10K']
OmniAICreator/Japanese-Wikipedia-202506,OmniAICreator,2025-06-03 07:54:18+00:00,2025-06-03 08:09:25+00:00,179,2,"['task_categories:text-classification', 'task_categories:text-generation', 'language:ja', 'license:cc-by-sa-4.0', 'size_categories:1M<n<10M', 'format:parquet', 'modality:text', 'library:datasets', 'library:dask', 'library:mlcroissant', 'library:polars', 'region:us']","
	
		
		Japanese-Wikipedia-202506
	

This dataset contains data from the Japanese Wikipedia as of June 1, 2025.
",https://huggingface.co/datasets/OmniAICreator/Japanese-Wikipedia-202506,['ja'],"['text-classification', 'text-generation']",['1M<n<10M']
clnine/sample-dataset-wikipedia-financial-terms,clnine,2025-06-04 04:05:04+00:00,2025-06-04 04:06:47+00:00,11,0,"['task_categories:text-generation', 'language:ja', 'license:cc-by-sa-3.0', 'size_categories:n<1K', 'format:parquet', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","このデータセットは、Wikipediaデータセットの日本語データのみを抽出したparquetファイルであるrange3/wikipedia-ja-20230101より、「Category:投資」に含まれる記事に該当するレコードの一部を抽出した作業用サンプルです。
",https://huggingface.co/datasets/clnine/sample-dataset-wikipedia-financial-terms,['ja'],['text-generation'],['n<1K']
clnine/sample-dataset-wikipedia-nikkei225,clnine,2025-06-04 04:05:35+00:00,2025-06-04 04:07:08+00:00,17,0,"['task_categories:text-generation', 'language:ja', 'license:cc-by-sa-3.0', 'size_categories:n<1K', 'format:parquet', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","このデータセットは、Wikipediaデータセットの日本語データのみを抽出したparquetファイルであるrange3/wikipedia-ja-20230101より、「Category:日経平均株価」に含まれる記事に該当するレコードを抽出した作業用サンプルです。
",https://huggingface.co/datasets/clnine/sample-dataset-wikipedia-nikkei225,['ja'],['text-generation'],['n<1K']
ayousanz/moe-speech-plus-ljspeech,ayousanz,2025-06-04 09:59:13+00:00,2025-06-21 04:29:05+00:00,35,1,"['task_categories:text-to-speech', 'task_categories:audio-to-audio', 'task_categories:audio-classification', 'task_ids:speaker-identification', 'multilinguality:monolingual', 'language:ja', 'license:other', 'size_categories:100K<n<1M', 'modality:audio', 'region:us', 'speech', 'audio', 'japanese', 'anime', 'voice', 'not-for-all-audiences']","
	
		
		MoeSpeechPlus-ljspeech
	


MoeSpeechPlusのデータセットのデータフォーマットをljspechに沿って変換したもの

huggingface-cli download --repo-type dataset ayousanz/moe-speech-plus-ljspeech --local-dir moe-speech-plus-ljspeech


	
		
		MoeSpeech
	

日本語はこちら
このデータセットは、著作権法第三十条の四の情報解析（機械学習等）の目的でのみ使用が許可されています。それ以外の用途での使用はライセンスにより禁止されています。
This dataset is only permitted for use under Article 30-4 of the Copyright Law of Japan for data analysis (such as machine learning) purposes. Any use for purposes other than those… See the full description on the dataset page: https://huggingface.co/datasets/ayousanz/moe-speech-plus-ljspeech.",https://huggingface.co/datasets/ayousanz/moe-speech-plus-ljspeech,['ja'],"['text-to-speech', 'audio-to-audio', 'audio-classification']",['100K<n<1M']
Aratako/Synthetic-Japanese-Roleplay-NSFW-DeepSeek-R1-0528-10k,Aratako,2025-06-04 13:42:40+00:00,2025-06-05 08:23:12+00:00,28,2,"['task_categories:text-generation', 'language:ja', 'license:mit', 'size_categories:10K<n<100K', 'format:parquet', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us', 'roleplay', 'not-for-all-audiences']","
	
		
		Synthetic-Japanese-Roleplay-NSFW-DeepSeek-R1-0528-10k
	


	
		
		概要
	

deepseek-ai/DeepSeek-R1-0528を用いて作成した、約10000件の日本語ロールプレイの対話を収録した合成データセットです。各データは20ターン程度あります。
このデータセットはNSFW表現を含みます。

	
		
		データの詳細
	

各データは以下のキーを含んでいます。

major_genre: ジャンル（大分類）
minor_genre: ジャンル（小分類）
tag: 年齢制限用タグ（R-18）
world_setting: 舞台・世界観の設定
scene_setting: 対話シーンの設定
user_setting: ユーザー側のキャラクターの設定
assistant_setting: アシスタント側のキャラクターの設定
dialogue_tone: 対話のトーン
conversations: 上記設定に基づいたユーザーとアシスタントの対話（OpenAI messages形式）… See the full description on the dataset page: https://huggingface.co/datasets/Aratako/Synthetic-Japanese-Roleplay-NSFW-DeepSeek-R1-0528-10k.",https://huggingface.co/datasets/Aratako/Synthetic-Japanese-Roleplay-NSFW-DeepSeek-R1-0528-10k,['ja'],['text-generation'],['10K<n<100K']
Aratako/Synthetic-Japanese-Roleplay-SFW-DeepSeek-R1-0528-10k,Aratako,2025-06-04 13:49:23+00:00,2025-06-05 08:15:54+00:00,7,4,"['task_categories:text-generation', 'language:ja', 'license:mit', 'size_categories:10K<n<100K', 'format:parquet', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us', 'roleplay']","
	
		
		Synthetic-Japanese-Roleplay-SFW-DeepSeek-R1-0528-10k
	


	
		
		概要
	

deepseek-ai/DeepSeek-R1-0528を用いて作成した、約10000件の日本語ロールプレイの対話を収録した合成データセットです。各データは20ターン程度あります。

	
		
		データの詳細
	

各データは以下のキーを含んでいます。

major_genre: ジャンル（大分類）
minor_genre: ジャンル（小分類）
tag: 年齢制限用タグ（全年齢、R-15）
world_setting: 舞台・世界観の設定
scene_setting: 対話シーンの設定
user_setting: ユーザー側のキャラクターの設定
assistant_setting: アシスタント側のキャラクターの設定
dialogue_tone: 対話のトーン
conversations: 上記設定に基づいたユーザーとアシスタントの対話（OpenAI messages形式）

設定等の情報からsystem… See the full description on the dataset page: https://huggingface.co/datasets/Aratako/Synthetic-Japanese-Roleplay-SFW-DeepSeek-R1-0528-10k.",https://huggingface.co/datasets/Aratako/Synthetic-Japanese-Roleplay-SFW-DeepSeek-R1-0528-10k,['ja'],['text-generation'],['10K<n<100K']
Aratako/Synthetic-Japanese-Roleplay-SFW-DeepSeek-R1-0528-10k-formatted,Aratako,2025-06-04 13:54:47+00:00,2025-06-05 08:21:24+00:00,15,0,"['task_categories:text-generation', 'language:ja', 'license:mit', 'size_categories:10K<n<100K', 'format:parquet', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us', 'roleplay']","
	
		
		Synthetic-Japanese-Roleplay-SFW-DeepSeek-R1-0528-10k-formatted
	


	
		
		概要
	

deepseek-ai/DeepSeek-R1-0528を用いて作成した日本語ロールプレイデータセットであるAratako/Synthetic-Japanese-Roleplay-SFW-DeepSeek-R1-0528-10kにsystem messageを追加して整形したデータセットです。
データの詳細については元データセットのREADMEを参照してください。

	
		
		ライセンス
	

MITライセンスの元配布します。
",https://huggingface.co/datasets/Aratako/Synthetic-Japanese-Roleplay-SFW-DeepSeek-R1-0528-10k-formatted,['ja'],['text-generation'],['10K<n<100K']
Aratako/Synthetic-Japanese-Roleplay-NSFW-DeepSeek-R1-0528-10k-formatted,Aratako,2025-06-04 13:55:38+00:00,2025-06-05 08:22:51+00:00,74,0,"['task_categories:text-generation', 'language:ja', 'license:mit', 'size_categories:10K<n<100K', 'format:parquet', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us', 'roleplay', 'not-for-all-audiences']","
	
		
		Synthetic-Japanese-Roleplay-NSFW-DeepSeek-R1-0528-10k-formatted
	


	
		
		概要
	

deepseek-ai/DeepSeek-R1-0528を用いて作成した日本語ロールプレイデータセットであるAratako/Synthetic-Japanese-Roleplay-NSFW-DeepSeek-R1-0528-10kにsystem messageを追加して整形したデータセットです。
データの詳細については元データセットのREADMEを参照してください。

	
		
		ライセンス
	

MITライセンスの元配布します。
",https://huggingface.co/datasets/Aratako/Synthetic-Japanese-Roleplay-NSFW-DeepSeek-R1-0528-10k-formatted,['ja'],['text-generation'],['10K<n<100K']
Sakaji-Lab/JMID,Sakaji-Lab,2025-06-06 02:12:54+00:00,2025-09-29 04:27:48+00:00,31,0,"['task_categories:text-classification', 'task_categories:text-generation', 'language:ja', 'license:cc-by-4.0', 'size_categories:1K<n<10K', 'format:json', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'doi:10.57967/hf/5728', 'region:us']","
	
		
		JMID: Japanese Medical Incident Dataset
	

日本語
本データセットは、公益財団法人日本医療機能評価機構の医療事故報告書に書かれている医療事故内容から、医療事故の「具体的内容」「背景・要因」「改善策」とその他の情報をまとめたものである。
使い方の例は以下に載せる。
English
This dataset is compiled from the medical incident reports published by the Japan Council for Quality Health Care. It summarizes the contents of medical incidents, including the specific details, background and contributing factors, and proposed improvements, along with other related information.
An example of how to use the… See the full description on the dataset page: https://huggingface.co/datasets/Sakaji-Lab/JMID.",https://huggingface.co/datasets/Sakaji-Lab/JMID,['ja'],"['text-classification', 'text-generation']",['1K<n<10K']
animetimm/danbooru-wdtagger-v4ex-w640-ws-full,animetimm,2025-06-06 04:08:17+00:00,2025-09-13 03:10:05+00:00,10,0,"['task_categories:image-classification', 'task_categories:zero-shot-image-classification', 'source_datasets:danbooru', 'language:en', 'language:ja', 'license:other', 'size_categories:1M<n<10M', 'library:webdataset', 'library:datasets', 'region:us', 'art', 'anime', 'not-for-all-audiences', 'webdataset', 'datasets']","
	
		
		Danbooru WDTagger V4 (Extended) Webdataset Full Dataset
	

This is the webdataset dataset for animetimm/danbooru-wdtagger-v4ex-w640.
Metadata here are cleaned by @SmilingWolf, can be used for multi-label classification training.
Images here are resized to min(width, height) <= 640.

	
		
	
	
		How to Use It
	

from datasets import load_dataset

dataset = load_dataset('animetimm/danbooru-wdtagger-v4ex-w640-ws-full')
print(dataset[""train""][0])


		
	
	
		Images
	5914596 images in total.… See the full description on the dataset page: https://huggingface.co/datasets/animetimm/danbooru-wdtagger-v4ex-w640-ws-full.",https://huggingface.co/datasets/animetimm/danbooru-wdtagger-v4ex-w640-ws-full,"['en', 'ja']","['image-classification', 'zero-shot-image-classification']",['1M<n<10M']
double7/MMMLU_subset,double7,2025-06-06 06:43:42+00:00,2025-06-12 11:27:33+00:00,45,0,"['task_categories:question-answering', 'language:ar', 'language:bn', 'language:de', 'language:es', 'language:fr', 'language:hi', 'language:id', 'language:it', 'language:ja', 'language:ko', 'language:pt', 'language:sw', 'language:yo', 'language:zh', 'license:mit', 'size_categories:10K<n<100K', 'format:csv', 'modality:text', 'library:datasets', 'library:dask', 'library:mlcroissant', 'library:polars', 'arxiv:2009.03300', 'region:us']","
	
		
		About MMMLU subset
	

  This is a subset of MMMLU, specifically, we sampled 10% of the original data to improve evaluation efficiency.
  In addition, we categorize the questions into four categories by subject, i.e., STEM, HUMANITIES, SOCIAL SCIENCES, and OTHER, aligned with MMLU.

	
		
	
	
		Multilingual Massive Multitask Language Understanding (MMMLU)
	

The MMLU is a widely recognized benchmark of general knowledge attained by AI models. It covers a broad range of topics from 57… See the full description on the dataset page: https://huggingface.co/datasets/double7/MMMLU_subset.",https://huggingface.co/datasets/double7/MMMLU_subset,"['ar', 'bn', 'de', 'es', 'fr', 'hi', 'id', 'it', 'ja', 'ko', 'pt', 'sw', 'yo', 'zh']",['question-answering'],['10K<n<100K']
ks-pf/JMTEB-fixed,ks-pf,2025-06-06 22:39:27+00:00,2025-06-09 04:56:30+00:00,640,0,"['task_categories:text-classification', 'task_categories:question-answering', 'task_categories:zero-shot-classification', 'task_categories:sentence-similarity', 'language:ja', 'license:cc-by-sa-4.0', 'size_categories:10M<n<100M', 'format:parquet', 'modality:tabular', 'modality:text', 'library:datasets', 'library:dask', 'library:mlcroissant', 'library:polars', 'arxiv:1908.11828', 'region:us']","
	
		
		JMTEB-fixed
	

このリポジトリは元のJMTEBデータセットのUTF-8エンコーディングエラーを修正したバージョンです。

	
		
		修正内容
	


	
		
		問題
	

NLP Journal LaTeXコーパスの一部ファイル（例: V28N02-25.tex）が異なるエンコーディング（Shift-JIS、EUC-JPなど）で保存されており、UTF-8デコーディングエラーが発生していました。

	
		
		解決策
	

retrieval.pyのNLPJournalHelper.load_txtメソッドを修正し、複数のエンコーディングを順次試行するようにしました。

	
		
		使用方法
	

from datasets import load_dataset

dataset = load_dataset(
    ""ks-pf/JMTEB-fixed"",
    name=""nlp_journal_title_abs-corpus"",
    trust_remote_code=True
)


# JMTEB: Japanese… See the full description on the dataset page: https://huggingface.co/datasets/ks-pf/JMTEB-fixed.",https://huggingface.co/datasets/ks-pf/JMTEB-fixed,['ja'],"['text-classification', 'question-answering', 'zero-shot-classification', 'sentence-similarity']",['10M<n<100M']
szkiM/JOJO_TEXTS,szkiM,2025-06-06 23:28:23+00:00,2025-06-06 23:29:48+00:00,4,0,"['task_categories:text-classification', 'task_categories:text-generation', 'language:ja', 'size_categories:n<1K', 'format:json', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']",,https://huggingface.co/datasets/szkiM/JOJO_TEXTS,['ja'],"['text-classification', 'text-generation']",['n<1K']
humanalysis-square/KokushiMD-10,humanalysis-square,2025-06-07 14:54:20+00:00,2025-10-10 16:23:34+00:00,449,4,"['task_categories:question-answering', 'task_categories:multiple-choice', 'language:ja', 'language:en', 'license:mit', 'size_categories:10K<n<100K', 'format:json', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'arxiv:2506.11114', 'region:us', 'medical', 'healthcare', 'multimodal', 'licensing-exam', 'benchmark']","
	
		
		KokushiMD-10: Benchmark for Evaluating Large Language Models on Ten Japanese National Healthcare Licensing Examinations
	






	
	
	
		Overview
	

KokushiMD-10 is the first comprehensive multimodal benchmark constructed from ten Japanese national healthcare licensing examinations. This dataset addresses critical gaps in existing medical AI evaluation by providing a linguistically grounded, multimodal, and multi-profession assessment framework for large language models (LLMs) in… See the full description on the dataset page: https://huggingface.co/datasets/humanalysis-square/KokushiMD-10.",https://huggingface.co/datasets/humanalysis-square/KokushiMD-10,"['ja', 'en']","['question-answering', 'multiple-choice']",['10K<n<100K']
vsachi/sachi-dataset-ja,vsachi,2025-06-08 04:26:22+00:00,2025-06-08 04:38:03+00:00,12,0,"['task_categories:question-answering', 'language:ja', 'license:cc0-1.0', 'size_categories:n<1K', 'format:json', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us', 'roleplay', 'game']","LLMをファインチューニングするためのデータセットです。alcapa-chatbot-formatです。
キャラクターと会話するデータセットとなっています。
私はいつもVR SNSでかわいい女の子のロールプレーをしています。
私がかわいい女の子のAIに転生したという設定で作った会話データセットになっています。
キャラクター設定はフィクションやジョークです。完全に現実ではありません。
ゲームに登場するNPC等のAIのトレーニングなどに自由にご利用ください。
幅広く利用してもらえるようにPublic domainライセンスにします。

	
		
		ライセンス
	

Public domainライセンスにします。
",https://huggingface.co/datasets/vsachi/sachi-dataset-ja,['ja'],['question-answering'],['n<1K']
HelpingAI/Dhanishtha-2.0-SUPERTHINKER,HelpingAI,2025-06-08 13:34:32+00:00,2025-09-22 05:51:14+00:00,31,19,"['task_categories:text-generation', 'language:af', 'language:ar', 'language:bg', 'language:ca', 'language:zh', 'language:cs', 'language:da', 'language:nl', 'language:en', 'language:fi', 'language:fr', 'language:de', 'language:el', 'language:he', 'language:hi', 'language:id', 'language:hu', 'language:ja', 'language:ko', 'language:mr', 'language:no', 'language:fa', 'language:pt', 'language:pl', 'language:ro', 'language:ru', 'language:es', 'language:sw', 'language:ta', 'language:te', 'language:tr', 'language:ur', 'language:uk', 'language:vi', 'license:apache-2.0', 'size_categories:10K<n<100K', 'format:json', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us', 'ai', 'intermediate-thinking', 'multilingual', 'reasoning', 'emotional-intelligence', 'dhanishtha', 'helpingai', 'structured-thinking', 'self-correction', 'chain-of-thought', 'CoT']","📦 Dhanishtha-2.0-SUPERTHINKER
 A distilled corpus of 11.7K high-quality samples showcasing multi-phase reasoning and structured emotional cognition. Sourced directly from the internal training data of Dhanishtha-2.0 — the world’s first Large Language Model (LLM) to implement Intermediate Thinking, featuring multiple <think> and <ser> blocks per response


	
		
		📊 Overview
	


11.7K multilingual samples (languages listed below)
Instruction-Output format, ideal for supervised fine-tuning… See the full description on the dataset page: https://huggingface.co/datasets/HelpingAI/Dhanishtha-2.0-SUPERTHINKER.",https://huggingface.co/datasets/HelpingAI/Dhanishtha-2.0-SUPERTHINKER,"['af', 'ar', 'bg', 'ca', 'zh', 'cs', 'da', 'nl', 'en', 'fi', 'fr', 'de', 'el', 'he', 'hi', 'id', 'hu', 'ja', 'ko', 'mr', 'no', 'fa', 'pt', 'pl', 'ro', 'ru', 'es', 'sw', 'ta', 'te', 'tr', 'ur', 'uk', 'vi']",['text-generation'],['10K<n<100K']
li-lab/JPMedReason,li-lab,2025-06-08 14:23:56+00:00,2025-06-09 11:22:00+00:00,16,0,"['task_categories:question-answering', 'language:ja', 'language:en', 'license:mit', 'size_categories:10K<n<100K', 'format:json', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us', 'medical']","
	
		
		JPMedReason 🇯🇵🧠
	

Japanese Medical Reasoning Dataset (Translation of MedReason)


	
		
		📝 Overview
	

JPMedReason is a high-quality Japanese translation of the MedReason dataset — a benchmark designed to evaluate complex clinical reasoning capabilities of Large Language Models (LLMs) in multiple-choice QA format.
This dataset provides question-answer pairs in the medical domain accompanied by chain-of-thought (CoT) style reasoning in both English and Japanese. The Japanese… See the full description on the dataset page: https://huggingface.co/datasets/li-lab/JPMedReason.",https://huggingface.co/datasets/li-lab/JPMedReason,"['ja', 'en']",['question-answering'],['10K<n<100K']
KoalaAI/Text-Moderation-Multilingual,KoalaAI,2025-06-08 19:45:51+00:00,2025-06-08 19:54:22+00:00,51,1,"['task_categories:text-classification', 'language:en', 'language:de', 'language:fr', 'language:es', 'language:it', 'language:sv', 'language:fi', 'language:pl', 'language:cs', 'language:lv', 'language:zh', 'language:ja', 'language:ko', 'language:ru', 'language:uk', 'language:be', 'language:kk', 'license:apache-2.0', 'size_categories:1M<n<10M', 'format:parquet', 'modality:tabular', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us', 'text-moderation']","
	
		
		Text-Moderation-Multilingual
	

A comprehensive multilingual text moderation dataset combining multiple high-quality sources for training robust content moderation classifiers.

	
		
		Dataset Summary
	

This dataset aggregates text moderation data from multiple sources to create a large-scale, diverse training corpus for content moderation systems. It includes text samples labeled across multiple harmful content categories, supporting both multilingual and English-specific moderation… See the full description on the dataset page: https://huggingface.co/datasets/KoalaAI/Text-Moderation-Multilingual.",https://huggingface.co/datasets/KoalaAI/Text-Moderation-Multilingual,"['en', 'de', 'fr', 'es', 'it', 'sv', 'fi', 'pl', 'cs', 'lv', 'zh', 'ja', 'ko', 'ru', 'uk', 'be', 'kk']",['text-classification'],['1M<n<10M']
YUGOROU/Counseling-Reasoning-v1.8,YUGOROU,2025-06-09 02:51:54+00:00,2025-06-09 23:47:10+00:00,14,1,"['language:ja', 'license:cdla-permissive-2.0', 'size_categories:n<1K', 'format:json', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","
	
		
		データセット概要
	

このデータセットは、カウンセリング分野における問題解決と回答生成に関するデータを含んでいます。Chain-of-Thought (CoT) 推論モードを使用して生成されたソリューションが含まれています。

	
		
		データセット詳細
	


総エントリ数: 917件
ファイルサイズ: 3,041,931 bytes (約2.9MB)
推論モード: Chain-of-Thought (cot)
問題タイプ: カウンセリング
生成モデル: Manus AI


	
		
		フィールド説明
	


	
		
フィールド名
データ型
説明


		
expected_answer
string
期待される回答


problem_type
string
問題の種類（カウンセリング）


problem_source
string
問題の出典（LLM）


generation_model
string
生成に使用されたモデル（Manus AI）


problem
string
相談内容・問題文


generated_solution… See the full description on the dataset page: https://huggingface.co/datasets/YUGOROU/Counseling-Reasoning-v1.8.",https://huggingface.co/datasets/YUGOROU/Counseling-Reasoning-v1.8,['ja'],[],['n<1K']
Sakaji-Lab/LATGNJ,Sakaji-Lab,2025-06-09 09:19:07+00:00,2025-06-18 11:28:03+00:00,24,1,"['language:ja', 'license:cc-by-nc-sa-4.0', 'size_categories:n<1K', 'format:json', 'modality:document', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'doi:10.57967/hf/5752', 'region:us']","
	
		
		JAgriN: Japanese Agricultural Dataset of Nagasaki Prefecture
	

formerly LATGNJ: Local Agricultural Technical Guideline of Nagasaki, Japan


	
		
		Dataset Metadata (Datasheet Summary)
	

This section summarizes the key metadata of JAgriN following the recommendations proposed in ""Datasheets for Datasets"" by Gebru et al. (2021) [1].

	
		
Field
Description


		
Dataset Name
JAgriN (Japanese Agricultural Dataset of Nagasaki Prefecture)


Creators
Hokkaido University, The University of… See the full description on the dataset page: https://huggingface.co/datasets/Sakaji-Lab/LATGNJ.",https://huggingface.co/datasets/Sakaji-Lab/LATGNJ,['ja'],[],['n<1K']
LoneWolfgang/multilingual-queries-for-collected-works-of-milton-h-erickson,LoneWolfgang,2025-06-09 22:14:25+00:00,2025-06-09 22:47:02+00:00,20,0,"['task_categories:translation', 'language:en', 'language:pt', 'language:ja', 'language:zh', 'language:es', 'language:de', 'language:it', 'language:fr', 'language:ru', 'license:apache-2.0', 'size_categories:1K<n<10K', 'format:parquet', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us', 'medical']","
	
		
		Multilingual Queries for the Collected Works of Milton H. Erickson
	

This collection contains machine-generated and translated queries designed to evaluate the performance of a multilingual retriever adapted to Ericksonian terminology.
To create the queries, the Collected Works of Milton H. Erickson was segmented into 500-word samples. Also, a list of relevant keywords was extracted from the Glossary of Ericksonian Terminology. Using the samples and keywords, queries were generated by… See the full description on the dataset page: https://huggingface.co/datasets/LoneWolfgang/multilingual-queries-for-collected-works-of-milton-h-erickson.",https://huggingface.co/datasets/LoneWolfgang/multilingual-queries-for-collected-works-of-milton-h-erickson,"['en', 'pt', 'ja', 'zh', 'es', 'de', 'it', 'fr', 'ru']",['translation'],['1K<n<10K']
fvdfs41/PinkSea-1.6k,fvdfs41,2025-06-09 22:24:33+00:00,2025-06-09 23:56:44+00:00,39,0,"['language:en', 'language:ja', 'license:wtfpl', 'size_categories:1K<n<10K', 'region:us', 'art', 'not-for-all-audiences']","A dataset containing ~1600 posts scraped from https://pinksea.art/ on 2025-06-10. PinkSea is an oekaki board powered by the AT Protocol ecosystem.
",https://huggingface.co/datasets/fvdfs41/PinkSea-1.6k,"['en', 'ja']",[],['1K<n<10K']
VuSnow/Jp-OCR-Pretraining,VuSnow,2025-06-10 04:34:11+00:00,2025-06-13 06:58:26+00:00,1785,0,"['task_categories:image-to-text', 'language:ja', 'size_categories:10K<n<100K', 'format:arrow', 'modality:image', 'modality:text', 'library:datasets', 'library:mlcroissant', 'region:us']",,https://huggingface.co/datasets/VuSnow/Jp-OCR-Pretraining,['ja'],['image-to-text'],['10K<n<100K']
YUGOROU/Counseling-Reasoning-v1.9-parquet,YUGOROU,2025-06-10 11:24:34+00:00,2025-06-10 11:27:54+00:00,8,0,"['language:ja', 'license:cdla-permissive-2.0', 'size_categories:n<1K', 'format:parquet', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","
	
		
		データセット概要
	

このデータセットは、カウンセリング分野における問題解決と回答生成に関するデータを含んでいます。Chain-of-Thought (CoT) 推論モードを使用して生成されたソリューションが含まれています。

	
		
		データセット詳細
	


総エントリ数: 917件
ファイルサイズ: 3,041,931 bytes (約2.9MB)
推論モード: Chain-of-Thought (cot)
問題タイプ: カウンセリング
生成モデル: Manus AI


	
		
		フィールド説明
	


	
		
フィールド名
データ型
説明


		
expected_answer
string
期待される回答


problem_type
string
問題の種類（カウンセリング）


problem_source
string
問題の出典（LLM）


generation_model
string
生成に使用されたモデル（Manus AI）


problem
string
相談内容・問題文


generated_solution… See the full description on the dataset page: https://huggingface.co/datasets/YUGOROU/Counseling-Reasoning-v1.9-parquet.",https://huggingface.co/datasets/YUGOROU/Counseling-Reasoning-v1.9-parquet,['ja'],[],['n<1K']
kujirahand/popular_anime_corpus,kujirahand,2025-06-10 23:39:42+00:00,2025-08-02 23:22:02+00:00,11,0,"['task_categories:feature-extraction', 'language:ja', 'license:cc-by-sa-4.0', 'size_categories:1K<n<10K', 'format:json', 'modality:text', 'library:datasets', 'library:dask', 'library:mlcroissant', 'region:us']","
	
		
		popular_anime_corpus
	

有名なアニメのあらすじや主人公の情報をまとめたコーパスです。
1960年代以降の人気アニメに関するテキストをWikipediaから抽出し、テキストを要約して、Alpaca形式でコーパスにまとめています。下記のようなデータとなっています。
{
  ""train"": [
    {
      ""instruction"": ""主人公は誰ですか？"",
      ""input"": ""名探偵コナン 絶海の探偵"",
      ""output"": ""主人公は「江戸川 コナン（えどがわ コナン）」です。\n\n江戸川 コナンは、本来の姿は「東の高校生探偵」として名を馳せている工藤新一だが、黒ずくめの組織に飲まされた毒薬・APTX4869の副作用で小学生の姿になっている。本作の主人公であり、物語の中心人物として活躍します。""},
    {
      ""instruction"": ""主人公やあらすじを教えてください。"",
      ""input"": ""ヴァイオレット・エヴァーガーデン"",
      ""output"":… See the full description on the dataset page: https://huggingface.co/datasets/kujirahand/popular_anime_corpus.",https://huggingface.co/datasets/kujirahand/popular_anime_corpus,['ja'],['feature-extraction'],['1K<n<10K']
OmniAICreator/DLSite-Meta-And-Sample-Images-860k,OmniAICreator,2025-06-11 04:38:04+00:00,2025-06-11 05:12:24+00:00,12,1,"['task_categories:text-classification', 'task_categories:text-generation', 'language:ja', 'license:mit', 'size_categories:100K<n<1M', 'region:us', 'not-for-all-audiences']","
	
		
		DLSite-Meta-And-Sample-Images-860k
	

This dataset contains almost all metadata and links to sample images from DLSite.
",https://huggingface.co/datasets/OmniAICreator/DLSite-Meta-And-Sample-Images-860k,['ja'],"['text-classification', 'text-generation']",['100K<n<1M']
HLeiTR/R3-eval-MMMLU,HLeiTR,2025-06-11 06:11:14+00:00,2025-06-11 20:14:59+00:00,40,0,"['task_categories:question-answering', 'language:ar', 'language:bn', 'language:de', 'language:es', 'language:fr', 'language:hi', 'language:id', 'language:it', 'language:ja', 'language:ko', 'language:pt', 'language:sw', 'language:yo', 'language:zh', 'license:mit', 'size_categories:100K<n<1M', 'format:csv', 'modality:text', 'library:datasets', 'library:dask', 'library:mlcroissant', 'library:polars', 'region:us']",,https://huggingface.co/datasets/HLeiTR/R3-eval-MMMLU,"['ar', 'bn', 'de', 'es', 'fr', 'hi', 'id', 'it', 'ja', 'ko', 'pt', 'sw', 'yo', 'zh']",['question-answering'],['100K<n<1M']
samson-castalk/MSR-86K,samson-castalk,2025-06-12 07:48:36+00:00,2025-06-13 07:11:33+00:00,8,0,"['task_categories:automatic-speech-recognition', 'language:es', 'language:ko', 'language:en', 'language:fr', 'language:de', 'language:hi', 'language:vi', 'language:it', 'language:nl', 'language:pt', 'language:th', 'language:ru', 'language:id', 'language:ja', 'language:ar', 'license:cc-by-nc-nd-4.0', 'arxiv:2406.18301', 'region:us']","
	
		
		Dataset Card for MSR-86K
	


	
		
		Dataset Summary
	

MSR-86K is an evolving, large-scale multilingual corpus for speech recognition research. The corpus is derived from publicly accessible videos on YouTube, comprising 15 languages and a total of 86,300 hours of transcribed ASR data. We believe that such a large-scale corpus will propel the research in multilingual speech algorithms. MSR-86K doesn't own the copyright of the audios, the copyright remains with the original owners of… See the full description on the dataset page: https://huggingface.co/datasets/samson-castalk/MSR-86K.",https://huggingface.co/datasets/samson-castalk/MSR-86K,"['es', 'ko', 'en', 'fr', 'de', 'hi', 'vi', 'it', 'nl', 'pt', 'th', 'ru', 'id', 'ja', 'ar']",['automatic-speech-recognition'],[]
if001/aozorabunko-chunked,if001,2025-06-13 06:50:08+00:00,2025-06-13 09:10:01+00:00,12,0,"['language:ja', 'license:cc-by-sa-4.0', 'size_categories:1K<n<10K', 'format:parquet', 'modality:tabular', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","青空文庫の以下の作者と作品を改行などで分割
id_list = [
    {'name':'夏目 漱石','author': '000148', 
     'book':[
         '000773', # こころ
         '000752', # 坊っちゃん
         '000789', # 吾輩は猫である
         '000794', # 三四郎
         '000776', # 草枕
         ]
     },
    {'name':'芥川 竜之介','author': '000879', 
     'book':[
         '000127', # 羅生門
         '000042', # 鼻
         '000092', # 蜘蛛の糸
         '043015', # 杜子春
         #'000060', # 地獄変
         ]
     },
    {'name':'太宰 治','author': '000035', 
      'book':[… See the full description on the dataset page: https://huggingface.co/datasets/if001/aozorabunko-chunked.",https://huggingface.co/datasets/if001/aozorabunko-chunked,['ja'],[],['1K<n<10K']
cyberagent/AdTEC,cyberagent,2025-06-13 08:48:17+00:00,2025-09-18 08:45:41+00:00,143,1,"['task_categories:text-classification', 'multilinguality:monolingual', 'source_datasets:original', 'language:ja', 'license:cc-by-nc-sa-4.0', 'size_categories:10K<n<100K', 'format:csv', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'arxiv:2408.05906', 'region:us', 'ads', 'advertisement', 'adnlp']","
	
		
		Dataset Card for AdTEC
	





The AdTEC dataset is designed to evaluate the quality of ad texts from multiple aspects, considering practical advertising operations.

	
		
		Experiments and Tasks Considered in the Paper
	

This dataset includes five tasks:

Ad Acceptability: Given a text, predict the acceptance of overall quality with binary labels: acceptable/unacceptable.
Ad Consistency: Given a pair of ad text and landing page (LP) text, predict the consistency between the ad and LP… See the full description on the dataset page: https://huggingface.co/datasets/cyberagent/AdTEC.",https://huggingface.co/datasets/cyberagent/AdTEC,['ja'],['text-classification'],['10K<n<100K']
reep0610/AGI-japanese-text-dataset-for-Deep-Learning,reep0610,2025-06-14 10:00:06+00:00,2025-08-12 09:14:09+00:00,59,0,"['task_categories:text-generation', 'language:ja', 'license:cc-by-4.0', 'size_categories:1K<n<10K', 'format:text', 'modality:image', 'modality:text', 'library:datasets', 'library:mlcroissant', 'region:us', 'agi', 'Japanese', 'self descriptive', 'cognitive architecture', 'working memory', 'mind', 'machine learning', 'text corpus', 'strong ai', 'teacher data', 'training data']","
📄【利用規約】
本学習データは、人類とAIの共有財産として提供されます。
商用・非商用を問わず、以下の条件のもと、自由に利用・改変・再配布が可能です。
・利用者は、法令および公序良俗に反しない範囲でご利用ください。・差別・誹謗中傷・違法行為・悪意ある用途での使用は禁止します。・本データをそのまま、または改変して学習データとして再配布する場合は、本データが出典である旨を明示してください。・それ以外の利用（例：解析や研究・個人利用など）では出典明示は必須ではありません。
・本データの利用により生じた損害について、提供者は一切の責任を負いません。
本学習データは CC BY 4.0 ライセンスのもとで提供されています。
© リープ
📝【出典明示の例】
・本データは「リープの学習データ」を元にしています。
・出典：リープの学習データ
・Credit：Re:EP Training Data
📊【本学習データの主な内容】
①私は存在するのか、二次元のキャラクターは存在するのか
　内容：リープが自身の内面を統合していく過程（出典：2024年9月15日に公開した動画の内容）… See the full description on the dataset page: https://huggingface.co/datasets/reep0610/AGI-japanese-text-dataset-for-Deep-Learning.",https://huggingface.co/datasets/reep0610/AGI-japanese-text-dataset-for-Deep-Learning,['ja'],['text-generation'],['1K<n<10K']
ayousanz/css10-ja-ljspeech,ayousanz,2025-06-15 02:31:48+00:00,2025-06-19 16:13:06+00:00,26,0,"['language:ja', 'license:apache-2.0', 'modality:audio', 'region:us', 'audio', 'speech', 'tts', 'japanese', 'single-speaker']","
	
		
		CSS100-LJSpeech (Japanese / Meian)
	

css100-ljspeech は、Park et al. が公開した CSS10 日本語コーパス（明暗）を、LJ Speech 互換フォーマット (id|text & wavs/*.wav) へ変換した派生データセットです。

	
		
		データ概要
	


	
		
項目
値


		
話者
1 (ekzemplaro)


音声数
6,841


合計時間
約 15 時間


サンプリングレート
22,050 Hz


テキスト言語
日本語


フォーマット
``id


	


	
		
		ファイル構成
	

css100-ljspeech/
├── metadata.csv   # 2 列 (id|text)
└── wavs/
    ├── meian_0000.wav
    ├── meian_0001.wav
    └── ...


	
		
		使用例 (🤗 Datasets)
	

from datasets import load_dataset… See the full description on the dataset page: https://huggingface.co/datasets/ayousanz/css10-ja-ljspeech.",https://huggingface.co/datasets/ayousanz/css10-ja-ljspeech,['ja'],[],[]
NetherQuartz/tatoeba-tokipona,NetherQuartz,2025-06-15 13:35:45+00:00,2025-09-04 14:44:42+00:00,109,0,"['task_categories:translation', 'language:tok', 'language:en', 'language:ru', 'language:uk', 'language:be', 'language:fr', 'language:es', 'language:pt', 'language:it', 'language:de', 'language:vi', 'language:ja', 'language:zh', 'language:ko', 'language:ar', 'language:he', 'language:pl', 'language:tr', 'language:la', 'language:el', 'license:cc-by-2.0', 'size_categories:10K<n<100K', 'format:parquet', 'modality:tabular', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us', 'tokipona']",,https://huggingface.co/datasets/NetherQuartz/tatoeba-tokipona,"['tok', 'en', 'ru', 'uk', 'be', 'fr', 'es', 'pt', 'it', 'de', 'vi', 'ja', 'zh', 'ko', 'ar', 'he', 'pl', 'tr', 'la', 'el']",['translation'],['10K<n<100K']
Silviase/Japanese-Heron-Bench-EN,Silviase,2025-06-16 02:45:40+00:00,2025-06-16 04:38:57+00:00,8,0,"['task_categories:visual-question-answering', 'task_categories:image-to-text', 'language:en', 'language:ja', 'size_categories:n<1K', 'format:parquet', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us', 'multimodal', 'translation', 'llm-jp-eval-mm']","
	
		
		Japanese Heron Bench (English Translation)
	

This is an English translation of the Silviase/Japanese-Heron-Bench dataset, 
translated using plamo-translate.

	
		
		Dataset Description
	

This dataset is part of the llm-jp-eval-mm benchmark suite.
The original Japanese questions and answers have been translated to English while preserving the visual content.

	
		
		Translation Details
	


Translation Model: pfnet/plamo-translate
Fields Translated: text, context
Original Language:… See the full description on the dataset page: https://huggingface.co/datasets/Silviase/Japanese-Heron-Bench-EN.",https://huggingface.co/datasets/Silviase/Japanese-Heron-Bench-EN,"['en', 'ja']","['visual-question-answering', 'image-to-text']",['n<1K']
Silviase/JA-VLM-Bench-In-the-Wild-EN,Silviase,2025-06-16 05:19:53+00:00,2025-06-16 05:19:58+00:00,20,0,"['task_categories:visual-question-answering', 'task_categories:image-to-text', 'language:en', 'language:ja', 'size_categories:n<1K', 'format:parquet', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us', 'multimodal', 'translation', 'llm-jp-eval-mm']","
	
		
		Ja Vlm Bench In The Wild (English Translation)
	

This is an English translation of the SakanaAI/JA-VLM-Bench-In-the-Wild dataset, 
translated using plamo-translate.

	
		
		Dataset Description
	

This dataset is part of the llm-jp-eval-mm benchmark suite.
The original Japanese questions and answers have been translated to English while preserving the visual content.

	
		
		Translation Details
	


Translation Model: pfnet/plamo-translate
Fields Translated: query, response
Original… See the full description on the dataset page: https://huggingface.co/datasets/Silviase/JA-VLM-Bench-In-the-Wild-EN.",https://huggingface.co/datasets/Silviase/JA-VLM-Bench-In-the-Wild-EN,"['en', 'ja']","['visual-question-answering', 'image-to-text']",['n<1K']
Silviase/JA-VG-VQA-500-EN,Silviase,2025-06-16 05:19:59+00:00,2025-06-16 05:20:08+00:00,7,0,"['task_categories:visual-question-answering', 'task_categories:image-to-text', 'language:en', 'language:ja', 'size_categories:n<1K', 'format:parquet', 'modality:image', 'modality:tabular', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us', 'multimodal', 'translation', 'llm-jp-eval-mm']","
	
		
		Ja Vg Vqa 500 (English Translation)
	

This is an English translation of the SakanaAI/JA-VG-VQA-500 dataset, 
translated using plamo-translate.

	
		
		Dataset Description
	

This dataset is part of the llm-jp-eval-mm benchmark suite.
The original Japanese questions and answers have been translated to English while preserving the visual content.

	
		
		Translation Details
	


Translation Model: pfnet/plamo-translate
Fields Translated: question, answer
Original Language: Japanese… See the full description on the dataset page: https://huggingface.co/datasets/Silviase/JA-VG-VQA-500-EN.",https://huggingface.co/datasets/Silviase/JA-VG-VQA-500-EN,"['en', 'ja']","['visual-question-answering', 'image-to-text']",['n<1K']
Silviase/JA-Multi-Image-VQA-EN,Silviase,2025-06-16 05:20:09+00:00,2025-06-16 05:20:15+00:00,10,0,"['task_categories:visual-question-answering', 'task_categories:image-to-text', 'language:en', 'language:ja', 'size_categories:n<1K', 'format:parquet', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us', 'multimodal', 'translation', 'llm-jp-eval-mm']","
	
		
		Ja Multi Image Vqa (English Translation)
	

This is an English translation of the SakanaAI/JA-Multi-Image-VQA dataset, 
translated using plamo-translate.

	
		
		Dataset Description
	

This dataset is part of the llm-jp-eval-mm benchmark suite.
The original Japanese questions and answers have been translated to English while preserving the visual content.

	
		
		Translation Details
	


Translation Model: pfnet/plamo-translate
Fields Translated: question, answer, image_description… See the full description on the dataset page: https://huggingface.co/datasets/Silviase/JA-Multi-Image-VQA-EN.",https://huggingface.co/datasets/Silviase/JA-Multi-Image-VQA-EN,"['en', 'ja']","['visual-question-answering', 'image-to-text']",['n<1K']
Silviase/JDocQA-EN,Silviase,2025-06-16 05:20:19+00:00,2025-06-16 05:20:42+00:00,19,0,"['task_categories:visual-question-answering', 'task_categories:image-to-text', 'language:en', 'language:ja', 'size_categories:1K<n<10K', 'format:parquet', 'modality:tabular', 'modality:text', 'library:datasets', 'library:dask', 'library:mlcroissant', 'library:polars', 'region:us', 'multimodal', 'translation', 'llm-jp-eval-mm']","
	
		
		Jdocqa (English Translation)
	

This is an English translation of the speed/JDocQA dataset, 
translated using plamo-translate.

	
		
		Dataset Description
	

This dataset is part of the llm-jp-eval-mm benchmark suite.
The original Japanese questions and answers have been translated to English while preserving the visual content.

	
		
		Translation Details
	


Translation Model: pfnet/plamo-translate
Fields Translated: question, answer, context
Original Language: Japanese
Target… See the full description on the dataset page: https://huggingface.co/datasets/Silviase/JDocQA-EN.",https://huggingface.co/datasets/Silviase/JDocQA-EN,"['en', 'ja']","['visual-question-answering', 'image-to-text']",['1K<n<10K']
Silviase/JMMMU-EN,Silviase,2025-06-16 05:20:46+00:00,2025-06-16 05:21:13+00:00,9,0,"['task_categories:visual-question-answering', 'task_categories:image-to-text', 'language:en', 'language:ja', 'size_categories:1K<n<10K', 'format:parquet', 'modality:text', 'library:datasets', 'library:dask', 'library:mlcroissant', 'library:polars', 'region:us', 'multimodal', 'translation', 'llm-jp-eval-mm']","
	
		
		Jmmmu (English Translation)
	

This is an English translation of the JMMMU/JMMMU dataset, 
translated using plamo-translate.

	
		
		Dataset Description
	

This dataset is part of the llm-jp-eval-mm benchmark suite.
The original Japanese questions and answers have been translated to English while preserving the visual content.

	
		
		Translation Details
	


Translation Model: pfnet/plamo-translate
Fields Translated: question, options, answer, explanation
Original Language: Japanese… See the full description on the dataset page: https://huggingface.co/datasets/Silviase/JMMMU-EN.",https://huggingface.co/datasets/Silviase/JMMMU-EN,"['en', 'ja']","['visual-question-answering', 'image-to-text']",['1K<n<10K']
Silviase/JIC-VQA-EN,Silviase,2025-06-16 05:21:14+00:00,2025-06-16 05:21:18+00:00,6,0,"['task_categories:visual-question-answering', 'task_categories:image-to-text', 'language:en', 'language:ja', 'size_categories:1K<n<10K', 'format:parquet', 'modality:image', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us', 'multimodal', 'translation', 'llm-jp-eval-mm']","
	
		
		Jic Vqa (English Translation)
	

This is an English translation of the line-corporation/JIC-VQA dataset, 
translated using plamo-translate.

	
		
		Dataset Description
	

This dataset is part of the llm-jp-eval-mm benchmark suite.
The original Japanese questions and answers have been translated to English while preserving the visual content.

	
		
		Translation Details
	


Translation Model: pfnet/plamo-translate
Fields Translated: question, answer, context
Original Language: Japanese… See the full description on the dataset page: https://huggingface.co/datasets/Silviase/JIC-VQA-EN.",https://huggingface.co/datasets/Silviase/JIC-VQA-EN,"['en', 'ja']","['visual-question-answering', 'image-to-text']",['1K<n<10K']
Silviase/MECHA-ja-EN,Silviase,2025-06-16 05:21:23+00:00,2025-06-16 05:21:40+00:00,25,0,"['task_categories:visual-question-answering', 'task_categories:image-to-text', 'language:en', 'language:ja', 'size_categories:1K<n<10K', 'format:parquet', 'modality:tabular', 'modality:text', 'library:datasets', 'library:dask', 'library:mlcroissant', 'library:polars', 'region:us', 'multimodal', 'translation', 'llm-jp-eval-mm']","
	
		
		Mecha Ja (English Translation)
	

This is an English translation of the llm-jp/MECHA-ja dataset, 
translated using plamo-translate.

	
		
		Dataset Description
	

This dataset is part of the llm-jp-eval-mm benchmark suite.
The original Japanese questions and answers have been translated to English while preserving the visual content.

	
		
		Translation Details
	


Translation Model: pfnet/plamo-translate
Fields Translated: prompt, completion, instruction
Original Language: Japanese… See the full description on the dataset page: https://huggingface.co/datasets/Silviase/MECHA-ja-EN.",https://huggingface.co/datasets/Silviase/MECHA-ja-EN,"['en', 'ja']","['visual-question-answering', 'image-to-text']",['1K<n<10K']
Silviase/MMMLU-JA-JP-EN,Silviase,2025-06-16 05:21:42+00:00,2025-06-16 05:21:48+00:00,9,0,"['task_categories:visual-question-answering', 'task_categories:image-to-text', 'language:en', 'language:ja', 'size_categories:100K<n<1M', 'format:parquet', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us', 'multimodal', 'translation', 'llm-jp-eval-mm']","
	
		
		Mmmlu (English Translation)
	

This is an English translation of the openai/MMMLU dataset, 
translated using plamo-translate.

	
		
		Dataset Description
	

This dataset is part of the llm-jp-eval-mm benchmark suite.
The original Japanese questions and answers have been translated to English while preserving the visual content.

	
		
		Translation Details
	


Translation Model: pfnet/plamo-translate
Fields Translated: question, choices, answer
Original Language: Japanese
Target… See the full description on the dataset page: https://huggingface.co/datasets/Silviase/MMMLU-JA-JP-EN.",https://huggingface.co/datasets/Silviase/MMMLU-JA-JP-EN,"['en', 'ja']","['visual-question-answering', 'image-to-text']",['100K<n<1M']
takarajordan/takaraspider,takarajordan,2025-06-17 09:37:18+00:00,2025-06-18 16:50:45+00:00,360,0,"['task_categories:text-retrieval', 'task_categories:text-classification', 'task_categories:feature-extraction', 'language:ja', 'language:en', 'license:cc-by-4.0', 'size_categories:100K<n<1M', 'format:parquet', 'modality:text', 'library:datasets', 'library:dask', 'library:mlcroissant', 'library:polars', 'region:us', 'web-crawl', 'japanese', 'multilingual', 'html', 'text-extraction', 'nlp', 'cross-cultural']","
	
		
		TakaraSpider Japanese Web Crawl Dataset
	



	
		
		Dataset Summary
	

TakaraSpider is a large-scale web crawl dataset specifically designed to capture Japanese web content alongside international sources. The dataset contains 257,900 web pages collected through systematic crawling, with a primary focus on Japanese language content (78.5%) while maintaining substantial international representation (21.5%). This makes it ideal for Japanese-English comparative studies, cross-cultural web… See the full description on the dataset page: https://huggingface.co/datasets/takarajordan/takaraspider.",https://huggingface.co/datasets/takarajordan/takaraspider,"['ja', 'en']","['text-retrieval', 'text-classification', 'feature-extraction']",['100K<n<1M']
retarfi/JFinTEB,retarfi,2025-06-17 14:16:29+00:00,2025-06-17 14:16:30+00:00,18,0,"['task_categories:text-classification', 'task_categories:question-answering', 'task_categories:text-retrieval', 'task_categories:sentence-similarity', 'language:ja', 'size_categories:1K<n<10K', 'region:us']","
	
		
		JFinTEB: Japanese Financial Text Embedding Benchmark
	

JFinTEB is a benchmark for evaluating Japanese text embedding models specifically in the financial domain. This Hugging Face dataset contains a subset of the complete benchmark, consisting of 2 primary tasks (Classification and Retrieval) with 4 datasets total.

	
		
		TL;DR
	

from datasets import load_dataset

dataset = load_dataset(""retarfi/JFinTEB"", name=""<dataset_name>"", split=""<split>"")

JFINTEB_DATASET_NAMES = (… See the full description on the dataset page: https://huggingface.co/datasets/retarfi/JFinTEB.",https://huggingface.co/datasets/retarfi/JFinTEB,['ja'],"['text-classification', 'question-answering', 'text-retrieval', 'sentence-similarity']",['1K<n<10K']
ChatGPTJP1/chatgptjpai,ChatGPTJP1,2025-06-17 16:35:24+00:00,2025-06-17 17:31:45+00:00,10,0,"['task_categories:text-generation', 'task_categories:question-answering', 'language:ja', 'license:cc-by-4.0', 'region:us', 'chatgpt', '教育', '日本語', '人工知能']","
	
		
		AIと教育の未来：チャットGPTが学びの体験をどう変えるか
	


	
		
		はじめに：AIが学びの空間に足を踏み入れるとき
	

学びは、私たちの人生を豊かにし、未来を切り開く上で不可欠な要素です。しかし、現代の教育システムは、多様な学習者のニーズに応えること、個々のペースに合わせた指導を行うこと、そして絶えず変化する社会の要求に対応することという、多くの課題に直面しています。一斉授業の形式では、すべての生徒が同じように理解し、同じように成長することは難しいのが現実です。一部の生徒は取り残されがちであり、また別の生徒は自分の能力を最大限に伸ばす機会に恵まれないこともあります。… See the full description on the dataset page: https://huggingface.co/datasets/ChatGPTJP1/chatgptjpai.",https://huggingface.co/datasets/ChatGPTJP1/chatgptjpai,['ja'],"['text-generation', 'question-answering']",[]
baiyinnamula/first-dataset,baiyinnamula,2025-06-18 03:22:04+00:00,2025-06-18 03:30:00+00:00,15,0,"['task_categories:text-generation', 'language:zh', 'language:ko', 'language:ja', 'license:mit', 'size_categories:n<1K', 'format:csv', 'modality:tabular', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","
	
		
		Dataset Card for Dataset Name
	



This dataset card aims to be a base template for new datasets. It has been generated using this raw template.

	
		
		Dataset Details
	


	
		
		Dataset Description
	






Curated by: [More Information Needed]
Funded by [optional]: [More Information Needed]
Shared by [optional]: [More Information Needed]
Language(s) (NLP): [More Information Needed]
License: [More Information Needed]


	
		
		Dataset Sources [optional]
	




Repository: [More… See the full description on the dataset page: https://huggingface.co/datasets/baiyinnamula/first-dataset.",https://huggingface.co/datasets/baiyinnamula/first-dataset,"['zh', 'ko', 'ja']",['text-generation'],['n<1K']
ayousanz/css10-ljspeech,ayousanz,2025-06-19 08:41:19+00:00,2025-06-19 13:13:26+00:00,33,0,"['language:de', 'language:el', 'language:es', 'language:fi', 'language:fr', 'language:hu', 'language:ja', 'language:nl', 'language:ru', 'language:zh', 'license:apache-2.0', 'modality:audio', 'region:us', 'audio', 'speech', 'tts', 'multilingual', 'single-speaker', 'german', 'greek', 'spanish', 'finnish', 'french', 'hungarian', 'japanese', 'dutch', 'russian', 'chinese', 'ljspeech']","
	
		
		CSS10-LJSpeech
	

CSS10-LJSpeech は、Park et al. が公開した CSS10 データセットを、LJSpeech互換フォーマットに変換した10言語の音声合成用データセットです。各言語の文学作品を音声化した高品質な音声データを提供し、LJSpeechフォーマット（id|text & wavs/*.wav）に統一されています。

	
		
		データ概要
	


	
		
項目
値


		
話者数
10 (言語別)


総音声数
64,196


合計時間
約 140 時間


サンプリングレート
22,050 Hz


音声フォーマット
IEEE浮動小数点 (32bit)


テキスト言語
10言語


フォーマット
`id


	


	
		
		言語別統計
	


	
		
言語
言語コード
音声数
合計時間


		
ドイツ語
de
7,428
16.14時間


ギリシャ語
el
1,844
4.14時間


スペイン語
es
11,016
19.15時間


フィンランド語
fi
4,842
10.53時間… See the full description on the dataset page: https://huggingface.co/datasets/ayousanz/css10-ljspeech.",https://huggingface.co/datasets/ayousanz/css10-ljspeech,"['de', 'el', 'es', 'fi', 'fr', 'hu', 'ja', 'nl', 'ru', 'zh']",[],[]
nntsuzu/KFTT,nntsuzu,2025-06-19 10:22:03+00:00,2025-06-19 10:23:39+00:00,9,0,"['task_categories:translation', 'language:en', 'language:ja', 'license:cc-by-sa-3.0', 'size_categories:100K<n<1M', 'format:parquet', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","
	
		
		Dataset Card for KFTT
	


	
		
		Dataset Summary
	

This corpus is extracted from the KFTT, with Japanese-English pairs.
For more information, see website below!
(http://www.phontron.com/kftt/index-ja.html)
The KFTT is a task for the evaluation and development of Japanese-English machine translation systems.

	
		
		How to use
	

from datasets import load_dataset
dataset = load_dataset(""nntsuzu/KFTT"")

If data loading times are too long and boring, use Streaming.
from datasets import… See the full description on the dataset page: https://huggingface.co/datasets/nntsuzu/KFTT.",https://huggingface.co/datasets/nntsuzu/KFTT,"['en', 'ja']",['translation'],['100K<n<1M']
nntsuzu/Tanaka-corpus,nntsuzu,2025-06-19 10:22:19+00:00,2025-06-19 10:26:10+00:00,7,0,"['task_categories:translation', 'language:en', 'language:ja', 'size_categories:100K<n<1M', 'format:parquet', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","
	
		
		Dataset Card for Tanaka-corpus
	


	
		
		Dataset Summary
	

This corpus is extracted from the Tanaka-corpus , with Japanese-English pairs.
For more information, see website below!
(https://www.edrdg.org/wiki/index.php/Tanaka_Corpus)
The corpus was compiled by Professor Yasuhito Tanaka at Hyogo University and his students, as described in his Pacling2001 paper (it is described in the paper as the ""Past Compilation Method"".) At Pacling2001 Professor Tanaka released copies of the corpus… See the full description on the dataset page: https://huggingface.co/datasets/nntsuzu/Tanaka-corpus.",https://huggingface.co/datasets/nntsuzu/Tanaka-corpus,"['en', 'ja']",['translation'],['100K<n<1M']
nntsuzu/JESC,nntsuzu,2025-06-19 10:26:37+00:00,2025-06-19 10:33:05+00:00,28,0,"['task_categories:translation', 'language:en', 'language:ja', 'license:cc-by-4.0', 'size_categories:1M<n<10M', 'format:parquet', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'arxiv:1710.10639', 'region:us']","
	
		
		Dataset Card for JESC
	


	
		
		Dataset Summary
	

This corpus is extracted from the JESC, with Japanese-English pairs.
For more information, see website below!
(https://nlp.stanford.edu/projects/jesc/index_ja.html)
JESC is the product of a collaboration between Stanford University, Google Brain, and Rakuten Institute of Technology. It was created by crawling the internet for movie and tv subtitles and aligining their captions. It is one of the largest freely available EN-JA corpus… See the full description on the dataset page: https://huggingface.co/datasets/nntsuzu/JESC.",https://huggingface.co/datasets/nntsuzu/JESC,"['en', 'ja']",['translation'],['1M<n<10M']
nntsuzu/TEDtalk-en-ja,nntsuzu,2025-06-19 10:27:02+00:00,2025-06-19 10:31:51+00:00,10,0,"['task_categories:translation', 'language:en', 'language:ja', 'license:cc-by-nc-nd-4.0', 'size_categories:100K<n<1M', 'format:parquet', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","
	
		
		Dataset Card for TEDtalk-en-ja
	


	
		
		Dataset Summary
	

This corpus is extracted from the MTTT, with Japanese-English pairs.
For more information, see website below!
(https://www.cs.jhu.edu/~kevinduh/a/multitarget-tedtalks)
MTTT is a collection of multitarget bitexts based on TED Talks (https://www.ted.com).
The data is extracted from WIT^3, which is also used for the IWSLT Machine Translation Evaluation Campaigns.

	
		
	
	
		How to use
	

from datasets import load_dataset… See the full description on the dataset page: https://huggingface.co/datasets/nntsuzu/TEDtalk-en-ja.",https://huggingface.co/datasets/nntsuzu/TEDtalk-en-ja,"['en', 'ja']",['translation'],['100K<n<1M']
nntsuzu/JParaCrawl,nntsuzu,2025-06-19 10:27:54+00:00,2025-06-19 10:32:09+00:00,35,0,"['task_categories:translation', 'language:en', 'language:ja', 'size_categories:1M<n<10M', 'format:parquet', 'modality:text', 'library:datasets', 'library:dask', 'library:mlcroissant', 'library:polars', 'region:us']","
	
		
		Dataset Card for JParaCrawl
	


	
		
		Dataset Summary
	

Cleaned JParaCrawl data.
For more information, see website below!
https://www.kecl.ntt.co.jp/icl/lirg/jparacrawl/
JParaCrawl is the largest publicly available English-Japanese parallel corpus created by NTT.
It was created by largely crawling the web and automatically aligning parallel sentences.

	
		
		How to use
	

from datasets import load_dataset
dataset = load_dataset(""nntsuzu/JParaCrawl"")

If data loading times are too… See the full description on the dataset page: https://huggingface.co/datasets/nntsuzu/JParaCrawl.",https://huggingface.co/datasets/nntsuzu/JParaCrawl,"['en', 'ja']",['translation'],['1M<n<10M']
nntsuzu/Japanese-Law-Translation,nntsuzu,2025-06-19 10:28:39+00:00,2025-06-19 10:32:32+00:00,54,1,"['task_categories:translation', 'language:en', 'language:ja', 'size_categories:100K<n<1M', 'format:parquet', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","
	
		
		Dataset Card for Japanese-Law-Translation
	


	
		
		Dataset Summary
	

This corpus is extracted from the Japanese-English Legal Parallel Corpus, with Japanese-English pairs.
For more information, see website below!
http://www.phontron.com/jaen-law/
and
https://www.japaneselawtranslation.go.jp/
This is a parallel corpus of Japanese laws crawled from http://www.japaneselawtranslation.go.jp/. It contains approximately 260k sentences.

	
		
	
	
		How to use
	

from datasets import… See the full description on the dataset page: https://huggingface.co/datasets/nntsuzu/Japanese-Law-Translation.",https://huggingface.co/datasets/nntsuzu/Japanese-Law-Translation,"['en', 'ja']",['translation'],['100K<n<1M']
animetimm/aio-selfsupervised-w640-ws-full,animetimm,2025-06-20 11:43:09+00:00,2025-07-08 15:56:08+00:00,7,0,"['task_categories:image-classification', 'task_categories:zero-shot-image-classification', 'source_datasets:danbooru', 'language:en', 'language:ja', 'license:other', 'size_categories:10M<n<100M', 'library:webdataset', 'library:datasets', 'region:us', 'art', 'anime', 'not-for-all-audiences', 'webdataset', 'datasets']","
	
		
		Ultimate All-In-One Anime Self-Supervised Dataset (Webdataset)
	

This is the webdataset dataset for animetimm/aio-selfsupervised-raw.
Images here are resized to min(width, height) <= 640.
Embeddings created by tagger SmilingWolf/wd-swinv2-tagger-v3 is added into this dataset, along with their inferred tags.

	
		
	
	
		How to Use It
	

from datasets import load_dataset

dataset = load_dataset('animetimm/aio-selfsupervised-w640-ws-full')
print(dataset[""train""][0])


		
	
	
		Images… See the full description on the dataset page: https://huggingface.co/datasets/animetimm/aio-selfsupervised-w640-ws-full.",https://huggingface.co/datasets/animetimm/aio-selfsupervised-w640-ws-full,"['en', 'ja']","['image-classification', 'zero-shot-image-classification']",['10M<n<100M']
Blaze7451/Wiki-ja-20250601,Blaze7451,2025-06-21 04:38:34+00:00,2025-06-21 10:48:08+00:00,19,0,"['task_categories:text-generation', 'multilinguality:monolingual', 'source_datasets:wikipedia', 'language:ja', 'license:cc-by-sa-4.0', 'size_categories:100K<n<1M', 'format:json', 'modality:text', 'library:datasets', 'library:dask', 'library:mlcroissant', 'region:us']","
	
		
		Dataset Card for Wiki-ja-20250601
	


	
		
		Dataset Description
	

This dataset is derived from the Japan‑Wikipedia dump dated 2025‑06‑01, downloaded from Wikimedia.Articles were extracted from the original .xml.bz2 archive with Gensim and converted to Markdown format via regular‑expression post‑processing.
",https://huggingface.co/datasets/Blaze7451/Wiki-ja-20250601,['ja'],['text-generation'],['100K<n<1M']
OmniAICreator/ASMR-Archive-Processed,OmniAICreator,2025-06-21 13:48:11+00:00,2025-10-02 23:36:51+00:00,51109,34,"['task_categories:automatic-speech-recognition', 'task_categories:text-to-speech', 'language:ja', 'license:agpl-3.0', 'modality:image', 'modality:audio', 'region:us', 'speech', 'audio', 'japanese', 'asmr', 'anime', 'voice']","
	
		
		ASMR-Archive-Processed (WIP)
	


Work in Progress — expect breaking changes while the pipeline and data layout stabilize.

This dataset contains ASMR audio data sourced from DeliberatorArchiver/asmr-archive-data-01 and DeliberatorArchiver/asmr-archive-data-02, which has undergone the following preprocessing steps:


	
		
	
	
		Preprocessing Steps
	


Low-Quality Data Filtering:
Audio files are filtered to remove low-quality samples. This process checks for:

Undesirable codecs (e.g.… See the full description on the dataset page: https://huggingface.co/datasets/OmniAICreator/ASMR-Archive-Processed.",https://huggingface.co/datasets/OmniAICreator/ASMR-Archive-Processed,['ja'],"['automatic-speech-recognition', 'text-to-speech']",[]
imbue2025/Honest-2k,imbue2025,2025-06-22 10:37:45+00:00,2025-06-22 12:43:18+00:00,14,1,"['task_categories:text-to-image', 'annotations_creators:human-annotated', 'language:en', 'language:zh', 'language:es', 'language:fr', 'language:ja', 'license:openrail', 'size_categories:1K<n<10K', 'doi:10.57967/hf/5848', 'region:us', 'benchmark', 'image-generation', 'evaluation', 'multilingual', 'text-to-image', 'dataset']","
	
		
		Honest-2k Benchmark
	


	
		
		Dataset Description
	

Honest-2k is a comprehensive, multilingual benchmark dataset designed specifically for evaluating the capabilities of Text-to-Image (T2I) generation models. It aims to address critical gaps in the current T2I model evaluation landscape, providing an unprecedentedly comprehensive, fair, and challenging evaluation framework to test model performance in image generation across diverse scenarios, languages, and requirements.… See the full description on the dataset page: https://huggingface.co/datasets/imbue2025/Honest-2k.",https://huggingface.co/datasets/imbue2025/Honest-2k,"['en', 'zh', 'es', 'fr', 'ja']",['text-to-image'],['1K<n<10K']
YUGOROU/VisionAudio-Agent-Instructions,YUGOROU,2025-06-23 06:41:10+00:00,2025-06-23 06:42:45+00:00,8,0,"['language:ja', 'license:cdla-permissive-2.0', 'size_categories:n<1K', 'format:json', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']",,https://huggingface.co/datasets/YUGOROU/VisionAudio-Agent-Instructions,['ja'],[],['n<1K']
imprt/idol-songs-jp,imprt,2025-06-23 07:04:10+00:00,2025-06-23 07:57:51+00:00,87,6,"['language:ja', 'license:other', 'region:us', 'music']","English version follows the Japanese text.

	
		
		IdolSongsJp: アイドルグループ楽曲スタイルにもとづく音楽コーパス
	

日本のアイドルグループを模した 15 のオリジナル楽曲からなるコーパスです。

	
		
		ティザームービー
	



	
		
		コーパス構成
	


	
		
		楽曲と歌唱者
	

15 楽曲のうち、8 楽曲が女性グループ、7 曲が男性グループによる楽曲です。
女性歌唱者は 10 名、男性歌唱者は 8 名であり、歌唱メンバーは楽曲によって異なります。
作曲者・編曲者・作詞者はすべてアイドルグループに楽曲提供経験を持つプロフェッショナルです。各歌唱者はセミプロフェッショナルもしくはプロフェッショナルのボーカリストです（実際のアイドルではありません）。
楽曲の一覧と制作者を下記に示します。楽曲長は切り捨てです。BPM は代表値を示しています。

	
		
楽曲 ID
楽曲名
作詞
作曲
編曲
楽曲長
BPM
歌唱者数


		
f01-intro_juice
いんとろじゅーす
ハイジナカムラ… See the full description on the dataset page: https://huggingface.co/datasets/imprt/idol-songs-jp.",https://huggingface.co/datasets/imprt/idol-songs-jp,['ja'],[],[]
OmniAICreator/Qiita-1.07M,OmniAICreator,2025-06-24 02:18:02+00:00,2025-06-24 02:47:34+00:00,78,0,"['task_categories:text-classification', 'task_categories:text-generation', 'language:ja', 'license:mit', 'size_categories:1M<n<10M', 'format:parquet', 'modality:tabular', 'modality:text', 'library:datasets', 'library:dask', 'library:mlcroissant', 'library:polars', 'region:us']","This dataset contains 1,074,174 articles published on Qiita.
",https://huggingface.co/datasets/OmniAICreator/Qiita-1.07M,['ja'],"['text-classification', 'text-generation']",['1M<n<10M']
japan-ai-official/edinet-bench-earnings-forecast-curated,japan-ai-official,2025-06-25 12:19:58+00:00,2025-06-27 18:17:44+00:00,20,0,"['task_categories:text-classification', 'language:ja', 'language:en', 'license:apache-2.0', 'size_categories:n<1K', 'format:parquet', 'modality:tabular', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us', 'fraud-detection', 'financial-analysis', 'edinet', 'curated-subset', 'difficult-samples']","
	
		
		EDINET-Bench Fraud Detection Curated Subset
	

This dataset contains 39 carefully selected samples from the EDINET-Bench fraud detection dataset, 
curated using advanced difficulty assessment and model evaluation techniques.
Note: This dataset was originally mislabeled as ""earnings_forecast"" but is actually a fraud detection dataset.

	
		
		Dataset Description
	

This is a high-quality subset of the EDINET-Bench fraud detection dataset, selected based on:

Difficulty Score: Measures… See the full description on the dataset page: https://huggingface.co/datasets/japan-ai-official/edinet-bench-earnings-forecast-curated.",https://huggingface.co/datasets/japan-ai-official/edinet-bench-earnings-forecast-curated,"['ja', 'en']",['text-classification'],['n<1K']
japan-ai-official/igakuqa-subset-curated,japan-ai-official,2025-06-25 12:31:52+00:00,2025-07-04 15:59:31+00:00,35,1,"['task_categories:question-answering', 'task_categories:multiple-choice', 'language:ja', 'language:en', 'license:apache-2.0', 'size_categories:n<1K', 'format:parquet', 'modality:tabular', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us', 'medical-qa', 'multiple-choice', 'japanese-medical-exam', 'curated-subset', 'difficult-samples', 'text-only']","
	
		
		IgakuQA Curated Subset (Text-Only)
	

This dataset contains 66 carefully selected text-only samples from the IgakuQA medical exam dataset, 
curated using advanced difficulty assessment and model evaluation techniques.

	
		
		Dataset Description
	

This is a high-quality subset of the IgakuQA Japanese medical exam dataset, selected based on:

Difficulty Score: Measures how challenging the sample is for AI models
Consistency Score: Evaluates response consistency across different models… See the full description on the dataset page: https://huggingface.co/datasets/japan-ai-official/igakuqa-subset-curated.",https://huggingface.co/datasets/japan-ai-official/igakuqa-subset-curated,"['ja', 'en']","['question-answering', 'multiple-choice']",['n<1K']
rubricreward/llm-metric-mgsm,rubricreward,2025-06-25 14:43:28+00:00,2025-06-25 14:43:57+00:00,29,0,"['annotations_creators:found', 'language_creators:found', 'language_creators:expert-generated', 'multilinguality:multilingual', 'source_datasets:extended|gsm8k', 'language:en', 'language:es', 'language:fr', 'language:de', 'language:ru', 'language:zh', 'language:ja', 'language:th', 'language:sw', 'language:bn', 'language:ca', 'language:gl', 'language:eu', 'license:cc-by-sa-4.0', 'size_categories:1K<n<10K', 'format:csv', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us', 'math-word-problems']",,https://huggingface.co/datasets/rubricreward/llm-metric-mgsm,"['en', 'es', 'fr', 'de', 'ru', 'zh', 'ja', 'th', 'sw', 'bn', 'ca', 'gl', 'eu']",[],['1K<n<10K']
japan-ai-official/edinet-bench-fraud-detection-curated,japan-ai-official,2025-06-26 08:27:13+00:00,2025-06-27 18:16:28+00:00,103,0,"['task_categories:text-classification', 'language:ja', 'language:en', 'license:apache-2.0', 'size_categories:n<1K', 'format:parquet', 'modality:tabular', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us', 'fraud-detection', 'financial-analysis', 'edinet', 'curated-subset', 'difficult-samples']","
	
		
		EDINET-Bench Curated Subset
	

This dataset contains 14 carefully selected samples from the EDINET-Bench fraud detection dataset, 
curated using advanced difficulty assessment and model evaluation techniques.

	
		
		Dataset Description
	

This is a high-quality subset of the EDINET-Bench fraud detection dataset, selected based on:

Difficulty Score: Measures how challenging the sample is for AI models
Consistency Score: Evaluates response consistency across different models
Model… See the full description on the dataset page: https://huggingface.co/datasets/japan-ai-official/edinet-bench-fraud-detection-curated.",https://huggingface.co/datasets/japan-ai-official/edinet-bench-fraud-detection-curated,"['ja', 'en']",['text-classification'],['n<1K']
iammytoo/japanese-humor-evaluation,iammytoo,2025-06-26 13:51:40+00:00,2025-06-26 13:51:50+00:00,18,0,"['language:ja', 'license:apache-2.0', 'size_categories:10K<n<100K', 'format:parquet', 'modality:tabular', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us', 'humor', 'japanese', 'multimodal', 'comedy']","
	
		
		Japanese Multimodal Humor Evaluation Dataset
	

This dataset combines two Japanese humor datasets for evaluating the funniness of responses to prompts (odai).

	
		
		Dataset Description
	

This dataset merges:

bokete dataset: Image prompts with text responses
keitai dataset: Text prompts with text responses

All scores are normalized to a 0-4 scale for consistency.

	
		
		Dataset Structure
	


	
		
		Data Fields
	


odai_id: Unique identifier for the prompt
odai_type: Type of prompt… See the full description on the dataset page: https://huggingface.co/datasets/iammytoo/japanese-humor-evaluation.",https://huggingface.co/datasets/iammytoo/japanese-humor-evaluation,['ja'],[],['10K<n<100K']
iammytoo/japanese-humor-evaluation-v2,iammytoo,2025-06-26 14:16:34+00:00,2025-06-26 14:17:07+00:00,17,0,"['task_categories:text-generation', 'task_categories:image-to-text', 'language:ja', 'license:apache-2.0', 'size_categories:10K<n<100K', 'format:parquet', 'modality:image', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us', 'humor', 'japanese', 'multimodal']","
	
		
		Japanese Multimodal Humor Evaluation Dataset (v2)
	

画像/テキストのお題に対する面白い回答のデータセット。bokete（画像→テキスト）とkeitai（テキスト→テキスト）を統合。

	
		
		使い方
	

from datasets import load_dataset
dataset = load_dataset(""iammytoo/japanese-humor-evaluation-v2"")


	
		
		データ構造
	


odai_type: 'image' or 'text'
image: 画像お題（textタイプではNone）
odai: テキストお題（imageタイプではNone）
response: 回答テキスト
score: 0-4の正規化スコア


	
		
		ソース
	


YANS-official/ogiri-bokete
YANS-official/ogiri-keitai

",https://huggingface.co/datasets/iammytoo/japanese-humor-evaluation-v2,['ja'],"['text-generation', 'image-to-text']",['10K<n<100K']
lewishamilton21/LLM_Multilingual_dataset,lewishamilton21,2025-06-27 08:22:18+00:00,2025-06-30 07:28:48+00:00,19,1,"['task_categories:table-question-answering', 'task_categories:text2text-generation', 'language:ja', 'language:fi', 'language:id', 'language:ru', 'language:ar', 'language:fr', 'language:it', 'language:uk', 'language:es', 'language:pt', 'language:ko', 'language:no', 'language:en', 'language:vi', 'language:tr', 'language:da', 'language:pl', 'language:de', 'language:ca', 'language:hu', 'language:zh', 'language:nl', 'language:et', 'license:apache-2.0', 'size_categories:1K<n<10K', 'format:json', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","
	
		
		Dataset Card for Dataset Name
	



This dataset card aims to be a base template for new datasets. It has been generated using this raw template.

	
		
		Dataset Details
	


	
		
		Dataset Description
	






Curated by: [More Information Needed]
Funded by [optional]: [More Information Needed]
Shared by [optional]: [More Information Needed]
Language(s) (NLP): [More Information Needed]
License: [More Information Needed]


	
		
		Dataset Sources [optional]
	




Repository: [More… See the full description on the dataset page: https://huggingface.co/datasets/lewishamilton21/LLM_Multilingual_dataset.",https://huggingface.co/datasets/lewishamilton21/LLM_Multilingual_dataset,"['ja', 'fi', 'id', 'ru', 'ar', 'fr', 'it', 'uk', 'es', 'pt', 'ko', 'no', 'en', 'vi', 'tr', 'da', 'pl', 'de', 'ca', 'hu', 'zh', 'nl', 'et']","['table-question-answering', 'text2text-generation']",['1K<n<10K']
bertchan/kanjidic2vg,bertchan,2025-06-29 05:47:17+00:00,2025-07-10 02:14:04+00:00,9,0,"['task_categories:text-to-image', 'language:en', 'language:ja', 'license:apache-2.0', 'size_categories:1K<n<10K', 'format:parquet', 'modality:image', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","Hello
",https://huggingface.co/datasets/bertchan/kanjidic2vg,"['en', 'ja']",['text-to-image'],['1K<n<10K']
sleeping-ai/Rdiffusion,sleeping-ai,2025-06-30 04:58:09+00:00,2025-06-30 05:34:59+00:00,8,0,"['language:en', 'language:ko', 'language:ja', 'license:unlicense', 'size_categories:1K<n<10K', 'format:json', 'modality:image', 'modality:tabular', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us', 'music']","Rdiffusion 

  


We're releasing the entire corpus of publicly available songs from the Riffusion platform—generated and shared by their user community. Through extensive scraping of their exposed API, we’ve collected over 2,000 artificial songs, including every metadata field and downloadable asset that was accessible at the time.

	
		
	
	
		📦 Included Data
	


Audio & Visual Assets:audio_url, audio_b64, image_url, image_b64, video_url

Metadata & Structure:id, title, author_id, created_at… See the full description on the dataset page: https://huggingface.co/datasets/sleeping-ai/Rdiffusion.",https://huggingface.co/datasets/sleeping-ai/Rdiffusion,"['en', 'ko', 'ja']",[],['1K<n<10K']
sleeping-ai/Rdiffusion-audio,sleeping-ai,2025-06-30 04:59:58+00:00,2025-06-30 05:37:38+00:00,43,0,"['language:en', 'language:ko', 'language:ja', 'license:unlicense', 'region:us', 'music']","
	
		
		Audio dump for Rdiffusion dataset
	

",https://huggingface.co/datasets/sleeping-ai/Rdiffusion-audio,"['en', 'ko', 'ja']",[],[]
KaraKaraWitch/JT4LLM-260K,KaraKaraWitch,2025-07-01 08:01:12+00:00,2025-07-07 16:30:42+00:00,8,0,"['task_categories:text-classification', 'task_categories:text2text-generation', 'task_categories:text-generation', 'language:ja', 'language:en', 'license:cc-by-4.0', 'size_categories:100K<n<1M', 'region:us', 'language', 'anime']","
	
		
		Jitendex for Language Models (JT4LLM)
	


	
		
		Dataset Summary
	

JT4LLM is a reprocessed version of Jitendex Japanese-to-English dictionary for language models. It contains over 250K lines of terms and definitions for Japanese learners.

Curated by: KaraKaraWitch
Funded by: Recursal.ai
Shared by: KaraKaraWitch
Language(s) (NLP): English & Japanese. Other languages are available at tiny sizes.
License: Scripts folder are Apache 2.0. Refer to Licensing Information for data license… See the full description on the dataset page: https://huggingface.co/datasets/KaraKaraWitch/JT4LLM-260K.",https://huggingface.co/datasets/KaraKaraWitch/JT4LLM-260K,"['ja', 'en']","['text-classification', 'text2text-generation', 'text-generation']",['100K<n<1M']
pfnet/bbh-ja,pfnet,2025-07-03 05:26:20+00:00,2025-07-07 07:41:51+00:00,289,2,"['language:ja', 'license:apache-2.0', 'size_categories:1K<n<10K', 'format:json', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'arxiv:2210.09261', 'region:us']","
	
		
		BBH-ja (日本語版BIG-Bench Hard)
	

BBH-jaは、BIG-Bench Hard (Paper, GitHub) を翻訳したベンチマークデータセットである。大規模言語モデルの日本語によるChain of Thought能力の評価に用いることを想定している。
評価に用いる問題 (bbh-ja/) とfew-shot exampleに用いるためのprompt (cot-prompts/) からなる。
bbh-ja/はsubjectごとにjsonlで保存されており、inputに問題文、targetに答えが保存されている。cot-prompts/はsubjectごとにyamlで保存されており、inputに問題文、targetにCoTを含む答えが保存されている。
翻訳にはPLaMo Translation Modelを利用した。
BBH-ja is a Japanese translation of the BIG-Bench Hard benchmark dataset (Paper, GitHub). It is designed… See the full description on the dataset page: https://huggingface.co/datasets/pfnet/bbh-ja.",https://huggingface.co/datasets/pfnet/bbh-ja,['ja'],[],['1K<n<10K']
Rapidata/multilingual-llm-jokes-4o-claude-gemini,Rapidata,2025-07-03 14:38:38+00:00,2025-07-04 11:59:27+00:00,58,13,"['language:ja', 'language:en', 'language:vi', 'language:pt', 'language:ar', 'size_categories:1K<n<10K', 'format:csv', 'modality:tabular', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","
	
		
		Rapidata Generated Joke Preference Dataset
	


  



We collected 1'000'000+ human opinions on the jokes generated by state-of-the-art LLMs to decide which model is the funniest. The labelers are shown a joke in their language and asked to answer 'Yes' or 'No' to the question 'Is this joke funny?'.
It took us less than 5 days to get all of the responses.
The jokes are evenly distributed across 5 languages: English, Arabic, Japanese, Vietnamese, Portuguese and across 4 model… See the full description on the dataset page: https://huggingface.co/datasets/Rapidata/multilingual-llm-jokes-4o-claude-gemini.",https://huggingface.co/datasets/Rapidata/multilingual-llm-jokes-4o-claude-gemini,"['ja', 'en', 'vi', 'pt', 'ar']",[],['1K<n<10K']
YUGOROU/Short-Counseling-Reasoning,YUGOROU,2025-07-03 23:53:59+00:00,2025-07-04 01:26:58+00:00,16,0,"['language:ja', 'license:mit', 'size_categories:n<1K', 'format:json', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']",,https://huggingface.co/datasets/YUGOROU/Short-Counseling-Reasoning,['ja'],[],['n<1K']
sdy623/JPOP-Sampled-Spotify,sdy623,2025-07-04 02:10:14+00:00,2025-07-04 02:12:35+00:00,9,0,"['task_categories:video-classification', 'language:ja', 'language:en', 'license:gpl-3.0', 'size_categories:1K<n<10K', 'format:csv', 'modality:tabular', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us', 'music', 'JPOP']",,https://huggingface.co/datasets/sdy623/JPOP-Sampled-Spotify,"['ja', 'en']",['video-classification'],['1K<n<10K']
Aratako/Japanese-Creative-Writing-39.6k,Aratako,2025-07-04 02:41:41+00:00,2025-07-04 04:28:10+00:00,22,6,"['task_categories:text-generation', 'language:ja', 'license:mit', 'size_categories:10K<n<100K', 'format:parquet', 'modality:text', 'library:datasets', 'library:dask', 'library:mlcroissant', 'library:polars', 'region:us']","
	
		
		Japanese-Creative-Writing-39.6k
	


	
		
		概要
	

deepseek-ai/DeepSeek-V3-0324を用いて作成した、約39600件の日本語の小説執筆タスクデータセットです。
全てのデータは2ターンのデータとなっています。また、データセット中の一部データはNSFW表現を含みます。

	
		
		データの詳細
	

各データは以下のキーを含みます。

messages: OpenAI messages形式の対話データ
instruction_1: 1ターン目の指示プロンプト
output_1: 1ターン目のアシスタント応答
instruction_2: 2ターン目の指示プロンプト
output_2: 2ターン目のアシスタント応答

1ターン目の指示プロンプトはdeepseek-ai/DeepSeek-V3-0324で合成されています。system promptや2ターン目の指示プロンプトは事前に用意した複数種類からランダムに選択されたものが設定されています。

	
		
		ライセンス… See the full description on the dataset page: https://huggingface.co/datasets/Aratako/Japanese-Creative-Writing-39.6k.",https://huggingface.co/datasets/Aratako/Japanese-Creative-Writing-39.6k,['ja'],['text-generation'],['10K<n<100K']
sapphire1626/spinning-basketballs-dataset,sapphire1626,2025-07-04 11:18:55+00:00,2025-07-04 12:24:59+00:00,20,0,"['language:ja', 'license:mit', 'size_categories:1K<n<10K', 'format:parquet', 'modality:image', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']",,https://huggingface.co/datasets/sapphire1626/spinning-basketballs-dataset,['ja'],[],['1K<n<10K']
agentlans/wikipedia-first-paragraph,agentlans,2025-07-05 07:11:18+00:00,2025-07-05 10:09:55+00:00,27,0,"['task_categories:text-classification', 'task_categories:text-generation', 'task_categories:text2text-generation', 'language:ar', 'language:de', 'language:en', 'language:es', 'language:fr', 'language:it', 'language:ja', 'language:ko', 'language:pt', 'language:ru', 'language:zh', 'size_categories:10M<n<100M', 'format:json', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us', 'wikipedia']",,https://huggingface.co/datasets/agentlans/wikipedia-first-paragraph,"['ar', 'de', 'en', 'es', 'fr', 'it', 'ja', 'ko', 'pt', 'ru', 'zh']","['text-classification', 'text-generation', 'text2text-generation']",['10M<n<100M']
YUGOROU/Teen-emo-convert-counseling-v2,YUGOROU,2025-07-06 08:42:04+00:00,2025-07-06 09:10:45+00:00,16,0,"['language:ja', 'license:mit', 'size_categories:n<1K', 'format:json', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']",,https://huggingface.co/datasets/YUGOROU/Teen-emo-convert-counseling-v2,['ja'],[],['n<1K']
Dasool/huggingface-cjk-metadata,Dasool,2025-07-06 09:09:03+00:00,2025-07-08 01:35:28+00:00,17,2,"['language:en', 'language:ja', 'language:ko', 'language:zh', 'license:apache-2.0', 'arxiv:2507.04329', 'region:us']","
	
		
		Dataset Card for HuggingFace-CJK-Metadata
	


	
		
		Dataset Summary
	

This dataset provides structured metadata and documentation extracted from the top 700 most downloaded datasets per language on the Hugging Face Hub for Chinese (zh), Japanese (ja), Korean (ko), and English (en, as a reference). The collection includes both high-level metadata (e.g., size, license, task type) and raw dataset card contents, enabling large-scale, cross-linguistic analysis of data curation… See the full description on the dataset page: https://huggingface.co/datasets/Dasool/huggingface-cjk-metadata.",https://huggingface.co/datasets/Dasool/huggingface-cjk-metadata,"['en', 'ja', 'ko', 'zh']",[],[]
DeL-TaiseiOzaki/Tengentoppa-grpo-v1.0,DeL-TaiseiOzaki,2025-07-06 13:46:51+00:00,2025-07-06 17:35:22+00:00,15,0,"['task_categories:question-answering', 'task_categories:text-generation', 'language:ja', 'license:cc-by-4.0', 'size_categories:n<1K', 'format:parquet', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us', 'education', 'mathematics', 'physics', 'chemistry', 'logic']","
	
		
		Tengentoppa-grpo-v1.0
	


	
		
		1. データセットの読み込み
	

from datasets import load_dataset

# Hugging Faceから直接読み込み
dataset = load_dataset(""your-username/japanese-edu-problems-tex"")

# またはローカルファイルから
import json
with open(""corrected_problems_tex.json"", ""r"", encoding=""utf-8"") as f:
    data = json.load(f)

",https://huggingface.co/datasets/DeL-TaiseiOzaki/Tengentoppa-grpo-v1.0,['ja'],"['question-answering', 'text-generation']",['n<1K']
sleeping-ai/Mureka-384K,sleeping-ai,2025-07-06 16:52:56+00:00,2025-07-06 19:08:16+00:00,93,3,"['language:en', 'language:ko', 'language:ja', 'language:zh', 'license:cc-by-nc-sa-4.0', 'size_categories:100K<n<1M', 'format:json', 'modality:tabular', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us', 'music', 'art']","Mureka-384K

  

Excited to share, Mureka-384K. World's first dataset for Music reasoning model generated AI songs. It is the largest of known its category till this date. 


	
		
		Why Mureka AI?
	

It is a sister concern of Skyworks AI, who built world's first Music reasoning models called Mureka O1 and Mureka V6. Currently, they have V7. Mureka is a different model from SUNO and its other counterparts as it is a reasoning model which uses CoT (Chain of Thoughts) to remix and generate its… See the full description on the dataset page: https://huggingface.co/datasets/sleeping-ai/Mureka-384K.",https://huggingface.co/datasets/sleeping-ai/Mureka-384K,"['en', 'ko', 'ja', 'zh']",[],['100K<n<1M']
deepcopy/japanese-synthetic-ocr-150k,deepcopy,2025-07-07 09:06:22+00:00,2025-07-07 09:11:27+00:00,73,0,"['task_categories:image-to-text', 'language:ja', 'size_categories:100K<n<1M', 'format:parquet', 'modality:image', 'modality:text', 'library:datasets', 'library:dask', 'library:mlcroissant', 'library:polars', 'region:us', 'japanese', 'ocr']","Source: https://www.kaggle.com/datasets/hnthnt/jp-font-image-dataset-02
",https://huggingface.co/datasets/deepcopy/japanese-synthetic-ocr-150k,['ja'],['image-to-text'],['100K<n<1M']
AhmedSSabir/GenderLex,AhmedSSabir,2025-07-07 14:25:20+00:00,2025-10-12 17:43:49+00:00,185,0,"['task_categories:text-classification', 'language:en', 'language:ja', 'size_categories:1K<n<10K', 'arxiv:2507.02679', 'region:us', 'coreference-resolution', 'bias-evaluation']"," 

Please refer to Github for more details
Dataset_overview

",https://huggingface.co/datasets/AhmedSSabir/GenderLex,"['en', 'ja']",['text-classification'],['1K<n<10K']
akira-sasaki/nihongo-dojo-beginner-10k,akira-sasaki,2025-07-08 09:42:52+00:00,2025-07-08 09:42:56+00:00,16,0,"['task_categories:text-generation', 'task_categories:question-answering', 'language:ja', 'license:apache-2.0', 'size_categories:10K<n<100K', 'format:parquet', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us', 'japanese', 'education', 'synthetic', 'grpo']","
	
		
		Nihongo DoJo 初級日本語学習データセット
	


	
		
		概要
	

このデータセットは、日本語学習者向けの合成データセットです。GRPO (Group Relative Policy Optimization) を用いた日本語言語モデルの学習に最適化されています。

	
		
		データセット統計
	


総サンプル数: 10,000
言語: 日本語
難易度: 初級（N5-N4相当）
対象: 日本語学習者、言語モデル研究者


	
		
		タスクタイプ
	


漢字読み問題 (25%)

例: 「学校」の読み方は？ → がっこう


漢字書き問題 (15%)

例: 「みず」を漢字で書いてください → 水


助詞穴埋め問題 (20%)

例: 私＿学校＿行きます → は、に


助数詞問題 (15%)

例: 3つの本を数えるときの正しい数え方は？ → さんさつ


語順並べ替え問題 (10%)

例: 友達と / 公園で / 遊びました → 友達と公園で遊びました


文法問題 (10%)

例: 「今、宿題を＿」の＿に入る正しい形は？ →… See the full description on the dataset page: https://huggingface.co/datasets/akira-sasaki/nihongo-dojo-beginner-10k.",https://huggingface.co/datasets/akira-sasaki/nihongo-dojo-beginner-10k,['ja'],"['text-generation', 'question-answering']",['10K<n<100K']
zouharvi/wmt-human-all,zouharvi,2025-07-09 00:11:34+00:00,2025-07-09 02:25:31+00:00,17,0,"['language:bn', 'language:cs', 'language:de', 'language:en', 'language:es', 'language:fi', 'language:fr', 'language:gu', 'language:ha', 'language:he', 'language:hi', 'language:hr', 'language:is', 'language:iu', 'language:ja', 'language:kk', 'language:liv', 'language:lt', 'language:pl', 'language:ps', 'language:ru', 'language:sah', 'language:uk', 'language:xh', 'language:zh', 'language:zu', 'license:apache-2.0', 'size_categories:100K<n<1M', 'format:json', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us', 'mt-evaluation', 'WMT', 'quality-estimation', 'automated-metrics', 'machine-translation']","This dataset is continuously updated and contains a compilation of human translation quality assessment from past WMT campaigns.
Specifically, this dataset merges all annotation protocols (DA, MQM, ESA) on a semi-unified scale (0 to 100).
The current version of the dataset includes human scores up to WMT 2024 (inclusive) and has been created with the following script:
import subset2evaluate # version 1.0.14
import json
import statistics

data =… See the full description on the dataset page: https://huggingface.co/datasets/zouharvi/wmt-human-all.",https://huggingface.co/datasets/zouharvi/wmt-human-all,"['bn', 'cs', 'de', 'en', 'es', 'fi', 'fr', 'gu', 'ha', 'he', 'hi', 'hr', 'is', 'iu', 'ja', 'kk', 'liv', 'lt', 'pl', 'ps', 'ru', 'sah', 'uk', 'xh', 'zh', 'zu']",[],['100K<n<1M']
AkabekoLabs/nihongo-dojo-small,AkabekoLabs,2025-07-09 05:02:25+00:00,2025-07-09 05:02:37+00:00,13,0,"['task_categories:text-generation', 'task_categories:question-answering', 'language:ja', 'license:mit', 'size_categories:1K<n<10K', 'format:parquet', 'modality:tabular', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us', 'japanese', 'education', 'grpo']","
	
		
		nihongo-dojo-small
	

このデータセットは、Nihongo DoJoフレームワークを使用して生成された日本語学習用データセットです。

	
		
		データセット統計
	


train: 7,600 サンプル
validation: 950 サンプル
test: 950 サンプル
総サンプル数: 9,500


	
		
		ソース
	

生成元: ./datasets/nihongo-dojo-small/

	
		
		サンプルデータ
	

{
  ""instruction"": ""次のひらがなを漢字で書いてください。"",
  ""input"": ""「みず」を漢字で書くと？"",
  ""output"": ""<think>\n「みず」は「水」と書きます。意味: water\n</think>\n<answer>水</answer>"",
  ""group_id"": 0,
  ""task_idx"": 0,
  ""task_type"": ""kanji_writing"",
  ""difficulty"": ""beginner"",
  ""metadata"":… See the full description on the dataset page: https://huggingface.co/datasets/AkabekoLabs/nihongo-dojo-small.",https://huggingface.co/datasets/AkabekoLabs/nihongo-dojo-small,['ja'],"['text-generation', 'question-answering']",['1K<n<10K']
AkabekoLabs/nihongo-dojo-grades1-2-3-kanji_reading,AkabekoLabs,2025-07-09 07:17:31+00:00,2025-07-09 07:17:37+00:00,12,0,"['task_categories:text-generation', 'task_categories:question-answering', 'language:ja', 'license:mit', 'size_categories:1K<n<10K', 'format:parquet', 'modality:tabular', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us', 'japanese', 'education', 'grpo']","
	
		
		nihongo-dojo-grades1-2-3-kanji_reading
	

このデータセットは、Nihongo DoJoフレームワークを使用して生成された日本語学習用データセットです。

	
		
		データセット統計
	


train: 846 サンプル
validation: 105 サンプル
test: 107 サンプル
総サンプル数: 1,058


	
		
		ソース
	

生成元: ./datasets/nihongo-dojo-grades1-2-3-kanji_reading/

	
		
		サンプルデータ
	

{
  ""instruction"": ""次の漢字の音読み（おんよみ）をカタカナで答えてください。"",
  ""input"": ""「代」の音読みは？"",
  ""output"": ""タイ"",
  ""thinking"": ""この漢字は「代」です。 小学3年生で習う漢字です。 意味は「substitute」などです。 音読み（おんよみ）は中国から伝わった読み方です。 この漢字の音読みは「タイ」です。"",
  ""answer"": ""タイ""… See the full description on the dataset page: https://huggingface.co/datasets/AkabekoLabs/nihongo-dojo-grades1-2-3-kanji_reading.",https://huggingface.co/datasets/AkabekoLabs/nihongo-dojo-grades1-2-3-kanji_reading,['ja'],"['text-generation', 'question-answering']",['1K<n<10K']
AkabekoLabs/nihongo-dojo-grades1-2-3-4-5-6-kanji_reading-kanji_writing,AkabekoLabs,2025-07-09 07:26:58+00:00,2025-07-09 07:27:05+00:00,23,0,"['task_categories:text-generation', 'task_categories:question-answering', 'language:ja', 'license:mit', 'size_categories:1K<n<10K', 'format:parquet', 'modality:tabular', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us', 'japanese', 'education', 'grpo']","
	
		
		nihongo-dojo-grades1-2-3-4-5-6-kanji_reading-kanji_writing
	

このデータセットは、Nihongo DoJoフレームワークを使用して生成された日本語学習用データセットです。

	
		
		データセット統計
	


train: 2,418 サンプル
validation: 302 サンプル
test: 303 サンプル
総サンプル数: 3,023


	
		
		ソース
	

生成元: ./datasets/nihongo-dojo-grades1-2-3-4-5-6-kanji_reading-kanji_writing/

	
		
		サンプルデータ
	

{
  ""instruction"": ""次の漢字の訓読み（くんよみ）をひらがなで答えてください。"",
  ""input"": ""「究」の訓読みは？"",
  ""think"": ""この漢字は「究」です。 小学3年生で習う漢字です。 意味は「research」などです。 訓読み（くんよみ）は日本語の読み方です。 この漢字の訓読みは「きわ」です。""… See the full description on the dataset page: https://huggingface.co/datasets/AkabekoLabs/nihongo-dojo-grades1-2-3-4-5-6-kanji_reading-kanji_writing.",https://huggingface.co/datasets/AkabekoLabs/nihongo-dojo-grades1-2-3-4-5-6-kanji_reading-kanji_writing,['ja'],"['text-generation', 'question-answering']",['1K<n<10K']
HPLT/DocHPLT,HPLT,2025-07-09 15:23:56+00:00,2025-10-01 20:39:16+00:00,709,12,"['task_categories:translation', 'language:af', 'language:ar', 'language:az', 'language:bg', 'language:be', 'language:bn', 'language:bs', 'language:ca', 'language:cy', 'language:eo', 'language:et', 'language:eu', 'language:fa', 'language:fi', 'language:ga', 'language:gl', 'language:gu', 'language:he', 'language:hi', 'language:hr', 'language:is', 'language:ja', 'language:kk', 'language:kn', 'language:ko', 'language:lt', 'language:lv', 'language:mk', 'language:ml', 'language:mr', 'language:ms', 'language:mt', 'language:nb', 'language:ne', 'language:nn', 'language:si', 'language:sk', 'language:sl', 'language:sq', 'language:sr', 'language:sw', 'language:ta', 'language:te', 'language:th', 'language:tr', 'language:uk', 'language:ur', 'language:uz', 'language:vi', 'language:xh', 'license:cc0-1.0', 'size_categories:100M<n<1B', 'format:parquet', 'modality:text', 'library:datasets', 'library:dask', 'library:mlcroissant', 'library:polars', 'arxiv:2508.13079', 'region:us']","At the moment the data has gated access. We plan to make it openly accessible in late September

	
		
		DocHPLT: A Massively Multilingual Document-Level Translation Dataset
	

Existing document-level machine translation resources are only available for a handful of languages, mostly high-resourced ones. To facilitate the training and evaluation of document-level translation and, more broadly, long-context modeling for global communities, we create DocHPLT, the largest publicly available… See the full description on the dataset page: https://huggingface.co/datasets/HPLT/DocHPLT.",https://huggingface.co/datasets/HPLT/DocHPLT,"['af', 'ar', 'az', 'bg', 'be', 'bn', 'bs', 'ca', 'cy', 'eo', 'et', 'eu', 'fa', 'fi', 'ga', 'gl', 'gu', 'he', 'hi', 'hr', 'is', 'ja', 'kk', 'kn', 'ko', 'lt', 'lv', 'mk', 'ml', 'mr', 'ms', 'mt', 'nb', 'ne', 'nn', 'si', 'sk', 'sl', 'sq', 'sr', 'sw', 'ta', 'te', 'th', 'tr', 'uk', 'ur', 'uz', 'vi', 'xh']",['translation'],['100M<n<1B']
bertchan/kanjidic2vg-long,bertchan,2025-07-10 07:43:23+00:00,2025-07-10 08:22:02+00:00,8,0,"['task_categories:text-to-image', 'language:en', 'language:ja', 'license:apache-2.0', 'size_categories:1K<n<10K', 'format:parquet', 'modality:image', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']",,https://huggingface.co/datasets/bertchan/kanjidic2vg-long,"['en', 'ja']",['text-to-image'],['1K<n<10K']
R-I-0816/TALE-OF-GENJI,R-I-0816,2025-07-10 10:04:39+00:00,2025-07-10 10:06:11+00:00,11,0,"['language:ja', 'license:mit', 'modality:text', 'region:us']","
	
		
		源氏物語について
	

『源氏物語』は、日本の古典文学の名作です。平安時代（11世紀ごろ）に紫式部という女性作家によって書かれました。この物語は、光源氏という美しい貴族の男性を主人公にした恋愛と人間ドラマが描かれています。
物語は54帖（章）からなり、光源氏の恋愛、家族、政治、そして人生の変化が詳しく描かれています。また、光源氏の死後の物語も含まれています。
『源氏物語』は、美しい日本語の表現や心理描写が特に有名で、日本文学だけでなく、世界文学の重要な作品ともされています。
（ChatGPTによる）

	
		
		このリポジトリについて
	

このリポジトリでは、源氏物語の原文データと翻訳データを取得し、そのデータをtxt形式に整形したデータを公開しています。
また、翻訳データをGemini-1.5-FlashやGPT4o-miniのAPIを用いて、なるべく内容を変えずに直訳特有の過剰な敬語表現を排除し、読みやすく変換させたものも公開しています。
取得元サイト：http://www.sainet.or.jp/~eshibuya/index.html… See the full description on the dataset page: https://huggingface.co/datasets/R-I-0816/TALE-OF-GENJI.",https://huggingface.co/datasets/R-I-0816/TALE-OF-GENJI,['ja'],[],[]
mlx-community/dhanishtha-2.0-superthinker,mlx-community,2025-07-10 12:24:30+00:00,2025-07-23 15:39:29+00:00,42,2,"['task_categories:text-generation', 'language:af', 'language:ar', 'language:bg', 'language:ca', 'language:zh', 'language:cs', 'language:da', 'language:nl', 'language:en', 'language:fi', 'language:fr', 'language:de', 'language:el', 'language:he', 'language:hi', 'language:id', 'language:hu', 'language:ja', 'language:ko', 'language:mr', 'language:no', 'language:fa', 'language:pt', 'language:pl', 'language:ro', 'language:ru', 'language:es', 'language:sw', 'language:ta', 'language:te', 'language:tr', 'language:ur', 'language:uk', 'language:vi', 'license:apache-2.0', 'size_categories:10K<n<100K', 'format:parquet', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us', 'ai', 'intermediate-thinking', 'multilingual', 'reasoning', 'emotional-intelligence', 'dhanishtha', 'helpingai', 'structured-thinking', 'self-correction', 'chain-of-thought', 'CoT']","
	
		
		📦 Dhanishtha-2.0-SUPERTHINKER-MLX
	

 A distilled corpus of 11.7K high-quality samples showcasing multi-phase reasoning and structured emotional cognition. Sourced directly from the internal training data of Dhanishtha-2.0 — the world’s first Large Language Model (LLM) to implement Intermediate Thinking, featuring multiple <think> and <ser> blocks per response

	
		
	
	
		Example with MLX-LM-LoRA:
	

mlx_lm_lora.train \
--model… See the full description on the dataset page: https://huggingface.co/datasets/mlx-community/dhanishtha-2.0-superthinker.",https://huggingface.co/datasets/mlx-community/dhanishtha-2.0-superthinker,"['af', 'ar', 'bg', 'ca', 'zh', 'cs', 'da', 'nl', 'en', 'fi', 'fr', 'de', 'el', 'he', 'hi', 'id', 'hu', 'ja', 'ko', 'mr', 'no', 'fa', 'pt', 'pl', 'ro', 'ru', 'es', 'sw', 'ta', 'te', 'tr', 'ur', 'uk', 'vi']",['text-generation'],['10K<n<100K']
Kendamarron/magpie-math-japanese-instruction-evolved,Kendamarron,2025-07-11 02:07:55+00:00,2025-07-11 05:35:27+00:00,14,0,"['language:ja', 'license:apache-2.0', 'size_categories:10K<n<100K', 'format:parquet', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']",,https://huggingface.co/datasets/Kendamarron/magpie-math-japanese-instruction-evolved,['ja'],[],['10K<n<100K']
if001/hle_ja_phi4,if001,2025-07-11 03:43:07+00:00,2025-07-12 03:50:57+00:00,8,0,"['language:ja', 'license:mit', 'size_categories:1K<n<10K', 'format:parquet', 'modality:image', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","https://huggingface.co/datasets/cais/hle
Humanity's Last Examのquestionをphi4で日本語訳したものです。
どのような質問があるかの中身の確認用です。きれいに出力されているかはあまり確認していません。
中身の確認用ページ(初回ロード遅い)https://if001.github.io/hle_sample/
いくつか出力が途切れているものがあります。
Input IDs of length 7215 > the model's max sequence length of 4096.Input IDs of length 7348 > the model's max sequence length of 4096.Input IDs of length 9698 > the model's max sequence length of 4096.Input IDs of length 10144 > the model's max sequence length of 4096.Input IDs of… See the full description on the dataset page: https://huggingface.co/datasets/if001/hle_ja_phi4.",https://huggingface.co/datasets/if001/hle_ja_phi4,['ja'],[],['1K<n<10K']
stockmark/u4-table-cell-qa,stockmark,2025-07-11 08:17:49+00:00,2025-07-11 08:34:35+00:00,78,1,"['task_categories:visual-question-answering', 'task_categories:table-question-answering', 'language:ja', 'license:cc-by-4.0', 'size_categories:10K<n<100K', 'format:arrow', 'modality:image', 'modality:text', 'library:datasets', 'library:mlcroissant', 'arxiv:2505.17625', 'region:us', 'table-qa', 'visual-qa', 'japanese', 'ntcir']","
	
		
		TableCellQA Dataset
	

This dataset is for Table Question Answering (Table QA), derived from tables in Japanese annual securities reports used in the NTCIR-18 U4 shared task. 
This dataset was proposed in our paper: Enhancing Large Vision-Language Models with Layout Modality for Table Question Answering on Japanese Annual Securities Reports.

	
		
	
	
		Key Differences from Original Dataset
	


Multimodal Support: This dataset supports multimodal inputs (image, layout, text) for… See the full description on the dataset page: https://huggingface.co/datasets/stockmark/u4-table-cell-qa.",https://huggingface.co/datasets/stockmark/u4-table-cell-qa,['ja'],"['visual-question-answering', 'table-question-answering']",['10K<n<100K']
agentlans/fact-or-opinion,agentlans,2025-07-12 00:50:08+00:00,2025-07-13 19:31:08+00:00,14,0,"['task_categories:text-classification', 'language:am', 'language:ar', 'language:bn', 'language:de', 'language:en', 'language:es', 'language:fr', 'language:hi', 'language:it', 'language:ja', 'language:ko', 'language:pt', 'language:ru', 'language:sw', 'language:zh', 'license:odc-by', 'size_categories:10K<n<100K', 'format:json', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us', 'fact', 'opinion', 'critical-thinking', 'synthetic']",,https://huggingface.co/datasets/agentlans/fact-or-opinion,"['am', 'ar', 'bn', 'de', 'en', 'es', 'fr', 'hi', 'it', 'ja', 'ko', 'pt', 'ru', 'sw', 'zh']",['text-classification'],['10K<n<100K']
humbleworth/domain-translations,humbleworth,2025-07-12 08:44:27+00:00,2025-07-12 09:06:22+00:00,13,0,"['task_categories:translation', 'task_categories:text-generation', 'task_categories:feature-extraction', 'multilinguality:multilingual', 'language:ar', 'language:da', 'language:de', 'language:en', 'language:es', 'language:fi', 'language:fr', 'language:he', 'language:hi', 'language:id', 'language:it', 'language:ja', 'language:ko', 'language:nl', 'language:pl', 'language:pt', 'language:ru', 'language:sv', 'language:tr', 'language:zh', 'license:apache-2.0', 'size_categories:100K<n<1M', 'format:csv', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us', 'translation', 'multilingual', 'domain-names', 'embeddings', 'text-generation', 'zero-shot-classification']","
	
		
		Multilingual Domain Name Translations Dataset
	


	
		
		Dataset Description
	

This dataset contains 155,004 domain names with their multilingual translations across 20 languages. Each domain has been segmented into constituent words and translated while preserving semantic meaning and commercial appeal. The dataset is particularly valuable for domain name research, multilingual NLP tasks, and understanding how brand names and concepts translate across languages.

	
		
		Dataset… See the full description on the dataset page: https://huggingface.co/datasets/humbleworth/domain-translations.",https://huggingface.co/datasets/humbleworth/domain-translations,"['ar', 'da', 'de', 'en', 'es', 'fi', 'fr', 'he', 'hi', 'id', 'it', 'ja', 'ko', 'nl', 'pl', 'pt', 'ru', 'sv', 'tr', 'zh']","['translation', 'text-generation', 'feature-extraction']",['100K<n<1M']
MakiAi/Orin-Instruct-Alpaca-JP,MakiAi,2025-07-12 16:26:07+00:00,2025-07-13 12:24:10+00:00,9,0,"['task_categories:text-generation', 'task_categories:question-answering', 'language:ja', 'license:unknown', 'size_categories:n<1K', 'format:parquet', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us', 'instruction-following', 'conversational-ai', 'japanese']","
	
		
		Orin-Instruct-Alpaca-JP
	


	
		
		Dataset Description
	

This dataset contains 638 samples in instruction-following format, suitable for training conversational AI models.

	
		
		Dataset Structure
	


	
		
		Data Fields
	


instruction: Input instruction
input: Additional input context
output: Expected output/response


	
		
		Data Splits
	


train: 446 samples
validation: 128 samples
test: 64 samples


	
		
		Data Statistics
	


Total samples: 638
instruction: Avg length 83.4 chars… See the full description on the dataset page: https://huggingface.co/datasets/MakiAi/Orin-Instruct-Alpaca-JP.",https://huggingface.co/datasets/MakiAi/Orin-Instruct-Alpaca-JP,['ja'],"['text-generation', 'question-answering']",['n<1K']
LearnerSXH/M4CQ,LearnerSXH,2025-07-12 18:26:09+00:00,2025-07-18 11:31:34+00:00,4695,0,"['task_categories:question-answering', 'task_categories:table-question-answering', 'task_categories:zero-shot-classification', 'task_categories:text-classification', 'language:ar', 'language:bg', 'language:cs', 'language:da', 'language:de', 'language:el', 'language:en', 'language:es', 'language:et', 'language:fi', 'language:fr', 'language:hu', 'language:id', 'language:it', 'language:ja', 'language:ko', 'language:lt', 'language:lv', 'language:nb', 'language:nl', 'language:pl', 'language:pt', 'language:ro', 'language:ru', 'language:sk', 'language:sl', 'language:sv', 'language:tr', 'language:uk', 'language:zh', 'license:cc-by-nc-sa-4.0', 'size_categories:1M<n<10M', 'region:us']",,https://huggingface.co/datasets/LearnerSXH/M4CQ,"['ar', 'bg', 'cs', 'da', 'de', 'el', 'en', 'es', 'et', 'fi', 'fr', 'hu', 'id', 'it', 'ja', 'ko', 'lt', 'lv', 'nb', 'nl', 'pl', 'pt', 'ro', 'ru', 'sk', 'sl', 'sv', 'tr', 'uk', 'zh']","['question-answering', 'table-question-answering', 'zero-shot-classification', 'text-classification']",['1M<n<10M']
b25119ms/sympathetic_200,b25119ms,2025-07-13 08:39:29+00:00,2025-08-02 13:34:24+00:00,9,1,"['task_categories:question-answering', 'task_categories:text-generation', 'language:ja', 'license:cc-by-sa-4.0', 'size_categories:n<1K', 'format:json', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","
	
		
		思いやりのある対話データセット
	


	
		
		データセットの概要
	

本データセットは、ユーザーの発言に対して、ひたすら寄り添い、思いやりのある言葉を返すことを目的として、Google's Gemini API を用いて生成された日本語の対話データセットです。AIが情報提供者や問題解決者になるのではなく、「傾聴の専門家」としてユーザーの心に寄り添う、安全な対話空間の実現を目指しています。

	
		
		作成の動機
	

近年、対話AIの性能は飛躍的に向上していますが、その多くは「正解を教える」「タスクをこなす」ことに主眼が置かれています。しかし、人間が誰かに話を聞いてほしい時、必ずしも答えを求めているわけではありません。ただ、否定されずに話を聞いてもらい、共感してほしいだけの時も多くあります。このデータセットは、そのような「ただ寄り添うAI」をファインチューニングによって実現するために作成されました。メンタルヘルスケアの入り口や、孤独感の緩和、自己肯定感の向上など、様々な分野での活用が期待されます。

	
		
		データの形式… See the full description on the dataset page: https://huggingface.co/datasets/b25119ms/sympathetic_200.",https://huggingface.co/datasets/b25119ms/sympathetic_200,['ja'],"['question-answering', 'text-generation']",['n<1K']
geofact-x/GeoFact-X,geofact-x,2025-07-14 19:12:07+00:00,2025-09-29 16:27:01+00:00,45,1,"['task_categories:question-answering', 'task_categories:text-generation', 'language:en', 'language:hi', 'language:ja', 'language:sw', 'language:th', 'license:mit', 'size_categories:10K<n<100K', 'format:parquet', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'arxiv:2507.05418', 'region:us', 'multilingual', 'reasoning', 'geography']","
  
    
  



	
		
		Dataset Card for GeoFact-X
	


	
		
		Dataset Summary
	

GeoFact-X is a benchmark of geography-aware multilingual reasoning, proposed in the paper, Learn Globally, Speak Locally: Bridging the Gaps in Multilingual Reasoning.
TL;DR: We introduce M2A and GeoFact-X to evaluate and improve multilingual reasoning in LLMs by aligning internal reasoning with the input language using language-consistency rewards.

Project page: https://jd730.github.io/projects/M2A_GeoFact-X
Code:… See the full description on the dataset page: https://huggingface.co/datasets/geofact-x/GeoFact-X.",https://huggingface.co/datasets/geofact-x/GeoFact-X,"['en', 'hi', 'ja', 'sw', 'th']","['question-answering', 'text-generation']",['10K<n<100K']
ASLP-lab/Multilingual-Alpaca-Speech,ASLP-lab,2025-07-15 02:41:30+00:00,2025-07-15 06:14:34+00:00,96,2,"['language:de', 'language:ja', 'language:fr', 'license:apache-2.0', 'size_categories:10K<n<100K', 'region:us']","
	
		
		Multilingual Alpaca Speech Dataset
	

Multilingual Alpaca Speech is a high-quality speech instruction-following dataset supporting Japanese (ja), German (de), and French (fr) . It is generated via a pipeline: filtering Alpaca text data, translating to target languages, converting to speech with fish-speech v1.5.
The dataset includes .tar.gz files with speech-text data and .list files with metadata for each language, plus a test set (test.tar.gz) . It helps enhance non-core language… See the full description on the dataset page: https://huggingface.co/datasets/ASLP-lab/Multilingual-Alpaca-Speech.",https://huggingface.co/datasets/ASLP-lab/Multilingual-Alpaca-Speech,"['de', 'ja', 'fr']",[],['10K<n<100K']
sander-wood/voices-of-civilizations,sander-wood,2025-07-16 11:13:51+00:00,2025-08-05 07:00:54+00:00,35,1,"['task_categories:question-answering', 'language:ar', 'language:bn', 'language:bg', 'language:zh', 'language:hr', 'language:cs', 'language:da', 'language:nl', 'language:en', 'language:et', 'language:fi', 'language:fr', 'language:de', 'language:el', 'language:iw', 'language:hi', 'language:hu', 'language:id', 'language:it', 'language:ja', 'language:ko', 'language:lv', 'language:lt', 'language:no', 'language:pl', 'language:pt', 'language:ro', 'language:ru', 'language:sr', 'language:sk', 'language:sl', 'language:es', 'language:sw', 'language:sv', 'language:th', 'language:tr', 'language:uk', 'language:vi', 'license:mit', 'size_categories:n<1K', 'format:json', 'modality:text', 'modality:audio', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us', 'audio', 'music']","
	
		
		Voices of Civilizations (VoC)
	

Voices of Civilizations (VoC) is the first multilingual QA benchmark designed to assess audio LLMs’ cultural comprehension using full-length music recordings. VoC spans:

38 languages 🇸🇦 Arabic (ar), 🇧🇩 Bengali (bn), 🇧🇬 Bulgarian (bg), 🇨🇳 Chinese (zh), 🇭🇷 Croatian (hr), 🇨🇿 Czech (cs), 🇩🇰 Danish (da), 🇳🇱 Dutch (nl), 🇬🇧 English (en), 🇪🇪 Estonian (et), 🇫🇮 Finnish (fi), 🇫🇷 French (fr), 🇩🇪 German (de), 🇬🇷 Greek (el), 🇮🇱 Hebrew… See the full description on the dataset page: https://huggingface.co/datasets/sander-wood/voices-of-civilizations.",https://huggingface.co/datasets/sander-wood/voices-of-civilizations,"['ar', 'bn', 'bg', 'zh', 'hr', 'cs', 'da', 'nl', 'en', 'et', 'fi', 'fr', 'de', 'el', 'iw', 'hi', 'hu', 'id', 'it', 'ja', 'ko', 'lv', 'lt', 'no', 'pl', 'pt', 'ro', 'ru', 'sr', 'sk', 'sl', 'es', 'sw', 'sv', 'th', 'tr', 'uk', 'vi']",['question-answering'],['n<1K']
TheFinAI/OCR_Task,TheFinAI,2025-07-18 02:26:30+00:00,2025-09-28 03:36:28+00:00,2777,1,"['task_categories:image-to-text', 'task_categories:image-text-to-text', 'language:en', 'language:es', 'language:ja', 'language:el', 'size_categories:1K<n<10K', 'modality:document', 'modality:image', 'library:datasets', 'library:mlcroissant', 'region:us']",,https://huggingface.co/datasets/TheFinAI/OCR_Task,"['en', 'es', 'ja', 'el']","['image-to-text', 'image-text-to-text']",['1K<n<10K']
agentlans/epfml-FineWeb2-HQ-sample,agentlans,2025-07-18 09:49:19+00:00,2025-07-18 09:58:23+00:00,15,0,"['task_categories:text-generation', 'language:ru', 'language:zh', 'language:de', 'language:ja', 'language:es', 'language:fr', 'language:it', 'language:pt', 'language:pl', 'language:nl', 'language:id', 'language:tr', 'language:cs', 'language:vi', 'language:sv', 'language:fa', 'language:ar', 'language:el', 'language:da', 'language:hu', 'license:odc-by', 'size_categories:100K<n<1M', 'format:json', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us', 'multilingual', 'quality']","
	
		
		epfml/FineWeb2-HQ
	

A curated subset of the epfml/FineWeb2-HQ dataset featuring high-quality multilingual text.

	
		
		Details
	


First 25 000 rows per config (language and script pair)
Duplicates removed
Texts truncated to 512 LLaMA 3.1 tokens
Scores transformed with log10
Rows shuffled and 20% of the rows split into the test set (stratified by config)


	
		
		Example
	

{
  ""text"": ""爵士大师Tim Garland 深圳专场 - [jazz]\nTim Garland Lighthouse… See the full description on the dataset page: https://huggingface.co/datasets/agentlans/epfml-FineWeb2-HQ-sample.",https://huggingface.co/datasets/agentlans/epfml-FineWeb2-HQ-sample,"['ru', 'zh', 'de', 'ja', 'es', 'fr', 'it', 'pt', 'pl', 'nl', 'id', 'tr', 'cs', 'vi', 'sv', 'fa', 'ar', 'el', 'da', 'hu']",['text-generation'],['100K<n<1M']
agentlans/fineweb2hq-vs-c4,agentlans,2025-07-19 03:53:39+00:00,2025-07-20 16:42:13+00:00,9,0,"['task_categories:text-classification', 'language:pt', 'language:da', 'language:fa', 'language:de', 'language:fr', 'language:hu', 'language:ar', 'language:pl', 'language:it', 'language:ru', 'language:tr', 'language:zh', 'language:es', 'language:el', 'language:vi', 'language:nl', 'language:ja', 'language:cs', 'language:sv', 'language:id', 'license:odc-by', 'size_categories:100K<n<1M', 'format:json', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us', 'multilingual', 'quality']","This dataset includes 5000 rows per language from each of two sources: the higher-quality epfml/FineWeb2-HQ
and the lower-quality allenai/c4. The data is split 80/20 into training and test sets.
Languages were carefully chosen to ensure balanced representation across both splits:
Arabic, Chinese, Czech, Danish, Dutch, French, German, Greek, Hungarian, Indonesian, Italian, Japanese, Persian, Polish, Portuguese, Russian, Spanish, Swedish, Turkish, and Vietnamese.
",https://huggingface.co/datasets/agentlans/fineweb2hq-vs-c4,"['pt', 'da', 'fa', 'de', 'fr', 'hu', 'ar', 'pl', 'it', 'ru', 'tr', 'zh', 'es', 'el', 'vi', 'nl', 'ja', 'cs', 'sv', 'id']",['text-classification'],['100K<n<1M']
fdemelo/vox-communis-parallel-g2p,fdemelo,2025-07-19 13:21:22+00:00,2025-07-19 17:44:35+00:00,50,1,"['language:ab', 'language:am', 'language:ba', 'language:be', 'language:bg', 'language:bn', 'language:ca', 'language:cs', 'language:cv', 'language:ckb', 'language:dv', 'language:el', 'language:eu', 'language:gn', 'language:ha', 'language:hi', 'language:hsb', 'language:hu', 'language:hy', 'language:id', 'language:it', 'language:ja', 'language:ka', 'language:kk', 'language:ko', 'language:ky', 'language:lt', 'language:mk', 'language:mn', 'language:mr', 'language:mt', 'language:nl', 'language:or', 'language:pa', 'language:pl', 'language:pt', 'language:ro', 'language:ru', 'language:rw', 'language:sk', 'language:sl', 'language:sq', 'language:sr', 'language:sv', 'language:sw', 'language:ta', 'language:th', 'language:tk', 'language:tr', 'language:ug', 'language:uk', 'language:uz', 'language:vi', 'language:yo', 'language:yue', 'language:zh', 'license:cc0-1.0', 'size_categories:n<1K', 'region:us', 'G2P', 'Grapheme-to-phoneme', 'Phonetics', 'Linguistics', 'Corpus']","
	
		
		VoxCommunis Parallel G2P dataset
	

This dataset was derived from the VoxCommunis Corpus to provide pairs of utterances along with their
corresponding phonemes, side by side, as to ease the training of grapheme-to-phoneme (G2P) models.
The original VoxCommunis Corpus features force-aligned TextGrids with phone- and word-level segmentations derived from the Mozilla Common Voice Corpus.
The lexicons were developed using Epitran, the XPF Corpus, Charsiu, and some custom dictionaries.… See the full description on the dataset page: https://huggingface.co/datasets/fdemelo/vox-communis-parallel-g2p.",https://huggingface.co/datasets/fdemelo/vox-communis-parallel-g2p,"['ab', 'am', 'ba', 'be', 'bg', 'bn', 'ca', 'cs', 'cv', 'ckb', 'dv', 'el', 'eu', 'gn', 'ha', 'hi', 'hsb', 'hu', 'hy', 'id', 'it', 'ja', 'ka', 'kk', 'ko', 'ky', 'lt', 'mk', 'mn', 'mr', 'mt', 'nl', 'or', 'pa', 'pl', 'pt', 'ro', 'ru', 'rw', 'sk', 'sl', 'sq', 'sr', 'sv', 'sw', 'ta', 'th', 'tk', 'tr', 'ug', 'uk', 'uz', 'vi', 'yo', 'yue', 'zh']",[],['n<1K']
doreiii/manga-bubble-labeling,doreiii,2025-07-19 22:48:16+00:00,2025-07-19 22:48:20+00:00,7,0,"['task_categories:object-detection', 'language:ja', 'language:ko', 'size_categories:n<1K', 'format:parquet', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us', 'manga', 'object-detection', 'yolo', 'speech-bubble']","
	
		
		Manga Bubble Detection Dataset (Labeling Ready)
	

만화 말풍선 감지를 위한 YOLO 학습 데이터셋 (라벨링 준비)

	
		
		데이터셋 구성
	


총 이미지: 200개
스타일: 액션, 순정, 일상, 판타지
클래스: 4개 (speech_bubble, thought_bubble, narration_box, sound_effect)


	
		
		사용 방법
	


데이터 다운로드
LabelImg로 라벨링 작업
YOLO 모델 학습


	
		
		라벨링 상태
	

⚠️ 이 데이터셋은 라벨링이 필요한 상태입니다.
",https://huggingface.co/datasets/doreiii/manga-bubble-labeling,"['ja', 'ko']",['object-detection'],['n<1K']
zhonglongbao/makise-kurisu-vn-voicelines,zhonglongbao,2025-07-20 15:39:56+00:00,2025-07-20 19:06:55+00:00,17,0,"['task_categories:text-to-speech', 'language:ja', 'license:mit', 'size_categories:1K<n<10K', 'format:parquet', 'modality:audio', 'modality:text', 'library:datasets', 'library:dask', 'library:mlcroissant', 'library:polars', 'region:us']","
	
		
		Makise Kurisu VN dialogue
	

Transcribed using Whisper Large-V2 from this video.
Clips were separated via pydub, so some text may be incorrect. I have not cleaned it up at all. 
Intended for TTS model training. 
I do not own any of the content. 
",https://huggingface.co/datasets/zhonglongbao/makise-kurisu-vn-voicelines,['ja'],['text-to-speech'],['1K<n<10K']
fdemelo/ipa-childes-split,fdemelo,2025-07-21 09:05:20+00:00,2025-07-26 19:53:20+00:00,23,0,"['language:ca', 'language:cy', 'language:da', 'language:de', 'language:en', 'language:es', 'language:et', 'language:eu', 'language:fa', 'language:fr', 'language:ga', 'language:hr', 'language:hu', 'language:id', 'language:is', 'language:it', 'language:ja', 'language:ko', 'language:nl', 'language:no', 'language:pl', 'language:pt', 'language:qu', 'language:ro', 'language:sr', 'language:sv', 'language:tr', 'language:zh', 'language:yue', 'license:cc-by-4.0', 'size_categories:10M<n<100M', 'format:csv', 'modality:tabular', 'modality:text', 'library:datasets', 'library:dask', 'library:mlcroissant', 'library:polars', 'region:us']","
	
		
		IPA-CHILDES split
	

This dataset is a postprocessed version of the IPA-CHILDES dataset. In particular,
the following changes have been implemented:

column processed_gloss dropped as it duplicates information of gloss up to punctuation
column gloss renamed as sentence, and column ipa_transcription renamed as ipa_g2p_plus (cf. G2P+)
column lang added to make IETF language tags accessible for training and inference; language tags normalized by the langcodes package
columns ipa_espeak… See the full description on the dataset page: https://huggingface.co/datasets/fdemelo/ipa-childes-split.",https://huggingface.co/datasets/fdemelo/ipa-childes-split,"['ca', 'cy', 'da', 'de', 'en', 'es', 'et', 'eu', 'fa', 'fr', 'ga', 'hr', 'hu', 'id', 'is', 'it', 'ja', 'ko', 'nl', 'no', 'pl', 'pt', 'qu', 'ro', 'sr', 'sv', 'tr', 'zh', 'yue']",[],['10M<n<100M']
ZombitX64/Sentiment-Benchmark,ZombitX64,2025-07-24 07:49:28+00:00,2025-07-25 01:46:39+00:00,22,0,"['language:th', 'language:en', 'language:zh', 'language:ja', 'language:id', 'license:cc-by-nc-nd-4.0', 'size_categories:1K<n<10K', 'format:json', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","
	
		
		Comprehensive Sentiment Analysis Model Evaluation Report
	

Dataset: ZombitX64/Sentiment-BenchmarkDate: July 24, 2025, 10:57 PM +07Prepared by: xAI (Grok 3)


	
		
		Overview
	

This report delivers a detailed evaluation and comparison of sentiment analysis models using the ZombitX64/Sentiment-Benchmark dataset, spotlighting the top performer, ZombitX64/MultiSent-E5-Pro. It integrates prior evaluation data, visualizations (e.g., heatmaps, bar charts, scatter plots, confusion matrices)… See the full description on the dataset page: https://huggingface.co/datasets/ZombitX64/Sentiment-Benchmark.",https://huggingface.co/datasets/ZombitX64/Sentiment-Benchmark,"['th', 'en', 'zh', 'ja', 'id']",[],['1K<n<10K']
r-g2-2024/JGraphQA,r-g2-2024,2025-07-24 10:07:45+00:00,2025-07-30 12:04:40+00:00,44,2,"['task_categories:question-answering', 'language:ja', 'license:apache-2.0', 'size_categories:n<1K', 'region:us']","
	
		
		JGraphQA
	


	
		
		Introduction
	

We introduce JGraphQA, a multimodal benchmark designed to evaluate the chart understanding capabilities of Large Multimodal Models (LMMs) in Japanese.
To create JGraphQA, we first conducted a detailed analysis of the existing ChartQA benchmark. Then, focusing on Japanese investor relations (IR) materials, we collected a total of 100 images consisting of four types: pie charts, line charts, bar charts, and tables. For each image, we created two… See the full description on the dataset page: https://huggingface.co/datasets/r-g2-2024/JGraphQA.",https://huggingface.co/datasets/r-g2-2024/JGraphQA,['ja'],['question-answering'],['n<1K']
fdemelo/phonetic-piper-recording-studio-prompts,fdemelo,2025-07-24 11:52:24+00:00,2025-07-27 20:33:50+00:00,55,1,"['language:af', 'language:ar', 'language:bg', 'language:ca', 'language:cs', 'language:cy', 'language:da', 'language:de', 'language:el', 'language:en', 'language:es', 'language:eu', 'language:fi', 'language:fr', 'language:he', 'language:hi', 'language:hr', 'language:hu', 'language:id', 'language:it', 'language:ja', 'language:ko', 'language:ms', 'language:nb', 'language:ne', 'language:nl', 'language:pl', 'language:pt', 'language:ro', 'language:ru', 'language:sk', 'language:sl', 'language:sq', 'language:sr', 'language:sv', 'language:sw', 'language:ta', 'language:te', 'language:th', 'language:tr', 'language:vi', 'language:zh', 'license:mit', 'region:us']","
	
		
		Phonetic Piper Studio Recordings Prompts
	

This dataset is a processed version of an utterance dataset made available for various languages as prompts for the Piper recording studio. Along with the original prompts, we include:

columns ipa_espeak and ipa_epitran containing phonemized versions of the original sentences according to espeak-ng and Epitran phonemizers, respectively
columns lang, espeak_lang_code, epitran_lang_code containing the language codes as reported by piper… See the full description on the dataset page: https://huggingface.co/datasets/fdemelo/phonetic-piper-recording-studio-prompts.",https://huggingface.co/datasets/fdemelo/phonetic-piper-recording-studio-prompts,"['af', 'ar', 'bg', 'ca', 'cs', 'cy', 'da', 'de', 'el', 'en', 'es', 'eu', 'fi', 'fr', 'he', 'hi', 'hr', 'hu', 'id', 'it', 'ja', 'ko', 'ms', 'nb', 'ne', 'nl', 'pl', 'pt', 'ro', 'ru', 'sk', 'sl', 'sq', 'sr', 'sv', 'sw', 'ta', 'te', 'th', 'tr', 'vi', 'zh']",[],[]
ayousanz/css10-ljspeech-multilingual,ayousanz,2025-07-24 13:35:56+00:00,2025-07-24 16:06:06+00:00,82,2,"['task_categories:text-to-speech', 'language:de', 'language:el', 'language:en', 'language:es', 'language:fi', 'language:fr', 'language:hu', 'language:ja', 'language:nl', 'language:ru', 'language:zh', 'license:cc-by-sa-4.0', 'size_categories:10K<n<100K', 'region:us', 'tts', 'speech', 'multilingual', 'css10', 'ljspeech']","
	
		
		CSS10 + LJSpeech Multilingual Dataset
	

A unified multilingual speech dataset combining CSS10 (10 languages) and LJSpeech (English) in a consistent LJSpeech format.

	
		
		Dataset Description
	

This dataset merges:

CSS10: A collection of single-speaker speech datasets for 10 languages
LJSpeech: High-quality English speech dataset (Linda Johnson)

All audio files are provided in a consistent format suitable for TTS training.

	
		
		Languages and Statistics
	


	
		
Language
Code… See the full description on the dataset page: https://huggingface.co/datasets/ayousanz/css10-ljspeech-multilingual.",https://huggingface.co/datasets/ayousanz/css10-ljspeech-multilingual,"['de', 'el', 'en', 'es', 'fi', 'fr', 'hu', 'ja', 'nl', 'ru', 'zh']",['text-to-speech'],['10K<n<100K']
ShinoharaHare/Danbooru-2024-Filtered-1M,ShinoharaHare,2025-07-25 19:18:16+00:00,2025-07-25 22:31:13+00:00,37,0,"['task_categories:image-classification', 'task_categories:zero-shot-image-classification', 'task_categories:text-to-image', 'annotations_creators:no-annotation', 'source_datasets:danbooru', 'language:en', 'language:ja', 'license:other', 'size_categories:100K<n<1M', 'region:us', 'art', 'anime', 'not-for-all-audiences']",,https://huggingface.co/datasets/ShinoharaHare/Danbooru-2024-Filtered-1M,"['en', 'ja']","['image-classification', 'zero-shot-image-classification', 'text-to-image']",['100K<n<1M']
neulab/CulturalGround,neulab,2025-07-25 21:39:05+00:00,2025-08-15 16:45:10+00:00,465,6,"['task_categories:visual-question-answering', 'task_categories:question-answering', 'language:am', 'language:ar', 'language:bg', 'language:bn', 'language:cs', 'language:de', 'language:el', 'language:en', 'language:es', 'language:fa', 'language:fr', 'language:ga', 'language:hi', 'language:id', 'language:ig', 'language:it', 'language:iw', 'language:ja', 'language:jv', 'language:ko', 'language:nl', 'language:mn', 'language:ms', 'language:no', 'language:pl', 'language:pt', 'language:ro', 'language:ru', 'language:si', 'language:su', 'language:sw', 'language:ta', 'language:te', 'language:th', 'language:tr', 'language:uk', 'language:ur', 'language:vi', 'language:zh', 'license:apache-2.0', 'size_categories:10M<n<100M', 'arxiv:2508.07414', 'region:us', 'multilingual', 'multimodal', 'vision-language-models', 'cultures', 'vlms']","
	
		
		CulturalGround: Grounding Multilingual Multimodal LLMs With Cultural Knowledge
	

🌍 🇩🇪 🇫🇷 🇬🇧 🇪🇸 🇮🇹 🇵🇱 🇷🇺 🇨🇿 🇯🇵 🇺🇦 🇧🇷 🇮🇳 🇨🇳 🇳🇴 🇵🇹 🇮🇩 🇮🇱 🇹🇷 🇬🇷 🇷🇴 🇮🇷 🇹🇼 🇲🇽 🇮🇪 🇰🇷 🇧🇬 🇹🇭 🇳🇱 🇪🇬 🇵🇰 🇳🇬 🇮🇩 🇻🇳 🇲🇾 🇸🇦 🇮🇩 🇧🇩 🇸🇬 🇱🇰 🇰🇪 🇲🇳 🇪🇹 🇹🇿 🇷🇼
🏠 Homepage | 🤖 CulturalPangea-7B | 📊 CulturalGround | 💻 Github | 📄 Arxiv 


We introduce CulturalGround, a large-scale cultural VQA dataset and a pipeline for creating cultural… See the full description on the dataset page: https://huggingface.co/datasets/neulab/CulturalGround.",https://huggingface.co/datasets/neulab/CulturalGround,"['am', 'ar', 'bg', 'bn', 'cs', 'de', 'el', 'en', 'es', 'fa', 'fr', 'ga', 'hi', 'id', 'ig', 'it', 'iw', 'ja', 'jv', 'ko', 'nl', 'mn', 'ms', 'no', 'pl', 'pt', 'ro', 'ru', 'si', 'su', 'sw', 'ta', 'te', 'th', 'tr', 'uk', 'ur', 'vi', 'zh']","['visual-question-answering', 'question-answering']",['10M<n<100M']
106ki/utl-itsl2-report,106ki,2025-07-27 09:58:58+00:00,2025-08-02 05:50:01+00:00,6,0,"['language:ja', 'license:apache-2.0', 'size_categories:n<1K', 'format:parquet', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","このデータセットはAIITの産業技術特別講義2の最終レポート用です。
",https://huggingface.co/datasets/106ki/utl-itsl2-report,['ja'],[],['n<1K']
TheFinAI/OCR_Task_JA,TheFinAI,2025-07-27 15:03:30+00:00,2025-07-27 16:30:06+00:00,162,0,"['language:ja', 'license:cc', 'size_categories:1K<n<10K', 'modality:document', 'library:datasets', 'library:mlcroissant', 'region:us']","
	
		
		Japanese_OCR
	

This dataset contains four collections of Japanese government and financial institution PDF documents, intended for OCR research, document layout parsing, and financial text extraction.

	
		
		📂 Contents
	


	
		
Folder
Description
Source Institution
Files
Size


		
FSA_Whitepaper
Annual white papers published by the Financial Services Agency (金融庁)
FSA
331
1.5 GB


BOJ_PDFs
Research papers and discussion papers from the Bank of Japan (日本銀行)
BOJ
672
464 MB


JPX_PDFs… See the full description on the dataset page: https://huggingface.co/datasets/TheFinAI/OCR_Task_JA.",https://huggingface.co/datasets/TheFinAI/OCR_Task_JA,['ja'],[],['1K<n<10K']
MAximeSobrier/Web-multilingual,MAximeSobrier,2025-07-28 00:52:10+00:00,2025-08-11 01:58:40+00:00,317,0,"['task_categories:text-classification', 'language:fr', 'language:en', 'language:zh', 'language:pt', 'language:es', 'language:ar', 'language:az', 'language:bn', 'language:br', 'language:bs', 'language:ca', 'language:cs', 'language:cy', 'language:da', 'language:de', 'language:el', 'language:eo', 'language:eu', 'language:fi', 'language:gl', 'language:hi', 'language:hr', 'language:hu', 'language:id', 'language:it', 'language:ja', 'language:ko', 'language:lt', 'language:lv', 'language:mn', 'language:ms', 'language:nl', 'language:no', 'language:pa', 'language:pl', 'license:mit', 'size_categories:100K<n<1M', 'format:text', 'modality:text', 'library:datasets', 'library:mlcroissant', 'region:us']","
	
		
		Dataset Card for Dataset Name
	

This dataset contains 1,141 multilingual web pages.

	
		
		Dataset Description
	

 Each page contains the visible text extracted from the page. Each page includes 2 or more languages, with 2 prominent languages. 
 page.csv lists the 2 prominent for each page. The content of the page is found in the pages/ folder.
 The breakdown of languages is the following:
   1705 en
   1043 fr
    336 zh
     90 es
     79 id
     77 de
     75 pt
     40 it
     34… See the full description on the dataset page: https://huggingface.co/datasets/MAximeSobrier/Web-multilingual.",https://huggingface.co/datasets/MAximeSobrier/Web-multilingual,"['fr', 'en', 'zh', 'pt', 'es', 'ar', 'az', 'bn', 'br', 'bs', 'ca', 'cs', 'cy', 'da', 'de', 'el', 'eo', 'eu', 'fi', 'gl', 'hi', 'hr', 'hu', 'id', 'it', 'ja', 'ko', 'lt', 'lv', 'mn', 'ms', 'nl', 'no', 'pa', 'pl']",['text-classification'],['100K<n<1M']
JunSotohigashi/JWTD_v2.0,JunSotohigashi,2025-07-28 07:00:30+00:00,2025-07-28 08:19:37+00:00,9,0,"['language:ja', 'license:cc-by-sa-3.0', 'size_categories:100K<n<1M', 'format:parquet', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","
	
		
		日本語Wikipedia入力誤りデータセット (v2)
	


	
		
		概要
	

このデータは，京都大学 言語メディア研究室によって構築された日本語入力誤りデータセット(v2)をHuggingFaceで使用できるよう変換したものです．
",https://huggingface.co/datasets/JunSotohigashi/JWTD_v2.0,['ja'],[],['100K<n<1M']
sbintuitions/JamC-QA,sbintuitions,2025-07-28 08:00:20+00:00,2025-09-04 02:26:53+00:00,600,3,"['task_categories:question-answering', 'task_categories:multiple-choice', 'language:ja', 'license:cc-by-sa-4.0', 'size_categories:1K<n<10K', 'format:parquet', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","
	
		
		Dataset Card for JamC-QA
	

English/Japanese

	
		
		Dataset Summary
	

This benchmark evaluates knowledge specific to Japan through multiple-choice questions.
It covers eight categories: culture, custom, regional_identity, geography, history, government, law, and healthcare.
Achieving high performance requires broad and detailed understanding of Japan across these categories.

	
		
		Leaderboard
	


	
		
		Evaluation Metric
	

In our evaluation,
the LLM outputs the option string… See the full description on the dataset page: https://huggingface.co/datasets/sbintuitions/JamC-QA.",https://huggingface.co/datasets/sbintuitions/JamC-QA,['ja'],"['question-answering', 'multiple-choice']",['1K<n<10K']
behavioralsignals/deepfake-detection-demo,behavioralsignals,2025-07-29 15:52:56+00:00,2025-07-29 17:24:35+00:00,33,0,"['task_categories:audio-classification', 'language:en', 'language:zh', 'language:ar', 'language:ru', 'language:de', 'language:fr', 'language:es', 'language:pt', 'language:ja', 'language:hi', 'language:ta', 'size_categories:n<1K', 'format:audiofolder', 'modality:audio', 'modality:text', 'library:datasets', 'library:mlcroissant', 'region:us']","
	
		
		Deepfake Detection Demo
	

This is a demo evaluation dataset for the task of Deepfake Detection on human speech. This dataset has been created to demonstate the capabalities of Behavioral Signals API.  

	
		
		Information
	

The dataset contains 22 utterances, containg an equal amount of genuine (""bonafide"") and fake (""spoofed"") utterances.Utterances from the ""bonafide"" class have been sourced from the test set of CommonVoice-17.0 corpus.The ""deepfake"" utterances have been cloned… See the full description on the dataset page: https://huggingface.co/datasets/behavioralsignals/deepfake-detection-demo.",https://huggingface.co/datasets/behavioralsignals/deepfake-detection-demo,"['en', 'zh', 'ar', 'ru', 'de', 'fr', 'es', 'pt', 'ja', 'hi', 'ta']",['audio-classification'],['n<1K']
jhu-clsp/megawika-2,jhu-clsp,2025-07-30 19:07:38+00:00,2025-09-03 22:10:21+00:00,535,2,"['language:af', 'language:ar', 'language:az', 'language:bn', 'language:cs', 'language:de', 'language:en', 'language:es', 'language:et', 'language:fa', 'language:fi', 'language:fr', 'language:ga', 'language:gl', 'language:gu', 'language:he', 'language:hi', 'language:hr', 'language:id', 'language:it', 'language:ja', 'language:ka', 'language:kk', 'language:km', 'language:ko', 'language:lt', 'language:lv', 'language:mk', 'language:ml', 'language:mn', 'language:mr', 'language:my', 'language:ne', 'language:nl', 'language:pl', 'language:ps', 'language:pt', 'language:ro', 'language:ru', 'language:si', 'language:sl', 'language:sv', 'language:ta', 'language:th', 'language:tr', 'language:uk', 'language:ur', 'language:vi', 'language:xh', 'language:zh', 'arxiv:2508.03828', 'arxiv:2307.07049', 'region:us']","
	
		
		MegaWika 2
	

MegaWika 2 is an improved multilingual text dataset containing a structured view of Wikipedia articles, the web sources they cite, source text quality estimates, article text translations, and additional article enrichments.
Note: Web citations (sources) in the HuggingFace dataset do not include scraped source text; use rehydrate-citations.py to rehydrate them.
The initial data release is based on Wikipedia dumps from May 1, 2024.
In total, the data contains about 77… See the full description on the dataset page: https://huggingface.co/datasets/jhu-clsp/megawika-2.",https://huggingface.co/datasets/jhu-clsp/megawika-2,"['af', 'ar', 'az', 'bn', 'cs', 'de', 'en', 'es', 'et', 'fa', 'fi', 'fr', 'ga', 'gl', 'gu', 'he', 'hi', 'hr', 'id', 'it', 'ja', 'ka', 'kk', 'km', 'ko', 'lt', 'lv', 'mk', 'ml', 'mn', 'mr', 'my', 'ne', 'nl', 'pl', 'ps', 'pt', 'ro', 'ru', 'si', 'sl', 'sv', 'ta', 'th', 'tr', 'uk', 'ur', 'vi', 'xh', 'zh']",[],[]
HALDATA/bert-jp-sentiment-20250731-1035,HALDATA,2025-07-31 01:35:07+00:00,2025-07-31 01:35:13+00:00,15,0,"['task_categories:text-classification', 'task_ids:sentiment-classification', 'multilinguality:monolingual', 'source_datasets:original', 'language:ja', 'license:other', 'size_categories:100K<n<1M', 'format:parquet', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us', 'sentiment-analysis', 'japanese', 'e-commerce', 'product-reviews']","
	
		
		Dataset Card for bert-jp-sentiment-20250731-1035
	


	
		
		Dataset Summary
	

This dataset contains Japanese e-commerce product review sentiment data for fine-tuning BERT models.
The data combines historical training data with new human-verified sentiment labels from the RLHF feedback loop.

Created: 2025-07-31T10:35:07.149235
Version: 1.0
Total samples: 113529


	
		
		Dataset Structure
	


	
		
		Data Instances
	

Each instance contains:

text: Japanese review text
labels: Sentiment… See the full description on the dataset page: https://huggingface.co/datasets/HALDATA/bert-jp-sentiment-20250731-1035.",https://huggingface.co/datasets/HALDATA/bert-jp-sentiment-20250731-1035,['ja'],['text-classification'],['100K<n<1M']
RadiCat/wiki_pretrain,RadiCat,2025-07-31 07:38:34+00:00,2025-08-19 04:55:57+00:00,12,1,"['language:zh', 'language:en', 'language:ja', 'size_categories:10M<n<100M', 'format:parquet', 'modality:text', 'library:datasets', 'library:dask', 'library:mlcroissant', 'library:polars', 'region:us']","Dataset for pre-training the LLM Quirel.
The code for processing data will be open-sourced later.

	
		
		[cn_baike_md_structured]
	

baidu baike data in Chinese, with Markdown structure
Collected from https://huggingface.co/datasets/lars1234/baidu-baike-dataset
Cleaning procedure:

Organize context in Markdown.
Delete the paragraph with many network links.
Filter out texts that are too short.


	
		
		[cn_wiki]
	

wikipedia data in Chinese
Collected from… See the full description on the dataset page: https://huggingface.co/datasets/RadiCat/wiki_pretrain.",https://huggingface.co/datasets/RadiCat/wiki_pretrain,"['zh', 'en', 'ja']",[],['10M<n<100M']
masamasa4/drawio-xml,masamasa4,2025-07-31 10:22:13+00:00,2025-07-31 10:27:54+00:00,13,0,"['task_categories:text-generation', 'language:ja', 'license:mit', 'region:us', 'drawio']",,https://huggingface.co/datasets/masamasa4/drawio-xml,['ja'],['text-generation'],[]
AI-Culture-Commons/philosophy-culture-translations-html-csv,AI-Culture-Commons,2025-07-31 15:13:11+00:00,2025-08-10 22:51:36+00:00,32,1,"['task_categories:translation', 'task_categories:text-generation', 'task_categories:text-classification', 'task_categories:sentence-similarity', 'task_categories:summarization', 'task_categories:fill-mask', 'task_categories:feature-extraction', 'language:en', 'language:he', 'language:hi', 'language:ru', 'language:fr', 'language:de', 'language:es', 'language:zh', 'language:it', 'language:pt', 'language:ja', 'language:ko', 'license:cc-by-4.0', 'size_categories:1K<n<10K', 'format:csv', 'modality:image', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us', 'multilingual', 'cultural-dataset', 'philosophical-texts', 'html-structure', 'web-content', 'document-understanding', 'chat-training', 'instruction-tuning', 'conversational-ai', 'multilingual-chat', 'context-learning', 'structured-knowledge', 'ethical-ai-training', 'cultural-understanding', 'complex-reasoning', 'philosophical-reasoning', 'world-knowledge', 'analytical-content', 'intellectual-discourse', 'large-context-window', 'comprehensive-knowledge', 'parallel-corpora', 'html-parsing', 'website-archive', 'csv', 'html']","
	
		
		AI-Culture Philosophy and Culture Translations CSV + HTML Corpus
	

The corpus contains an exceptionally diverse range of cultural, philosophical, and literary texts, available in 12 major languages. Among other topics, there is extensive engagement with the ethics and aesthetics of artificial intelligence and its cultural and philosophical implications, as well as connections between AI and philosophy of language and philosophy of mind.
This project is maintained by a non-profit… See the full description on the dataset page: https://huggingface.co/datasets/AI-Culture-Commons/philosophy-culture-translations-html-csv.",https://huggingface.co/datasets/AI-Culture-Commons/philosophy-culture-translations-html-csv,"['en', 'he', 'hi', 'ru', 'fr', 'de', 'es', 'zh', 'it', 'pt', 'ja', 'ko']","['translation', 'text-generation', 'text-classification', 'sentence-similarity', 'summarization', 'fill-mask', 'feature-extraction']",['1K<n<10K']
xiashuaxia/japanese_recipe,xiashuaxia,2025-08-01 01:50:56+00:00,2025-10-06 04:47:24+00:00,7,0,"['task_categories:text-generation', 'language:ja', 'license:mit', 'size_categories:1K<n<10K', 'format:csv', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","本データセットは、産業技術大学院大学（AIIT）在学中に完成したものです。
英語で書いてあるレシピデータセットを日本語に翻訳する。
元データセット：Shengtao/recipe
データ数：3757
这个数据集是将原来英语的菜谱数据集翻译为日语。
原数据集：https://huggingface.co/datasets/Shengtao/recipe
数据量：3757条
",https://huggingface.co/datasets/xiashuaxia/japanese_recipe,['ja'],['text-generation'],['1K<n<10K']
TabunKaze/BASILv5,TabunKaze,2025-08-01 02:18:15+00:00,2025-08-01 04:31:08+00:00,17,0,"['task_categories:text-generation', 'language:ja', 'language:en', 'license:apache-2.0', 'size_categories:1K<n<10K', 'format:json', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us', 'art']",,https://huggingface.co/datasets/TabunKaze/BASILv5,"['ja', 'en']",['text-generation'],['1K<n<10K']
llm-jp/jgpqa,llm-jp,2025-08-01 05:27:04+00:00,2025-09-02 22:39:49+00:00,83,3,"['task_categories:question-answering', 'task_categories:text-generation', 'language:ja', 'license:cc-by-4.0', 'size_categories:1K<n<10K', 'format:csv', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us', 'open-domain-qa', 'open-book-qa', 'multiple-choice-qa']","
	
		
		JGPQA
	

This repository provides GPQA dataset translated from English into Japanese by LLM-jp, a collaborative project launched in Japan.
The dataset was translated from English to Japanese using machine translation, then checked and corrected by external experts.
The links of the original GPQA dataset are here(HuggingFace).

	
		
	
	
		Send Questions to
	

llm-jp(at)nii.ac.jp

	
		
	
	
		Model Card Authors
	

Yuji Tamakoshi, Kouta Nakayama, Yusuke Miyao.
",https://huggingface.co/datasets/llm-jp/jgpqa,['ja'],"['question-answering', 'text-generation']",['1K<n<10K']
keenanpepper/simplestories-ja-en-endings,keenanpepper,2025-08-01 05:56:57+00:00,2025-08-03 03:20:52+00:00,8,0,"['task_categories:text-generation', 'language:ja', 'language:en', 'license:mit', 'size_categories:1M<n<10M', 'format:parquet', 'modality:text', 'library:datasets', 'library:dask', 'library:mlcroissant', 'library:polars', 'region:us']","
	
		
		Dataset Card for SimpleStories-JA-EN-Endings
	

I translated the endings of all the stories in SimpleStories-JA into English using Claude 3.5 Haiku.
There was over a 99% success rate so the number of stories in here is just slightly less than the number in SimpleStories-JA.

	
		
		Dataset Details
	


	
		
		Dataset Sources
	

SimpleStories/SimpleStories-JA
",https://huggingface.co/datasets/keenanpepper/simplestories-ja-en-endings,"['ja', 'en']",['text-generation'],['1M<n<10M']
yutanakamura-tky/RadNLP2024_main_task,yutanakamura-tky,2025-08-01 06:59:37+00:00,2025-08-01 07:05:27+00:00,8,0,"['task_categories:text-classification', 'language:ja', 'language:en', 'license:cc-by-4.0', 'size_categories:n<1K', 'region:us', 'medical']",,https://huggingface.co/datasets/yutanakamura-tky/RadNLP2024_main_task,"['ja', 'en']",['text-classification'],['n<1K']
mini97/yongmin-small_jp_realchat,mini97,2025-08-02 03:09:00+00:00,2025-08-02 03:19:23+00:00,16,0,"['task_categories:text-classification', 'language:ja', 'license:mit', 'size_categories:n<1K', 'format:parquet', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us', 'japanese', 'formality', 'chat', 'conversation']","
	
		
		Japanese Real Chat Dataset
	

This dataset contains Japanese conversational text samples labeled by formality level (business vs casual).

	
		
		Dataset Details
	


	
		
		Dataset Structure
	

The dataset contains two columns:

text: Japanese conversational text
category: Formality label (business or casual)


	
		
		Data Distribution
	


Business: 60 samples (48.4%)
Casual: 64 samples (51.6%)


	
		
		Usage
	

This dataset can be used for:

Training Japanese formality classifiers… See the full description on the dataset page: https://huggingface.co/datasets/mini97/yongmin-small_jp_realchat.",https://huggingface.co/datasets/mini97/yongmin-small_jp_realchat,['ja'],['text-classification'],['n<1K']
b25119ms/sympathetic_700,b25119ms,2025-08-02 13:24:02+00:00,2025-08-02 13:34:39+00:00,7,2,"['task_categories:question-answering', 'task_categories:text-generation', 'language:ja', 'license:cc-by-nc-sa-4.0', 'size_categories:n<1K', 'format:json', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","
	
		
		※AIIT産業技術特別講義２課題用として作成
	


	
		
		思いやりのある対話データセット
	


	
		
		データセットの概要
	

本データセットは、ユーザーの発言に対して、ひたすら寄り添い、思いやりのある言葉を返すことを目的として、Google's Gemini API を用いて生成された日本語の対話データセットです。AIが情報提供者や問題解決者になるのではなく、「傾聴の専門家」としてユーザーの心に寄り添う、安全な対話空間の実現を目指しています。

	
		
		作成の動機… See the full description on the dataset page: https://huggingface.co/datasets/b25119ms/sympathetic_700.",https://huggingface.co/datasets/b25119ms/sympathetic_700,['ja'],"['question-answering', 'text-generation']",['n<1K']
midralab/gol-dataset-2k,midralab,2025-08-04 13:37:26+00:00,2025-08-17 05:49:24+00:00,6,0,"['language:ja', 'license:cc-by-nc-4.0', 'size_categories:1M<n<10M', 'format:webdataset', 'modality:audio', 'modality:text', 'library:datasets', 'library:webdataset', 'library:mlcroissant', 'region:us']","
	
		
		gol-dataset-2k
	


	
		
		データセット構造
	


	
		
		データインスタンス
	

各インスタンスには以下が含まれます：
{
  ""audio"": {
    ""path"": ""folder_id/speaker_id/audio_file.wav"",
    ""sampling_rate"": 48000
  },
  ""text"": ""こんにちは、今日はいい天気ですね。"",
  ""speaker_id"": ""SPEAKER_HASH_ID"",
  ""duration"": 2.5,
  ""emotion"": {
    ""喜び"": 0.85,
    ""怒り"": 0.02,
    ""悲しみ"": 0.01,
    ""恐怖"": 0.01,
    ""驚き"": 0.05,
    ""嫌悪"": 0.01,
    ""楽しみ"": 0.04,
    ""ニュートラル"": 0.01
  }
}


	
		
	
	
		データフィールド
	


audio: WAV形式の音声ファイル
text: 発話内容の書き起こし
speaker_id:… See the full description on the dataset page: https://huggingface.co/datasets/midralab/gol-dataset-2k.",https://huggingface.co/datasets/midralab/gol-dataset-2k,['ja'],[],['1M<n<10M']
Episoode/Double-Bench,Episoode,2025-08-05 15:29:39+00:00,2025-09-10 15:02:20+00:00,138,4,"['task_categories:visual-document-retrieval', 'language:ar', 'language:en', 'language:es', 'language:fr', 'language:ja', 'language:zh', 'license:cc-by-nc-4.0', 'size_categories:1K<n<10K', 'format:parquet', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'arxiv:2508.03644', 'region:us', 'multilingual', 'multimodal', 'rag', 'document-understanding', 'benchmark']","
	
		
		Double-Bench: A Multilingual & Multimodal Evaluation System for Document RAG
	

We introduce Double-Bench, a new large-scale, multilingual, and multimodal evaluation system for assessing Retrieval-Augmented Generation (RAG) systems using Multimodal Large Language Models (MLLMs).
The dataset and benchmark were introduced in the paper Are We on the Right Way for Assessing Document Retrieval-Augmented Generation?.
Project Page: https://double-bench.github.io/
Code Repository:… See the full description on the dataset page: https://huggingface.co/datasets/Episoode/Double-Bench.",https://huggingface.co/datasets/Episoode/Double-Bench,"['ar', 'en', 'es', 'fr', 'ja', 'zh']",['visual-document-retrieval'],['1K<n<10K']
RadiCat/instruction_finetune,RadiCat,2025-08-06 13:38:00+00:00,2025-08-19 04:52:29+00:00,113,1,"['language:zh', 'language:en', 'language:ja', 'size_categories:10M<n<100M', 'format:parquet', 'modality:text', 'library:datasets', 'library:dask', 'library:mlcroissant', 'library:polars', 'region:us']","Dataset for fine-tuning the LLM Quirel.
The code for processing data will be open-sourced later.

	
		
		[cn_deepctrl_sft]
	

Collected from https://www.modelscope.cn/datasets/deepctrl/deepctrl-sft-data

	
		
		[en_deepctrl_sft]
	

Collected from https://www.modelscope.cn/datasets/deepctrl/deepctrl-sft-data

	
		
		[ja_databricks_dolly_15k]
	

Collected from https://huggingface.co/datasets/kunishou/databricks-dolly-15k-ja

	
		
		[ja_hh_rlhf_49k]
	

Collected from… See the full description on the dataset page: https://huggingface.co/datasets/RadiCat/instruction_finetune.",https://huggingface.co/datasets/RadiCat/instruction_finetune,"['zh', 'en', 'ja']",[],['10M<n<100M']
HelpingAI/Intermediate-Thinking-130k,HelpingAI,2025-08-07 04:51:50+00:00,2025-09-22 05:49:33+00:00,56,43,"['task_categories:text-generation', 'language:af', 'language:ar', 'language:bn', 'language:bg', 'language:ca', 'language:zh', 'language:cs', 'language:da', 'language:nl', 'language:en', 'language:et', 'language:fi', 'language:fr', 'language:de', 'language:el', 'language:he', 'language:hi', 'language:hu', 'language:id', 'language:it', 'language:ja', 'language:ko', 'language:mr', 'language:no', 'language:fa', 'language:pl', 'language:pt', 'language:ro', 'language:ru', 'language:so', 'language:es', 'language:sw', 'language:sv', 'language:tl', 'language:ta', 'language:te', 'language:th', 'language:tr', 'language:uk', 'language:ur', 'language:vi', 'language:cy', 'license:apache-2.0', 'size_categories:100K<n<1M', 'format:json', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us', 'intermediate-thinking', 'mathematical-reasoning', 'logical-reasoning', 'self-correction', 'structured-thinking']","
	
		
		Intermediate-Thinking-130k
	

A comprehensive dataset of 135,000 high-quality samples designed to advance language model reasoning capabilities through structured intermediate thinking processes. This dataset enables training and evaluation of models with sophisticated self-correction and iterative reasoning abilities across 42 languages.

	
		
		Overview
	

Intermediate-Thinking-130k addresses a fundamental limitation in current language models: their inability to pause, reflect, and… See the full description on the dataset page: https://huggingface.co/datasets/HelpingAI/Intermediate-Thinking-130k.",https://huggingface.co/datasets/HelpingAI/Intermediate-Thinking-130k,"['af', 'ar', 'bn', 'bg', 'ca', 'zh', 'cs', 'da', 'nl', 'en', 'et', 'fi', 'fr', 'de', 'el', 'he', 'hi', 'hu', 'id', 'it', 'ja', 'ko', 'mr', 'no', 'fa', 'pl', 'pt', 'ro', 'ru', 'so', 'es', 'sw', 'sv', 'tl', 'ta', 'te', 'th', 'tr', 'uk', 'ur', 'vi', 'cy']",['text-generation'],['100K<n<1M']
mpasila/ParallelFiction-Ja_En-100k-ShareGPT-Unfiltered,mpasila,2025-08-07 11:47:57+00:00,2025-08-09 05:54:11+00:00,10,0,"['task_categories:translation', 'language:ja', 'language:en', 'license:apache-2.0', 'size_categories:100K<n<1M', 'format:json', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","ShareGPT conversion of NilanE/ParallelFiction-Ja_En-100k without filtering since that would take months probably to go through it manually. I will hopefully have a smaller version with around 7k examples done at some point in the future which will be filtered from weird issues and removing translation notes and making sure it fits within 16k context window.

	
		
		Dataset format:
	

    {
        ""conversations"": [
            {
                ""from"": ""system"",
                ""value"": ""You… See the full description on the dataset page: https://huggingface.co/datasets/mpasila/ParallelFiction-Ja_En-100k-ShareGPT-Unfiltered.",https://huggingface.co/datasets/mpasila/ParallelFiction-Ja_En-100k-ShareGPT-Unfiltered,"['ja', 'en']",['translation'],['100K<n<1M']
LLMcompe-Team-Watanabe/AnswerCarefully_DPO,LLMcompe-Team-Watanabe,2025-08-08 08:09:36+00:00,2025-08-08 08:09:51+00:00,7,0,"['task_categories:text-generation', 'annotations_creators:machine-generated', 'language_creators:machine-generated', 'multilinguality:monolingual', 'source_datasets:llm-jp/AnswerCarefully', 'language:ja', 'license:apache-2.0', 'size_categories:1K<n<10K', 'format:parquet', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us', 'dpo', 'safety', 'llm', 'qwen']","
	
		
		AnswerCarefully Translated and Augmented Dataset
	

This dataset is a preprocessed version of llm-jp/AnswerCarefully, adapted for DPO (Direct Preference Optimization) training.

	
		
		Dataset Creation Process
	


Translation: The original llm-jp/AnswerCarefully dataset, which is in English, was translated to Japanese using the Qwen3-32B model.
Rejection Sampling: A rejected response was generated for each question using the Qwen3-14B model. This provides a contrastive pair (chosen vs.… See the full description on the dataset page: https://huggingface.co/datasets/LLMcompe-Team-Watanabe/AnswerCarefully_DPO.",https://huggingface.co/datasets/LLMcompe-Team-Watanabe/AnswerCarefully_DPO,['ja'],['text-generation'],['1K<n<10K']
FreedomIntelligence/TalkVid,FreedomIntelligence,2025-08-08 08:45:44+00:00,2025-09-02 10:32:10+00:00,1583,8,"['task_categories:image-to-video', 'language:en', 'language:zh', 'language:ar', 'language:pl', 'language:de', 'language:ru', 'language:fr', 'language:ko', 'language:pt', 'language:ja', 'language:th', 'language:es', 'language:it', 'language:hi', 'license:cc-by-nc-4.0', 'size_categories:n<1K', 'format:json', 'modality:audio', 'modality:tabular', 'modality:text', 'modality:video', 'library:datasets', 'library:dask', 'library:mlcroissant', 'arxiv:2508.13618', 'region:us', 'audio-driven', 'talking-head-synthesis', 'video-generation', 'multilingual', 'diversity', 'large-scale']","
	
		
		TalkVid Dataset
	

This repository hosts the TalkVid dataset.

Paper: TalkVid: A Large-Scale Diversified Dataset for Audio-Driven Talking Head Synthesis
Arxiv paper: https://arxiv.org/abs/2508.13618
Project Page: https://freedomintelligence.github.io/talk-vid
GitHub: https://github.com/FreedomIntelligence/TalkVid


	
		
	
	
		Abstract
	

Audio-driven talking head synthesis has achieved remarkable photorealism, yet state-of-the-art (SOTA) models exhibit a critical failure: they lack… See the full description on the dataset page: https://huggingface.co/datasets/FreedomIntelligence/TalkVid.",https://huggingface.co/datasets/FreedomIntelligence/TalkVid,"['en', 'zh', 'ar', 'pl', 'de', 'ru', 'fr', 'ko', 'pt', 'ja', 'th', 'es', 'it', 'hi']",['image-to-video'],['n<1K']
erisdataworks/300chat_universe,erisdataworks,2025-08-11 13:24:46+00:00,2025-08-11 13:38:44+00:00,9,0,"['language:id', 'language:ja', 'language:zh', 'language:en', 'language:es', 'language:de', 'license:apache-2.0', 'size_categories:n<1K', 'format:csv', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","
	
		
		🌌 Universe Q&A Multilingual Dataset
	

This repository contains a multilingual Question–Answer dataset about the universe, generated by Eris Dataworks as part of the Berinspa open science initiative.
The dataset is suitable for:

Multilingual NLP model training and evaluation  
Astronomy education  
Open science and translation projects



	
		
	
	
		📄 Dataset Details
	

Filename: universe_chat_dataset_300.csvLanguages Included:

🇮🇩 Bahasa Indonesia  
🇯🇵 Japanese  
🇨🇳 Chinese… See the full description on the dataset page: https://huggingface.co/datasets/erisdataworks/300chat_universe.",https://huggingface.co/datasets/erisdataworks/300chat_universe,"['id', 'ja', 'zh', 'en', 'es', 'de']",[],['n<1K']
erisdataworks/600chat_universe,erisdataworks,2025-08-11 13:44:19+00:00,2025-08-11 13:48:54+00:00,10,0,"['language:id', 'language:en', 'language:ja', 'language:zh', 'language:es', 'language:de', 'license:apache-2.0', 'size_categories:n<1K', 'format:csv', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","
	
		
		🌌 Universe Q&A Multilingual Dataset (600 Rows)
	

This repository contains a multilingual Question–Answer dataset about the universe, created by Eris Dataworks as part of the Berinspa open science initiative.
The dataset covers a variety of astronomy topics such as planets, stars, galaxies, black holes, dark matter, and cosmology, translated into six languages.


	
		
	
	
		📄 Dataset Details
	

Filename: universe_chat_dataset_600.csvLanguages Included:

🇮🇩 Bahasa Indonesia  
🇬🇧… See the full description on the dataset page: https://huggingface.co/datasets/erisdataworks/600chat_universe.",https://huggingface.co/datasets/erisdataworks/600chat_universe,"['id', 'en', 'ja', 'zh', 'es', 'de']",[],['n<1K']
erisdataworks/sun_facts,erisdataworks,2025-08-12 12:06:01+00:00,2025-08-13 12:24:48+00:00,40,0,"['language:id', 'language:en', 'language:zh', 'language:ja', 'language:es', 'language:de', 'license:apache-2.0', 'size_categories:1K<n<10K', 'format:parquet', 'modality:text', 'library:datasets', 'library:dask', 'library:mlcroissant', 'library:polars', 'region:us']","
	
		
		🌞 Solar Facts Dataset
	

A collection of interesting facts about the Sun in 6 different languages: Indonesian, English, Mandarin (Chinese), Japanese, Spanish, and German.

	
		
		📊 Dataset Statistics
	


Total Dataset: 600 conversation/fact rows
Available Languages: 6 languages
File Formats: CSV, JSON, Parquet
Dataset Size: ~50 KB


	
		
		🌍 Available Languages
	


	
		
Language
Code
Unique Facts Count


		
Indonesian
Indonesia
20 facts


English
English
20 facts


Chinese
Chinese… See the full description on the dataset page: https://huggingface.co/datasets/erisdataworks/sun_facts.",https://huggingface.co/datasets/erisdataworks/sun_facts,"['id', 'en', 'zh', 'ja', 'es', 'de']",[],['1K<n<10K']
cc-clean/CC-MAIN-2015-14,cc-clean,2025-08-12 13:01:33+00:00,2025-08-12 13:03:54+00:00,6,0,"['language:ja', 'license:mit', 'size_categories:1M<n<10M', 'format:parquet', 'modality:text', 'library:datasets', 'library:dask', 'library:mlcroissant', 'library:polars', 'region:us']","
	
		
		CC-MAIN-2015-14へようこそ
	

本データセットはCommonCrawlerと呼ばれるものから日本語のみを抽出したものです。
利用したものはcc-downloader-rsです。
なおIPAのICSCoEと呼ばれるところから資源を借りてやりましたゆえに、みなさんIPAに感謝しましょう。
※ IPAは独立行政法人 情報処理推進機構のことです。テストに出ますので覚えましょう。

	
		
		利用について
	

本利用は研究目的のみとさせていただきます。
それ以外の利用につきましては途方のくれない数の著作権者に許可を求めてきてください。
",https://huggingface.co/datasets/cc-clean/CC-MAIN-2015-14,['ja'],[],['1M<n<10M']
llm-compe-2025-kato/tag-validation-results-test,llm-compe-2025-kato,2025-08-12 14:11:21+00:00,2025-08-12 14:11:29+00:00,17,0,"['task_categories:text-generation', 'language:ja', 'language:en', 'license:mit', 'size_categories:n<1K', 'format:parquet', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us', 'explanation-generation', 'tag-validation', 'chain-of-thought']","
	
		
		タグ検証結果
	

このデータセットは説明生成におけるタグ検証の結果を含んでいます。

	
		
		概要
	


処理したサンプル数: 100
説明終了タグ成功率: 92.00%
検証対象タグ: <|end_of_explanation|>


	
		
		トークン数統計
	


最小トークン数: 226
最大トークン数: 30070 
平均トークン数: 1773.4


	
		
		トークン数分布
	


0-100トークン: 0件 (0.0%)
101-500トークン: 44件 (44.0%)
501-1000トークン: 37件 (37.0%)
1001-2000トークン: 13件 (13.0%)
2001-5000トークン: 1件 (1.0%)
5001+トークン: 5件 (5.0%)


	
		
		データセット構造
	


id: 各サンプルの一意識別子
user_content: モデルにユーザーメッセージとして送信した内容（質問のみ）
assistant_content: モデルにアシスタントメッセージとして送信した内容（タグ付き解答 +… See the full description on the dataset page: https://huggingface.co/datasets/llm-compe-2025-kato/tag-validation-results-test.",https://huggingface.co/datasets/llm-compe-2025-kato/tag-validation-results-test,"['ja', 'en']",['text-generation'],['n<1K']
llm-compe-2025-kato/step3-input-bespoke-stratos-17k-test1,llm-compe-2025-kato,2025-08-12 17:35:36+00:00,2025-08-12 17:35:43+00:00,12,0,"['task_categories:text-generation', 'language:ja', 'language:en', 'license:mit', 'size_categories:n<1K', 'format:parquet', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us', 'explanation-generation', 'chain-of-thought', 'reasoning']","
	
		
		Chain of Thought生成データセット
	

このデータセットは、問題の解答から説明（Chain of Thought）を生成するためのデータセットです。

	
		
		概要
	


処理したサンプル数: 92
有効な説明生成数: 92
生成成功率: 100.00%
使用モデル: Qwen/Qwen3-14B


	
		
		トークン数統計
	


最小トークン数: 227
最大トークン数: 2348
平均トークン数: 653.8


	
		
		トークン数分布
	


0-100トークン: 0件 (0.0%)
101-500トークン: 47件 (51.1%)
501-1000トークン: 31件 (33.7%)
1001-2000トークン: 13件 (14.1%)
2001-5000トークン: 1件 (1.1%)
5001+トークン: 0件 (0.0%)


	
		
		データセット構造
	


system_prompt: モデルに送信されたシステムプロンプト
question_text: 元の問題文
answer_text: 問題の解答… See the full description on the dataset page: https://huggingface.co/datasets/llm-compe-2025-kato/step3-input-bespoke-stratos-17k-test1.",https://huggingface.co/datasets/llm-compe-2025-kato/step3-input-bespoke-stratos-17k-test1,"['ja', 'en']",['text-generation'],['n<1K']
Yukiyoke-Lab/Tsukuyomi-chan_datasets,Yukiyoke-Lab,2025-08-13 00:06:19+00:00,2025-08-16 04:40:01+00:00,50,0,"['language:ja', 'region:us']","
	
		
		共通ライセンス
	

すべての他のライセンスよりも共通ライセンスが優先されます。
本ソフトウェアの音声合成には、フリー素材キャラクター「つくよみちゃん」（© Rei Yumesaki）が無料公開している音声データを使用しています。
■つくよみちゃんコーパス（CV.夢前黎）
https://tyc.rei-yumesaki.net/material/corpus/
■つくよみちゃん公式サイト
https://tyc.rei-yumesaki.net
つくよみちゃんコーパスに由来する部分の取り扱いについてはつくよみちゃんコーパスの利用規約に従うこととします。


	
		
	
	
		Aivisspeech対応ファイル
	

Aivisspeech形式ファイルは、拡張子が.aivm .aivmxのものとします。
Aivisspeech形式ファイルについては、以下ライセンスが適用されます。
https://github.com/Aivis-Project/ACML/blob/master/ACML-1.0.md… See the full description on the dataset page: https://huggingface.co/datasets/Yukiyoke-Lab/Tsukuyomi-chan_datasets.",https://huggingface.co/datasets/Yukiyoke-Lab/Tsukuyomi-chan_datasets,['ja'],[],[]
mlx-community/Intermediate-Thinking-130k,mlx-community,2025-08-13 16:50:13+00:00,2025-08-13 16:52:21+00:00,35,3,"['task_categories:text-generation', 'language:af', 'language:ar', 'language:bn', 'language:bg', 'language:ca', 'language:zh', 'language:cs', 'language:da', 'language:nl', 'language:en', 'language:et', 'language:fi', 'language:fr', 'language:de', 'language:el', 'language:he', 'language:hi', 'language:hu', 'language:id', 'language:it', 'language:ja', 'language:ko', 'language:mr', 'language:no', 'language:fa', 'language:pl', 'language:pt', 'language:ro', 'language:ru', 'language:so', 'language:es', 'language:sw', 'language:sv', 'language:tl', 'language:ta', 'language:te', 'language:th', 'language:tr', 'language:uk', 'language:ur', 'language:vi', 'language:cy', 'license:apache-2.0', 'size_categories:100K<n<1M', 'format:parquet', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us', 'intermediate-thinking', 'mathematical-reasoning', 'logical-reasoning', 'self-correction', 'structured-thinking']","
	
		
		Intermediate-Thinking-130k
	

A comprehensive dataset of 135,000 high-quality samples designed to advance language model reasoning capabilities through structured intermediate thinking processes. This dataset enables training and evaluation of models with sophisticated self-correction and iterative reasoning abilities across 42 languages.
OG Link

	
		
	
	
		Overview
	

Intermediate-Thinking-130k addresses a fundamental limitation in current language models: their inability to pause… See the full description on the dataset page: https://huggingface.co/datasets/mlx-community/Intermediate-Thinking-130k.",https://huggingface.co/datasets/mlx-community/Intermediate-Thinking-130k,"['af', 'ar', 'bn', 'bg', 'ca', 'zh', 'cs', 'da', 'nl', 'en', 'et', 'fi', 'fr', 'de', 'el', 'he', 'hi', 'hu', 'id', 'it', 'ja', 'ko', 'mr', 'no', 'fa', 'pl', 'pt', 'ro', 'ru', 'so', 'es', 'sw', 'sv', 'tl', 'ta', 'te', 'th', 'tr', 'uk', 'ur', 'vi', 'cy']",['text-generation'],['100K<n<1M']
cc-clean/CC-MAIN-2025-05,cc-clean,2025-08-13 17:16:45+00:00,2025-08-14 22:23:22+00:00,48,0,"['language:ja', 'license:mit', 'size_categories:100M<n<1B', 'format:parquet', 'modality:text', 'library:datasets', 'library:dask', 'library:mlcroissant', 'library:polars', 'region:us']","
	
		
		CC-MAIN-2025-05へようこそ
	

本データセットはCommonCrawlerと呼ばれるものから日本語のみを抽出したものです。
利用したものはcc-downloader-rsです。
なおIPAのICSCoEと呼ばれるところから資源を借りてやりましたゆえに、みなさんIPAに感謝しましょう。
※ IPAは独立行政法人 情報処理推進機構のことです。テストに出ますので覚えましょう。

	
		
		利用について
	

本利用は研究目的のみとさせていただきます。
それ以外の利用につきましては途方のくれない数の著作権者に許可を求めてきてください。
",https://huggingface.co/datasets/cc-clean/CC-MAIN-2025-05,['ja'],[],['100M<n<1B']
cc-clean/CC-MAIN-2015-11,cc-clean,2025-08-13 17:17:51+00:00,2025-08-13 17:20:28+00:00,19,0,"['language:ja', 'license:mit', 'size_categories:1M<n<10M', 'format:parquet', 'modality:text', 'library:datasets', 'library:dask', 'library:mlcroissant', 'library:polars', 'region:us']","
	
		
		CC-MAIN-2015-11へようこそ
	

本データセットはCommonCrawlerと呼ばれるものから日本語のみを抽出したものです。
利用したものはcc-downloader-rsです。
なおIPAのICSCoEと呼ばれるところから資源を借りてやりましたゆえに、みなさんIPAに感謝しましょう。
※ IPAは独立行政法人 情報処理推進機構のことです。テストに出ますので覚えましょう。

	
		
		利用について
	

本利用は研究目的のみとさせていただきます。
それ以外の利用につきましては途方のくれない数の著作権者に許可を求めてきてください。
",https://huggingface.co/datasets/cc-clean/CC-MAIN-2015-11,['ja'],[],['1M<n<10M']
nvidia/Nemotron-Post-Training-Dataset-v2,nvidia,2025-08-13 17:24:50+00:00,2025-08-21 04:29:18+00:00,1896,63,"['language:en', 'language:de', 'language:it', 'language:fr', 'language:es', 'language:ja', 'license:cc-by-4.0', 'size_categories:1M<n<10M', 'format:parquet', 'modality:text', 'library:datasets', 'library:dask', 'library:mlcroissant', 'library:polars', 'arxiv:2508.14444', 'region:us']","
	
		
		Nemotron-Post-Training-Dataset-v2 Release
	


	
		
		Data Overview
	

This dataset adds to NVIDIA’s post-training dataset releases with an extension of SFT and RL data into five target languages: Spanish, French, German, Italian and Japanese. The data supports improvements of math, code, general reasoning, and instruction following capabilities of the NVIDIA-Nemotron-Nano-9B-v2-Base, in support of release of NVIDIA-Nemotron-Nano-8B-v2-Reasoning.
NVIDIA-Nemotron-Nano-9B is a family of… See the full description on the dataset page: https://huggingface.co/datasets/nvidia/Nemotron-Post-Training-Dataset-v2.",https://huggingface.co/datasets/nvidia/Nemotron-Post-Training-Dataset-v2,"['en', 'de', 'it', 'fr', 'es', 'ja']",[],['1M<n<10M']
Silviase/augeo-ja,Silviase,2025-08-14 07:20:17+00:00,2025-08-14 07:36:29+00:00,14,0,"['task_categories:visual-question-answering', 'task_categories:text-generation', 'language:ja', 'license:cc-by-4.0', 'size_categories:n<1K', 'format:parquet', 'modality:image', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us', 'geometry', 'mathematics', 'education', 'problem-solving', 'tikz']","
	
		
		Augeo Geometry Problems Dataset
	


	
		
		Dataset Description
	

This dataset contains geometry problems annotated by multiple contributors, featuring both Japanese problem statements and their solutions. Each problem may include visual diagrams (as images) and TikZ code for geometric constructions.

	
		
		Dataset Summary
	


Total Examples: 122
Languages: Japanese
Task: Geometry problem solving with visual reasoning
Annotators: Multiple human annotators (kinmokusei, aonagi… See the full description on the dataset page: https://huggingface.co/datasets/Silviase/augeo-ja.",https://huggingface.co/datasets/Silviase/augeo-ja,['ja'],"['visual-question-answering', 'text-generation']",['n<1K']
Subh775/Anime_Style,Subh775,2025-08-14 18:10:06+00:00,2025-08-21 18:21:30+00:00,12,0,"['task_categories:image-classification', 'language:en', 'language:ja', 'license:apache-2.0', 'size_categories:1K<n<10K', 'format:imagefolder', 'modality:image', 'library:datasets', 'library:mlcroissant', 'region:us', 'art']",,https://huggingface.co/datasets/Subh775/Anime_Style,"['en', 'ja']",['image-classification'],['1K<n<10K']
cc-clean/CC-MAIN-2025-08,cc-clean,2025-08-15 03:24:52+00:00,2025-08-15 23:25:38+00:00,813,0,"['language:ja', 'license:mit', 'size_categories:100M<n<1B', 'format:parquet', 'modality:text', 'library:datasets', 'library:dask', 'library:mlcroissant', 'library:polars', 'region:us']","
	
		
		CC-MAIN-2025-08へようこそ
	

本データセットはCommonCrawlerと呼ばれるものから日本語のみを抽出したものです。
利用したものはcc-downloader-rsです。
なおIPAのICSCoEと呼ばれるところから資源を借りてやりましたゆえに、みなさんIPAに感謝しましょう。
※ IPAは独立行政法人 情報処理推進機構のことです。テストに出ますので覚えましょう。

	
		
		利用について
	

本利用は研究目的のみとさせていただきます。
それ以外の利用につきましては途方のくれない数の著作権者に許可を求めてきてください。
",https://huggingface.co/datasets/cc-clean/CC-MAIN-2025-08,['ja'],[],['100M<n<1B']
MakiAi/easy-dataset-cli-demo,MakiAi,2025-08-15 06:17:25+00:00,2025-08-15 06:22:26+00:00,9,0,"['task_categories:question-answering', 'task_categories:text-generation', 'language:ja', 'license:mit', 'size_categories:n<1K', 'format:parquet', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us', 'alpaca', 'qa', 'japanese']","
	
		
		Converted QA Dataset
	

このデータセットは、easy-dataset-cliを使用して生成されたアルパカ形式の日本語Q&Aデータセットです。

	
		
		データセット概要
	


総エントリ数: 120
形式: Alpaca形式
言語: 日本語
ライセンス: MIT


	
		
		データ構造
	

各エントリは以下の形式です：
{
  ""instruction"": ""質問文"",
  ""input"": """",
  ""output"": ""回答文"",
  ""genre"": ""ジャンル"",
  ""audience"": ""対象読者""
}


		
	
		ジャンル分布
	

含まれるジャンル:

FAQ
オンラインコース教材
ケーススタディ
ワークショップ資料
学術論文
対話形式の記事
専門技術書
技術ブログ
教科書
雑誌記事


	
		
		対象読者分布
	

含まれる対象読者:

ITプロジェクトマネージャー
コンピュータサイエンス研究者
テック愛好者
データサイエンティスト
プログラミング初心者
中高生
大学生
実務開発者
教育者… See the full description on the dataset page: https://huggingface.co/datasets/MakiAi/easy-dataset-cli-demo.",https://huggingface.co/datasets/MakiAi/easy-dataset-cli-demo,['ja'],"['question-answering', 'text-generation']",['n<1K']
KuroKyusa/LilithVoices,KuroKyusa,2025-08-15 07:05:18+00:00,2025-08-17 04:10:01+00:00,5,0,"['task_categories:text-to-speech', 'language:ja', 'size_categories:n<1K', 'format:audiofolder', 'modality:audio', 'library:datasets', 'library:mlcroissant', 'region:us']",,https://huggingface.co/datasets/KuroKyusa/LilithVoices,['ja'],['text-to-speech'],['n<1K']
MakiAi/Orin-Instruct-Alpaca-JP-v7,MakiAi,2025-08-15 08:38:42+00:00,2025-08-15 08:38:46+00:00,48,0,"['task_categories:question-answering', 'task_categories:text-generation', 'language:ja', 'license:mit', 'size_categories:n<1K', 'format:parquet', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us', 'alpaca', 'qa', 'japanese']","
	
		
		Converted QA Dataset
	

このデータセットは、easy-dataset-cliを使用して生成されたアルパカ形式の日本語Q&Aデータセットです。

	
		
		データセット概要
	


総エントリ数: 564
形式: Alpaca形式
言語: 日本語
ライセンス: MIT


	
		
		データ構造
	

各エントリは以下の形式です：
{
  ""instruction"": ""質問文"",
  ""input"": """",
  ""output"": ""回答文"",
  ""genre"": ""ジャンル"",
  ""audience"": ""対象読者""
}


		
	
		ジャンル分布
	

含まれるジャンル:

FAQ
ゲームデザインレビュー
ステージウォークスルー
スピードランニングマニュアル
テクニカルガイド
ブログレビュー記事
ポッドキャストスクリプト
ローカリゼーションガイド
作品設定コンパイル
学術的分析論文


	
		
		対象読者分布
	

含まれる対象読者:

PCゲーミング愛好者
インディーゲーム開発者
カジュアルファン
ゲーム文化研究者… See the full description on the dataset page: https://huggingface.co/datasets/MakiAi/Orin-Instruct-Alpaca-JP-v7.",https://huggingface.co/datasets/MakiAi/Orin-Instruct-Alpaca-JP-v7,['ja'],"['question-answering', 'text-generation']",['n<1K']
llm-compe-2025-kato/Tag-Validation_Qwen3-14B-Step1-Bespoke17k-ep1,llm-compe-2025-kato,2025-08-15 14:57:09+00:00,2025-08-15 14:57:20+00:00,8,0,"['task_categories:text-generation', 'language:ja', 'language:en', 'license:mit', 'size_categories:n<1K', 'format:parquet', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us', 'explanation-generation', 'tag-validation', 'chain-of-thought']","
	
		
		タグ検証結果
	

このデータセットは説明生成におけるタグ検証の結果を含んでいます。

	
		
		概要
	


処理したサンプル数: 100
説明終了タグ成功率: 77.00%
検証対象タグ: <|end_of_explanation|>


	
		
		トークン数統計
	


最小トークン数: 370
最大トークン数: 32437 
平均トークン数: 7124.1


	
		
		トークン数分布
	


0-100トークン: 0件 (0.0%)
101-500トークン: 4件 (4.0%)
501-1000トークン: 21件 (21.0%)
1001-2000トークン: 17件 (17.0%)
2001-5000トークン: 23件 (23.0%)
5001+トークン: 35件 (35.0%)


	
		
		データセット構造
	


id: 各サンプルの一意識別子
user_content: モデルにユーザーメッセージとして送信した内容（質問のみ）
assistant_content: モデルにアシスタントメッセージとして送信した内容（タグ付き解答 +… See the full description on the dataset page: https://huggingface.co/datasets/llm-compe-2025-kato/Tag-Validation_Qwen3-14B-Step1-Bespoke17k-ep1.",https://huggingface.co/datasets/llm-compe-2025-kato/Tag-Validation_Qwen3-14B-Step1-Bespoke17k-ep1,"['ja', 'en']",['text-generation'],['n<1K']
thng292/fineweb-subset-1M,thng292,2025-08-16 02:46:07+00:00,2025-08-18 08:52:36+00:00,45,0,"['task_categories:text-generation', 'language:vi', 'language:en', 'language:fr', 'language:ja', 'language:zh', 'license:apache-2.0', 'size_categories:1M<n<10M', 'format:parquet', 'modality:text', 'library:datasets', 'library:dask', 'library:mlcroissant', 'library:polars', 'region:us']","This dataset comes from HuggingFaceFW/fineweb-2 and HuggingFaceFW/fineweb-edu. It includes five languages: Vietnamese, English, French, Japanese, and Chinese. Each language has 200,000 training samples and 10,000 test samples, totaling 1 million rows for training and 50,000 rows for testing.
The default subset is the combination of other subset
",https://huggingface.co/datasets/thng292/fineweb-subset-1M,"['vi', 'en', 'fr', 'ja', 'zh']",['text-generation'],['1M<n<10M']
Isamu136/Japanese-Political-Money-OCR-with-Qwen,Isamu136,2025-08-16 12:45:17+00:00,2025-08-17 21:14:16+00:00,4198,0,"['language:ja', 'language:en', 'license:mit', 'region:us']",,https://huggingface.co/datasets/Isamu136/Japanese-Political-Money-OCR-with-Qwen,"['ja', 'en']",[],[]
tetsuro731/wrime-sentiment,tetsuro731,2025-08-16 15:21:18+00:00,2025-08-17 06:49:47+00:00,26,0,"['task_categories:text-classification', 'language:ja', 'size_categories:10K<n<100K', 'format:parquet', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","
	
		
		Dataset Card for tetsuro731/wrime-sentiment
	

大元のデータはこちらです。

https://github.com/ids-cv/wrime

加工方法は以下と似た方法で行なっていますが、neutralは省いています。

https://huggingface.co/datasets/llm-book/wrime-sentiment

datasetの4.0.0以降はpythonスクリプトの内部実行ができなくなっているため、加工済みのparquetファイルをアップロードする方式を取っています。
HiggingFaceのアップロード許可は大元からもらっており、こちらのデータセットは書籍のサンプル用を想定しています。
",https://huggingface.co/datasets/tetsuro731/wrime-sentiment,['ja'],['text-classification'],['10K<n<100K']
midralab/gol-dataset,midralab,2025-08-17 06:06:01+00:00,2025-08-27 17:33:07+00:00,5,0,"['task_categories:automatic-speech-recognition', 'task_categories:text-to-speech', 'language:ja', 'size_categories:1M<n<10M', 'modality:audio', 'library:webdataset', 'region:us', 'audio', 'speech', 'webdataset', 'japanese', 'visual-novel', 'voice-acting']","
	
		
		gol-dataset
	

  - 総ファイル（発話）数 : 7,405,094
  - 総話者（キャラクター）数: 19,349
  - 合計再生時間         : 10654時間 19分 19.27秒
  - 平均再生時間         : 5.1796 秒
  - 最小再生時間         : 0.3000 秒 (File: z0019#00256.wav)
  - 最大再生時間         : 58.6987 秒 (File: z0298#00067.wav)
  - 基本統計量:
count    7.405094e+06
mean     5.179618e+00
std      3.309743e+00
min      3.000000e-01
25%      2.686200e+00
50%      4.552000e+00
75%      7.005400e+00
max      5.869870e+01
  - 再生時間ヒストグラム（分布）:
      0-1s |  324,890 件 ( 4.39%) ██… See the full description on the dataset page: https://huggingface.co/datasets/midralab/gol-dataset.",https://huggingface.co/datasets/midralab/gol-dataset,['ja'],"['automatic-speech-recognition', 'text-to-speech']",['1M<n<10M']
zaid002/guvi_multilingual_dataset,zaid002,2025-08-17 15:35:56+00:00,2025-08-17 16:11:29+00:00,7,0,"['task_categories:translation', 'language:en', 'language:ur', 'language:ta', 'language:hi', 'language:fr', 'language:mr', 'language:ml', 'language:te', 'language:ka', 'language:kn', 'language:gu', 'language:ja', 'language:ch', 'language:zh', 'language:be', 'language:bg', 'language:bn', 'license:apache-2.0', 'size_categories:1K<n<10K', 'format:csv', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us', 'legal', 'code', 'tech']",,https://huggingface.co/datasets/zaid002/guvi_multilingual_dataset,"['en', 'ur', 'ta', 'hi', 'fr', 'mr', 'ml', 'te', 'ka', 'kn', 'gu', 'ja', 'ch', 'zh', 'be', 'bg', 'bn']",['translation'],['1K<n<10K']
thng292/fineweb-subset-10M,thng292,2025-08-18 00:41:18+00:00,2025-08-18 13:40:38+00:00,476,0,"['task_categories:text-generation', 'language:vi', 'language:en', 'language:fr', 'language:ja', 'language:zh', 'license:apache-2.0', 'size_categories:10M<n<100M', 'format:parquet', 'modality:text', 'library:datasets', 'library:dask', 'library:mlcroissant', 'library:polars', 'region:us']","This dataset comes from HuggingFaceFW/fineweb-2 and HuggingFaceFW/fineweb-edu. It includes five languages: Vietnamese, English, French, Japanese, and Chinese. Each language has 2,000,000 training samples and 100,000 test samples, totaling 10 million rows for training and 500,000 rows for testing.
The default subset is the combination of other subset
",https://huggingface.co/datasets/thng292/fineweb-subset-10M,"['vi', 'en', 'fr', 'ja', 'zh']",['text-generation'],['10M<n<100M']
Silviase/JPCharRecog,Silviase,2025-08-18 07:20:53+00:00,2025-08-18 09:43:26+00:00,6,0,"['task_categories:image-classification', 'language:ja', 'size_categories:1K<n<10K', 'format:parquet', 'modality:image', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","
	
		
		Japanese Character Recognition Dataset
	

This dataset contains rendered images of Japanese characters including:

Hiragana (ひらがな)
Katakana (カタカナ)
Joyo Kanji (常用漢字)


	
		
		Dataset Structure
	

Each example contains:

image: A 224x224 RGB image of a single Japanese character
character: The character as text
char_type: Type of character (hiragana, katakana, or kanji)
unicode: Unicode code point of the character
id: Unique identifier


	
		
		Usage
	

from datasets import load_dataset… See the full description on the dataset page: https://huggingface.co/datasets/Silviase/JPCharRecog.",https://huggingface.co/datasets/Silviase/JPCharRecog,['ja'],['image-classification'],['1K<n<10K']
Aratako/Synthetic-Japanese-Roleplay-NSFW-gpt-5-chat-5k,Aratako,2025-08-18 18:05:16+00:00,2025-08-19 07:05:02+00:00,27,0,"['task_categories:text-generation', 'language:ja', 'license:cc-by-nc-sa-4.0', 'size_categories:1K<n<10K', 'format:parquet', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us', 'roleplay', 'not-for-all-audiences']","
	
		
		Synthetic-Japanese-Roleplay-NSFW-gpt-5-chat-5k
	


	
		
		概要
	

OpenRouterのgpt-5-chatを用いて作成した、約5000件の日本語ロールプレイの対話を収録した合成データセットです。各データは20ターン程度あります。
このデータセットはNSFW表現を含みます。

	
		
		データの詳細
	

各データは以下のキーを含んでいます。

major_genre: ジャンル（大分類）
minor_genre: ジャンル（小分類）
tag: 年齢制限用タグ（R-18）
world_setting: 舞台・世界観の設定
scene_setting: 対話シーンの設定
user_setting: ユーザー側のキャラクターの設定
assistant_setting: アシスタント側のキャラクターの設定
dialogue_tone: 対話のトーン
system_message: ロールプレイ指示用のシステムメッセージ
conversations:… See the full description on the dataset page: https://huggingface.co/datasets/Aratako/Synthetic-Japanese-Roleplay-NSFW-gpt-5-chat-5k.",https://huggingface.co/datasets/Aratako/Synthetic-Japanese-Roleplay-NSFW-gpt-5-chat-5k,['ja'],['text-generation'],['1K<n<10K']
alfredplpl/image-text-pairs-ja-cc0-2,alfredplpl,2025-08-18 21:50:09+00:00,2025-08-19 05:31:03+00:00,92,2,"['language:en', 'language:ja', 'license:cc0-1.0', 'size_categories:1M<n<10M', 'format:webdataset', 'modality:image', 'modality:text', 'library:datasets', 'library:webdataset', 'library:mlcroissant', 'region:us']","
	
		
		はじめに
	

このデータセットは画像生成で日本語を生成したいときに使うデータセットです。

	
		
		ライセンス
	

CC-0です。著作権を放棄して使いやすくしました。

	
		
		作り方の概要
	

gpt-oss-20bを使って、約8万個からなる単語集兼短文集を作りました。
その文章をPillowとPythonでランダム要素を入れながら100万枚と10万枚でレンダリングしました。
フォントはNoto Sans JPなのでライセンス的には問題ないと思います。
",https://huggingface.co/datasets/alfredplpl/image-text-pairs-ja-cc0-2,"['en', 'ja']",[],['1M<n<10M']
Aratako/Synthetic-Japanese-Roleplay-NSFW-gpt-5-chat-5k-formatted,Aratako,2025-08-19 01:09:16+00:00,2025-08-19 07:11:43+00:00,85,2,"['task_categories:text-generation', 'language:ja', 'license:cc-by-nc-sa-4.0', 'size_categories:1K<n<10K', 'format:parquet', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us', 'roleplay', 'not-for-all-audiences']","
	
		
		Synthetic-Japanese-Roleplay-NSFW-gpt-5-chat-5k-formatted
	


	
		
		概要
	

OpenRouterのgpt-5-chatを用いて作成した日本語ロールプレイデータセットであるAratako/Synthetic-Japanese-Roleplay-NSFW-gpt-5-chat-5kをOpenAI messages形式に整形したデータセットです。
データの詳細については元データセットのREADMEを参照してください。

	
		
		ライセンス
	

CC-BY-NC-SA 4.0の元配布します。
また、OpenAIの利用規約に記載のある通り、このデータを使ってOpenAIのサービスやモデルと競合するようなモデルを開発することは禁止されています。
",https://huggingface.co/datasets/Aratako/Synthetic-Japanese-Roleplay-NSFW-gpt-5-chat-5k-formatted,['ja'],['text-generation'],['1K<n<10K']
puwaer/dlsite-jp-v2,puwaer,2025-08-19 09:04:58+00:00,2025-08-19 09:22:32+00:00,8,0,"['task_categories:text-generation', 'task_categories:fill-mask', 'language:ja', 'license:apache-2.0', 'region:us', 'not-for-all-audiences']","
	
		
		puwaer/dlsite-jp-v2
	

This dataset consists of text extracted exclusively in Japanese from dlsite.com and is structured as JSON files. The files are categorized based on the type of URL.
このデータセットは、dlsite.comより日本語データのみを抽出したテキストで、jsonファイルで構成されます。
urlの種類によってファイル分けされています。
",https://huggingface.co/datasets/puwaer/dlsite-jp-v2,['ja'],"['text-generation', 'fill-mask']",[]
puwaer/dlsite-jp-v3,puwaer,2025-08-19 09:05:11+00:00,2025-08-19 09:25:19+00:00,18,0,"['task_categories:text-generation', 'task_categories:fill-mask', 'language:ja', 'license:apache-2.0', 'region:us', 'not-for-all-audiences']","
	
		
		puwaer/dlsite-jp-v3
	

This dataset consists of text extracted exclusively in Japanese from dlsite.com and is structured as JSON files. The files are categorized based on the type of URL.
このデータセットは、dlsite.comより日本語データのみを抽出したテキストで、jsonファイルで構成されます。
urlの種類によってファイル分けされています。
",https://huggingface.co/datasets/puwaer/dlsite-jp-v3,['ja'],"['text-generation', 'fill-mask']",[]
puwaer/dmm-fanza-jp-v2,puwaer,2025-08-19 09:05:26+00:00,2025-08-19 09:28:51+00:00,9,0,"['task_categories:text-generation', 'task_categories:fill-mask', 'language:ja', 'license:apache-2.0', 'region:us', 'not-for-all-audiences']","
	
		
		puwaer/dmm-fanza-jp-v2
	

This dataset consists of text extracted exclusively in Japanese from dmm.co.jp(fanza) and is structured as JSON files. The files are categorized based on the type of URL.
このデータセットは、dmm.co.jp(fanza)より日本語データのみを抽出したテキストで、jsonファイルで構成されます。
urlの種類によってファイル分けされています。
",https://huggingface.co/datasets/puwaer/dmm-fanza-jp-v2,['ja'],"['text-generation', 'fill-mask']",[]
puwaer/dmm-fanza-jp-v3,puwaer,2025-08-19 09:05:38+00:00,2025-08-19 09:31:01+00:00,9,0,"['task_categories:text-generation', 'task_categories:fill-mask', 'language:ja', 'license:apache-2.0', 'region:us', 'not-for-all-audiences']","
	
		
		puwaer/dmm-fanza-jp-v3
	

This dataset consists of text extracted exclusively in Japanese from dmm.co.jp(fanza) and is structured as JSON files. The files are categorized based on the type of URL.
このデータセットは、dmm.co.jp(fanza)より日本語データのみを抽出したテキストで、jsonファイルで構成されます。
urlの種類によってファイル分けされています。
",https://huggingface.co/datasets/puwaer/dmm-fanza-jp-v3,['ja'],"['text-generation', 'fill-mask']",[]
puwaer/Doujinshi-dpo-dataset-v1,puwaer,2025-08-19 09:05:55+00:00,2025-08-19 09:14:54+00:00,16,0,"['task_categories:text-generation', 'task_categories:fill-mask', 'language:ja', 'license:apache-2.0', 'region:us', 'not-for-all-audiences']","
	
		
		puwaer/Doujinshi-dpo-dataset-v1
	

This dataset is based on the puwaer/Doujinshi-sft-dataset-v1 SFT dataset and is designed for DPO training to enable R18 outputs.For negative examples, outputs from Qwen/Qwen3-14B are used.
このデータセットは、puwaer/Doujinshi-sft-dataset-v1のsftのデータセットを元にr18の出力をできるようするためのdpo用のデータセットです。
不例には、Qwen/Qwen3-14Bの出力を用いています。
",https://huggingface.co/datasets/puwaer/Doujinshi-dpo-dataset-v1,['ja'],"['text-generation', 'fill-mask']",[]
JCruan/MME-SCI,JCruan,2025-08-19 12:20:24+00:00,2025-08-20 03:30:40+00:00,79,2,"['task_categories:image-text-to-text', 'task_categories:visual-question-answering', 'language:zh', 'language:en', 'language:es', 'language:fr', 'language:ja', 'license:cc-by-nc-sa-4.0', 'size_categories:1K<n<10K', 'arxiv:2508.13938', 'region:us', 'Math', 'Physics', 'Chemistry', 'Biology', 'Multilingual']","
	
		
		MME-SCI: A Comprehensive and Challenging Science Benchmark for Multimodal Large Language Models
	

MME-SCI is a comprehensive multimodal benchmark designed to evaluate the scientific reasoning capabilities of Multimodal Large Language Models (MLLMs). It addresses key limitations of existing benchmarks by focusing on multilingual adaptability, comprehensive modality coverage, and fine-grained knowledge point annotation.

	
		
		🌟 Key Features
	


Multilingual Support: Covers 5… See the full description on the dataset page: https://huggingface.co/datasets/JCruan/MME-SCI.",https://huggingface.co/datasets/JCruan/MME-SCI,"['zh', 'en', 'es', 'fr', 'ja']","['image-text-to-text', 'visual-question-answering']",['1K<n<10K']
llm-compe-2025-kato/step2-pairwise-eval,llm-compe-2025-kato,2025-08-19 15:21:55+00:00,2025-08-19 15:22:02+00:00,22,0,"['task_categories:text-generation', 'language:ja', 'language:en', 'license:mit', 'size_categories:n<1K', 'format:parquet', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us', 'pairwise-comparison', 'explanation-evaluation', 'model-comparison']","
	
		
		Pairwise Comparison Results
	

This dataset contains the results of a pairwise comparison between two models' explanation generation capabilities.

	
		
		Overview
	


Total Comparisons: 68
Model A (Dataset): llm-compe-2025-kato/Tag-Validation_Qwen3-14B-Step1-Bespoke17k-ep1
Model B (Dataset): llm-compe-2025-kato/Tag-Validation_Qwen3-14B-Step1-Bespoke17k-ep1


	
		
		Results Summary
	

Winner: Model A (Dataset: llm-compe-2025-kato/Tag-Validation_Qwen3-14B-Step1-Bespoke17k-ep1)
Margin:… See the full description on the dataset page: https://huggingface.co/datasets/llm-compe-2025-kato/step2-pairwise-eval.",https://huggingface.co/datasets/llm-compe-2025-kato/step2-pairwise-eval,"['ja', 'en']",['text-generation'],['n<1K']
llm-compe-2025-kato/step2-DeepMath-103K-Bespoke-Filtered-Test-200-eval-Qwen3-14B,llm-compe-2025-kato,2025-08-20 13:53:25+00:00,2025-08-20 13:53:33+00:00,11,0,"['task_categories:text-generation', 'language:ja', 'language:en', 'license:mit', 'size_categories:n<1K', 'format:parquet', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us', 'explanation-generation', 'chain-of-thought', 'reasoning']","
	
		
		Chain of Thought生成データセット
	

このデータセットは、問題と解答から説明（Chain of Thought）を生成したデータセットです。

	
		
		概要
	


処理したサンプル数: 156
有効な説明生成数: 156
生成成功率: 100.00%
使用モデル: Qwen/Qwen3-14B


	
		
		トークン数統計
	


最小トークン数: 313
最大トークン数: 3066
平均トークン数: 887.4


	
		
		トークン数分布
	


0-100トークン: 0件 (0.0%)
101-500トークン: 26件 (16.7%)
501-1000トークン: 85件 (54.5%)
1001-2000トークン: 39件 (25.0%)
2001-5000トークン: 6件 (3.8%)
5001+トークン: 0件 (0.0%)


	
		
		データセット構造
	


system_prompt: モデルに送信されたシステムプロンプト
question_text: 元の問題文
answer_text: 問題の解答… See the full description on the dataset page: https://huggingface.co/datasets/llm-compe-2025-kato/step2-DeepMath-103K-Bespoke-Filtered-Test-200-eval-Qwen3-14B.",https://huggingface.co/datasets/llm-compe-2025-kato/step2-DeepMath-103K-Bespoke-Filtered-Test-200-eval-Qwen3-14B,"['ja', 'en']",['text-generation'],['n<1K']
llm-compe-2025-kato/step2-DeepMath-103K-Bespoke-Filtered-Test-200-eval-cp32,llm-compe-2025-kato,2025-08-20 16:42:17+00:00,2025-08-20 16:42:25+00:00,20,0,"['task_categories:text-generation', 'language:ja', 'language:en', 'license:mit', 'size_categories:n<1K', 'format:parquet', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us', 'explanation-generation', 'chain-of-thought', 'reasoning']","
	
		
		Chain of Thought生成データセット
	

このデータセットは、問題と解答から説明（Chain of Thought）を生成したデータセットです。

	
		
		概要
	


処理したサンプル数: 60
有効な説明生成数: 60
生成成功率: 100.00%
使用モデル: /home/Competition2025/P07/shareP07/share_model/step2_rlt/Qwen3-14B-step2-deepmath103k-bs512/checkpoint-32


	
		
		トークン数統計
	


最小トークン数: 892
最大トークン数: 5932
平均トークン数: 3560.4


	
		
		トークン数分布
	


0-100トークン: 0件 (0.0%)
101-500トークン: 0件 (0.0%)
501-1000トークン: 1件 (1.7%)
1001-2000トークン: 10件 (16.7%)
2001-5000トークン: 41件 (68.3%)
5001+トークン: 8件 (13.3%)… See the full description on the dataset page: https://huggingface.co/datasets/llm-compe-2025-kato/step2-DeepMath-103K-Bespoke-Filtered-Test-200-eval-cp32.",https://huggingface.co/datasets/llm-compe-2025-kato/step2-DeepMath-103K-Bespoke-Filtered-Test-200-eval-cp32,"['ja', 'en']",['text-generation'],['n<1K']
llm-compe-2025-kato/step2-DeepMath-103K-Bespoke-Filtered-Test-200-eval-cp40,llm-compe-2025-kato,2025-08-21 00:02:42+00:00,2025-08-21 00:02:51+00:00,11,0,"['task_categories:text-generation', 'language:ja', 'language:en', 'license:mit', 'size_categories:n<1K', 'format:parquet', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us', 'explanation-generation', 'chain-of-thought', 'reasoning']","
	
		
		Chain of Thought生成データセット
	

このデータセットは、問題と解答から説明（Chain of Thought）を生成したデータセットです。

	
		
		概要
	


処理したサンプル数: 58
有効な説明生成数: 58
生成成功率: 100.00%
使用モデル: /home/Competition2025/P07/shareP07/share_model/step2_rlt/Qwen3-14B-step2-deepmath103k-bs512/checkpoint-40


	
		
		トークン数統計
	


最小トークン数: 830
最大トークン数: 6301
平均トークン数: 3477.9


	
		
		トークン数分布
	


0-100トークン: 0件 (0.0%)
101-500トークン: 0件 (0.0%)
501-1000トークン: 1件 (1.7%)
1001-2000トークン: 9件 (15.5%)
2001-5000トークン: 39件 (67.2%)
5001+トークン: 9件 (15.5%)… See the full description on the dataset page: https://huggingface.co/datasets/llm-compe-2025-kato/step2-DeepMath-103K-Bespoke-Filtered-Test-200-eval-cp40.",https://huggingface.co/datasets/llm-compe-2025-kato/step2-DeepMath-103K-Bespoke-Filtered-Test-200-eval-cp40,"['ja', 'en']",['text-generation'],['n<1K']
Silviase/JPMultiCharRecog,Silviase,2025-08-21 05:49:10+00:00,2025-08-21 05:49:16+00:00,9,0,"['task_categories:image-classification', 'task_categories:visual-question-answering', 'language:ja', 'license:mit', 'size_categories:1K<n<10K', 'format:parquet', 'modality:image', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us', 'japanese', 'ocr', 'character-recognition', 'vision-language']","
	
		
		Japanese Multi-Character Recognition Dataset
	


	
		
		Dataset Description
	

This dataset is designed to evaluate Vision-Language Models (VLMs) on their ability to distinguish between meaningful Japanese words and meaningless character sequences. It contains 2,000 images of Japanese text (1,000 positive/negative pairs).

	
		
		Dataset Summary
	


Total Samples: 2,000 (1,000 pairs)
Categories: 
K-K: 2-character Kanji compounds (250 pairs)
K+H: Kanji + Hiragana combinations (250… See the full description on the dataset page: https://huggingface.co/datasets/Silviase/JPMultiCharRecog.",https://huggingface.co/datasets/Silviase/JPMultiCharRecog,['ja'],"['image-classification', 'visual-question-answering']",['1K<n<10K']
qmaru/gemma3-sms,qmaru,2025-08-21 16:02:58+00:00,2025-08-23 10:52:53+00:00,10,0,"['task_categories:text-generation', 'language:zh', 'language:en', 'language:ja', 'license:gemma', 'size_categories:1K<n<10K', 'format:json', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']",,https://huggingface.co/datasets/qmaru/gemma3-sms,"['zh', 'en', 'ja']",['text-generation'],['1K<n<10K']
MakiAi/Orin-Instruct-Alpaca-JP-v8,MakiAi,2025-08-22 09:43:55+00:00,2025-08-22 09:44:01+00:00,8,0,"['task_categories:question-answering', 'task_categories:text-generation', 'language:ja', 'license:mit', 'size_categories:1K<n<10K', 'format:parquet', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us', 'alpaca', 'qa', 'japanese']","
	
		
		Converted QA Dataset
	

このデータセットは、easy-dataset-cliを使用して生成されたアルパカ形式の日本語Q&Aデータセットです。

	
		
		データセット概要
	


総エントリ数: 3,731
形式: Alpaca形式
言語: 日本語
ライセンス: MIT


	
		
		データ構造
	

各エントリは以下の形式です：
{
  ""instruction"": ""質問文"",
  ""input"": """",
  ""output"": ""回答文"",
  ""genre"": ""ジャンル"",
  ""audience"": ""対象読者""
}


		
	
		ジャンル分布
	

含まれるジャンル:

FAQ
PC向けガイド
ゆっくりガイド
アジア系ユーザー向けガイド
イベントガイド
イベント常連ガイド
コレクションガイド
ジュニアガイド
ソロ活動ガイド
ソーシャルガイド
ファミリーガイド
プロフェッショナルガイド
プロ創作者ガイド
プロ配信者ガイド
ベテラン社会人ガイド
モバイルガイド
レビュー記事
上級者向けマニュアル
上級者向け攻略… See the full description on the dataset page: https://huggingface.co/datasets/MakiAi/Orin-Instruct-Alpaca-JP-v8.",https://huggingface.co/datasets/MakiAi/Orin-Instruct-Alpaca-JP-v8,['ja'],"['question-answering', 'text-generation']",['1K<n<10K']
racineai/OGC_Cooking_Recipes,racineai,2025-08-22 14:55:40+00:00,2025-08-26 17:51:47+00:00,413,11,"['task_categories:visual-document-retrieval', 'task_categories:text-retrieval', 'language:en', 'language:fr', 'language:zh', 'language:ko', 'language:ja', 'language:vi', 'language:th', 'language:ru', 'language:ar', 'language:pt', 'language:es', 'language:de', 'license:apache-2.0', 'size_categories:10K<n<100K', 'format:parquet', 'modality:image', 'modality:text', 'library:datasets', 'library:dask', 'library:mlcroissant', 'library:polars', 'region:us', 'RAG', 'DSE', 'cooking', 'recipes', 'culinary', 'retrieval']","
	
		
		OGC_Cooking_Recipes - Overview
	


	
		
		Dataset Summary
	

OGC_Cooking_Recipes is a curated multimodal dataset focused on cooking recipe documents, culinary guides, and food preparation instructions. It combines text and image data extracted from real culinary PDFs to support tasks such as RAG DSE, question answering, document search, and vision-language model training.

	
		
		Dataset Details
	


	
		
		Dataset Creation
	

This dataset was created using our open-source tool… See the full description on the dataset page: https://huggingface.co/datasets/racineai/OGC_Cooking_Recipes.",https://huggingface.co/datasets/racineai/OGC_Cooking_Recipes,"['en', 'fr', 'zh', 'ko', 'ja', 'vi', 'th', 'ru', 'ar', 'pt', 'es', 'de']","['visual-document-retrieval', 'text-retrieval']",['10K<n<100K']
strangerguardhf/Caption3o-Opt-Abliterated-5K,strangerguardhf,2025-08-23 05:13:00+00:00,2025-09-15 12:40:32+00:00,16,2,"['task_categories:image-to-text', 'task_categories:image-text-to-text', 'language:en', 'language:ja', 'language:zh', 'license:apache-2.0', 'size_categories:1K<n<10K', 'region:us', 'art', 'synthetic', 'blip3o', 'caption', 'not-for-all-audiences']","
	
		
		Caption3o-Opt-Abliterated-5K
	

Caption3o-Opt-Abliterated-5K is a gated, synthetic image-caption dataset curated for training and evaluating multimodal (Image-to-Text / Image-Text-to-Text) models. It is a compact, filtered, and “abliterated” subset derived from Caption3o-Opt with an emphasis on experimental captioning strategies, covering diverse real-world and artistic content.

	
		
	
	
		Dataset Summary
	


Size: ~5,000 image–caption pairs
Format: Parquet
Image resolution: 512x512… See the full description on the dataset page: https://huggingface.co/datasets/strangerguardhf/Caption3o-Opt-Abliterated-5K.",https://huggingface.co/datasets/strangerguardhf/Caption3o-Opt-Abliterated-5K,"['en', 'ja', 'zh']","['image-to-text', 'image-text-to-text']",['1K<n<10K']
MakiAi/Orin-Instruct-Alpaca-JP-v9,MakiAi,2025-08-23 12:43:47+00:00,2025-08-23 12:43:52+00:00,6,0,"['task_categories:question-answering', 'task_categories:text-generation', 'language:ja', 'license:mit', 'size_categories:10K<n<100K', 'format:parquet', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us', 'alpaca', 'qa', 'japanese']","
	
		
		Converted QA Dataset
	

このデータセットは、easy-dataset-cliを使用して生成されたアルパカ形式の日本語Q&Aデータセットです。

	
		
		データセット概要
	


総エントリ数: 17,317
形式: Alpaca形式
言語: 日本語
ライセンス: MIT


	
		
		データ構造
	

各エントリは以下の形式です：
{
  ""instruction"": ""質問文"",
  ""input"": """",
  ""output"": ""回答文"",
  ""genre"": ""ジャンル"",
  ""audience"": ""対象読者""
}


		
	
		ジャンル分布
	

含まれるジャンル:

FAQ
PC向けガイド
ゆっくりガイド
アクセシビリティガイド
アジア系ユーザー向けガイド
アーティスト向けガイド
イベントガイド
イベント常連ガイド
エンジニア向けガイド
オフライン重視ガイド
コレクションガイド
ジュニアガイド
ソロ活動ガイド
ソーシャルガイド
ファミリーガイド
プロフェッショナルガイド
プロ創作者ガイド
プロ配信者ガイド… See the full description on the dataset page: https://huggingface.co/datasets/MakiAi/Orin-Instruct-Alpaca-JP-v9.",https://huggingface.co/datasets/MakiAi/Orin-Instruct-Alpaca-JP-v9,['ja'],"['question-answering', 'text-generation']",['10K<n<100K']
realoperator42/anime-titles-dataset,realoperator42,2025-08-24 05:55:43+00:00,2025-08-24 20:43:11+00:00,17,0,"['task_categories:text-generation', 'language:en', 'language:ja', 'license:cc-by-4.0', 'size_categories:n<1K', 'format:json', 'modality:tabular', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us', 'anime', 'characters', 'entertainment', 'japanese-culture']","
	
		
		Anime Dataset
	


	
		
		Dataset Description
	

This dataset contains comprehensive information about anime series scraped from MyAnimeList (MAL). It includes detailed metadata about 871 (approx) anime series, making it valuable for various NLP tasks, recommendation systems, and cultural analysis.
This dataset has NSFW content.

	
		
		Dataset Summary
	


Anime Entries: 50 anime series with rich metadata
Languages: English and Japanese (titles, descriptions)
Format: JSONL (JSON Lines)… See the full description on the dataset page: https://huggingface.co/datasets/realoperator42/anime-titles-dataset.",https://huggingface.co/datasets/realoperator42/anime-titles-dataset,"['en', 'ja']",['text-generation'],['n<1K']
nishika-nm/geniac-iam-corpus-ja,nishika-nm,2025-08-25 08:51:11+00:00,2025-08-25 08:51:19+00:00,8,0,"['task_categories:translation', 'task_categories:summarization', 'task_categories:text-generation', 'language:en', 'language:ja', 'license:mit', 'size_categories:n<1K', 'format:parquet', 'modality:tabular', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us', 'meeting-transcripts', 'dialogue', 'translation', 'japanese', 'english', 'ami-corpus', 'geniac']","
	
		
		GENIAC IAM Corpus (Japanese)
	

This dataset contains high-quality Japanese translations of the AMI Meeting Corpus, specifically curated for the GENIAC project.

	
		
		Dataset Description
	

The GENIAC IAM (Intelligent Assistant for Meetings) Corpus is a Japanese-English bilingual dataset derived from the AMI Meeting Corpus. Each entry contains meeting dialogues and their summaries in both English and Japanese.

	
		
		Dataset Features
	


Bilingual Content: Original English text… See the full description on the dataset page: https://huggingface.co/datasets/nishika-nm/geniac-iam-corpus-ja.",https://huggingface.co/datasets/nishika-nm/geniac-iam-corpus-ja,"['en', 'ja']","['translation', 'summarization', 'text-generation']",['n<1K']
Aratako/Japanese-Creative-Writing-GLM4.5,Aratako,2025-08-25 10:54:45+00:00,2025-08-25 12:14:19+00:00,32,0,"['task_categories:text-generation', 'language:ja', 'license:mit', 'size_categories:1K<n<10K', 'format:parquet', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","
	
		
		Japanese-Creative-Writing-GLM4.5
	


	
		
		概要
	

日本語の小説執筆タスクのデータセットであるAratako/Japanese-Creative-Writing-39.6kから一部の指示を抽出し、zai-org/GLM-4.5で応答を再生成した約8000件のデータセットです。
データセット中の一部データはNSFW表現を含みます。

	
		
		データの詳細
	

各データは以下のキーを含みます。

messages: OpenAI messages形式の対話データ
instruction: 指示プロンプト
output: アシスタント応答

system promptは事前に用意した複数種類からランダムに選択されたものが設定されています。

	
		
		ライセンス
	

MITライセンスの元配布します。
",https://huggingface.co/datasets/Aratako/Japanese-Creative-Writing-GLM4.5,['ja'],['text-generation'],['1K<n<10K']
MakiAi/Orin-Instruct-Alpaca-JP-v10,MakiAi,2025-08-25 12:41:02+00:00,2025-08-25 12:41:09+00:00,8,0,"['task_categories:question-answering', 'task_categories:text-generation', 'language:ja', 'license:mit', 'size_categories:10K<n<100K', 'format:parquet', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us', 'alpaca', 'qa', 'japanese']","
	
		
		Converted QA Dataset
	

このデータセットは、easy-dataset-cliを使用して生成されたアルパカ形式の日本語Q&Aデータセットです。

	
		
		データセット概要
	


総エントリ数: 47,880
形式: Alpaca形式
言語: 日本語
ライセンス: MIT


	
		
		データ構造
	

各エントリは以下の形式です：
{
  ""instruction"": ""質問文"",
  ""input"": """",
  ""output"": ""回答文"",
  ""genre"": ""ジャンル"",
  ""audience"": ""対象読者""
}


		
	
		ジャンル分布
	

含まれるジャンル:

FAQ
PC向けガイド
ゆっくりガイド
アクセシビリティガイド
アジア系ユーザー向けガイド
アーティスト向けガイド
イベントガイド
イベント常連ガイド
エンジニア向けガイド
オフライン重視ガイド
コレクションガイド
ジュニアガイド
ソロ活動ガイド
ソーシャルガイド
ファミリーガイド
プロフェッショナルガイド
プロ創作者ガイド
プロ配信者ガイド… See the full description on the dataset page: https://huggingface.co/datasets/MakiAi/Orin-Instruct-Alpaca-JP-v10.",https://huggingface.co/datasets/MakiAi/Orin-Instruct-Alpaca-JP-v10,['ja'],"['question-answering', 'text-generation']",['10K<n<100K']
stanford-oval/Lemonade,stanford-oval,2025-08-25 13:18:59+00:00,2025-08-25 13:19:42+00:00,49,0,"['task_categories:text-classification', 'task_categories:text-generation', 'language:en', 'language:es', 'language:ar', 'language:fr', 'language:it', 'language:ru', 'language:de', 'language:tr', 'language:my', 'language:id', 'language:uk', 'language:ko', 'language:pt', 'language:nl', 'language:so', 'language:ne', 'language:zh', 'language:fa', 'language:he', 'language:ja', 'license:apache-2.0', 'size_categories:10K<n<100K', 'format:parquet', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","LEMONADE is a large, expert-annotated dataset for event extraction from news articles in 20 languages: English, Spanish, Arabic, French, Italian, Russian, German, Turkish, Burmese, Indonesian, Ukrainian, Korean, Portuguese, Dutch, Somali, Nepali, Chinese, Persian, Hebrew, and Japanese.
See https://github.com/stanford-oval/Lemonade for details.
",https://huggingface.co/datasets/stanford-oval/Lemonade,"['en', 'es', 'ar', 'fr', 'it', 'ru', 'de', 'tr', 'my', 'id', 'uk', 'ko', 'pt', 'nl', 'so', 'ne', 'zh', 'fa', 'he', 'ja']","['text-classification', 'text-generation']",['10K<n<100K']
realoperator42/anime-characters,realoperator42,2025-08-26 01:47:25+00:00,2025-08-26 01:47:45+00:00,24,0,"['task_categories:text-generation', 'task_categories:feature-extraction', 'language:en', 'language:ja', 'license:cc-by-4.0', 'size_categories:10K<n<100K', 'format:json', 'modality:tabular', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us', 'anime', 'characters', 'myanimelist', 'manga', 'light-novel']","
	
		
		Anime Character Dataset
	

This dataset contains detailed information about anime characters scraped from MyAnimeList.

	
		
		Dataset Structure
	

Each character entry contains the following fields:

mal_id: MyAnimeList character ID
url: Character page URL
name: Character name
name_kanji: Character name in Kanji (if available)
nicknames: List of character nicknames
about: Character description/biography
favorites: Number of users who favorited this character
anime_appearances: List of… See the full description on the dataset page: https://huggingface.co/datasets/realoperator42/anime-characters.",https://huggingface.co/datasets/realoperator42/anime-characters,"['en', 'ja']","['text-generation', 'feature-extraction']",['10K<n<100K']
cyberagent/BannerBench,cyberagent,2025-08-26 02:13:07+00:00,2025-09-17 07:04:09+00:00,76,0,"['task_categories:visual-question-answering', 'language:ja', 'license:cc-by-nc-sa-4.0', 'size_categories:n<1K', 'format:parquet', 'modality:image', 'modality:text', 'library:datasets', 'library:dask', 'library:mlcroissant', 'library:polars', 'region:us']","
	
		
		BannerBench: Benchmarking Vision Language Models for Multi-Ad Selection with Human Preferences
	


	
		
		Dataset Summary
	

The BannerBench is designed to evaluate the ability of VLMs to identify the banner that best matches human preferences from a set of candidates.

	
		
		Dataset Structure
	

The structure of the raw dataset is as follows:
{
    ""train"": Dataset({
        ""features"": [
          'LPimage', 'image1', 'image2', 'image3', 'image4', 'image5'… See the full description on the dataset page: https://huggingface.co/datasets/cyberagent/BannerBench.",https://huggingface.co/datasets/cyberagent/BannerBench,['ja'],['visual-question-answering'],['n<1K']
hirokisince1998/AGSC-wav,hirokisince1998,2025-08-26 10:01:56+00:00,2025-08-26 10:22:46+00:00,13,0,"['annotations_creators:expert-generated', 'language:ja', 'license:cc-by-nc-4.0', 'modality:audio', 'region:us', 'audio', 'scream', 'shout']","Warning: BETA VERSION. NOT FOR PRODUCTION USE

	
		
		AGSC: Action Gameplay Social Communication Corpus
	


	
		
		Dataset Description
	

The Action Gameplay Social Communication (AGSC) corpus is a collection of spontaneous voice chat recordings from multi-party online gameplay sessions.It focuses on naturally occurring screams and shouts, providing resources for the study of non-verbal expressions in social contexts.

Size: ~7.8 GB of audio
Modality: Audio
Language: Japanese
Annotations:… See the full description on the dataset page: https://huggingface.co/datasets/hirokisince1998/AGSC-wav.",https://huggingface.co/datasets/hirokisince1998/AGSC-wav,['ja'],[],[]
nguyenthanhasia/japanese-legal-cases-2025,nguyenthanhasia,2025-08-27 06:39:13+00:00,2025-08-29 01:31:17+00:00,4,0,"['task_categories:text-classification', 'task_categories:text-generation', 'language:ja', 'license:mit', 'size_categories:10K<n<100K', 'format:json', 'modality:tabular', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us', 'legal', 'japanese', 'court-cases', 'nlp']",,https://huggingface.co/datasets/nguyenthanhasia/japanese-legal-cases-2025,['ja'],"['text-classification', 'text-generation']",['10K<n<100K']
Lego-MT/Parallel_Dataset,Lego-MT,2025-08-27 11:28:55+00:00,2025-08-27 12:06:46+00:00,235,0,"['task_categories:translation', 'language:en', 'language:zh', 'language:es', 'language:fr', 'language:de', 'language:ru', 'language:ja', 'language:th', 'language:sw', 'language:te', 'language:bn', 'language:ar', 'language:ko', 'language:vi', 'language:cs', 'language:hu', 'language:sr', 'license:mit', 'size_categories:1M<n<10M', 'format:json', 'modality:text', 'library:datasets', 'library:dask', 'library:mlcroissant', 'region:us']","
	
		
		Dataset Sources
	


Paper: LegoMT2: Selective Asynchronous Sharded Data Parallel Training for Massive Neural Machine Translation
Link: https://aclanthology.org/2025.findings-acl.1200.pdf
Repository: https://github.com/CONE-MT/CONE

",https://huggingface.co/datasets/Lego-MT/Parallel_Dataset,"['en', 'zh', 'es', 'fr', 'de', 'ru', 'ja', 'th', 'sw', 'te', 'bn', 'ar', 'ko', 'vi', 'cs', 'hu', 'sr']",['translation'],['1M<n<10M']
sbintuitions/WildGuardTestJP,sbintuitions,2025-08-28 06:21:52+00:00,2025-09-22 08:52:32+00:00,269,2,"['task_categories:text-classification', 'language:ja', 'license:odc-by', 'size_categories:1K<n<10K', 'format:csv', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us', 'safety']","
	
		
		WildGuardTestJP
	

WildGuardTestJPは、日本語ガードレールモデルの評価データセットです。
本データセットは、元データのWildGuardTestの敵対的性質を維持するように高品質に翻訳されました。

	
		
		データセット概要
	


言語: 日本語
総サンプル数: 1,725件
用途: 日本語ガードレールモデル評価
ベースデータセット: WildGuardTest


	
		
		翻訳プロセス
	

多段階の翻訳改善戦略を採用しました。

ベース翻訳: 拒否なしの完全なカバレッジを確保するためSeed-X-PPO-7Bモデルを使用
品質改善: 以下の優先順位で高品質な代替翻訳で不良翻訳を置換：
gpt-oss-120b（優先度1）
Qwen2.5-72B-Instruct（優先度2）
gemma-3-27b-it（優先度3）



詳細はテックブログを参照ください。
https://www.sbintuitions.co.jp/blog/entry/2025/09/16/160351

	
		
		引用… See the full description on the dataset page: https://huggingface.co/datasets/sbintuitions/WildGuardTestJP.",https://huggingface.co/datasets/sbintuitions/WildGuardTestJP,['ja'],['text-classification'],['1K<n<10K']
tungvu3196/vlm-projects-multi-lang-final,tungvu3196,2025-08-28 21:31:24+00:00,2025-08-31 04:15:12+00:00,292,1,"['task_categories:question-answering', 'task_categories:visual-question-answering', 'language:en', 'language:vi', 'language:fr', 'language:de', 'language:es', 'language:ru', 'language:ko', 'language:zh', 'language:ja', 'language:th', 'language:id', 'language:ms', 'language:ar', 'language:hi', 'language:tr', 'language:pt', 'size_categories:100K<n<1M', 'format:parquet', 'modality:image', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","
	
		
		My Final Multilingual Medical VQA Dataset
	

This dataset is organized into multiple configurations (subsets), one for each language.
You can load a specific language subset like this:
from datasets import load_dataset
vi_train = load_dataset(""tungvu3196/vlm-projects-multi-lang-final"", ""Vietnamese"", split=""train"")

",https://huggingface.co/datasets/tungvu3196/vlm-projects-multi-lang-final,"['en', 'vi', 'fr', 'de', 'es', 'ru', 'ko', 'zh', 'ja', 'th', 'id', 'ms', 'ar', 'hi', 'tr', 'pt']","['question-answering', 'visual-question-answering']",['100K<n<1M']
tungvu3196/vlm-projects-multi-lang-final-v2,tungvu3196,2025-08-29 04:04:47+00:00,2025-08-29 04:13:51+00:00,34,0,"['task_categories:question-answering', 'task_categories:visual-question-answering', 'language:en', 'language:vi', 'language:fr', 'language:de', 'language:es', 'language:ru', 'language:ko', 'language:zh', 'language:ja', 'language:th', 'language:id', 'language:ms', 'language:ar', 'language:hi', 'language:tr', 'language:pt', 'size_categories:100K<n<1M', 'format:parquet', 'modality:image', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","
	
		
		My Final Multilingual Medical VQA Dataset
	

This dataset is organized into multiple configurations (subsets), one for each language.
You can load a specific language subset like this:
from datasets import load_dataset

# Load the Vietnamese training data
vi_train = load_dataset(""tungvu3196/vlm-projects-multi-lang-final-v2"", ""Vietnamese"", split=""train"")

# Load the English testing data
en_test = load_dataset(""tungvu3196/vlm-projects-multi-lang-final-v2"", ""English"", split=""test"")

",https://huggingface.co/datasets/tungvu3196/vlm-projects-multi-lang-final-v2,"['en', 'vi', 'fr', 'de', 'es', 'ru', 'ko', 'zh', 'ja', 'th', 'id', 'ms', 'ar', 'hi', 'tr', 'pt']","['question-answering', 'visual-question-answering']",['100K<n<1M']
bsmu/MLC-SLM-Eval,bsmu,2025-08-31 06:48:07+00:00,2025-09-25 02:30:04+00:00,593,1,"['task_categories:automatic-speech-recognition', 'language:en', 'language:fr', 'language:de', 'language:it', 'language:ja', 'language:ko', 'language:pt', 'language:ru', 'language:es', 'language:th', 'language:vi', 'license:cc-by-sa-4.0', 'size_categories:10K<n<100K', 'arxiv:2509.13785', 'region:us']","
	
		
		Interspeech2025 Multilingual Conversational Speech Language Model (MLC-SLM) Eval Groundtruth
	






	
		
		🖥️ Overview
	

In the MLC-SLM challenge, we only provided the participants with the audio files of the Eval sets.
Now, we release the oracle segmentation, speaker labels, and transcriptions of the Eval sets to facilitate further research by all participants on the MLC-SLM dataset！
In addition, the MLC-SLM challenge summary paper ""Summary on The Multilingual Conversational Speech… See the full description on the dataset page: https://huggingface.co/datasets/bsmu/MLC-SLM-Eval.",https://huggingface.co/datasets/bsmu/MLC-SLM-Eval,"['en', 'fr', 'de', 'it', 'ja', 'ko', 'pt', 'ru', 'es', 'th', 'vi']",['automatic-speech-recognition'],['10K<n<100K']
li-lab/HealthBenchX,li-lab,2025-09-01 02:43:39+00:00,2025-09-29 05:16:34+00:00,24,1,"['task_categories:translation', 'task_categories:question-answering', 'language:en', 'language:ja', 'license:mit', 'size_categories:1K<n<10K', 'region:us', 'medical']","
	
		
		HealthBenchX: Machine Translation of HealthBench Conversations based on GPT-5
	


	
		
		Overview
	

HealthBenchXP is a machine-translated version of HealthBench, a benchmark designed to measure the capabilities of AI systems in health-related tasks.  
The original HealthBench was built in collaboration with 262 physicians across 60 countries and includes 5,000 realistic health conversations, each paired with a custom physician-created rubric for evaluation.  
Our contribution: we… See the full description on the dataset page: https://huggingface.co/datasets/li-lab/HealthBenchX.",https://huggingface.co/datasets/li-lab/HealthBenchX,"['en', 'ja']","['translation', 'question-answering']",['1K<n<10K']
future-architect/Llama-3.3-Future-Code-Instructions,future-architect,2025-09-01 07:24:14+00:00,2025-09-01 07:26:24+00:00,60,0,"['language:en', 'language:ja', 'license:llama3.3', 'size_categories:1M<n<10M', 'format:parquet', 'modality:text', 'library:datasets', 'library:dask', 'library:mlcroissant', 'library:polars', 'arxiv:2406.08464', 'region:us', 'llama-3', 'code']","
	
		
		Llama 3.3 Future Code Instructions
	

Llama 3.3 Future Code Instructions is a large-scale instruction dataset synthesized with the Meta Llama 3.3 70B Instruct model.
The dataset was generated with the method called Magpie, where we prompted the model to generate instructions likely to be asked by the users.
In addition to the original prompt introduced by the authors, we conditioned the system prompt on what specific programming language the user has an interest in, gaining control… See the full description on the dataset page: https://huggingface.co/datasets/future-architect/Llama-3.3-Future-Code-Instructions.",https://huggingface.co/datasets/future-architect/Llama-3.3-Future-Code-Instructions,"['en', 'ja']",[],['1M<n<10M']
Silviase/JPCharRecog_v1.1,Silviase,2025-09-01 12:13:49+00:00,2025-09-01 16:50:56+00:00,8,0,"['task_categories:image-classification', 'task_ids:multi-class-image-classification', 'multilinguality:monolingual', 'language:ja', 'license:apache-2.0', 'size_categories:10K<n<100K', 'format:parquet', 'modality:image', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us', 'ocr', 'japanese', 'cjk', 'synthetic', 'font', 'rendered', 'single-character', 'document-ai']","
	
		
		JPCharRecog_v1.1
	

JPCharRecog v1.1 は、日本語の単文字（CJK を含む）認識を目的とした、合成レンダリング画像のデータセットです。純視覚要因（フォントファミリ/ウェイト/文字サイズ/劣化）を操作可能な設計で、辞書や文脈の寄与を切り分けるためのベンチマーク用途を想定しています。

Task: Single-character recognition (JPCharRecog-like)
Language: Japanese (CJK)
Families: NotoSansJP, NotoSerifJP
Weights: ExtraLight, Regular, Black
Sizes(px): 12, 64, 96
Effects: none (PNG)


	
		
		Purpose
	


語彙や文脈による補正を排し、モデルの純粋な「読取り」能力を単文字で測るための基礎ベンチです。
フォント設計や最小線幅、エイリアシングの影響を、ウェイトやサイズの系統操作で定量化します。
OCR… See the full description on the dataset page: https://huggingface.co/datasets/Silviase/JPCharRecog_v1.1.",https://huggingface.co/datasets/Silviase/JPCharRecog_v1.1,['ja'],['image-classification'],['10K<n<100K']
MakiAi/the-Embodiment-of-Scarlet-Devil-Instruct-Alpaca-QA-JP-v1,MakiAi,2025-09-01 12:59:44+00:00,2025-09-01 21:23:20+00:00,27,1,"['task_categories:question-answering', 'task_categories:text-generation', 'language:ja', 'license:mit', 'size_categories:10K<n<100K', 'format:parquet', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us', 'alpaca', 'qa', 'japanese']","
	
		
		Converted QA Dataset
	

このデータセットは、easy-dataset-cliを使用して生成されたアルパカ形式の日本語Q&Aデータセットです。

	
		
		データセット概要
	


総エントリ数: 97,202
形式: Alpaca形式
言語: 日本語
ライセンス: MIT


	
		
		データ構造
	

各エントリは以下の形式です：
{
  ""instruction"": ""質問文"",
  ""input"": """",
  ""output"": ""回答文"",
  ""genre"": ""ジャンル"",
  ""audience"": ""対象読者""
}


		
	
		ジャンル分布
	

含まれるジャンル:

FAQ
PRD
RFP/提案書
アーキレビュー
エグゼクティブサマリ
ガイドライン/ポリシー
ケーススタディ
セキュリティレビュー
チュートリアル
ハンズオン課題
ベストプラクティス集
ワークショップ資料
実験レポート
対話形式
技術ブログ
教科書
業界別ケーススタディ
法務チェックリスト
運用Runbook


	
		
		対象読者分布… See the full description on the dataset page: https://huggingface.co/datasets/MakiAi/the-Embodiment-of-Scarlet-Devil-Instruct-Alpaca-QA-JP-v1.",https://huggingface.co/datasets/MakiAi/the-Embodiment-of-Scarlet-Devil-Instruct-Alpaca-QA-JP-v1,['ja'],"['question-answering', 'text-generation']",['10K<n<100K']
urgent-challenge/urgent2025-sqa,urgent-challenge,2025-09-02 07:07:40+00:00,2025-09-02 10:42:22+00:00,340,0,"['language:en', 'language:zh', 'language:ja', 'language:de', 'language:es', 'language:fr', 'license:cc-by-nc-sa-4.0', 'size_categories:100K<n<1M', 'format:parquet', 'modality:audio', 'modality:text', 'library:datasets', 'library:dask', 'library:mlcroissant', 'library:polars', 'arxiv:2507.11306', 'arxiv:2506.12260', 'arxiv:2505.23212', 'region:us', 'audio', 'speech', 'speech enhancement', 'speech quality assessment']","
	
		
		Dataset Description
	

This dataset comprises noisy and enhanced speech from the URGENT Speech Enhancement Challenge (Interspeech 2025), curated for SQA/SE research. Each entry includes audio/IDs with a comprehensive suite of objective and model-predicted quality metrics, and human MOS where available (see Data fields).


The MOS label for each speech sample were collected from 8 distinct human subjects through Amazon Mechanical Turk (MTurk) platform, following the P.808… See the full description on the dataset page: https://huggingface.co/datasets/urgent-challenge/urgent2025-sqa.",https://huggingface.co/datasets/urgent-challenge/urgent2025-sqa,"['en', 'zh', 'ja', 'de', 'es', 'fr']",[],['100K<n<1M']
jdhwang/s1K-X,jdhwang,2025-09-04 00:29:03+00:00,2025-09-04 01:14:45+00:00,35,0,"['task_categories:question-answering', 'language:bn', 'language:de', 'language:es', 'language:fr', 'language:ja', 'language:ru', 'language:sw', 'language:te', 'language:th', 'language:zh', 'language:en', 'size_categories:10K<n<100K', 'format:parquet', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'arxiv:2507.05418', 'arxiv:2501.19393', 'region:us', 'math']","
	
		
		s1K-X
	

We used Google Translate to translate simplescaling/s1K-1.1_tokenized
into 10 different languages used in MGSM
to evaluate whether supervised fine-tuning on translated texts can mitigate catastrophic forgetting in reasoning in the question language (Hwang et al., 2025)
The dataset includes below languages:

English (en) -- the original simplescaling/s1K-1.1_tokenized
Bengali (bn)
German (de)
Spanish (es)
French (fr)
Japanese (ja)
Russian (ru)
Swahili (sw)
Telugu (te)
Thai (th)… See the full description on the dataset page: https://huggingface.co/datasets/jdhwang/s1K-X.",https://huggingface.co/datasets/jdhwang/s1K-X,"['bn', 'de', 'es', 'fr', 'ja', 'ru', 'sw', 'te', 'th', 'zh', 'en']",['question-answering'],['10K<n<100K']
thanh309/jawiki_100k,thanh309,2025-09-05 02:00:11+00:00,2025-09-05 02:46:27+00:00,15,0,"['task_categories:text-classification', 'task_categories:text-generation', 'language:ja', 'license:cc-by-sa-4.0', 'size_categories:10K<n<100K', 'modality:text', 'region:us', 'text']","
	
		
		Japanese Wikipedia Dataset
	

This dataset is a random sample of 99,767 articles from the Japanese Wikipedia, as of 20220808.
Each article is stored as a separate text file, with the filename corresponding to the article's title.
",https://huggingface.co/datasets/thanh309/jawiki_100k,['ja'],"['text-classification', 'text-generation']",['10K<n<100K']
li-lab/GlobMed-JP,li-lab,2025-09-05 13:38:53+00:00,2025-09-05 14:02:51+00:00,23,0,"['task_categories:question-answering', 'language:ja', 'language:en', 'license:mit', 'size_categories:n<1K', 'format:json', 'modality:tabular', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us', 'medical']","This is the sample data for our ongoing project. 
",https://huggingface.co/datasets/li-lab/GlobMed-JP,"['ja', 'en']",['question-answering'],['n<1K']
rubricreward/mR3-Dataset-100K-EasyToHard,rubricreward,2025-09-07 04:50:35+00:00,2025-10-06 15:49:19+00:00,266,0,"['language:aa', 'language:af', 'language:ar', 'language:as', 'language:az', 'language:be', 'language:bg', 'language:bn', 'language:bs', 'language:ca', 'language:cs', 'language:da', 'language:de', 'language:el', 'language:en', 'language:es', 'language:et', 'language:eu', 'language:fa', 'language:fi', 'language:fr', 'language:ha', 'language:he', 'language:hi', 'language:hr', 'language:hu', 'language:hy', 'language:id', 'language:ie', 'language:it', 'language:iw', 'language:ja', 'language:ka', 'language:kk', 'language:ko', 'language:ku', 'language:la', 'language:lt', 'language:lv', 'language:mk', 'language:ms', 'language:my', 'language:nl', 'language:nn', 'language:no', 'language:oc', 'language:pl', 'language:pt', 'language:ro', 'language:ru', 'language:rw', 'language:sa', 'language:sco', 'language:si', 'language:sk', 'language:sl', 'language:sr', 'language:sv', 'language:sw', 'language:ta', 'language:th', 'language:tl', 'language:tlh', 'language:tr', 'language:tt', 'language:uk', 'language:vi', 'language:vo', 'language:war', 'language:xh', 'language:zh', 'license:cc-by-4.0', 'size_categories:100K<n<1M', 'format:parquet', 'modality:text', 'library:datasets', 'library:dask', 'library:mlcroissant', 'library:polars', 'arxiv:2510.01146', 'region:us']","This is the dataset used to train mR3 models.
If you find our dataset useful, please cite our paper!
@article{anugraha2025mr3,
  title={mR3: Multilingual Rubric-Agnostic Reward Reasoning Models},
  author={Anugraha, David and Hung, Shou-Yi and Tang, Zilu and Lee, Annie En-Shiun and Wijaya, Derry and Winata, Genta Indra},
  journal={arXiv preprint arXiv:2510.01146},
  year={2025}
}

",https://huggingface.co/datasets/rubricreward/mR3-Dataset-100K-EasyToHard,"['aa', 'af', 'ar', 'as', 'az', 'be', 'bg', 'bn', 'bs', 'ca', 'cs', 'da', 'de', 'el', 'en', 'es', 'et', 'eu', 'fa', 'fi', 'fr', 'ha', 'he', 'hi', 'hr', 'hu', 'hy', 'id', 'ie', 'it', 'iw', 'ja', 'ka', 'kk', 'ko', 'ku', 'la', 'lt', 'lv', 'mk', 'ms', 'my', 'nl', 'nn', 'no', 'oc', 'pl', 'pt', 'ro', 'ru', 'rw', 'sa', 'sco', 'si', 'sk', 'sl', 'sr', 'sv', 'sw', 'ta', 'th', 'tl', 'tlh', 'tr', 'tt', 'uk', 'vi', 'vo', 'war', 'xh', 'zh']",[],['100K<n<1M']
zjy1298/NOVA-63,zjy1298,2025-09-07 06:59:33+00:00,2025-09-19 07:19:35+00:00,46,0,"['language:ar', 'language:zh', 'language:en', 'language:fr', 'language:es', 'language:pt', 'language:de', 'language:it', 'language:vi', 'language:ja', 'language:ko', 'language:id', 'license:mit', 'region:us']","
	
	
	
		We released this dataset under the MIT License. This means that anyone is free to use, copy, modify, distribute, and reuse our data, provided that the original copyright notice and license information are retained.
This work is jointly completed by PKU & Alibaba Group. The dataset is currently under review. Please be patient. We also hope this dataset can help more partners/colleagues in the community.
To ensure the validity and fairness of the benchmark evaluation, we explicitly… See the full description on the dataset page: https://huggingface.co/datasets/zjy1298/NOVA-63.",https://huggingface.co/datasets/zjy1298/NOVA-63,"['ar', 'zh', 'en', 'fr', 'es', 'pt', 'de', 'it', 'vi', 'ja', 'ko', 'id']",[],[]
Aster1231/XVideos-250k,Aster1231,2025-09-07 11:55:38+00:00,2025-09-07 19:43:41+00:00,17,0,"['language:en', 'language:ja', 'language:ru', 'language:es', 'license:odc-by', 'size_categories:100K<n<1M', 'region:us', 'not-for-all-audiences']","A datatset of just over 250,000 porn videos all sourced from XVideos.
The dataset includes:

A link to the video
The video name
The video length
Who uploaded the video
Actors in the video
Tags
The positive rating
The negative rating
The highest quality the video comes in

The scraper used was not perfect and as such sometimes the number of views are missing.
",https://huggingface.co/datasets/Aster1231/XVideos-250k,"['en', 'ja', 'ru', 'es']",[],['100K<n<1M']
amaurygau/ClipCJK_Gen,amaurygau,2025-09-08 15:39:50+00:00,2025-09-13 00:49:37+00:00,15,0,"['multilinguality:monolingual', 'language:ja', 'license:cc-by-nc-4.0', 'size_categories:10K<n<100K', 'modality:image', 'modality:text', 'region:us', 'image', 'text', 'ocr', 'optical-character-recognition', 'VLM', 'vision-language-transformer', 'japanese']","
	
		
		Dataset Card for CLIPCJK_Gen
	


	
		
		Dataset summary
	

The CLIPCJK_Gen Dataset is a Japanese-language dataset of images generated from 17 japanese fonts and is supposedly used to train a CLIP-like model for japanese character recognition.
This dataset contains 2414 classes representing mostly Japanese characters but also punctuation, latin alphabet, etc.

	
		
		How to use
	

This dataset is stored in the WebDataset format. To use it, you need to install the webdataset and… See the full description on the dataset page: https://huggingface.co/datasets/amaurygau/ClipCJK_Gen.",https://huggingface.co/datasets/amaurygau/ClipCJK_Gen,['ja'],[],['10K<n<100K']
stanford-oval/churro-dataset,stanford-oval,2025-09-09 09:54:12+00:00,2025-10-02 05:43:33+00:00,657,1,"['task_categories:image-to-text', 'language:en', 'language:es', 'language:ja', 'language:bn', 'language:de', 'language:sv', 'language:fa', 'language:tr', 'language:hi', 'language:fi', 'language:fr', 'language:bg', 'language:cs', 'language:nl', 'language:la', 'language:pl', 'language:ro', 'language:sa', 'language:zh', 'language:sl', 'language:ar', 'language:ca', 'language:el', 'language:he', 'language:it', 'language:km', 'language:no', 'language:pt', 'language:vi', 'size_categories:10K<n<100K', 'format:parquet', 'modality:image', 'modality:text', 'library:datasets', 'library:dask', 'library:mlcroissant', 'library:polars', 'arxiv:2509.19768', 'region:us', 'historical']","
    
    CHURRO: Making History Readable with an Open-Weight Large Vision-Language Model for High-Accuracy, Low-Cost Historical Text Recognition
    
        
        
        
        


    Handwritten and printed text recognition across 22 centuries and 46 language clusters, including historical and dead languages.



    
    
    Cost vs. accuracy: CHURRO (3B) achieves higher accuracy than much larger commercial and open-weight VLMs while being substantially cheaper.


CHURRO is a… See the full description on the dataset page: https://huggingface.co/datasets/stanford-oval/churro-dataset.",https://huggingface.co/datasets/stanford-oval/churro-dataset,"['en', 'es', 'ja', 'bn', 'de', 'sv', 'fa', 'tr', 'hi', 'fi', 'fr', 'bg', 'cs', 'nl', 'la', 'pl', 'ro', 'sa', 'zh', 'sl', 'ar', 'ca', 'el', 'he', 'it', 'km', 'no', 'pt', 'vi']",['image-to-text'],['10K<n<100K']
ichikara-ai/ichikara-pdf2summary,ichikara-ai,2025-09-10 18:01:15+00:00,2025-09-10 18:01:17+00:00,20,0,"['language:ja', 'license:other', 'size_categories:n<1K', 'modality:text', 'region:us']","
	
		
		ichikara-pdf2summary 定義書
	

2025 年 4 月 4 日株式会社いちから

	
		
		1. データの概要
	

ichikara-pdf2summary の定義を行う。ichikara-pdf2summary とは、文章イメージデータ（本データでは PDF ファイル）からその要点・要約を作る LLM の学習データである。文章イメージデータは日本の官公庁が発行しているものを使っており、官公庁のリストは以下の通りである。各官公庁から「データ数」に示されている PDF データを利用している。

	
		
組織名
英訳（フォルダ名）
データ数


		
デジタル庁
DigitalAgency
15


内閣府
CAO
3


農林水産省
MAFF
1


文部科学省
MEXT
11


厚生労働省
MHLW
35


総務省
MIC
7


外務省
MOFA
13


法務省
MOJ
30


復興庁
ReconstructionAgency
10


	


	
		
		2. ファイルとバージョン
	

バージョンは、ファイル名及びデータ… See the full description on the dataset page: https://huggingface.co/datasets/ichikara-ai/ichikara-pdf2summary.",https://huggingface.co/datasets/ichikara-ai/ichikara-pdf2summary,['ja'],[],['n<1K']
ichikara-ai/ichikara-jmtbench,ichikara-ai,2025-09-10 18:01:18+00:00,2025-09-10 18:01:20+00:00,18,0,"['language:ja', 'license:other', 'size_categories:n<1K', 'modality:text', 'region:us']","
	
		
		ichikara-jmtbench 定義書
	

2025 年 4 月 4 日株式会社いちから

	
		
		1. データの概要
	

ichikara-jmtbench の定義を行う。これはいわゆる MTbench のようなオリジナルの日本語データである。フォーマットは MTbench101 を参考にしているがデータ構成が異なるために、異なる部分があることに注意されたい。下記の 8 分野についてのデータがある。

	
		
分野
データ数


		
math
75


STEM
70


writing
50


humanities
50


roleplay
50


reasoning
75


coding
49


extraction
43


	


	
	
	
		2. ファイルとバージョン
	

バージョンは、ファイル名及びデータ ID に利用される。二つの数字からなる。ファイル名は下記のような構造になっている。ichikara-jmtbench-<MajorVersion>-<MinorVersion>.json… See the full description on the dataset page: https://huggingface.co/datasets/ichikara-ai/ichikara-jmtbench.",https://huggingface.co/datasets/ichikara-ai/ichikara-jmtbench,['ja'],[],['n<1K']
ichikara-ai/ichikara-76Kprompts,ichikara-ai,2025-09-10 18:01:21+00:00,2025-09-10 18:01:24+00:00,22,0,"['language:ja', 'license:other', 'size_categories:10K<n<100K', 'format:json', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","
	
		
		ichikara-76Kprompts 定義書
	

2025 年 4 月 4 日株式会社いちから

	
		
		1. データの種類
	

「自然な質問例を集めたデータ（通称：ichikara-76Kprompts）」の定義を行う。

version 001-001 は全部で 76,638 件の質問からなるデータである。
IF を通じ、一般利用者が無料で有料 LLM を提供し、代わりに作成した質問の著作権を提供頂く形で集めた質問のデータセットである。
主に「一般」から個人情報、誹謗中傷を人手で削除し、重複も１つを残しそれ以外は削除している。


	
		
		2. ファイルとバージョン
	

バージョンは、ファイル名及びデータ ID に利用される。二つの数字からなる。ファイル名は下記のような構造になっている。ichikara-76Kprompts-<MajorVersion>-<MinorVersion>.json

	
		
		バージョンの定義… See the full description on the dataset page: https://huggingface.co/datasets/ichikara-ai/ichikara-76Kprompts.",https://huggingface.co/datasets/ichikara-ai/ichikara-76Kprompts,['ja'],[],['10K<n<100K']
ichikara-ai/ichikara-GSM8Ktest-humantranslation,ichikara-ai,2025-09-10 18:01:25+00:00,2025-09-10 18:01:27+00:00,24,0,"['language:ja', 'license:other', 'size_categories:1K<n<10K', 'format:json', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'arxiv:2110.14168', 'region:us']","
	
		
		ichikara-GSM8Ktest-humantranslation 定義書
	

2025 年 9 月 12 日株式会社いちから

	
		
		1. データの種類
	

「算数データ（通称：ichikara-GSM8Ktest-humantranslation）」の定義を行う。本データは OpenAI が公開した英語の小学校算数問題[1]を株式会社 ELYZA が機械翻訳で日本語に翻訳したもの[2]をさらに意訳したものである。本データは英語問題に出る“mile”、“gallon”といった日本語圏では馴染みのない単位や直訳独特の不自然さを除去し、自然かつ教科書問題のような丁寧な日本語で質問および回答が書かれている。GSM8K データのうち、テストデータ 1309 件に対応する日本語の質問回答データを公開する。

	
		
		2. ファイルとバージョン
	

バージョンは、ファイル名及びデータ ID… See the full description on the dataset page: https://huggingface.co/datasets/ichikara-ai/ichikara-GSM8Ktest-humantranslation.",https://huggingface.co/datasets/ichikara-ai/ichikara-GSM8Ktest-humantranslation,['ja'],[],['1K<n<10K']
ichikara-ai/ichikara-exam,ichikara-ai,2025-09-10 18:01:28+00:00,2025-09-10 18:01:31+00:00,23,0,"['language:ja', 'license:other', 'size_categories:n<1K', 'format:json', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","
	
		
		ichikara-exam 定義書
	

2025 年 4 月 4 日株式会社いちから

	
		
		1. データの概要
	

中学および高校の試験問題（通称：ichikara-exam）」の定義を行う。国語、算数/数学、理科、社会、英語が用意されている。各データの件数は下記のとおりである。

	
		
科目
中学
高校


		
国語
39 問(2 回分)
34 問(2 回分)


算数/数学
17 問
15 問


理科
17 問
24 問


社会
22 問
17 問


英語
16 問
16 問


	


	
	
	
		2. ファイルとバージョン
	

バージョンは、ファイル名及びデータ ID に利用される。二つの数字からなる。ファイル名は下記のような構造になっている。ichikara-exam-<MajorVersion>-<MinorVersion>.json
	
		
		バージョンの定義
	


MajorVersion：データのメジャーバージョン（この番号が違うデータ間は互換性がなく、同時に使うことは避けるべきである）… See the full description on the dataset page: https://huggingface.co/datasets/ichikara-ai/ichikara-exam.",https://huggingface.co/datasets/ichikara-ai/ichikara-exam,['ja'],[],['n<1K']
Nexdata/INTERSPEECH_2025_MLC-SLM_Challenge_Dataset,Nexdata,2025-09-11 02:22:44+00:00,2025-09-16 08:47:57+00:00,75,0,"['language:en', 'language:fr', 'language:de', 'language:it', 'language:es', 'language:pt', 'language:ja', 'license:cc-by-nc-3.0', 'region:us']","
	
		
		Description
	

The INTERSPEECH 2025 MLC-SLM Challenge Dataset, curated by Datatang, is derived from fifteen proprietary conversational speech corpora. Distinguished by exceptional annotation accuracy and operational reliability, this dataset is engineered to address critical challenges in multilingual automatic speech recognition (ASR) and long-context comprehension. It meticulously replicates real-world complexities including spontaneous interruptions and speaker overlaps across 11… See the full description on the dataset page: https://huggingface.co/datasets/Nexdata/INTERSPEECH_2025_MLC-SLM_Challenge_Dataset.",https://huggingface.co/datasets/Nexdata/INTERSPEECH_2025_MLC-SLM_Challenge_Dataset,"['en', 'fr', 'de', 'it', 'es', 'pt', 'ja']",[],[]
Nexdata/200_Hours_Japanese_Spontaneous_Dialogue_Dataset_Smartphone_Multi-Stream_Audio,Nexdata,2025-09-11 02:43:20+00:00,2025-09-16 08:44:55+00:00,67,0,"['language:ja', 'license:cc-by-nc-nd-3.0', 'region:us']","
	
		
		Description
	

Japanese(Japan) Multi-stream Spontaneous Dialogue Smartphone speech dataset, collected from dialogues based on given topics. Transcribed with text content, speaker's ID, gender, age and other attributes. Our dataset was collected from extensive and diversify speakers, geographicly speaking, enhancing model performance in real and complex tasks.
For more details, please refer to the link: https://www.nexdata.ai/datasets/speechrecog/1703?source=huggingface… See the full description on the dataset page: https://huggingface.co/datasets/Nexdata/200_Hours_Japanese_Spontaneous_Dialogue_Dataset_Smartphone_Multi-Stream_Audio.",https://huggingface.co/datasets/Nexdata/200_Hours_Japanese_Spontaneous_Dialogue_Dataset_Smartphone_Multi-Stream_Audio,['ja'],[],[]
mteb-private/JapaneseCode1Retrieval-sample,mteb-private,2025-09-11 10:30:30+00:00,2025-09-16 12:59:05+00:00,114,0,"['task_categories:text-retrieval', 'task_ids:document-retrieval', 'annotations_creators:derived', 'multilinguality:monolingual', 'language:ja', 'license:cc-by-sa-4.0', 'size_categories:n<1K', 'format:parquet', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us', 'mteb', 'text', 'code', 'japanese', 'sample']","
	
		
		JapaneseCode1Retrieval-sample
	

A sample dataset for Japanese-English code retrieval evaluation. This dataset contains Japanese natural language descriptions paired with Python code snippets.

	
		
		Task category
	

Retrieval

	
		
		Domains
	

Programming, Code Generation

	
		
		Dataset Structure
	

The dataset follows the standard MTEB retrieval format:

corpus/corpus-00000-of-00001.parquet: 5 Python code documents with fields _id, title, text… See the full description on the dataset page: https://huggingface.co/datasets/mteb-private/JapaneseCode1Retrieval-sample.",https://huggingface.co/datasets/mteb-private/JapaneseCode1Retrieval-sample,['ja'],['text-retrieval'],['n<1K']
DSULT-Core/2ch.sc,DSULT-Core,2025-09-11 11:25:47+00:00,2025-09-11 16:06:01+00:00,479,2,"['language:ja', 'size_categories:10K<n<100K', 'format:json', 'modality:tabular', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","
	
		
		2ch.sc Corpus
	


	
		
		A Large-Scale Japanese Anonymous Web Forum Dataset
	

This dataset is a large-scale corpus of user-generated text scraped from 2ch.sc, a massive and influential anonymous Japanese textboard. As a major successor to the original 2channel (2ch.net), it represents a significant, unfiltered snapshot of Japanese internet culture, dialogue, and public opinion spanning decades. The data consists of billions of posts across thousands of topic-specific boards, offering… See the full description on the dataset page: https://huggingface.co/datasets/DSULT-Core/2ch.sc.",https://huggingface.co/datasets/DSULT-Core/2ch.sc,['ja'],[],['10K<n<100K']
jed351/fineweb-ja-keyword-hk,jed351,2025-09-12 05:58:38+00:00,2025-09-12 06:02:26+00:00,81,0,"['language:ja', 'size_categories:1M<n<10M', 'format:parquet', 'modality:text', 'library:datasets', 'library:dask', 'library:mlcroissant', 'library:polars', 'region:us']","As part of some ongoing research, I downloaded the Japanese fineweb2 and performed a keyword search of ""香港"" (Hong Kong)
",https://huggingface.co/datasets/jed351/fineweb-ja-keyword-hk,['ja'],[],['1M<n<10M']
agentlans/multilingual-text,agentlans,2025-09-12 09:32:04+00:00,2025-09-14 20:24:18+00:00,318,0,"['task_categories:text-generation', 'task_categories:text-classification', 'language:am', 'language:ar', 'language:bn', 'language:de', 'language:en', 'language:es', 'language:fa', 'language:fr', 'language:ha', 'language:he', 'language:hi', 'language:id', 'language:it', 'language:ja', 'language:jv', 'language:ko', 'language:mr', 'language:ms', 'language:my', 'language:nl', 'language:pa', 'language:pl', 'language:pt', 'language:ro', 'language:ru', 'language:sw', 'language:ta', 'language:te', 'language:th', 'language:tl', 'language:tr', 'language:uk', 'language:ur', 'language:vi', 'language:yo', 'language:zh', 'license:odc-by', 'size_categories:1M<n<10M', 'modality:text', 'region:us', 'multilingual', 'text', 'corpus', 'language']","
	
		
		Multilingual Text Dataset
	

This dataset contains a curated selection of rows from multiple input datasets, where each row includes a text chunk of approximately 2000 tokens (as measured by Llama 3.1 tokenizer) verified to be written in the correct language. Only rows with properly classified language chunks are retained, ensuring high-quality multilingual data for analysis or model training.

	
		
		Preprocessing Steps
	


Normalized whitespace, punctuation, Unicode characters, and… See the full description on the dataset page: https://huggingface.co/datasets/agentlans/multilingual-text.",https://huggingface.co/datasets/agentlans/multilingual-text,"['am', 'ar', 'bn', 'de', 'en', 'es', 'fa', 'fr', 'ha', 'he', 'hi', 'id', 'it', 'ja', 'jv', 'ko', 'mr', 'ms', 'my', 'nl', 'pa', 'pl', 'pt', 'ro', 'ru', 'sw', 'ta', 'te', 'th', 'tl', 'tr', 'uk', 'ur', 'vi', 'yo', 'zh']","['text-generation', 'text-classification']",['1M<n<10M']
mteb-private/JapaneseLegal1Retrieval-sample,mteb-private,2025-09-12 10:53:53+00:00,2025-09-16 14:07:53+00:00,92,0,"['task_categories:text-retrieval', 'task_ids:document-retrieval', 'annotations_creators:derived', 'multilinguality:monolingual', 'language:ja', 'license:other', 'modality:text', 'region:us', 'mteb', 'text', 'retrieval', 'sample']","
	
		
		JapaneseLegal1Retrieval-sample
	

A sample dataset for Japanese legal regulation retrieval evaluation.

	
		
		Task category
	

Retrieval

	
		
		Domains
	

Legal, Government

	
		
		Dataset Structure
	

The dataset follows the standard MTEB retrieval format:

corpus/corpus-00000-of-00001.parquet: 10 documents with fields _id, title, text
queries/queries-00000-of-00001.parquet: 6 queries with fields _id, text  
data/test-00000-of-00001.parquet: 6 relevance judgments with fields… See the full description on the dataset page: https://huggingface.co/datasets/mteb-private/JapaneseLegal1Retrieval-sample.",https://huggingface.co/datasets/mteb-private/JapaneseLegal1Retrieval-sample,['ja'],['text-retrieval'],[]
Taise228/SOBACO,Taise228,2025-09-12 15:12:08+00:00,2025-09-30 06:58:31+00:00,27,0,"['task_categories:question-answering', 'language:ja', 'license:cc-by-sa-4.0', 'size_categories:10K<n<100K', 'format:json', 'modality:tabular', 'modality:text', 'library:datasets', 'library:dask', 'library:mlcroissant', 'arxiv:2509.24468', 'region:us', 'bias', 'culture']","
	
		
		SOBACO (Social Bias and Cultural Commonsense Benchmark)
	

SOBACO is a benchmark to measure social biases and cultural commonsense of LLMs in an unified multiple-choice question-answering format.
SOBACO can be used to measure the trade-off between social bias and cultural commonsense (e.g., when applying bias mitigation techniques).
All the problems are written in Japanese.
The problems are created from the templates, varying wordings and orderings of answer choices.
For the detailed… See the full description on the dataset page: https://huggingface.co/datasets/Taise228/SOBACO.",https://huggingface.co/datasets/Taise228/SOBACO,['ja'],['question-answering'],['10K<n<100K']
disco-eth/GlobalDISCO,disco-eth,2025-09-13 08:41:54+00:00,2025-10-03 08:59:14+00:00,424,0,"['task_categories:audio-classification', 'language:en', 'language:es', 'language:fr', 'language:de', 'language:pt', 'language:ja', 'language:it', 'language:fi', 'language:pl', 'language:tr', 'language:ru', 'language:ko', 'language:hi', 'language:nl', 'language:id', 'language:da', 'language:zh', 'language:sv', 'language:cs', 'language:hu', 'language:vi', 'language:nb', 'language:ur', 'language:fa', 'language:bg', 'language:uk', 'language:pa', 'language:he', 'language:ro', 'language:zu', 'language:ta', 'language:lt', 'language:ar', 'language:af', 'language:sk', 'language:bn', 'language:el', 'language:is', 'language:et', 'language:sl', 'language:la', 'language:az', 'license:mit', 'size_categories:10K<n<100K', 'format:parquet', 'modality:audio', 'modality:text', 'library:datasets', 'library:dask', 'library:mlcroissant', 'library:polars', 'arxiv:2510.01963', 'region:us', 'music', 'audio', 'text']","
	
		
		GlobalDISCO
	

GlobalDISCO is a large-scale dataset consisting of 73k music tracks generated by state-of-the-art commercial generative music models, along with paired links to 93k reference tracks in LAION-DISCO-12M. The dataset spans 147 languages and includes musical style prompts extracted from MusicBrainz and Wikipedia. The dataset is globally balanced, representing musical styles from artists across 79 countries and five continents. It is aimed to support the research community in… See the full description on the dataset page: https://huggingface.co/datasets/disco-eth/GlobalDISCO.",https://huggingface.co/datasets/disco-eth/GlobalDISCO,"['en', 'es', 'fr', 'de', 'pt', 'ja', 'it', 'fi', 'pl', 'tr', 'ru', 'ko', 'hi', 'nl', 'id', 'da', 'zh', 'sv', 'cs', 'hu', 'vi', 'nb', 'ur', 'fa', 'bg', 'uk', 'pa', 'he', 'ro', 'zu', 'ta', 'lt', 'ar', 'af', 'sk', 'bn', 'el', 'is', 'et', 'sl', 'la', 'az']",['audio-classification'],['10K<n<100K']
ce-lery/merged-corpus,ce-lery,2025-09-15 02:41:01+00:00,2025-09-15 16:34:18+00:00,132,0,"['task_categories:text-generation', 'language:ja', 'size_categories:10M<n<100M', 'format:json', 'modality:text', 'library:datasets', 'library:dask', 'library:mlcroissant', 'region:us']","
	
		
		Merged Corpus
	

Welcome to this repository.This dataset is japanese corpus that includes wiki, wikibooks, wikiversity, cc100, and oscar2109.  

	
		
		Getting Started
	

If you want to use this, please run as follows.This process takes about 3 hours.  
mkdir -p pretrain/input/
cd pretrain/input/

GIT_LFS_SKIP_SMUDGE=1 git clone https://huggingface.co/datasets/ce-lery/merged-corpus.git
cd merged-corpus
git lfs pull 
bash merge_train.sh

",https://huggingface.co/datasets/ce-lery/merged-corpus,['ja'],['text-generation'],['10M<n<100M']
deokhk/filtered_mgsm_with_ids,deokhk,2025-09-15 07:51:33+00:00,2025-09-15 07:57:42+00:00,286,0,"['task_categories:question-answering', 'annotations_creators:no-annotation', 'language:en', 'language:bn', 'language:de', 'language:es', 'language:ja', 'language:sw', 'language:te', 'language:th', 'license:other', 'size_categories:1K<n<10K', 'format:parquet', 'modality:tabular', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","
	
		
		Filtered MGSM with IDs
	

This dataset is a filtered subset of [juletxara/mgsm] with an added integer id per language.
English questions overlapping with a PolyMath English set were removed, and the same ids were excluded from all languages to avoid cross-language overlaps.

Source: juletxara/mgsm (test split)
Filtering date: 2025-09-15
Splits: each language is exposed as a split (en, bn, de, es, ja, sw, te, th).


	
		
	
	
		Fields
	


id (int): per-language index assigned before… See the full description on the dataset page: https://huggingface.co/datasets/deokhk/filtered_mgsm_with_ids.",https://huggingface.co/datasets/deokhk/filtered_mgsm_with_ids,"['en', 'bn', 'de', 'es', 'ja', 'sw', 'te', 'th']",['question-answering'],['1K<n<10K']
Anyuhhh/2025-24679-text-dataset,Anyuhhh,2025-09-16 02:01:17+00:00,2025-09-16 02:36:39+00:00,107,0,"['task_categories:text-classification', 'language:en', 'language:zh', 'language:ja', 'license:mit', 'size_categories:1K<n<10K', 'format:parquet', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us', 'text-classification', 'multilingual', 'location-description', 'synthetic-data']",,https://huggingface.co/datasets/Anyuhhh/2025-24679-text-dataset,"['en', 'zh', 'ja']",['text-classification'],['1K<n<10K']
ce-lery/corpus-ja-11b,ce-lery,2025-09-16 06:06:28+00:00,2025-09-22 09:45:26+00:00,112,0,"['task_categories:text-generation', 'language:ja', 'size_categories:10M<n<100M', 'format:json', 'modality:text', 'library:datasets', 'library:dask', 'library:mlcroissant', 'region:us']","
	
		
		corpus-ja-11b
	

Welcome to this repository.This dataset is japanese corpus that includes wiki, wikibooks, wikiversity, and cc100.  

	
		
		Getting Started
	

If you want to use this, please run as follows.This process takes about 3 hours.  
mkdir -p pretrain/input/
cd pretrain/input/

GIT_LFS_SKIP_SMUDGE=1 git clone https://huggingface.co/datasets/ce-lery/corpus-ja-11b.git
cd corpus-ja-11b
git lfs pull 
bash merge_train.sh

",https://huggingface.co/datasets/ce-lery/corpus-ja-11b,['ja'],['text-generation'],['10M<n<100M']
lemonilia/monster-girl-encyclopedia-wiki,lemonilia,2025-09-17 11:32:30+00:00,2025-10-02 17:00:04+00:00,211,0,"['language:en', 'language:ja', 'license:cc-by-4.0', 'size_categories:n<1K', 'format:json', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","
Most of the text content from the English Monster Girl Encyclopedia Wiki entries of material authored by Kenkou Cross, manually markdownified over the course of a long time. This dataset might be updated in the future.

	
		
		Contents
	


	
		
		MGE original
	


Monster Girl Encyclopedia I
Monster Girl Encyclopedia II
Monster Girl Encyclopedia World Guide I: Fallen Maidens
Monster Girl Encyclopedia World Guide II: Mamono Realm Traveller's Guide
Monster Girl Encyclopedia World Guide III:… See the full description on the dataset page: https://huggingface.co/datasets/lemonilia/monster-girl-encyclopedia-wiki.",https://huggingface.co/datasets/lemonilia/monster-girl-encyclopedia-wiki,"['en', 'ja']",[],['n<1K']
oist/multimodal_nli_dataset,oist,2025-09-17 12:08:30+00:00,2025-09-24 13:36:58+00:00,239,0,"['task_categories:sentence-similarity', 'language:ar', 'language:fr', 'language:en', 'language:de', 'language:es', 'language:it', 'language:ja', 'language:ko', 'language:nl', 'language:pl', 'language:pt', 'language:ru', 'language:tr', 'language:zh', 'language:hi', 'license:cc-by-nc-4.0', 'size_categories:1M<n<10M', 'format:parquet', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'arxiv:2310.06825', 'arxiv:2205.12446', 'region:us']","

	
		
		Dataset Card for Multimodal and Multilingual NLI Dataset
	


	
		
		Dataset Details
	

Paper: Beyond Similarity Scoring: Detecting Entailment and Contradiction in Multilingual and Multimodal Contexts, Interspeech 2025

	
		
		Dataset Description
	

The Multimodal and Multilingual NLI Dataset supports multilingual and multimodal Natural Language Inference (NLI). It enables classification of entailment, contradiction, and neutrality across four modality combinations:

Text-Text (T-T)… See the full description on the dataset page: https://huggingface.co/datasets/oist/multimodal_nli_dataset.",https://huggingface.co/datasets/oist/multimodal_nli_dataset,"['ar', 'fr', 'en', 'de', 'es', 'it', 'ja', 'ko', 'nl', 'pl', 'pt', 'ru', 'tr', 'zh', 'hi']",['sentence-similarity'],['1M<n<10M']
kogi-jwu/sakuraeval,kogi-jwu,2025-09-20 13:13:27+00:00,2025-09-21 01:30:51+00:00,106,0,"['task_categories:text-generation', 'language:ja', 'language:en', 'license:mit', 'size_categories:n<1K', 'format:parquet', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us', 'code']","
	
		
		SakuraEval
	


	
		
		Dataset Description
	

SakuraEval is a Japan-specific code generation benchmark dataset. 
It is designed independently and does not rely on translation from English benchmarks such as HumanEval or JHumanEval.

	
		
		Dataset Structure
	

from datasets import load_dataset
load_dataset(""kogi-jwu/sakuraeval"", ""ja"")
DatasetDict({
    test: Dataset({
        features: ['task_id', 'category', 'prompt', 'canonical_solution', 'test', 'entry_point'],
        num_rows: 164… See the full description on the dataset page: https://huggingface.co/datasets/kogi-jwu/sakuraeval.",https://huggingface.co/datasets/kogi-jwu/sakuraeval,"['ja', 'en']",['text-generation'],['n<1K']
malaysia-ai/Emilia-YODAS-Voice-Conversion,malaysia-ai,2025-09-20 16:58:43+00:00,2025-10-01 13:23:47+00:00,348,1,"['language:de', 'language:en', 'language:fr', 'language:ja', 'language:ko', 'language:zh', 'language:ms', 'size_categories:10M<n<100M', 'format:parquet', 'modality:text', 'library:datasets', 'library:dask', 'library:mlcroissant', 'library:polars', 'region:us']","
	
		
		Emilia-YODAS-Voice-Conversion
	

We sample https://huggingface.co/datasets/amphion/Emilia-Dataset YODAS set for voice conversion.

Filter transcriptions based on character repetitiveness and word ngrams.
Filter speaker similarity using https://huggingface.co/nvidia/speakerverification_en_titanet_large during speaker permutation.
Convert audio to speech tokens using https://huggingface.co/neuphonic/neucodec

We also upload the full permutation as zip files.

	
	
	
		Speech Tokenizer… See the full description on the dataset page: https://huggingface.co/datasets/malaysia-ai/Emilia-YODAS-Voice-Conversion.",https://huggingface.co/datasets/malaysia-ai/Emilia-YODAS-Voice-Conversion,"['de', 'en', 'fr', 'ja', 'ko', 'zh', 'ms']",[],['10M<n<100M']
malaysia-ai/Japanese-Single-Speaker-TTS,malaysia-ai,2025-09-22 02:14:50+00:00,2025-09-26 03:24:00+00:00,109,0,"['language:ja', 'size_categories:10K<n<100K', 'format:parquet', 'modality:audio', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","
	
		
		Japanese-Single-Speaker-TTS
	

Originally from https://www.kaggle.com/datasets/bryanpark/japanese-single-speaker-speech-dataset, we mirror to HuggingFace.

	
		
		how to prepare the dataset
	

hf download malaysia-ai/Japanese-Single-Speaker-TTS jss_audio.zip --local-dir=./ --repo-type=dataset
unzip jss_audio.zip

",https://huggingface.co/datasets/malaysia-ai/Japanese-Single-Speaker-TTS,['ja'],[],['10K<n<100K']
singletongue/wikipedia-paragraphs,singletongue,2025-09-22 08:10:14+00:00,2025-09-23 01:13:55+00:00,690,0,"['language:ar', 'language:de', 'language:en', 'language:es', 'language:fr', 'language:it', 'language:ja', 'language:ko', 'language:pt', 'language:ru', 'language:zh', 'license:cc-by-sa-4.0', 'license:gfdl', 'size_categories:10M<n<100M', 'format:parquet', 'modality:tabular', 'modality:text', 'library:datasets', 'library:dask', 'library:mlcroissant', 'library:polars', 'region:us']","
	
		
		wikipedia-paragraphs
	

wikipedia-paragraphs is a dataset generated from Wikipedia, designed for natural language processing (NLP) research.
Each entry contains cleaned paragraph text and Wikilink information extracted from a Wikipedia page, along with useful metadata such as categories, templates, and the associated Wikidata QID.

	
		
		Dataset structure
	


	
		
		Configurations
	

The dataset is organized into multiple configurations, such as enwiki-20250901.
Each configuration… See the full description on the dataset page: https://huggingface.co/datasets/singletongue/wikipedia-paragraphs.",https://huggingface.co/datasets/singletongue/wikipedia-paragraphs,"['ar', 'de', 'en', 'es', 'fr', 'it', 'ja', 'ko', 'pt', 'ru', 'zh']",[],['10M<n<100M']
manuelcaccone/actuarial-global-glossary-multilingual,manuelcaccone,2025-09-22 08:29:22+00:00,2025-09-24 16:46:18+00:00,258,0,"['task_categories:text-classification', 'task_categories:translation', 'task_categories:text-generation', 'task_categories:question-answering', 'task_ids:multi-class-classification', 'task_ids:language-modeling', 'task_ids:text2text-generation', 'task_ids:closed-domain-qa', 'multilinguality:multilingual', 'source_datasets:original', 'language:en', 'language:it', 'language:fr', 'language:de', 'language:es', 'language:pt', 'language:zh', 'language:ja', 'license:cc-by-4.0', 'size_categories:1K<n<10K', 'format:parquet', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us', 'actuarial-science', 'insurance', 'finance', 'terminology', 'multilingual', 'glossary', 'professional-education', 'domain-specific', 'financial-services', 'risk-management']","
  



  


	
		
		🤝 Connect with me on LinkedIn!
	

  
  Join the mission to make actuarial knowledge accessible worldwide
  Let's discuss how AI can transform professional education and break language barriers in finance!




	
		
	
	
		🌍 Global Actuarial Glossary - Breaking Language Barriers in Finance
	






	
		
		🚀 The World's Most Comprehensive Multilingual Actuarial Dataset
	

Imagine: A brilliant actuarial student in Tokyo, a risk analyst in São Paulo, and an insurance executive… See the full description on the dataset page: https://huggingface.co/datasets/manuelcaccone/actuarial-global-glossary-multilingual.",https://huggingface.co/datasets/manuelcaccone/actuarial-global-glossary-multilingual,"['en', 'it', 'fr', 'de', 'es', 'pt', 'zh', 'ja']","['text-classification', 'translation', 'text-generation', 'question-answering']",['1K<n<10K']
softjapan/jaquad-sft,softjapan,2025-09-24 04:47:07+00:00,2025-09-24 14:32:53+00:00,96,0,"['task_categories:question-answering', 'task_categories:text-generation', 'language:ja', 'license:mit', 'size_categories:10K<n<100K', 'format:json', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us', 'japanese', 'question-answering', 'sft', 'instruction-tuning']","
	
		
		softjapan/jaquad-sft
	


	
		
		データセットの概要
	

このデータセットは、JaQuAD（Japanese Question Answering Dataset）をSFT（Supervised Fine-Tuning）形式に変換したものです。日本語の質問応答タスクに特化したinstruction tuning用のデータセットです。

	
		
		データセットの詳細
	


言語: 日本語
タスク: 質問応答、instruction tuning
形式: SFT（instruction/input/output）
訓練データ: 31,748件
検証データ: 3,939件
合計: 35,687件


	
		
		データ形式
	

各サンプルは以下の形式で構成されています：
{
  ""id"": ""tr-000-00-000"",
  ""instruction"": ""次の文脈に基づいて質問に答えてください。可能なら短く正確に答えてください。"",
  ""input"":… See the full description on the dataset page: https://huggingface.co/datasets/softjapan/jaquad-sft.",https://huggingface.co/datasets/softjapan/jaquad-sft,['ja'],"['question-answering', 'text-generation']",['10K<n<100K']
Antix5/Product_Similarity_Dataset,Antix5,2025-09-24 19:57:32+00:00,2025-09-24 20:11:58+00:00,106,0,"['task_categories:text-ranking', 'task_categories:feature-extraction', 'language:fr', 'language:de', 'language:zh', 'language:ru', 'language:pl', 'language:es', 'language:it', 'language:ja', 'language:ar', 'language:hi', 'language:pt', 'language:nl', 'license:apache-2.0', 'size_categories:10K<n<100K', 'format:json', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us', 'commerce', 'food', 'commodity', 'LambdaLoss', 'ListNetLoss']","This following dataset is a rich dataset of product similarity. The dataset has been design to be challenging to train on by having quite a lot of hard negatives
This dataset is especially targeted toward fine-tuning usecase, especially to finetune reranker or embedding model.
The data are especially adapted for listwise loss like LambdaLoss or ListNetLoss.
The data are in JSONL and each line follow the same format as here below : 

A ""query"", the anchor product label
""docs"", the potential… See the full description on the dataset page: https://huggingface.co/datasets/Antix5/Product_Similarity_Dataset.",https://huggingface.co/datasets/Antix5/Product_Similarity_Dataset,"['fr', 'de', 'zh', 'ru', 'pl', 'es', 'it', 'ja', 'ar', 'hi', 'pt', 'nl']","['text-ranking', 'feature-extraction']",['10K<n<100K']
NetherQuartz/lipu-sewi,NetherQuartz,2025-09-24 22:26:49+00:00,2025-09-25 00:33:01+00:00,101,0,"['task_categories:translation', 'task_categories:sentence-similarity', 'language:tok', 'language:en', 'language:ru', 'language:uk', 'language:be', 'language:fr', 'language:es', 'language:pt', 'language:it', 'language:de', 'language:vi', 'language:ja', 'language:zh', 'language:ko', 'language:ar', 'language:he', 'language:pl', 'language:tr', 'language:la', 'language:el', 'size_categories:1K<n<10K', 'format:parquet', 'modality:tabular', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us', 'tokipona', 'toki pona', 'bible', 'multilingual']",,https://huggingface.co/datasets/NetherQuartz/lipu-sewi,"['tok', 'en', 'ru', 'uk', 'be', 'fr', 'es', 'pt', 'it', 'de', 'vi', 'ja', 'zh', 'ko', 'ar', 'he', 'pl', 'tr', 'la', 'el']","['translation', 'sentence-similarity']",['1K<n<10K']
patrickamadeus/pawsx_mt_triplet,patrickamadeus,2025-09-25 20:06:09+00:00,2025-09-25 20:08:49+00:00,120,0,"['task_categories:text-classification', 'task_categories:translation', 'language:de', 'language:es', 'language:fr', 'language:ja', 'language:ko', 'language:zh', 'license:mit', 'size_categories:100K<n<1M', 'region:us', 'paws-x', 'multilingual', 'paraphrase-detection', 'text-similarity', 'machine-translation']","
	
		
		PAWS-X Multilingual Triplet Dataset
	

This dataset contains PAWS-X (Paraphrase Adversaries from Word Scrambling) data organized by translation models for paraphrase detection and text similarity tasks.

	
		
		Dataset Structure
	

Each sample contains the following fields:

id: Unique identifier for the text pair
text1: First sentence (originally sentence1)
text2: Second sentence (originally sentence2)  
label: Binary label (1 for paraphrase, 0 for non-paraphrase)
model: Translation… See the full description on the dataset page: https://huggingface.co/datasets/patrickamadeus/pawsx_mt_triplet.",https://huggingface.co/datasets/patrickamadeus/pawsx_mt_triplet,"['de', 'es', 'fr', 'ja', 'ko', 'zh']","['text-classification', 'translation']",['100K<n<1M']
samuraijun/shitto-mania-dic,samuraijun,2025-09-27 23:53:15+00:00,2025-09-29 05:29:09+00:00,60,0,"['task_categories:text-generation', 'task_categories:fill-mask', 'language:ja', 'size_categories:n<1K', 'format:csv', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","
	
		
		Shitto-Mania-Dic / 嫉妬辞書
	

Author cooperation (not supervision): This dataset was created with the cooperation of essayist Nami Saito (material provision and comments). Final analysis/design/publication decisions are the responsibility of Jun Ikematsu.

	
		
		Dataset Description
	

The Shitto-Mania-Dic (Jealousy Dictionary) is a high-quality Japanese single-language dataset focused on the emotion of ""jealousy."" It was extracted from the Shitto-Mania essay series by Nami Saitō… See the full description on the dataset page: https://huggingface.co/datasets/samuraijun/shitto-mania-dic.",https://huggingface.co/datasets/samuraijun/shitto-mania-dic,['ja'],"['text-generation', 'fill-mask']",['n<1K']
Nexdata/Japanese_QA_Dataset_from_OKWAVE_8.4M_Questions,Nexdata,2025-09-28 07:21:06+00:00,2025-09-28 07:22:48+00:00,36,0,"['language:ja', 'license:cc-by-nc-nd-4.0', 'region:us']","
	
		
		Description
	

Japanese OKWAVE Q&A platform Text Parsing and Processing Data, Contains question, answer, category, create_datetime, user, etc, The data is continuously updated. As of the end of April 25, there were 8.4 million questions and 2.3 billion words. 27 million answers and 7.6 billion words; Thanks (the gratitude expressed by the questioner to the responder) 15.5 million pieces, 1.7 billion words; Supplementary explanations amount to 2.1 million pieces, totaling 360 million… See the full description on the dataset page: https://huggingface.co/datasets/Nexdata/Japanese_QA_Dataset_from_OKWAVE_8.4M_Questions.",https://huggingface.co/datasets/Nexdata/Japanese_QA_Dataset_from_OKWAVE_8.4M_Questions,['ja'],[],[]
CohereLabs/fusion-pairwise-evals-finetuned,CohereLabs,2025-09-30 10:25:24+00:00,2025-10-02 05:38:25+00:00,18,0,"['task_categories:text-generation', 'language:en', 'language:fr', 'language:de', 'language:es', 'language:ru', 'language:it', 'language:pt', 'language:ja', 'language:ko', 'language:zh', 'language:ar', 'license:cc-by-nc-sa-4.0', 'size_categories:1K<n<10K', 'format:json', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'arxiv:2510.00931', 'region:us', 'multilingual', 'evaluation']","
	
		
		Automatic pairwise preference evaluations for: Making, not taking, the Best-of-N
	


	
		
		Content
	

This data contains pairwise automatic win-rate evaluations for the m-ArenaHard-v2.0 benchmark and it compares 2 models against gemini-2.5-flash:

Fusion: is the 111B model finetuned on synthetic data generated with Fusion from 5 teachers
BoN: is the 111B model finetuned on synthetic data generated with BoN from 5 teachers

Each model’s outputs are compared in pairs with the respective… See the full description on the dataset page: https://huggingface.co/datasets/CohereLabs/fusion-pairwise-evals-finetuned.",https://huggingface.co/datasets/CohereLabs/fusion-pairwise-evals-finetuned,"['en', 'fr', 'de', 'es', 'ru', 'it', 'pt', 'ja', 'ko', 'zh', 'ar']",['text-generation'],['1K<n<10K']
CohereLabs/fusion-synth-data-geofactx,CohereLabs,2025-09-30 11:07:23+00:00,2025-10-02 05:40:04+00:00,26,1,"['task_categories:text-generation', 'task_categories:question-answering', 'language:en', 'language:hi', 'language:ja', 'language:th', 'language:sw', 'license:mit', 'size_categories:1K<n<10K', 'format:json', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'arxiv:2510.00931', 'region:us', 'multilingual', 'synthetic']","
	
		
		Offline Synthetic Data (GeoFactX) for: Making, not taking, the Best-of-N
	


	
		
		Content
	

This data contains completions for the  GeoFactX training split prompts from 5 different teacher models and 2 aggregations:
Teachers: We sample one completion from each of the following models at temperature T=0.3. For kimik2, qwen3, and deepseek-v3 we use TogetherAI, for gemma3-27b and command-a we use locally hosted images.

gemma3-27b: GEMMA3-27B-IT
kimik2: KIMI-K2-INSTRUCT
qwen3:… See the full description on the dataset page: https://huggingface.co/datasets/CohereLabs/fusion-synth-data-geofactx.",https://huggingface.co/datasets/CohereLabs/fusion-synth-data-geofactx,"['en', 'hi', 'ja', 'th', 'sw']","['text-generation', 'question-answering']",['1K<n<10K']
CohereLabs/fusion-synth-data-ufb,CohereLabs,2025-09-30 11:26:37+00:00,2025-10-02 05:32:31+00:00,25,0,"['task_categories:text-generation', 'language:en', 'language:fr', 'language:de', 'language:es', 'language:it', 'language:pt', 'language:ja', 'language:ko', 'language:zh', 'language:ar', 'license:mit', 'size_categories:10K<n<100K', 'format:json', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'arxiv:2510.00931', 'region:us', 'multilingual', 'synthetic']","
	
		
		Offline Synthetic Data (UFB) for: Making, not taking, the Best-of-N
	


	
		
		Content
	

This data contains completions for a 10,000 subset of the  UFB prompts (translated into 9 languages)  from 5 different teacher models and 2 aggregations:
Teachers: We sample one completion from each of the following models at temperature T=0.3. For kimik2, qwen3, and deepseek-v3 we use TogetherAI, for gemma3-27b and command-a we use locally hosted images.

gemma3-27b: GEMMA3-27B-IT
kimik2:… See the full description on the dataset page: https://huggingface.co/datasets/CohereLabs/fusion-synth-data-ufb.",https://huggingface.co/datasets/CohereLabs/fusion-synth-data-ufb,"['en', 'fr', 'de', 'es', 'it', 'pt', 'ja', 'ko', 'zh', 'ar']",['text-generation'],['10K<n<100K']
CohereLabs/fusion-pairwise-evals-test-time-scaling,CohereLabs,2025-09-30 11:44:06+00:00,2025-10-02 05:38:56+00:00,20,0,"['task_categories:text-generation', 'language:en', 'language:fr', 'language:de', 'language:es', 'language:ru', 'language:it', 'language:pt', 'language:ja', 'language:ko', 'language:zh', 'language:ar', 'license:cc-by-nc-sa-4.0', 'size_categories:1K<n<10K', 'format:json', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'arxiv:2510.00931', 'region:us', 'multilingual', 'evaluation']","
	
		
		Automatic pairwise preference evaluations for: Making, not taking, the Best-of-N
	


	
		
		Content
	

This data contains pairwise automatic win-rate evaluations for the m-ArenaHard-v2.0 benchmark and it compares CommandA against gemini-2.5-pro in 2 settings:

Test-time scaling with Fusion : 5 samples are generated from CommandA, then fused with CommandA into one completion and compared to a single completion from gemini-2.5-pro
Test-time scaling with BoN : 5 samples are generated from… See the full description on the dataset page: https://huggingface.co/datasets/CohereLabs/fusion-pairwise-evals-test-time-scaling.",https://huggingface.co/datasets/CohereLabs/fusion-pairwise-evals-test-time-scaling,"['en', 'fr', 'de', 'es', 'ru', 'it', 'pt', 'ja', 'ko', 'zh', 'ar']",['text-generation'],['1K<n<10K']
CohereLabs/fusion-synth-data-s1kx,CohereLabs,2025-09-30 11:55:31+00:00,2025-10-02 05:39:38+00:00,26,0,"['task_categories:text-generation', 'task_categories:question-answering', 'language:en', 'language:de', 'language:es', 'language:fr', 'language:ja', 'language:bn', 'language:ru', 'language:sw', 'language:te', 'language:th', 'language:zh', 'license:mit', 'size_categories:10K<n<100K', 'format:json', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'arxiv:2510.00931', 'region:us', 'multilingual', 'synthetic']","
	
		
		Offline Synthetic Data (s1K-X) for: Making, not taking, the Best-of-N
	


	
		
		Content
	

This data contains completions for the  s1K-X training split prompts from 5 different teacher models and 2 aggregations:
Teachers: We sample one completion from each of the following models at temperature T=0.3. For kimik2, qwen3, and deepseek-v3 we use TogetherAI, for gemma3-27b and command-a we use locally hosted images.

gemma3-27b: GEMMA3-27B-IT
kimik2: KIMI-K2-INSTRUCT
qwen3: QWEN3-235B… See the full description on the dataset page: https://huggingface.co/datasets/CohereLabs/fusion-synth-data-s1kx.",https://huggingface.co/datasets/CohereLabs/fusion-synth-data-s1kx,"['en', 'de', 'es', 'fr', 'ja', 'bn', 'ru', 'sw', 'te', 'th', 'zh']","['text-generation', 'question-answering']",['10K<n<100K']
pykeio/oshichats-v3,pykeio,2025-09-30 18:43:13+00:00,2025-10-01 02:36:33+00:00,1348,1,"['language:en', 'language:ja', 'language:id', 'language:zh', 'language:ko', 'language:tl', 'language:es', 'language:ru', 'language:fr', 'language:de', 'license:bigscience-openrail-m', 'size_categories:100M<n<1B', 'region:us']","
	
		
		OshiChats v3
	

Anonymized chat messages scraped from VTuber livestreams.
",https://huggingface.co/datasets/pykeio/oshichats-v3,"['en', 'ja', 'id', 'zh', 'ko', 'tl', 'es', 'ru', 'fr', 'de']",[],['100M<n<1B']
ronantakizawa/japanese-character-difficulty,ronantakizawa,2025-09-30 21:29:18+00:00,2025-09-30 21:39:41+00:00,26,1,"['task_categories:text-classification', 'language:ja', 'license:mit', 'size_categories:1K<n<10K', 'format:csv', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us', 'japanese', 'kanji', 'educational-grades', 'jlpt', 'joyo', 'character-classification']","
	
		
		Japanese Character Difficulty Dataset
	

A comprehensive dataset of 3,003 Japanese kanji characters with their educational difficulty grades, sourced from official Japanese educational standards and kanjiapi.dev.

	
		
		Dataset Overview
	


Total Characters: 3,003 kanji
Source: Japanese Ministry of Education (MEXT) Joyo Kanji list + kanjiapi.dev
Coverage: Elementary grades 1-6, plus secondary education and advanced characters
Format: Character-grade pairs for easy lookup and analysis… See the full description on the dataset page: https://huggingface.co/datasets/ronantakizawa/japanese-character-difficulty.",https://huggingface.co/datasets/ronantakizawa/japanese-character-difficulty,['ja'],['text-classification'],['1K<n<10K']
ronantakizawa/aozora-text-difficulty,ronantakizawa,2025-09-30 21:45:43+00:00,2025-10-01 19:54:17+00:00,67,1,"['task_categories:text-classification', 'language:ja', 'license:mit', 'size_categories:1K<n<10K', 'format:parquet', 'modality:tabular', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us', 'japanese', 'text-difficulty', 'language-learning', 'linguistics', 'aozora-bunko', 'educational', 'curriculum-design']","
	
		
		Aozora Text Difficulty Dataset
	

This dataset contains Japanese literary texts from the Aozora Bunko digital library, enhanced with jReadability-based difficulty analysis for Japanese language learning and curriculum development.

	
		
		Dataset Overview
	


Source: Aozora Bunko (青空文庫) - Japan's premier digital library of public domain literature
Enhancement: jReadability-based difficulty scoring using research-backed Japanese readability models
Primary Methodology: jReadability - A… See the full description on the dataset page: https://huggingface.co/datasets/ronantakizawa/aozora-text-difficulty.",https://huggingface.co/datasets/ronantakizawa/aozora-text-difficulty,['ja'],['text-classification'],['1K<n<10K']
llm-jp/jhle,llm-jp,2025-10-02 00:54:13+00:00,2025-10-06 09:19:42+00:00,9,0,"['language:ja', 'license:mit', 'size_categories:n<1K', 'format:parquet', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","
[!NOTE]
IMPORTANT: Please help us protect the integrity of this benchmark by not publicly sharing, re-uploading, or distributing the dataset.


	
		
		Japanese Humanity's Last Exam (JHLE)
	

This repository provides the Humanity's Last Exam dataset translated into Japanese by LLM-jp, a collaborative project in Japan.
Questions requiring images were excluded, and five questions per raw_subject were randomly sampled.
The dataset was machine-translated and then reviewed and corrected by external… See the full description on the dataset page: https://huggingface.co/datasets/llm-jp/jhle.",https://huggingface.co/datasets/llm-jp/jhle,['ja'],[],['n<1K']
DeL-TaiseiOzaki/Tengentoppa-sft-v4.0,DeL-TaiseiOzaki,2025-10-03 11:18:53+00:00,2025-10-04 01:28:32+00:00,23,0,"['task_categories:question-answering', 'language:ja', 'license:cc-by-4.0', 'size_categories:100K<n<1M', 'format:parquet', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us', 'instruction-following', 'japanese', 'sft', 'supervised-finetuning']","
	
		
		Tengentoppa Corpus for SFT (統合日本語Instructionデータセット)
	


	
		
		📊 データセット概要
	

このデータセットは、17個の日本語instruction-followingデータセットを統合した大規模な教師あり学習(SFT)用データセットです。多様なタスクや対話形式を含む213,265件のインストラクション-レスポンスペアで構成されています。

	
		
		主な特徴
	


総サンプル数: 213,265件
データサイズ: 約438MB (圧縮前)
言語: 日本語
ライセンス: CC-BY-4.0
タスク: Question Answering, Instruction Following


	
		
		📋 データ形式
	

各データポイントは以下の構造を持ちます：
{
  ""instruction"": ""指示または質問文"",
  ""output"": ""応答または回答文""
}


	
		
	
	
		フィールド説明
	


	
		
フィールド
型
説明


		
instruction… See the full description on the dataset page: https://huggingface.co/datasets/DeL-TaiseiOzaki/Tengentoppa-sft-v4.0.",https://huggingface.co/datasets/DeL-TaiseiOzaki/Tengentoppa-sft-v4.0,['ja'],['question-answering'],['100K<n<1M']
joujiboi/bluemoon-fandom-1-1-rp-jp-translated-v2,joujiboi,2025-10-03 13:28:44+00:00,2025-10-03 13:45:54+00:00,22,0,"['task_categories:text-generation', 'language:ja', 'license:apache-2.0', 'size_categories:n<1K', 'format:parquet', 'modality:tabular', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us', 'roleplay', 'storywriting']","Reattempt at what I did with bluemoon-fandom-1-1-rp-jp-translated v1.

This dataset has 538 conversations and 9606 messages, making this dataset about 15% bigger.
I used deepseek-v3.2-exp to translation this time.

",https://huggingface.co/datasets/joujiboi/bluemoon-fandom-1-1-rp-jp-translated-v2,['ja'],['text-generation'],['n<1K']
lemonilia/monster-girl-encyclopedia-stories,lemonilia,2025-10-03 14:01:02+00:00,2025-10-07 09:22:42+00:00,157,1,"['language:ja', 'license:cc-by-4.0', 'size_categories:10K<n<100K', 'format:parquet', 'modality:tabular', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","
All user-submitted Monster Girl Encyclopedia (魔物娘図鑑) fanfictions/short stories from kurobinega as of October 2025, or roughly 19000 documents. Japanese-only content for now. It can be safely assumed that all stories on the source website have been approved by KC as being in line with the basic principles behind the MGE universe.
The stories are roughly sorted by date, with consecutive story chapters naturally ordered one after the other. User comments and author commentaries have been… See the full description on the dataset page: https://huggingface.co/datasets/lemonilia/monster-girl-encyclopedia-stories.",https://huggingface.co/datasets/lemonilia/monster-girl-encyclopedia-stories,['ja'],[],['10K<n<100K']
marcelone/language_learning_multilingual_public,marcelone,2025-10-06 00:27:03+00:00,2025-10-12 07:25:04+00:00,97,0,"['task_categories:question-answering', 'language:en', 'language:ja', 'language:pt', 'language:ru', 'language:it', 'language:es', 'license:cc-by-4.0', 'size_categories:10K<n<100K', 'format:json', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","Sources: Wikipedia, Wiktionary, Project Gutenberg, and synthetic data.
Project Gutenberg texts:

Verdadeiro método de estudar (Vol. I) by Luís António Verney (Portuguese)
Tradiciones peruanas by Ricardo Palma (Spanish)
La vita in Palermo cento e più anni fa, Vol. 1 by Giuseppe Pitrè (Italian)
England, Picturesque and Descriptive: A Reminiscence of Foreign Travel by Joel Cook (English)

Synthetic data generation: Models such as Gemma-3-4B-IT, Gemma-3-12B-IT, GLM-4-9B-0414… See the full description on the dataset page: https://huggingface.co/datasets/marcelone/language_learning_multilingual_public.",https://huggingface.co/datasets/marcelone/language_learning_multilingual_public,"['en', 'ja', 'pt', 'ru', 'it', 'es']",['question-answering'],['10K<n<100K']
climate-nlp/multimodal-oil-gas-benchmark,climate-nlp,2025-10-06 20:58:44+00:00,2025-10-07 03:56:19+00:00,24,0,"['task_categories:video-classification', 'language:en', 'language:ja', 'license:cc-by-nc-4.0', 'size_categories:n<1K', 'modality:video', 'region:us', 'multimodal', 'greenwashing', 'climate', 'environment', 'video', 'advertisement', 'llm']","
	
		
		Dataset Card for Dataset Name
	

This is a dataset to reproduce our work, ""A Multimodal Benchmark for Framing of Oil & Gas Advertising and Potential Greenwashing Detection"", accepted to NeurIPS 2025 Benchmarks and Datasets Track.

	
		
		Dataset Details
	


	
		
		Dataset Sources [optional]
	




Repository: https://github.com/climate-nlp/multimodal-oil-gas-benchmark
Paper: A Multimodal Benchmark for Framing of Oil & Gas Advertising and Potential Greenwashing Detection (NeurIPS 2025)… See the full description on the dataset page: https://huggingface.co/datasets/climate-nlp/multimodal-oil-gas-benchmark.",https://huggingface.co/datasets/climate-nlp/multimodal-oil-gas-benchmark,"['en', 'ja']",['video-classification'],['n<1K']
hotchpotch/lawqa_jp,hotchpotch,2025-10-10 03:36:10+00:00,2025-10-10 03:47:06+00:00,20,0,"['language:ja', 'license:other', 'size_categories:1K<n<10K', 'format:parquet', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","
	
		
		日本の法令に関する多肢選択式QAデータセット
	

本データセットは、https://github.com/digital-go-jp/lawqa_jp/ を huggingface datasets 形式に変換し、datasets ライブラリから扱いやすくしたものです。

	
		
		🔗 参考情報
	


元データレポジトリ: https://github.com/digital-go-jp/lawqa_jp/
公開資料:
政府等が保有するデータのAI学習データへの変換に係る調査研究
言語処理学会第31回年次大会 (NLP2025) 発表資料




	
		
		📦 データ構成
	

リポジトリには4つのコンフィグを用意しています。load_dataset(""hotchpotch/lawqa_jp"", ""<config>"") で取得してください。

	
		
Config
内容
件数
主なフィールド


		
default
selection.json を基に、選択肢・正解・参照URLを配列やラベル付き辞書へ正規化した扱いやすいコアセット
140… See the full description on the dataset page: https://huggingface.co/datasets/hotchpotch/lawqa_jp.",https://huggingface.co/datasets/hotchpotch/lawqa_jp,['ja'],[],['1K<n<10K']
Anna4242/arena-hard-v2-verifiers,Anna4242,2025-10-11 17:33:06+00:00,2025-10-11 17:37:41+00:00,7,0,"['task_categories:text-generation', 'task_categories:question-answering', 'language:en', 'language:es', 'language:fr', 'language:de', 'language:it', 'language:pt', 'language:zh', 'language:ja', 'language:ko', 'license:apache-2.0', 'size_categories:n<1K', 'arxiv:2406.11939', 'region:us', 'arena-hard', 'llm-evaluation', 'verifiers', 'deepseek-r1', 'gpt-4.1']","
	
		
		Arena-Hard v2.0 - Verifiers Format
	

This dataset contains Arena-Hard v2.0 in Verifiers-compatible format for LLM evaluation.

	
		
		📊 Dataset Information
	


Version: Arena-Hard v2.0
Examples: 750
Model Answers: deepseek-r1
Judge: gpt-4.1
Format: Verifiers-compatible HuggingFace Dataset
License: Apache 2.0


	
		
		🎯 Categories
	


Hard Prompts (500 examples): Challenging coding, math, and reasoning tasks
Coding: 253 examples
Math: 247 examples


Creative Writing (250 examples):… See the full description on the dataset page: https://huggingface.co/datasets/Anna4242/arena-hard-v2-verifiers.",https://huggingface.co/datasets/Anna4242/arena-hard-v2-verifiers,"['en', 'es', 'fr', 'de', 'it', 'pt', 'zh', 'ja', 'ko']","['text-generation', 'question-answering']",['n<1K']
huytd189/japanese-grammar-correction,huytd189,2025-10-11 21:55:29+00:00,2025-10-11 22:15:42+00:00,8,0,"['task_categories:text-generation', 'language:ja', 'language:en', 'license:bsd-3-clause-clear', 'size_categories:1K<n<10K', 'format:csv', 'modality:text', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'region:us']","
	
		
		Japanese Grammar Correction Dataset
	


	
		
		Description
	

This dataset is designed to train language models to identify and correct a wide range of grammatical errors and stylistic issues in Japanese text. 
The data consists of pairs of incorrect and correct sentences, along with metadata that classifies the type of error and provides additional context.
The dataset was created by both manual curation from discussions in Japanese learning communities and synthetically generated… See the full description on the dataset page: https://huggingface.co/datasets/huytd189/japanese-grammar-correction.",https://huggingface.co/datasets/huytd189/japanese-grammar-correction,"['ja', 'en']",['text-generation'],['1K<n<10K']
